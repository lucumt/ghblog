[{"categories":["个人博客"],"contents":"简要介绍在如何在Hugo博客中基于Even主题开启flowchart、sequence和mermaid图表的支持。\n背景 个人Hugo博客切换为Even已经有好几年了，相关功能也是基于此主题扩展而来，不过Even主题的作者已经很久没有此主题,GitHub上大量的issue都由于过期而自动关闭1，同时个人发现该主题下layouts/partials/scripts.html对于flowchart和sequence的实现并不完善，缺少对应的初始化代码，基于此我决定在该主题的基础上自己实现相关功能！\nPS: Even主题2很受欢迎，希望作者早日恢复维护!\n修改说明 由于Hugo支持代码高亮，当图表相关的数据当采用Markdown的codeblock方式写入时，如下图所示默认情况下，其会以代码高亮的方式显示，很明显此种方式不满足要求。\n从上图可知经过高亮处理后的图表代码已经与html标签混杂在一起，为了能正常展示图表数据，必须要有一种方式能够准确的获取原始的图表代码，此时需要借助Hugo的Render Hooks功能，其主要功能是让我们通过自定义的模板来覆盖Hugo默认的功能实现。如下图所示经过Markup处理后的，会将原始的代码文件基于对应codeblock文件中的代码来展示，在对应的html中包含我们原始的代码块文件，采用JavaScript或jQuery都能快速的获取到对应代码，之后调用对应图表JavaScript库来进行渲染或初始化即可。\n根据Hugo官方Render Hooks上的说明，需要在layouts/_default/_markup文件夹下建立对应的html文件，其命名规则为render-xxx-[yyy].html,其中xxx为一级类别，yyy为二级类别(可选的)，如要重写所有的代码展示可创建文件render-codeblock.html，要重写所有的图片展示可创建文件render-image.html,要重写所有的mermaid代码展示则需要添加上二级分类render-codeblock-mermiad.html。\n1 2 3 4 5 6 7 8 9 layouts/ └── _default/ └── _markup/ ├── render-codeblock-bash.html ├── render-codeblock.html ├── render-heading.html ├── render-image.html ├── render-image.rss.xml └── render-link.html 注意\n当我们最终修改完毕后，若页面上没有正常展示相关的图表且浏览器控制台出现如下错误，需要在layouts/partials/scripts.html或config.toml中重新修改相关报错文件的integrity值，或在static/lib下重新下载相关的文件，确保其校验值一致，即可消除错误。\nflowchart图表 修改过程 在layouts/_default/_markup创建文件render-codeblock-flow.html并添加如下代码\n1 2 3 \u0026lt;div id=\u0026#34;flow_{{ .Ordinal }}\u0026#34;\u0026gt; {{- .Inner | safeHTML }} \u0026lt;/div\u0026gt; 在layouts/partials/scripts.html补充原有的代码，添加上初始化功能\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \u0026lt;!-- flowchart --\u0026gt; {{- if and (or .Params.flowchartDiagrams.enable (and .Site.Params.flowchartDiagrams.enable (ne .Params.flowchartDiagrams.enable false))) (or .IsPage .IsHome) -}} {{- if .Site.Params.publicCDN.enable -}} {{ .Site.Params.publicCDN.flowchartDiagramsJS | safeHTML }} {{- else -}} \u0026lt;script src=\u0026#34;{{ \u0026#34;lib/flowchartDiagrams/raphael-2.2.7.min.js\u0026#34; | relURL }}\u0026#34; integrity=\u0026#34;sha256-67By+NpOtm9ka1R6xpUefeGOY8kWWHHRAKlvaTJ7ONI=\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;{{ \u0026#34;lib/flowchartDiagrams/flowchart-1.8.0.min.js\u0026#34; | relURL }}\u0026#34; integrity=\u0026#34;sha256-zNGWjubXoY6rb5MnmpBNefO0RgoVYfle9p0tvOQM+6k=\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; {{- end -}} \u0026lt;script\u0026gt; /*{{- if .Params.flowchartDiagrams.options -}} window.flowchartDiagramsOptions = {{ .Params.flowchartDiagrams.options | safeJS }}; {{- else if .Site.Params.flowchartDiagrams.options -}} window.flowchartDiagramsOptions = {{ .Site.Params.flowchartDiagrams.options | safeJS }}; {{- end -}}*/ \u0026lt;!-- below is newly added code --\u0026gt; let flowPageOptions = {{ .Page.Params.flowchartDiagrams.options }}; let flowSiteOptions = {{ .Site.Params.flowchartDiagrams.options }}; flowPageOptions = !!flowPageOptions ? flowPageOptions : \u0026#34;{}\u0026#34; flowSiteOptions = !!flowSiteOptions ? flowSiteOptions : \u0026#34;{}\u0026#34; flowPageOptions = eval(\u0026#34;(\u0026#34; + flowPageOptions + \u0026#34;)\u0026#34;) flowSiteOptions = eval(\u0026#34;(\u0026#34; + flowSiteOptions + \u0026#34;)\u0026#34;) // page options have high priority then site options let flowOptions = {...flowSiteOptions, ...flowPageOptions}; $(\u0026#34;[id^=flow_]\u0026#34;).flowChart(flowOptions); \u0026lt;/script\u0026gt; {{- end -}} 上述代码中通过let flowOptions = {...flowSiteOptions, ...flowPageOptions};来确保页面上的配置覆盖全局配置，优先级更高。\n在对应的markdown页面头部开启flowchart的展示，可根据实际情况添加自定义配置，保存对应markdown文件后页面会自动刷新并展示对应效果3。\n1 2 3 4 5 6 7 8 9 10 flowchartDiagrams: enable: true options: \u0026#34;{ \u0026#39;x\u0026#39;: 0, \u0026#39;y\u0026#39;: 0, \u0026#39;width\u0026#39;:1, \u0026#39;line-width\u0026#39;: 1, \u0026#39;line-length\u0026#39;: 50, \u0026#39;text-margin\u0026#39;: 10 }\u0026#34; 自定义样式 不同于sequence,flowchart的使用很灵活，其官网上虽然只有4个demo，但已经覆盖了大部分功能，本小节简要介绍如何根据实际情况自定义样式。\n展示效果 基于对应markdown页面的下述配置展示相关效果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 flowchartDiagrams: enable: true options: \u0026#34;{ \u0026#39;x\u0026#39;: 0, \u0026#39;y\u0026#39;: 0, \u0026#39;width\u0026#39;:1, \u0026#39;line-width\u0026#39;: 1, \u0026#39;line-length\u0026#39;: 50, \u0026#39;text-margin\u0026#39;: 10, \u0026#39;font-size\u0026#39;: 14, \u0026#39;font-color\u0026#39;: \u0026#39;black\u0026#39;, \u0026#39;line-color\u0026#39;: \u0026#39;black\u0026#39;, \u0026#39;element-color\u0026#39;: \u0026#39;black\u0026#39;, \u0026#39;fill\u0026#39;: \u0026#39;white\u0026#39;, \u0026#39;yes-text\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;no-text\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;arrow-end\u0026#39;: \u0026#39;block\u0026#39;, \u0026#39;scale\u0026#39;: 1, \u0026#39;symbols\u0026#39;: { \u0026#39;start\u0026#39;: { \u0026#39;font-color\u0026#39;: \u0026#39;red\u0026#39;, \u0026#39;element-color\u0026#39;: \u0026#39;green\u0026#39;, \u0026#39;fill\u0026#39;: \u0026#39;yellow\u0026#39; }, \u0026#39;end\u0026#39;: { \u0026#39;class\u0026#39;: \u0026#39;end-element\u0026#39;, \u0026#39;element-color\u0026#39;: \u0026#39;green\u0026#39; } }, \u0026#39;flowstate\u0026#39;: { \u0026#39;aaa\u0026#39;: {\u0026#39;fill\u0026#39;: \u0026#39;pink\u0026#39;}, \u0026#39;approved\u0026#39;: {\u0026#39;fill\u0026#39;: \u0026#39;peru\u0026#39;} } }\u0026#34; 图表1 原始代码\n1 2 3 4 5 6 7 8 9 10 11 ​```flow st=\u0026gt;start: 开始框 op=\u0026gt;operation: 处理框 cond=\u0026gt;condition: 判断框(是或否?) sub1=\u0026gt;subroutine: 子流程 io=\u0026gt;inputoutput: 输入输出框|approved e=\u0026gt;end: 结束框 st-\u0026gt;op-\u0026gt;cond cond(yes)-\u0026gt;io-\u0026gt;e cond(no)-\u0026gt;sub1(right)-\u0026gt;op ​``` 展示效果\nst=\u003estart: 开始框 op=\u003eoperation: 处理框 cond=\u003econdition: 判断框(是或否?) sub1=\u003esubroutine: 子流程 io=\u003einputoutput: 输入输出框|approved e=\u003eend: 结束框 st-\u003eop-\u003econd cond(yes)-\u003eio-\u003ee cond(no)-\u003esub1(right)-\u003eop 图表2 原始代码\n1 2 3 4 5 6 7 8 9 10 11 12 ​```flow st=\u0026gt;start: 开始节点 in=\u0026gt;inputoutput: 输入 e=\u0026gt;end: 结束节点 op=\u0026gt;operation: 操作节点 cond=\u0026gt;condition: 条件节点 sub=\u0026gt;subroutine: 子例程 out=\u0026gt;inputoutput: 输出 st(right)-\u0026gt;in-\u0026gt;op-\u0026gt;cond cond(yes,right)-\u0026gt;out-\u0026gt;e cond(no)-\u0026gt;sub ​``` 展示效果\nst=\u003estart: 开始节点 in=\u003einputoutput: 输入 e=\u003eend: 结束节点 op=\u003eoperation: 操作节点 cond=\u003econdition: 条件节点 sub=\u003esubroutine: 子例程 out=\u003einputoutput: 输出 st(right)-\u003ein-\u003eop-\u003econd cond(yes,right)-\u003eout-\u003ee cond(no)-\u003esub 图表3 原始代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ​```flow st=\u0026gt;start: Start|past:\u0026gt;http://www.google.com[blank] e=\u0026gt;end: End:\u0026gt;http://www.google.com op1=\u0026gt;operation: My Operation|past op2=\u0026gt;operation: Stuff|aaa sub1=\u0026gt;subroutine: My Subroutine|invalid cond=\u0026gt;condition: Yes or No?|approved:\u0026gt;http://www.google.com c2=\u0026gt;condition: Good idea|rejected io=\u0026gt;inputoutput: catch something...|aaa st-\u0026gt;op1(right)-\u0026gt;cond cond(yes, right)-\u0026gt;c2 cond(no)-\u0026gt;sub1(left)-\u0026gt;op1 c2(yes)-\u0026gt;io-\u0026gt;e c2(no)-\u0026gt;op2-\u0026gt;e ​``` 展示效果\nst=\u003estart: Start|past:\u003ehttp://www.google.com[blank] e=\u003eend: End:\u003ehttp://www.google.com op1=\u003eoperation: My Operation|past op2=\u003eoperation: Stuff|aaa sub1=\u003esubroutine: My Subroutine|invalid cond=\u003econdition: Yes or No?|approved:\u003ehttp://www.google.com c2=\u003econdition: Good idea|rejected io=\u003einputoutput: catch something...|aaa st-\u003eop1(right)-\u003econd cond(yes, right)-\u003ec2 cond(no)-\u003esub1(left)-\u003eop1 c2(yes)-\u003eio-\u003ee c2(no)-\u003eop2-\u003ee sequence图表1 图表1\nTitle: Here is a title A-\u003eB: Normal line B--\u003eC: Dashed line C-\u003e\u003eD: Open arrow D--\u003e\u003eA: Dashed open arrow 图表2\n# Example of a comment. Note left of A: Note to the\\n left of A Note right of A: Note to the\\n right of A Note over A: Note over A Note over A,B: Note over both A and B 图表3\nparticipant C participant B participant A Note right of A: By listing the participants\\n you can change their order 图表4\nAndrew-\u003eChina: Says Hello Note right of China: China thinks\\nabout it China--\u003eAndrew: How are you? Andrew-\u003e\u003eChina: I am good thanks! 图表5\nparticipant System participant App System-\u003e\u003eApp: Do you hear me App--\u003e\u003eModule: Alive? Module--\u003e\u003eApp: Yay! App-\u003e\u003eSystem: Stop mermaid图表1 图表1\ngraph TB c1--\u003ea2 subgraph one a1--\u003ea2 end subgraph two b1--\u003eb2 end subgraph three c1--\u003ec2 end 图表2\ngraph TD A[Christmas] --\u003e|Get money| B(Go shopping) B --\u003e C{Let me think} C --\u003e|One| D[Laptop] C --\u003e|Two| E[iPhone] C --\u003e|Three| F[fa:fa-car Car] 图表3\nsequenceDiagram Alice-\u003e\u003eJohn: Hello John, how are you? loop Healthcheck John-\u003e\u003eJohn: Fight against hypochondria end Note right of John: Rational thoughts! John--\u003e\u003eAlice: Great! John-\u003e\u003eBob: How about you? Bob--\u003e\u003eJohn: Jolly good! 图表4\ngantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, d Parallel 3 : des5, after des3, 3d Parallel 4 : des6, after des2, 1d 图表5\nclassDiagram Animal \u003c|-- Duck Animal \u003c|-- Fish Animal \u003c|-- Zebra Animal : +int age Animal : +String gender Animal: +isMammal() Animal: +mate() class Duck{ +String beakColor +swim() +quack() } class Fish{ -int sizeInFeet -canEat() } class Zebra{ +bool is_wild +run() } 图表6\ngantt title Git Issues - days since last update dateFormat X axisFormat %s section Issue19062 71 : 0, 71 section Issue19401 36 : 0, 36 section Issue193 34 : 0, 34 section Issue7441 9 : 0, 9 section Issue1300 5 : 0, 5 图表7\npie \"Dogs\" : 386 \"Cats\" : 85.9 \"Rats\" : 15 图表8\ngitGraph commit commit branch develop checkout develop commit commit checkout main merge develop commit commit 图表9\njourney title My working day section Go to work Make tea: 5: Me Go upstairs: 3: Me Do work: 1: Me, Cat section Go home Go downstairs: 5: Me Sit down: 3: Me 图表10\nmindmap root((mindmap)) Origins Long history ::icon(fa fa-book) Popularisation British popular psychology author Tony Buzan Research On effectivnessand features On Automatic creation Uses Creative techniques Strategic planning Argument mapping Tools Pen and paper Mermaid 图表11\nerDiagram CUSTOMER }|..|{ DELIVERY-ADDRESS : has CUSTOMER ||--o{ ORDER : places CUSTOMER ||--o{ INVOICE : \"liable for\" DELIVERY-ADDRESS ||--o{ ORDER : receives INVOICE ||--|{ ORDER : covers ORDER ||--|{ ORDER-ITEM : includes PRODUCT-CATEGORY ||--|{ PRODUCT : contains PRODUCT ||--o{ ORDER-ITEM : \"ordered in\" 图表12\ntimeline title 我的日常 section 努力搬砖 上午 : 早会: 收邮件/回复邮件 : 查看线上问题 下午 : 需求评审会 : 小组周会: coding 晚上: 加班coding 图表13\n参考文章:\nhttps://snowdreams1006.github.io/write/mermaid-flow-chart.html https://github.com/olOwOlo/hugo-theme-even/issues?q=is%3Aissue+is%3Aclosed\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n作者个人网站地址为https://olowolo.com，GitHub地址为https://github.com/olOwOlo/hugo-theme-even\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n此处假设我们采用hugo server -w -D来开启草稿模式和动态监测模式\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/hugo/enable-diagrams-in-hugo/","tags":["hugo","go"],"title":"在Hugo中开启图表支持"},{"categories":["容器化"],"contents":"Nacos官方的docker镜像不支持LDAP1同时在连接mysql方面在某些版本中会出现No Datasource Set 的异常，而其官方的release版本则很很稳定，同时又支持LDAP。目前部门很多项目都是基于docker部署的，处于简化使用，基于部署维护等原因，我决定通过Dockerfile来构建符合自己要求的nacos镜像，在确保性能稳定的同时也能支持ldap登录。\n构建过程 初始构建 一开始自己基于Nacos2.2.1下载的tar.gz文件进行构建，主要有如下几个步骤：\n通过FROM拉取openjdk-8基础镜像 拷贝并解压nacos压缩文件 通过sed命令来替换application.properties中的相关配置 通过startup.sh -m standalone 启动nacos 初步的Dockerfile如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 FROM openjdk:8-jdk MAINTAINER 卢运强 \u0026#34;yunqiang.lu@hirain.com\u0026#34; # 在联网环境下可以通过wget直接下载压缩文件 COPY nacos-server-2.2.1.tar.gz /home/nacos-server-2.2.1.tar.gz WORKDIR /home RUN echo \u0026#34;解压nacos文件\u0026#34; RUN tar -zxvf nacos-server-2.2.1.tar.gz RUN rm -rf nacos-server-2.2.1.tar.gz nacos/conf/*.sql nacos/conf/*.example nacos/bin/* COPY startup.sh /home/nacos/bin/startup.sh RUN mkdir -p /home/nacos/logs #开始修改配置文件 ARG conf=nacos/conf/application.properties RUN sed -i \u0026#34;s/server.servlet.contextPath=\\/nacos/server.servlet.contextPath=\\${SERVER_SERVLET_CONTEXTPATH:\\/nacos}/g\u0026#34; $conf RUN sed -i \u0026#34;s/server.port=8848/server.port=\\${NACOS_SERVER_PORT:8848}/g\u0026#34; $conf #RUN sed -i \u0026#34;s/\\#.*spring.datasource.platform=mysql/spring.datasource.platform=\\${SPRING_DATASOURCE_PLATFORM:\\\u0026#34;mysql\\\u0026#34;}/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*spring.sql.init.platform=mysql/spring.sql.init.platform=\\${SPRING_DATASOURCE_PLATFORM:mysql}/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.num=1/db.num=1/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.url.0.*/db.url.0=jdbc:mysql:\\/\\/\\${MYSQL_SERVICE_HOST}:\\${MYSQL_SERVICE_PORT:3306}\\/\\${MYSQL_SERVICE_DB_NAME}\\?characterEncoding=utf8\\\u0026amp;connectTimeout=1000\\\u0026amp;socketTimeout=3000\\\u0026amp;autoReconnect=true/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.user.0=nacos/db.user=\\${MYSQL_SERVICE_USER:root}/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.password.0=nacos/db.password=\\${MYSQL_SERVICE_PASSWORD}/g\u0026#34; $conf RUN sed -i \u0026#34;s/.*server.tomcat.accesslog.enabled.*/server.tomcat.accesslog.enabled=\\${TOMCAT_ACCESSLOG_ENABLED:false}/g\u0026#34; $conf RUN sed -i \u0026#34;s/.*nacos.core.auth.plugin.nacos.token.secret.key=.*/nacos.core.auth.plugin.nacos.token.secret.key=SecretKey012345678901234567890123456789012345678901234567890123456789/g\u0026#34; $conf; fi RUN chmod +x /home/nacos/bin/startup.sh ENTRYPOINT [\u0026#34;/bin/bash\u0026#34;,\u0026#34;/home/nacos/bin/startup.sh\u0026#34;,\u0026#34;-m\u0026#34;,\u0026#34;standalone\u0026#34;] 基于上述文件构建的镜像通过docker run指令执行时一直启动不成功，而在Linux终端中通过bash startup.sh -m standlone的方式则可以顺利启动nacos，初次尝试失败!\n改进版本 对startup.sh进行检查之后，发现其主要是通过如下的nohup指令启动的\n1 2 3 4 5 if [[ \u0026#34;$JAVA_OPT_EXT_FIX\u0026#34; == \u0026#34;\u0026#34; ]]; then nohup \u0026#34;$JAVA\u0026#34; ${JAVA_OPT} nacos.nacos \u0026gt;\u0026gt; ${BASE_DIR}/logs/start.out 2\u0026gt;\u0026amp;1 \u0026amp; else nohup \u0026#34;$JAVA\u0026#34; \u0026#34;$JAVA_OPT_EXT_FIX\u0026#34; ${JAVA_OPT} nacos.nacos \u0026gt;\u0026gt; ${BASE_DIR}/logs/start.out 2\u0026gt;\u0026amp;1 \u0026amp; fi 而docker默认支不支持nohup2,无奈之下只能去nacos官网寻找帮助，在其官方GtiHub中找到了一个文档Dockerfile，其中的启动脚本为docker-startup.sh，对比startup.sh发现主要的差异是前者是采用exec而非 nohup，于是将Dockerfile仿照官方说明修改如下，之后能正常启动\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 FROM openjdk:8-jdk MAINTAINER 卢运强 \u0026#34;lucumt@gmail.com\u0026#34; RUN echo $JAVA_HOME #ENV BASE_DIR=\u0026#34;/home/nacos\u0026#34; ENV MODE=\u0026#34;standalone\u0026#34; \\ PREFER_HOST_MODE=\u0026#34;ip\u0026#34;\\ BASE_DIR=\u0026#34;/home/nacos\u0026#34; \\ CLASSPATH=\u0026#34;.:/home/nacos/conf:$CLASSPATH\u0026#34; \\ FUNCTION_MODE=\u0026#34;all\u0026#34; \\ JAVA_HOME=\u0026#34;/usr/local/openjdk-8\u0026#34; \\ NACOS_USER=\u0026#34;nacos\u0026#34; \\ JAVA=\u0026#34;/usr/local/openjdk-8/bin/java\u0026#34; \\ JVM_XMS=\u0026#34;1g\u0026#34; \\ JVM_XMX=\u0026#34;1g\u0026#34; \\ JVM_XMN=\u0026#34;512m\u0026#34; \\ JVM_MS=\u0026#34;128m\u0026#34; \\ JVM_MMS=\u0026#34;320m\u0026#34; \\ NACOS_DEBUG=\u0026#34;y\u0026#34; \\ TOMCAT_ACCESSLOG_ENABLED=\u0026#34;false\u0026#34; \\ TIME_ZONE=\u0026#34;Asia/Shanghai\u0026#34; # 在联网环境下可以通过wget直接下载压缩文件 COPY nacos-server-2.2.1.tar.gz /home/nacos-server-2.2.1.tar.gz WORKDIR /home RUN echo \u0026#34;解压nacos文件\u0026#34; RUN tar -zxvf nacos-server-2.2.1.tar.gz RUN rm -rf nacos-server-2.2.1.tar.gz nacos/conf/*.sql nacos/conf/*.example nacos/bin/* COPY docker-startup.sh /home/nacos/bin/docker-startup.sh RUN mkdir -p /home/nacos/logs #开始修改配置文件 ARG conf=nacos/conf/application.properties RUN sed -i \u0026#34;s/server.servlet.contextPath=\\/nacos/server.servlet.contextPath=\\${SERVER_SERVLET_CONTEXTPATH:\\/nacos}/g\u0026#34; $conf RUN sed -i \u0026#34;s/server.port=8848/server.port=\\${NACOS_SERVER_PORT:8848}/g\u0026#34; $conf #RUN sed -i \u0026#34;s/\\#.*spring.datasource.platform=mysql/spring.datasource.platform=\\${SPRING_DATASOURCE_PLATFORM:\\\u0026#34;mysql\\\u0026#34;}/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*spring.sql.init.platform=mysql/spring.sql.init.platform=\\${SPRING_DATASOURCE_PLATFORM:mysql}/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.num=1/db.num=1/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.url.0.*/db.url.0=jdbc:mysql:\\/\\/\\${MYSQL_SERVICE_HOST}:\\${MYSQL_SERVICE_PORT:3306}\\/\\${MYSQL_SERVICE_DB_NAME}\\?characterEncoding=utf8\\\u0026amp;connectTimeout=1000\\\u0026amp;socketTimeout=3000\\\u0026amp;autoReconnect=true/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.user.0=nacos/db.user=\\${MYSQL_SERVICE_USER:root}/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.password.0=nacos/db.password=\\${MYSQL_SERVICE_PASSWORD}/g\u0026#34; $conf RUN sed -i \u0026#34;s/.*server.tomcat.accesslog.enabled.*/server.tomcat.accesslog.enabled=\\${TOMCAT_ACCESSLOG_ENABLED:false}/g\u0026#34; $conf RUN sed -i \u0026#34;s/.*nacos.core.auth.plugin.nacos.token.secret.key=.*/nacos.core.auth.plugin.nacos.token.secret.key=SecretKey012345678901234567890123456789012345678901234567890123456789/g\u0026#34; $conf RUN chmod +x /home/nacos/bin/docker-startup.sh ENTRYPOINT [\u0026#34;/bin/bash\u0026#34;,\u0026#34;/home/nacos/bin/docker-startup.sh\u0026#34;,\u0026#34;-m\u0026#34;,\u0026#34;standalone\u0026#34;] 支持LDAP 结合公司的实际情况，在部门内部使用时一般采用LDAP登录，而交付给客户时更多的采用普通账号登录，为此需要2份Dockerfile来构建2个不同的镜像，处于简化维护的考虑，自己决定采用1份Dockerfile文件根据构建参数来动态的生成不同的镜像。\n在网络上搜索后发现可以在Dockerfile中执行类似if else的指令3，于是在原有的Dockerfile基础上添加如下指令即可动态的支持LDAP登录\n1 2 3 4 5 6 7 8 9 10 11 ARG LOGIN_TYPE=nacos RUN sed -i \u0026#34;s/nacos.core.auth.system.type=.*/nacos.core.auth.system.type=${LOGIN_TYPE}/g\u0026#34; $conf RUN if [ $LOGIN_TYPE = \u0026#34;nacos\u0026#34; ];then echo \u0026#34;基于普通登录方式构建\u0026#34;;else echo \u0026#34;基于ldap登录方式构建\u0026#34;; fi # ldap登录认证方式的额外处理 RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.url=.*/nacos.core.auth.ldap.url=\\${LDAP_URL}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.basedc=.*/nacos.core.auth.ldap.basedc=\\${LDAP_BASE_DC}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.userDn=.*/nacos.core.auth.ldap.userDn=\\${LDAP_USER_DN}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.password=.*/nacos.core.auth.ldap.password=\\${LDAP_USER_PASSWORD}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.filter.prefix=.*/nacos.core.auth.ldap.filter.prefix=\\${LDAP_UID}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.case.sensitive=.*/nacos.core.auth.ldap.case.sensitive\\${LDAP_CASE_SENSITIVE}/g\u0026#34; $conf; fi 最终文件 Dockerfile 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 FROM openjdk:8-jdk MAINTAINER 卢运强 \u0026#34;lucumt@gmail.com\u0026#34; RUN echo $JAVA_HOME #ENV BASE_DIR=\u0026#34;/home/nacos\u0026#34; ENV MODE=\u0026#34;standalone\u0026#34; \\ PREFER_HOST_MODE=\u0026#34;ip\u0026#34;\\ BASE_DIR=\u0026#34;/home/nacos\u0026#34; \\ CLASSPATH=\u0026#34;.:/home/nacos/conf:$CLASSPATH\u0026#34; \\ FUNCTION_MODE=\u0026#34;all\u0026#34; \\ JAVA_HOME=\u0026#34;/usr/local/openjdk-8\u0026#34; \\ NACOS_USER=\u0026#34;nacos\u0026#34; \\ JAVA=\u0026#34;/usr/local/openjdk-8/bin/java\u0026#34; \\ JVM_XMS=\u0026#34;1g\u0026#34; \\ JVM_XMX=\u0026#34;1g\u0026#34; \\ JVM_XMN=\u0026#34;512m\u0026#34; \\ JVM_MS=\u0026#34;128m\u0026#34; \\ JVM_MMS=\u0026#34;320m\u0026#34; \\ NACOS_DEBUG=\u0026#34;y\u0026#34; \\ TOMCAT_ACCESSLOG_ENABLED=\u0026#34;false\u0026#34; \\ TIME_ZONE=\u0026#34;Asia/Shanghai\u0026#34; # 在联网环境下可以通过wget直接下载压缩文件 COPY nacos-server-2.2.1.tar.gz /home/nacos-server-2.2.1.tar.gz WORKDIR /home RUN echo \u0026#34;解压nacos文件\u0026#34; RUN tar -zxvf nacos-server-2.2.1.tar.gz RUN rm -rf nacos-server-2.2.1.tar.gz nacos/conf/*.sql nacos/conf/*.example nacos/bin/* COPY docker-startup.sh /home/nacos/bin/docker-startup.sh RUN mkdir -p /home/nacos/logs #开始修改配置文件 ARG conf=nacos/conf/application.properties RUN sed -i \u0026#34;s/server.servlet.contextPath=\\/nacos/server.servlet.contextPath=\\${SERVER_SERVLET_CONTEXTPATH:\\/nacos}/g\u0026#34; $conf RUN sed -i \u0026#34;s/server.port=8848/server.port=\\${NACOS_SERVER_PORT:8848}/g\u0026#34; $conf #RUN sed -i \u0026#34;s/\\#.*spring.datasource.platform=mysql/spring.datasource.platform=\\${SPRING_DATASOURCE_PLATFORM:\\\u0026#34;mysql\\\u0026#34;}/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*spring.sql.init.platform=mysql/spring.sql.init.platform=\\${SPRING_DATASOURCE_PLATFORM:mysql}/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.num=1/db.num=1/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.url.0.*/db.url.0=jdbc:mysql:\\/\\/\\${MYSQL_SERVICE_HOST}:\\${MYSQL_SERVICE_PORT:3306}\\/\\${MYSQL_SERVICE_DB_NAME}\\?characterEncoding=utf8\\\u0026amp;connectTimeout=1000\\\u0026amp;socketTimeout=3000\\\u0026amp;autoReconnect=true/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.user.0=nacos/db.user=\\${MYSQL_SERVICE_USER:root}/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.password.0=nacos/db.password=\\${MYSQL_SERVICE_PASSWORD}/g\u0026#34; $conf RUN sed -i \u0026#34;s/.*server.tomcat.accesslog.enabled.*/server.tomcat.accesslog.enabled=\\${TOMCAT_ACCESSLOG_ENABLED:false}/g\u0026#34; $conf RUN sed -i \u0026#34;s/.*nacos.core.auth.plugin.nacos.token.secret.key=.*/nacos.core.auth.plugin.nacos.token.secret.key=SecretKey012345678901234567890123456789012345678901234567890123456789/g\u0026#34; $conf ARG LOGIN_TYPE=nacos RUN sed -i \u0026#34;s/nacos.core.auth.system.type=.*/nacos.core.auth.system.type=${LOGIN_TYPE}/g\u0026#34; $conf RUN if [ $LOGIN_TYPE = \u0026#34;nacos\u0026#34; ];then echo \u0026#34;基于普通登录方式构建\u0026#34;;else echo \u0026#34;基于ldap登录方式构建\u0026#34;; fi # ldap登录认证方式的额外处理 RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.url=.*/nacos.core.auth.ldap.url=\\${LDAP_URL}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.basedc=.*/nacos.core.auth.ldap.basedc=\\${LDAP_BASE_DC}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.userDn=.*/nacos.core.auth.ldap.userDn=\\${LDAP_USER_DN}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.password=.*/nacos.core.auth.ldap.password=\\${LDAP_USER_PASSWORD}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.filter.prefix=.*/nacos.core.auth.ldap.filter.prefix=\\${LDAP_UID}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.case.sensitive=.*/nacos.core.auth.ldap.case.sensitive\\${LDAP_CASE_SENSITIVE}/g\u0026#34; $conf; fi RUN chmod +x /home/nacos/bin/docker-startup.sh ENTRYPOINT [\u0026#34;/bin/bash\u0026#34;,\u0026#34;/home/nacos/bin/docker-startup.sh\u0026#34;,\u0026#34;-m\u0026#34;,\u0026#34;standalone\u0026#34;] 构建方式 在构建时需要将Dockerfile、docker-startup.sh以及对应的nacos压缩文件放到同一个目录下\n普通登录方式构建\n1 2 3 4 5 # 不传递登录参数 docker build -t nacos_custom:v1.0 . # 显示指定登录参数 docker build -t nacos_custom:v1.0 --build-arg LOGIN_TYPE=nacos . LDAP登录方式构建\n1 docker build -t nacos_custom:v1.0 --build-arg LOGIN_TYPE=ldap . 使用方式 假设存储数据库为mysql采用docker-compose方式登录，相关的docker-compose.yml文件如下:\n普通方式登录\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 version: \u0026#34;3\u0026#34; services: nacos: image: nacos_custom:v1.0 restart: always container_name: nacos_custom ports: - 8858:8858 environment: - TZ=Asia/Shanghai - NACOS_SERVER_PORT=8858 - SPRING_DATASOURCE_PLATFORM=mysql - MYSQL_SERVICE_HOST=xxxx - MYSQL_SERVICE_PORT=xxxx - MYSQL_SERVICE_DB_NAME=nacos_test - MYSQL_SERVICE_USER=root - MYSQL_SERVICE_PASSWORD=654321 volumes: - $PWD/logs:/home/nacos/logs/ LDAP登录\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 version: \u0026#34;3\u0026#34; services: nacos: image: nacos_custom:v1.0 restart: always container_name: nacos_custom ports: - 8858:8858 environment: - TZ=Asia/Shanghai - NACOS_SERVER_PORT=8858 - SPRING_DATASOURCE_PLATFORM=mysql - MYSQL_SERVICE_HOST=xxxx - MYSQL_SERVICE_PORT=3316 - MYSQL_SERVICE_DB_NAME=nacos_test - MYSQL_SERVICE_USER=root - MYSQL_SERVICE_PASSWORD=xxxx - LDAP_URL=ldap://xxxx:389 - LDAP_BASE_DC=dc=xxx,dc=xxx - LDAP_USER_DN=cn=xxx,dc=xxx,dc=com - LDAP_USER_PASSWORD=xxxx - LDAP_UID=uid - LDAP_CASE_SENSITIVE=false volumes: - $PWD/logs:/home/nacos/logs/ 镜像参数说明 属性 作用 默认值 可选值 NACOS_SERVER_PORT nacos服务器端口 8848 SPRING_DATASOURCE_PLATFORM 指定nacos的数据源 mysql mysql或空 MYSQL_SERVICE_HOST mysql服务器地址 MYSQL_SERVICE_PORT mysql服务器端口 3306 MYSQL_SERVICE_DB_NAME mysql数据库名称 MYSQL_SERVICE_USER mysql数据库用户名 root MYSQL_SERVICE_PASSWORD mysql数据据密码 LDAP_URL ldap服务的地址和端口号 LDAP_BASE_DC ldap搜索范围 LDAP_USER_DN ldap绑定账号4 LDAP_USER_PASSWORD ldap绑定账号的密码 LDAP_UID 用户账号字段 LDAP_CASE_SENSITIVE ldap认证时是否大小写敏感 https://github.com/alibaba/nacos/issues/9751\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://unix.stackexchange.com/questions/268284/nohup-doesnt-work-as-expected-in-docker-script\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://stackoverflow.com/questions/43654656/dockerfile-if-else-condition-with-external-arguments\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n部分LDAP数据库不支持匿名登录，此时需要管理员账号来绑定登录\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/docker/build-custom-nacos-image-to-support-ldap-and-mysql/","tags":["docker","nacos","ldap"],"title":"构建自定义的Nacos镜像支持MySQL数据源与LDAP认证"},{"categories":["脚本操作"],"contents":"简要介绍在Windows系统中采用基于CMD的批处理脚本进行自动化部署时，对通过\u0026amp;\u0026amp;拼接的指令以更优雅的方式实现，以提高批处理脚本的可读性和可维护性。\n问题说明 项目背景 公司有个基于Python开发的项目近期要交付给客户，为了便于安装和后续升级，之前都是采用PyInstaller安装成exe可执行文件实现傻瓜式的操作，而这个项目出于避免与客户服务器其它Python环境冲突以及便于后续扩展的考量，在软件部署和升级时采用了Anaconda进行隔离式部署，其部署流程如下1\nstart=\u003estart: 开始 end=\u003eend: 结束 conda_create=\u003eoperation: 创建conda环境 conda_active=\u003eoperation: 激活conda环境 pip_install=\u003eoperation: pip安装依赖 python_run=\u003eoperation: 执行python程序 start-\u003econda_create conda_create-\u003econda_active conda_active-\u003epip_install pip_install-\u003epython_run python_run-\u003eend 各步骤涉及到的操作主要有:\n创建conda环境，conda create -n lyq_test -y 激活conda环境，conda activate lyq_test 安装pip依赖，pip install -r requirements.txt 执行python程序，python hello.py 这些步骤对于专业的开发人员而言操作起来很快速，但对于相关的使用客户而言，他们不一定具有相关的编程经验，执行上述指令容易出错，便利性有待提高。\n由于目标客户的环境为Windows，同项目成员沟通后决定采用CMD批处理脚本来包含上述命令，实际部署或升级时只需要运行该批处理脚本即可。\n面临的问题 最开始采用的install.bat批处理脚本类似如下\n1 2 3 4 5 6 7 8 @echo off title 一键部署与升级脚本 echo ===========开始创建conda环境============== conda create -n lyq_test -y conda activate lyq_test pip install -r requirements.txt python hello.py pause 运行结果如下，可发现从conda create -n lyq_test -y之后的指令均没有执行\n一开始自己以为是由于Anaconda的创建需要时间，于是参考Stackoverflow中的说明2在conda activate之前添加了一条睡眠指令，测试结果和上图一样，问题依旧。\n1 2 3 4 5 6 7 8 9 10 @echo off title 一键部署与升级脚本 echo ===========开始创建conda环境============== conda create -n lyq_test -y rem 睡眠10秒钟 ping -n 10 127.0.0.1 \u0026gt; nul conda activate lyq_test pip install -r requirements.txt python hello.py pause 参考网上的资料和自己尝试后发现将批处理脚本中的命令用\u0026amp;\u0026amp;3拼接起来然后一起执行就能达到要求\n1 2 3 4 5 @echo off title 一键部署与升级脚本 echo ===========开始创建conda环境============== conda create -n lyq_test -y \u0026amp;\u0026amp; conda activate lyq_test \u0026amp;\u0026amp; pip install -r requirements.txt \u0026amp;\u0026amp; python hello.py pause 运行结果如下，虽然批处理脚本的执行结果符合自己的预期，但此种解决方案带来了一个很严重的副作用\n通过\u0026amp;\u0026amp;将多条指令拼接在一起的结果是脚本中只有一条超长的指令，会导致批处理脚本的可读性和可维护性都严重降低！\n解决方案 由于随着项目的进行，install.bat脚本肯定会进行不断地修正与更新，install.bat脚本的可维护性与可读性是必须要解决的问题，但采用\u0026amp;\u0026amp;拼接的方式也不能放弃，只能另想它法。\n继续寻求Stackoverflow4的协助5，将install.bat通过SET来重新赋值的方式进行变量拼接，修改后的代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 @echo off title 一键部署与升级脚本 echo ===========开始创建conda环境============== set command=conda create -n lyq_test -y set command=%command% \u0026amp;\u0026amp; conda activate lyq_test set command=%command% \u0026amp;\u0026amp; pip install -r requirements.txt set command=%command% \u0026amp;\u0026amp; python hello.py echo 拼接后的命令如下 echo %command% echo 开始执行拼接后的命令 %command% pause 执行结果如下，虽然能成功进入Anaconda环境，但是后续的指令都没有执行。\n看起来似乎是胜利在望，但仔细分析后发现只所以能进入Anaconda环境是由于第1个\u0026amp;\u0026amp;配置生效，导致批处理文件提前执行，而后续的拼接指令没有机会执行6，还是没法实现最终目的。\n为了避免提前执行，尝试用双引号将相关指令封装起来，在拼接完成后统一执行\n1 2 3 4 5 6 7 8 9 10 11 12 @echo off title 一键部署与升级脚本 echo ===========开始创建conda环境============== set \u0026#34;command=conda create -n lyq_test -y\u0026#34; set \u0026#34;command=%command% \u0026amp;\u0026amp; conda activate lyq_test\u0026#34; set \u0026#34;command=%command% \u0026amp;\u0026amp; pip install -r requirements.txt\u0026#34; set \u0026#34;command=%command% \u0026amp;\u0026amp; python hello.py\u0026#34; echo 拼接后的命令如下 echo %command% echo 开始执行拼接后的命令 %command% pause 执行结果如下，虽然最终的执行结果符合预期，但很明显打印出来的拼接数据不是我们想要的，不利于后续分析，同时一些echo打印指令没有执行，此方案存在瑕疵，实际使用中风险很大。\n经过一段时间的搜索后没有找到自己想要的答案，只能在Stackoverflow上提问希望能获得帮助，最终通过7得到了一个较为满意的解决方案。\n该方案主要通过字符串截取来实现8，修改后的脚本如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 @echo off title 一键部署与升级脚本 echo ===========开始创建conda环境============== set command=conda create -n lyq_test -y rem 要特别注意第1次拼接时不能加上:~1,-1 set command=\u0026#34;%command% \u0026amp;\u0026amp; conda activate lyq_test\u0026#34; set command=\u0026#34;%command:~1,-1% \u0026amp;\u0026amp; pip install -r requirements.txt\u0026#34; set command=\u0026#34;%command:~1,-1% \u0026amp;\u0026amp; python hello.py\u0026#34; echo ==========拼接后的命令如下=========== echo %command% echo ==========开始执行拼接后的命令============ %command:~1,-1% pause 脚本执行结果如下，结果符合预期，在确保脚本能正常执行的前提下也满足了可维护性与可读性，问题解决!\n此处出于简化篇幅的考虑，只列出了这4个步骤，实际项目中的步骤会更多\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://stackoverflow.com/questions/735285/how-to-wait-in-a-batch-script\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026amp;\u0026amp;在批处理文件中表示只有当前面的指令执行成功时才执行后面的指令，\u0026amp;则表示无论前述指令是否执行成功，都执行后面的指令\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://stackoverflow.com/questions/17743757/how-to-concatenate-strings-in-windows-batch-file-for-loop\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n或许求助ChatGPT是一个更好的方案\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n此处是基于个人理解的说明，不一定正确，主要是为了说明通过常规的变量重新赋值方式不可行\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://stackoverflow.com/questions/75646525/how-to-use-in-command-line-in-variable-in-windows\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://superuser.com/questions/228794/how-to-extract-part-of-a-string-in-windows-batch-file\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/cmd/combine-mutiple-command-with-ampersand-elegant-in-cmd/","tags":["cmd"],"title":"在批处理脚本中利用\u0026\u0026命令将多条命令优雅的拼接在一起"},{"categories":[],"contents":"一个混迹于帝都的程序猿，主要从事Java、Python和Golang相关的开发工作。\n编程领域 Java，主要用它进行web开发 Python，主要用它进行网络爬虫开发和web开发 Golang,个人业余爱好 MySQL、MongoDB HTML、Javascript、jQuery、CSS 个人信息 教育信息 中国矿业大学 (2006.9-2010.6) 计算机科学与技术 (本科) 自我评价 热爱学习和使用新技术； 有着十分强烈的代码洁癖； 喜欢重构代码，善于分析和解决问题； 个人爱好 编程 英语 学习 联系方式 Email: lucumt@gmail.com,cumtlu@126.com Skype: lu.rosen QQ: 317801876 领英: 卢运强 友情链接 Frantic log#1048 cold\u0026rsquo;s world 邪恶二进制 Javmain\u0026rsquo;s Blog 小林Coding 云原生实验室 ","permalink":"https://lucumt.info/about/","tags":[],"title":"关于我"},{"categories":[],"contents":" 记录个人觉得有意义的各种博客、公众号页面、视频等。\n博客园 地址 内容 其它 程序员自由之路 主要是JavaEE开发，关于Java框架的文章很多 Michael翔 主要是JavaEE开发 微信公众号Coder 魔法院 秋风飒飒吹 软件开发的各方面均有涉及 Ccww 主要是Java和Spring框架 Throwable 主要是JavaEE开发 简书 单个博文 docker安装Elasticsearch7.6集群并设置密码 ","permalink":"https://lucumt.info/links/","tags":[],"title":"各种外链"},{"categories":["Java编程"],"contents":"在软件开发领域，大部分时间精确到秒或毫秒即可满足日常需求，但在某些对时间要求严格的场景中需要使用微秒、纳秒等更精确的时间值，本文简要记录如何在Java中通过LocalDateTime实现对于微秒、纳秒的精确解析以及转化为long型时间戳。\njava.util.Date中相关实现 格式化测试 首先采用采用如下代码验证java.util.Date和java.text.SimpleDateFormat对于时间戳的支持情况。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 public class TestDateConvert1 { public static void main(String[] args) { String text1 = \u0026#34;2023/01/04 17:54:38\u0026#34;; String text2 = \u0026#34;2023/01/04 17:54:38.610\u0026#34;; String text3 = \u0026#34;2023/01/04 17:54:38.610502\u0026#34;; String text4 = \u0026#34;2023/01/04 17:54:38.610502567\u0026#34;; try { testDate1(text1); testDate2(text2); testDate3(text3); testDate4(text4); } catch (ParseException e) { throw new RuntimeException(e); } } public static void testDate1(String text) throws ParseException { DateFormat df = new SimpleDateFormat(\u0026#34;yyyy/MM/dd HH:mm:ss\u0026#34;); //精确到秒 Date newDate = df.parse(text); System.out.println(\u0026#34;----------------精确到秒------------------------------\u0026#34;); System.out.println(\u0026#34;原始时间:\\t\u0026#34; + text); System.out.println(\u0026#34;解析后的时间:\\t\u0026#34; + df.format(newDate)); System.out.println(); } public static void testDate2(String text) throws ParseException { DateFormat df = new SimpleDateFormat(\u0026#34;yyyy/MM/dd HH:mm:ss.SSS\u0026#34;); // 精确到毫秒 Date newDate = df.parse(text); System.out.println(\u0026#34;----------------精确到毫秒----------------------------\u0026#34;); System.out.println(\u0026#34;原始时间:\\t\u0026#34; + text); System.out.println(\u0026#34;解析后的时间:\\t\u0026#34; + df.format(newDate)); System.out.println(); } public static void testDate3(String text) throws ParseException { DateFormat df = new SimpleDateFormat(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSS\u0026#34;); //精确到微秒 Date newDate = df.parse(text); System.out.println(\u0026#34;----------------精确到微秒----------------------------\u0026#34;); System.out.println(\u0026#34;原始时间:\\t\u0026#34; + text); System.out.println(\u0026#34;解析后的时间:\\t\u0026#34; + df.format(newDate)); System.out.println(); } public static void testDate4(String text) throws ParseException { DateFormat df = new SimpleDateFormat(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSSSSS\u0026#34;); //精确到微秒 Date newDate = df.parse(text); System.out.println(\u0026#34;----------------精确到纳秒----------------------------\u0026#34;); System.out.println(\u0026#34;原始时间:\\t\u0026#34; + text); System.out.println(\u0026#34;解析后的时间:\\t\u0026#34; + df.format(newDate)); } } 运行结果如下：\n从上图中可以看出时间精确到微秒之后，采用java.util.Date和java.text.SimpleDateFormat进行输出时前后的结果已经不一致。同时也可以大致猜测，当使用java.util.Date时不能用其进行微秒或纳秒等高精度的时间存储展示，但此问题是由java.util.Date还是java.text.SimpleDateFormat造成的暂不确定。\n对比数据测试 为了测试结果的准确性，在www.timestamp-converter.com中获取一个可用于验证的时间戳信息如下所示\n其中基于毫秒的时间戳为1676628010725，格式化后的显示为2023-02-17T10:00:10.725Z，采用下述代码进行验证：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public static void testDateCreate() { DateFormat df1 = new SimpleDateFormat(\u0026#34;yyyy/MM/dd HH:mm:ss\u0026#34;); DateFormat df2 = new SimpleDateFormat(\u0026#34;yyyy/MM/dd HH:mm:ss.SSS\u0026#34;); DateFormat df3 = new SimpleDateFormat(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSS\u0026#34;); DateFormat df4 = new SimpleDateFormat(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSSSSS\u0026#34;); long timestamp1 = 1676628010725L;//前述获取到的时间戳 Date date = new Date(timestamp1); long timestamp2 = date.getTime(); System.out.println(\u0026#34;timestamp1:\\t\u0026#34; + timestamp1); System.out.println(\u0026#34;timestamp2:\\t\u0026#34; + timestamp2); System.out.println(\u0026#34;精确到秒:\\t\u0026#34; + df1.format(date)); System.out.println(\u0026#34;精确到毫秒:\\t\u0026#34; + df2.format(date)); System.out.println(\u0026#34;精确到微秒:\\t\u0026#34; + df3.format(date)); System.out.println(\u0026#34;精确到纳秒:\\t\u0026#34; + df4.format(date)); } 运行结果如下\n从结果中可知微秒与纳秒的结果与网站中展示的不一致，但是仍然无法确定到底是java.util.Date还是java.text.SimpleDateFormat的原因。\n在java.util.Date的官方文档中可找到如下说明，从图中可知当采用时间戳来构造java.util.Date时，其接收的参数为毫秒相对数据值，不支持微秒和纳秒。\n在java.text.SimpleDateFormate的官方文档中有如下说明，同样可知道java.text.SimpleDateFormat不支持微秒和纳秒级别的时间精度。\n初步结论:\njava.util.Date和java.text.SimpleDateFormat均不支持微秒和纳秒级别的时间精度。\nLocalDateTime中实现 由于JDK8中引入了LocalDateTime，故将最开始的测试代码都修改为使用java.time.LocalDateTime和java.time.format.DateTimeFormatter进行测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 public class TestDateConvert3 { public static void main(String[] args) { String text1 = \u0026#34;2023/01/04 17:54:38\u0026#34;; String text2 = \u0026#34;2023/01/04 17:54:38.610\u0026#34;; String text3 = \u0026#34;2023/01/04 17:54:38.610502\u0026#34;; String text4 = \u0026#34;2023/01/04 17:54:38.610502567\u0026#34;; try { testDate1(text1); testDate2(text2); testDate3(text3); testDate4(text4); } catch (ParseException e) { throw new RuntimeException(e); } } public static void testDate1(String text) throws ParseException { DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy/MM/dd HH:mm:ss\u0026#34;); //精确到秒 LocalDateTime newDate = LocalDateTime.parse(text,formatter); System.out.println(\u0026#34;----------------精确到秒------------------------------\u0026#34;); System.out.println(\u0026#34;原始时间:\\t\u0026#34; + text); System.out.println(\u0026#34;解析后的时间:\\t\u0026#34; + formatter.format(newDate)); System.out.println(); } public static void testDate2(String text) throws ParseException { DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy/MM/dd HH:mm:ss.SSS\u0026#34;); //精确到毫秒 LocalDateTime newDate = LocalDateTime.parse(text,formatter); System.out.println(\u0026#34;----------------精确到毫秒----------------------------\u0026#34;); System.out.println(\u0026#34;原始时间:\\t\u0026#34; + text); System.out.println(\u0026#34;解析后的时间:\\t\u0026#34; + formatter.format(newDate)); System.out.println(); } public static void testDate3(String text) throws ParseException { DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSS\u0026#34;); //精确到微秒 LocalDateTime newDate = LocalDateTime.parse(text,formatter); System.out.println(\u0026#34;----------------精确到微秒----------------------------\u0026#34;); System.out.println(\u0026#34;原始时间:\\t\u0026#34; + text); System.out.println(\u0026#34;解析后的时间:\\t\u0026#34; + formatter.format(newDate)); System.out.println(); } public static void testDate4(String text) throws ParseException { DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSSSSS\u0026#34;); //精确到纳秒 LocalDateTime newDate = LocalDateTime.parse(text,formatter); System.out.println(\u0026#34;----------------精确到纳秒----------------------------\u0026#34;); System.out.println(\u0026#34;原始时间:\\t\u0026#34; + text); System.out.println(\u0026#34;解析后的时间:\\t\u0026#34; + formatter.format(newDate)); System.out.println(); } } 测试结果如下：\n从中可知当联合采用java.time.LocalDateTime和java.time.format.DateTimeFormatter时，能够支持到纳秒级别，可满足要求。\n在java.time.LocalDateTime的官方文档中有如下说明，从图中可知java.time.LocalDateTime支持到纳秒级别的时间精度\n在java.time.format.DateTimeFormatter的官方文档中有如下说明,从图中可知java.time.format.DateTimeFormatter也支持纳秒级别的格式化。\n最终结论:\njava.time.LocalDateTime支持纳秒级别的时间存储，支持java.time.format.DateTimeFormatter支持纳秒级别的时间显示。\nLocalDateTime与时间戳互转 在java.util.Date中可以很容易的通过Date().getTime()和new Date(long timestamp)来分别获取时间戳和基于时间戳构造时间，而在java.time.LocalDateTime中要实现类似功能则稍微复杂点。\n当要获取long类型的时间戳时，需要先获取秒，再获取微秒或纳秒，然后根据他们之前的换算关系进行累加返回，相关公式如下：\n$微秒时间戳=秒 \\times 10^6 +微秒$ $纳秒时间戳=秒 \\times 10^9 +纳秒$ 有了时间戳之后根据上述公式进行反向操作，分别获取秒与微秒(纳秒)，然后根据这2个数值通过Instant构建即可。\n与微秒互转 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 public class TestDateConvert4 { public static void main(String[] args) { long time = convertTimeToMills(\u0026#34;2023/01/04 17:54:38.610502\u0026#34;); convertMillsToTime(time); } public static long convertTimeToMills(String originalText) { DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSS\u0026#34;); System.out.println(originalText); LocalDateTime dateTime = LocalDateTime.parse(originalText, formatter); ZoneId zoneId = ZoneId.systemDefault(); Instant instant = dateTime.atZone(zoneId).toInstant(); long seconds = instant.getEpochSecond(); int micros = instant.get(ChronoField.MICRO_OF_SECOND); long total = seconds * 1_000_000 + micros; return total; } public static LocalDateTime convertMillsToTime(long time) { long sec = time / 1_000_000; long mic = time % 1_000_000; Instant instant1 = Instant.ofEpochSecond(sec).plus(mic, ChronoUnit.MICROS); ZoneId zoneId = ZoneId.systemDefault(); LocalDateTime localDateTime = LocalDateTime.ofInstant(instant1, zoneId); DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSS\u0026#34;); System.out.println(formatter.format(localDateTime)); return localDateTime; } } 测试结果如下，符合预期\n与纳秒互转 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 public class TestDateConvert5 { public static void main(String[] args) { long time = convertTimeToMills(\u0026#34;2023/01/04 17:54:38.610502987\u0026#34;); convertMillsToTime(time); } public static long convertTimeToMills(String originalText) { DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSSSSS\u0026#34;); System.out.println(originalText); LocalDateTime dateTime = LocalDateTime.parse(originalText, formatter); ZoneId zoneId = ZoneId.systemDefault(); Instant instant = dateTime.atZone(zoneId).toInstant(); long seconds = instant.getEpochSecond(); int micros = instant.get(ChronoField.NANO_OF_SECOND); long total = seconds * 1_000_000_000 + micros; return total; } public static LocalDateTime convertMillsToTime(long time) { long sec = time / 1_000_000_000; long mic = time % 1_000_000_000; Instant instant1 = Instant.ofEpochSecond(sec).plus(mic, ChronoUnit.NANOS); ZoneId zoneId = ZoneId.systemDefault(); LocalDateTime localDateTime = LocalDateTime.ofInstant(instant1, zoneId); DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSSSSS\u0026#34;); System.out.println(formatter.format(localDateTime)); return localDateTime; } } 测试结果如下，符合预期\n参考文章：\nhttps://www.cnblogs.com/yangxunwu1992/p/5769533.html https://stackoverflow.com/questions/30135025/java-date-parsing-with-microsecond-or-nanosecond-accuracy ","permalink":"https://lucumt.info/post/java-core/parse-and-store-microsecond-nanosecond-in-java/","tags":["Java"],"title":"在Java中解析和存储包含微秒与纳秒的时间"},{"categories":["容器化"],"contents":"工作中涉及到Kubernetes相关知识，自己之前一直没有系统性的学习Kubernetes，近期在腾讯云上想安装Kubernetes时一直遇到在执行kubeadm init时6443和10280端口无法访问导致操作失败进而无法顺利安装Kubernetes。一番排查后发现是由于从1.24.0之后Kubernetes默认采用containerd作为运行时容器，其默认镜像为registry.k8s.io，该镜像在国内无法访问导致的，简单记录下。\n安装过程主要参考1，相关配置与安装步骤如下：\n系统配置与依赖 关闭防火墙 1 2 3 4 5 6 7 8 9 10 11 12 # 关闭交换内存 swapoff -a #关闭selinux getenforce setenforce 0 sed -i \u0026#39;s/^SELINUX=enforcing$/SELINUX=disabled/\u0026#39; /etc/selinux/config #关闭防火墙 firewall-cmd --state systemctl stop firewalld.service systemctl disable firewalld.service 配置docker参数 1 2 3 4 5 6 7 8 9 10 11 mkdir /etc/docker/ vim /etc/docker/daemon.json { \u0026#34;storage-driver\u0026#34;: \u0026#34;overlay2\u0026#34;, \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://registry.docker-cn.com\u0026#34;, \u0026#34;http://hub-mirror.c.163.com\u0026#34; ], \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;] } 配置内核参数 1 2 3 4 5 6 7 8 9 10 11 12 13 ## 配置网卡转发,看值是否为1 sysctl -a |grep \u0026#39;net.ipv4.ip_forward = 1\u0026#39; sysctl -a |grep \u0026#39;net.bridge.bridge-nf-call-iptables = 1\u0026#39; sysctl -a |grep \u0026#39;net.bridge.bridge-nf-call-ip6tables = 1\u0026#39; ## 若未配置，需要执行如下 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/sysctl.d/k8s.conf net.ipv4.ip_forward=1 net.bridge.bridge-nf-call-ip6tables=1 net.bridge.bridge-nf-call-iptables=1 EOF sysctl -p /etc/sysctl.d/k8s.conf 安装docker 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #安装相关依赖 yum install -y yum-utils device-mapper-persistent-data lvm2 epel-release #添加阿里云docker-ce源 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo yum clean all yum install -y docker-ce containerd.io #设置docker开机自启 systemctl enable docker #启动docker服务 systemctl start docker #查看docker信息 docker info 配置container 1 2 3 containerd config default \u0026gt; /etc/containerd/config.toml systemctl daemon-reload systemctl restart containerd 安装Kubernetes 添加k8s源 1 2 3 4 5 6 7 8 9 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF 安装kubelet和kubeadm 执行下述指令，安装kubelet kubeadm\n1 yum -y install kubectl kubelet kubeadm 执行下述指令，修改kubelet配置**（把kubelet驱动方式改为和docker驱动方式一致，否则会有报错）**\n1 2 3 cat \u0026lt;\u0026lt;EOF \u0026gt;/etc/sysconfig/kubelet KUBELET_CGROUP_ARGS=\u0026#34;--cgroup-driver=systemd\u0026#34; EOF 执行下述执行添加自启动\n1 systemctl enable kubelet 前序步骤执行完成后，执行kubectl version输出结果如下，可以看出其无法访问8080端口，结果输出不完整。造成此现象的原因为没有执行kubeadm init\n执行kubeadm init 执行下述命令进行初始化\n1 kubeadm init --v=5 --upload-certs --image-repository k8s.m.daocloud.io 前述命令的输出如下，可以看出创建过程一直阻塞\n经过一段时间的等待，最终在控制台中出现如下错误信息，kubeadm init过程失败!\n问题分析\u0026amp;解决 由于原始的报错信息没有提供太多有用的信息，故通过下述命令来输出其完整的日志2\n1 2 systemctl status kubelet -l \u0026gt; logs.txt cat logs.txt 查看logs.txt的内容，输出如下\n从上图中可知报错信息是由于无法下载registry.k8s.io/pause:3.6导致的，由于registry.k8s.io在国内被墙，但是自己在执行kubeadm init的时候已经通过--image-repository k8s.m.daocloud.io制定了国内的镜像，为啥还会访问旧的镜像呢？奇怪！\n网上搜索一番后，在其官网说明中3的首页有如下说明\nAfter its deprecation in v1.20, the dockershim component has been removed from the kubelet. From v1.24 onwards, you will need to either use one of the other supported runtimes (such as containerd or CRI-O) or use cri-dockerd if you are relying on Docker Engine as your container runtime. For more information about ensuring your cluster is ready for this removal, please see this guide.\n而在前面通过kubectl version命令可知当前的版本为v1.26.0，很明显其使用的是containerd，而自己没有对其进行相关配置。\n执行cat /etc/containerd/config.toml|grep registry.k8s.io后的结果如下，containerd使用的还是默认镜像，至此问题原因找出！\n依次执行下述命令来重新配置containerd\n1 2 3 sed -i \u0026#39;s/registry.k8s.io/registry.aliyuncs.com\\/google_containers/\u0026#39; /etc/containerd/config.toml systemctl daemon-reload systemctl restart containerd 之后重新执行下述命令\n1 2 3 4 5 # 移除之前的旧配置 kubeadm reset -f # 初始化 kubeadm init --v=5 --upload-certs --image-repository k8s.m.daocloud.io 运行上述命令后的输出类似如下，可以看出kubeadm init顺利执行成功，整个过程耗时不超过1分钟，至此问题解决!\nhttps://www.cnblogs.com/cerberus43/p/15881294.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n之所以要写入文件是由于直接执行systemctl status kubelet时其输出信息较多，在屏幕中显示不完整，不利于分析\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.24.md\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/k8s/kubeadm-init-not-working-due-to-default-registry-config/","tags":["kubernetes","linux"],"title":"利用kubeadm init初始化时由于registry.k8s.io/pause:3.6导致初始化失败"},{"categories":["Java编程"],"contents":"在项目中某个请求的参数采用了较为复杂的规则拼接而成，在服务器端查询时需要将其解析成符合要求的Map与List组合的格式。一开始自己采用的是传统的遍历方式实现，后续发现用Java8中引入的lambda表达式后代码变的更简洁、更优雅，故简单记录下。\n问题描述 项目中有类似如下的字符串输入参数\n1 010$$fengtai,010$$chaoyang,010$$haidain,027$$wuchang,027$$hongshan,027$$caidan,021$$changnin,021$$xuhui,020$$tianhe 调用方期望将输入参数转化为如下格式(即首先根据,进行分割，然后在根据$$进行进一步的拆分，最终的结果是按照$$前面的数据为key，$$后面的数据分别放入同一个数组中，最终结果以Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt;的格式返回)。\n1 {027=[wuchang, hongshan, caidan], 020=[tianhe], 010=[fengtai, chaoyang, haidain], 021=[changnin, xuhui]} 传统方式 最开始由于需要尽快部署调试，自己才用的是传统的遍历方式，此种方式编码起来很简单，具备简单的Java基础即可实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; parseParametersByIterate(String sensors) { List\u0026lt;String[]\u0026gt; dataList = Arrays.stream(sensors.split(\u0026#34;,\u0026#34;)).map(s -\u0026gt; s.split(\u0026#34;\\\\$\\\\$\u0026#34;)).collect(Collectors.toList()); Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; resultMap = new HashMap\u0026lt;\u0026gt;(); for (String[] d : dataList) { List\u0026lt;String\u0026gt; list = resultMap.get(d[0]); if (list == null) { list = new ArrayList\u0026lt;\u0026gt;(); list.add(d[1]); resultMap.put(d[0], list); } else { list.add(d[1]); } } return resultMap; } 基于Lambda实现 在Stack Overflow上咨询后，发现用lambda实现更简洁，只用一行代码就能搞定!\n1 2 3 4 5 6 7 public Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; parseByLambda(String data) { Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; resultMap = Arrays.stream(data.split(\u0026#34;,\u0026#34;)) .map(s -\u0026gt; s.split(\u0026#34;\\\\$\\\\$\u0026#34;)) .collect(Collectors.groupingBy(s -\u0026gt; s[0], Collectors.mapping(s -\u0026gt; s[1], Collectors.toList()))); return resultMap; } 上述代码的核心是采用Java8中引入的Collectors类，采用其中的groupingBy和mapping方法实现，而自己用的最多的只是toList和toMap，基本功有待加强！\n","permalink":"https://lucumt.info/post/java-core/using-lambda-to-parse-and-group-data/","tags":["Java"],"title":"利用Java8中的lambda来实现字符串的解析与分组"},{"categories":[],"contents":"","permalink":"https://lucumt.info/search/","tags":[],"title":"搜索结果展示"},{"categories":["持续集成","容器化"],"contents":"记录下自己在使用KubeSphere过程中由于YAML中错误的配置导致Kubernetes经常资源紧张而无法创建与部署新节点的问题。\n问题描述 部门在使用KubeSphere过程中经常遇到类似如下图所示的由于kubernetes无法调度而导致的无法部署的问题\n进一步查看报错节点信息会发现提示CPU资源不足，从而导致无法部署。\n之前自己采取的解决方案是暴力的删除一部分节点来释放CPU资源，但此种方式治标不治本，且随着KubeSphere在部门内部使用的普及，此问题发生的频率越来越高，只能想办法从根源上处理。\n分析与解决 由于提示的是CPU资源不足，首先检查是否为CPU的问题，采用lscpu | egrep 'Model name|Socket|Thread|NUMA|CPU\\(s\\)'和free -g分别查看CPU和内存信息，结果如下\n从查询结果可知系统的CPU配置和内存配置都很高，而自己在KubeSphere中部署的都是一些普通的Java程序，不可能占用特别多的CPU和内存资源，Linux服务器本身的配置问题排除。\n接下来利用kubectl describe node查看节点信息，输出结果如下\n在上图中可发现相关节点汇总后的CPU和内存占用的百分比非常大，其中CPU在Requests部分占比为84%，由于Linux系统自身运行和运行Kubesphere与Kubernetes都需要占用一定的CPU资源，从而导致当Kubersphere中部署的项目超过一定数量时，Linux系统无法给Kubernetes分配足够的CPU资源导致部署失败。至此，问题的表面原因找出来了。\n进一步分析上面的问题，自己觉得很好奇的是为啥Requests部分占用的资源，自己在对应的YAML文件中压根就没指定Requests相关的参数，检查代码发现Limits配置的值比较大\n1 2 3 4 resources: limits: cpu: 500m memory: 2000Mi 同时基于kubectl describe node发现相关节点的Requests和Limits的值都相同，猜测是否Kubernetes默认将Ruquests的值设置为与Limits的值相同。\n在Kubernetes官网发现如下说明\nNote: If you specify a limit for a resource, but do not specify any request, and no admission-time mechanism has applied a default request for that resource, then Kubernetes copies the limit you specified and uses it as the requested value for the resource.\n上述文字说明当我们在YAML文件中只设置了Limits但是没有指定Requests，则Kubernetes会将Request的值默认设置为与Limits相同，从而导致CPU和内存资源占用都很高，至此问题根源找到！\n解决的方式也很简单，要么移除掉Limits，让Kubernetes根据Linux系统资源和节点状况给我们动态的分配节点，或者同时指定Requests和Limits即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 屏蔽此部分代码 #resources: # limits: # cpu: 500m # memory: 2000Mi # 或者显示配置request和limits resources: limits: cpu: 500m memory: 2000Mi requests: cpu: 20m memory: 64Mi 经验教训： 需要对自己项目中的代码要有更深入的理解，尤其是配置文件，要做到理解每一行的作用，不能简单的复制别人的代码。\n参考文档：\nhttps://kubesphere.io/zh/blogs/deep-dive-into-the-k8s-request-and-limit/\nhttps://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\n","permalink":"https://lucumt.info/post/k8s/cpu-resource-not-enough-due-to-invalid-k8s-config/","tags":["kubernetes","kubesphere","linux"],"title":"由于k8s中的错误配置导致无法创建新节点"},{"categories":["个人博客"],"contents":"记录下个人Hugo博客使用Even主题时的一些使用心得与个人改进。\nGitHub Actions自动部署 参见利用GitHub Action实现Hugo博客在GitHub Pages自动部署。\n改进Back to top 背景 原始的返回顶部按钮太小且背景提示色不明显，查看起来不直观。\n修改代码 在assets/sass/_partial/_back-to-top.scss中修改如下配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 .back-to-top { display: none; transition-property: transform; transition-timing-function: ease-out; transition-duration: 0.3s; z-index: 10; background-color: $content-blockquote-backgroud; position: fixed; right: 10px; bottom: 10px; height: 30px; width: 50px; text-align: center; padding-top: 20px; border-radius: 20%; overflow: hidden; \u0026amp;:hover { transform: translateY(-5px); } .icon-up { vertical-align: top; } } 运行效果 改进后的效果如下所示，不仅按钮变大，而且也能根据不同的主题颜色动态的进行改变。\n其它 在assets/sass/_partial/_back-to-top.scss中有如下代码用于控制此按钮只有在非手机浏览器的环境下显示，此方式可用于其它需要在手机浏览器环境禁用的场景。\n1 2 3 4 5 @include max-screen() { .back-to-top { display: none !important; } } 区分Draft与非Draft 背景 有时候会遇到一些典型场景或者灵感突发，想把它们写入博客中，但由于时间限制一时半会又难以完成，可创建对应的markdown文件，将draft设置为true，然后在正常打包时即可排除这些草稿文章，在本地编写时可用类似hugo server -w -D的指令来包含草稿文章。\n当采用hugo server -w -D时在文章列表中不会显示是否为草稿文章，使用上有些不方便\n修改代码 测试assets/sass/_partial/_archive.scss添加如下代码\n1 2 3 .archive-post-status { color: $theme-color; } layouts/_default/section.html中添加如下代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026lt;span class=\u0026#34;archive-post-time\u0026#34;\u0026gt; {{ $element.Date.Format \u0026#34;01-02\u0026#34; }} \u0026lt;/span\u0026gt; \u0026lt;!-- show draft status in none production environment --\u0026gt; {{- if not (in (slice (getenv \u0026#34;HUGO_ENV\u0026#34;) hugo.Environment) \u0026#34;production\u0026#34;) -}} \u0026lt;span class=\u0026#34;archive-post-status\u0026#34;\u0026gt; {{ if .Draft }} \u0026amp;#9711; {{ else }} \u0026amp;#9632; {{ end }} \u0026lt;/span\u0026gt; {{ end }} \u0026lt;span class=\u0026#34;archive-post-title\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;{{ $element.RelPermalink }}\u0026#34; class=\u0026#34;archive-post-link\u0026#34;\u0026gt; {{ .Title }} {{ .Title }} \u0026lt;/a\u0026gt; \u0026lt;/span\u0026gt; layouts/_default/taxonomy.html中添加如下代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026lt;span class=\u0026#34;archive-post-time\u0026#34;\u0026gt; {{ .Date.Format (.Site.Params.dateFormatToUse | default \u0026#34;2006-01-02\u0026#34;) }} \u0026lt;/span\u0026gt; \u0026lt;!-- show draft status in none production environment --\u0026gt; {{- if not (in (slice (getenv \u0026#34;HUGO_ENV\u0026#34;) hugo.Environment) \u0026#34;production\u0026#34;) -}} \u0026lt;span class=\u0026#34;archive-post-status\u0026#34;\u0026gt; {{ if .Draft }} \u0026amp;#9711; {{ else }} \u0026amp;#9632; {{ end }} \u0026lt;/span\u0026gt; {{ end }} \u0026lt;span class=\u0026#34;archive-post-title\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;{{ .RelPermalink }}\u0026#34; class=\u0026#34;archive-post-link\u0026#34;\u0026gt; {{ .Title }} {{ .Title }} \u0026lt;/a\u0026gt; \u0026lt;/span\u0026gt; 运行效果 部署时才添加访问统计 背景 在本地编写博客时，需要多次访问未完成的页面，此种页面没必要添加记录到网站访问次数统计中。\n修改代码 在layouts/partials/scripts.html中修改如下，在最外层添加 if (in (slice (getenv \u0026quot;HUGO_ENV\u0026quot;) hugo.Environment) \u0026quot;production\u0026quot;)来判断环境\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 \u0026lt;!-- only work in production mode --\u0026gt; {{- if (in (slice (getenv \u0026#34;HUGO_ENV\u0026#34;) hugo.Environment) \u0026#34;production\u0026#34;) -}} \u0026lt;!-- Analytics --\u0026gt; {{- if .Site.GoogleAnalytics -}} {{ template \u0026#34;_internal/google_analytics_async.html\u0026#34; . }} {{- end -}} {{- with .Site.Params.baiduAnalytics -}} \u0026lt;script id=\u0026#34;baidu_analytics\u0026#34;\u0026gt; var _hmt = _hmt || []; (function() { if (window.location.hostname === \u0026#39;localhost\u0026#39;) return; var hm = document.createElement(\u0026#34;script\u0026#34;); hm.async = true; hm.src = \u0026#34;https://hm.baidu.com/hm.js?{{.}}\u0026#34;; var s = document.getElementsByTagName(\u0026#34;script\u0026#34;)[0]; s.parentNode.insertBefore(hm, s); })(); \u0026lt;/script\u0026gt; {{- end }} \u0026lt;!-- baidu push --\u0026gt; {{- if .Site.Params.baiduPush -}} \u0026lt;script id=\u0026#34;baidu_push\u0026#34;\u0026gt; (function(){ if (window.location.hostname === \u0026#39;localhost\u0026#39;) return; var bp = document.createElement(\u0026#39;script\u0026#39;); bp.async = true; var curProtocol = window.location.protocol.split(\u0026#39;:\u0026#39;)[0]; if (curProtocol === \u0026#39;https\u0026#39;) { bp.src = \u0026#39;https://zz.bdstatic.com/linksubmit/push.js\u0026#39;; } else { bp.src = \u0026#39;http://push.zhanzhang.baidu.com/push.js\u0026#39;; } var s = document.getElementsByTagName(\u0026#34;script\u0026#34;)[0]; s.parentNode.insertBefore(bp, s); })(); \u0026lt;/script\u0026gt; {{- end }} {{- end -}} 使用方式 在项目部署时通过添加-e \u0026quot;production\u0026quot;来指定为生产环境，如hugo -b \u0026quot;https://lucumt.info/\u0026quot; -e \u0026quot;production\u0026quot;。\nFork me on Github 原始代码来源https://github.com/olOwOlo/hugo-theme-even/pull/4121，参考代码见如何在博客园添加 Fork me on GitHub 彩带效果\n修改代码 config.toml中添加如下配置，若ithubForkURL值为空，则不显示Fork me on GitHub\n1 2 3 [params] githubForkURL = \u0026#34;\u0026#34; # Fork me on Github repository address # Fork me on Github仓库地址 layouts/_default/baseof.html中添加如下代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 {{ with .Site.Params.githubForkURL }} \u0026lt;!-- fork me on github ---\u0026gt; \u0026lt;!-- see https://github.blog/2008-12-19-github-ribbons/ --\u0026gt; \u0026lt;a href=\u0026#34;{{ . }}\u0026#34; title=\u0026#34;{{ . }}\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt; \u0026lt;img style=\u0026#34;position: fixed; top: 0; right: 0; border: 0; z-index:9999;\u0026#34; src=\u0026#34;/forkme_right_gray.png\u0026#34; alt=\u0026#34;Fork me on GitHub\u0026#34;\u0026gt; \u0026lt;/a\u0026gt; {{ end }} \u0026lt;!-- 在此代码块之前添加 --\u0026gt; \u0026lt;main id=\u0026#34;main\u0026#34; class=\u0026#34;main\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;content-wrapper\u0026#34;\u0026gt; static目录下添加一个名为forkme_right_gray.png的图片，\n运行效果 代码块可复制 原始代码来源https://github.com/olOwOlo/hugo-theme-even/pull/413\n修改代码 config.toml中添加如下配置，用于控制是否开启代码复制功能\n1 2 [params] enableCopyCode = true assets/sass/_partial/_post/_code.scss添加如下代码\n1 2 3 4 5 6 7 8 9 10 11 12 .copy-code { position: absolute; right: 0; z-index: 2; font-size: .9em !important; padding: 0px 1.5rem !important; color: #b1b1b1; font-family: Arial; font-weight: bold; cursor: pointer; user-select: none; } 在layouts/partials/scripts.html底部添加如下代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 \u0026lt;!-- copy to clipboard --\u0026gt; {{- if .Site.Params.enableCopyCode -}} \u0026lt;script\u0026gt; function createCopyButton(highlightDiv) { const div = document.createElement(\u0026#34;div\u0026#34;); div.className = \u0026#34;copy-code\u0026#34;; div.innerText = \u0026#34;Copy\u0026#34;; div.addEventListener(\u0026#34;click\u0026#34;, () =\u0026gt; copyCodeToClipboard(div, highlightDiv) ); addCopyButtonToDom(div, highlightDiv); } async function copyCodeToClipboard(button, highlightDiv) { const codeToCopy = highlightDiv.querySelector(\u0026#34;:last-child \u0026gt; .chroma \u0026gt; code\u0026#34;) .innerText; await navigator.clipboard.writeText(codeToCopy); button.blur(); button.innerText = \u0026#34;Copied!\u0026#34;; setTimeout(() =\u0026gt; button.innerText = \u0026#34;Copy\u0026#34;, 2000); } function addCopyButtonToDom(button, highlightDiv) { highlightDiv.insertBefore(button, highlightDiv.firstChild); const wrapper = document.createElement(\u0026#34;div\u0026#34;); wrapper.className = \u0026#34;highlight-wrapper\u0026#34;; highlightDiv.parentNode.insertBefore(wrapper, highlightDiv); wrapper.appendChild(highlightDiv); } var isMobile = /iPhone|iPad|iPod|Android/i.test(navigator.userAgent); if(!isMobile){ document.querySelectorAll(\u0026#34;.highlight\u0026#34;).forEach((highlightDiv) =\u0026gt; createCopyButton(highlightDiv)); } \u0026lt;/script\u0026gt; {{ end }} 运行效果 在非手机浏览器中当开启enableCopyCode开关后，在代码左侧会出现如下效果2\n添加搜索功能 修改代码 此部分的代码主要参考给hugo添加搜索功能基于fuse实现的，由于基于此博文实现的搜索效果展示比较简陋，故个人做了如下改进:\n在layouts/_default/search.html下添加了，用于将搜索结果用博客默认的风格包装起来\n1 {{ define \u0026#34;main\u0026#34; }} … {{ end }} 在layouts/_default/baseof.html实现前述步骤中相关的定义\n1 2 3 4 5 6 7 8 9 10 {{ block \u0026#34;main\u0026#34; . }} \u0026lt;main id=\u0026#34;main\u0026#34; class=\u0026#34;main\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;content-wrapper\u0026#34;\u0026gt; \u0026lt;div id=\u0026#34;content\u0026#34; class=\u0026#34;content\u0026#34;\u0026gt; {{ block \u0026#34;content\u0026#34; . }}{{ end }} \u0026lt;/div\u0026gt; {{ partial \u0026#34;comments.html\u0026#34; . }} \u0026lt;/div\u0026gt; \u0026lt;/main\u0026gt; {{ end }} 在assets/sass/_base.scss添加下述样式，用于分隔显示不同的检索结果\n1 2 3 4 5 6 7 #search-results-info { display: none; } .search_list { border-top: $post-border; } 运行效果3 默认的搜索界面\n输入关键字后，有显示结果的界面\n截至本文编写时(2022年9月)Even主题的作者尚未merge这些pull request\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n此部分的提示文字采用硬编码copy，尚未做成通用的国际化代码\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n由于分词的原因，中文检测结果可能存在一定误差\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/hugo/share-experience-for-using-hugo-even-theme/","tags":["hugo","Go"],"title":"个人Hugo博客关于Even主题的一些使用改进"},{"categories":["持续集成"],"contents":"基于KubeSphere使用心得给部门搭建了dev、sit、test、prod这4套环境之后，一开始使用较为顺利，但随着项目的推进以及开发人员的增多，同时有多个功能模块需要并行开发与测试，导致原有的4套环境不够用。经过一番摸索后，实现了结合Nacos在KubeSphere中动态配置多套环境功能，通过修改Nacos中的JSON配置文件可很容易的从4套扩展为16套甚至更多。\n原实现方式 最开始自己只准备了dev、sit、test、prod这4套环境，由于环境数量不多，对于不同环境的端口配置自己是在代码中直接实现的1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 switch(PRODUCT_PHASE) { case \u0026#34;dev\u0026#34;: env.NODE_PORT = 12002 break case \u0026#34;sit\u0026#34;: env.NODE_PORT = 13002 break case \u0026#34;test\u0026#34;: env.NODE_PORT = 14002 break case \u0026#34;prod\u0026#34;: env.NODE_PORT = 15002 break } 此种方式将相关环境相关的配置全都集中到Jenkins流水线中，在最初的使用阶段可减少配置文件数量，能够快速编写流水线，快速交付使用。但随着项目规模与人员的扩大，当需要灵活配置多套环境时，此种方式采用硬编码的方式会显得捉襟见肘。\n修改后的方式 结合项目实际情况以及避免后续再次修改KubeSphere流水线，为了实现灵活的配置多套环境，自己制定了如下2个规则：\n端口信息存放到配置文件中，KubeSphere在构建时去流水线读取相关配置 当需要扩展环境或修改端口时，不需要修改KubeSphere中的流水线，只需要修改对应的端口配置文件即可2 由于项目中采用Nacos作为配置中心与服务管理平台，故决定采用Nacos作为端口的配置中心，实现流程如下：\n基于上述流程，在个人项目中面临如下问题：\n利用Groovy代码获取Nacos中特定的端口JSON配置文件，并能动态解析 利用Groovy代码根据输入输入参数动态的获取Nacos中对应的namespace 由于环境的增多，不可能每套环境都准备一个YAML文件，此时需要动态的读取并更新YAML文件 安装Pipeline Utility Steps插件 Jenkins默认不支持JSON、YAML的解析，需要在KubeSphere中预先安装Pipeline Utility Steps插件，该插件提供了对JSON、YAML、CSV、PROPERTIES等常见文件格式的读取与修改操作。\nJSON文件设计 JSON文件设计如下，通过env、server、dubbo等属性记录环境和端口信息，通过project来记录具体的项目名称，由于配置文件中的key都是固定的，后续Groovy解析时会较为方便，在需要扩展环境时只需要更新此JSON文件即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 { \u0026#34;portConfig\u0026#34;:[ { \u0026#34;project\u0026#34;:\u0026#34;lucumt-system\u0026#34;, \u0026#34;ports\u0026#34;:[ { \u0026#34;env\u0026#34;:\u0026#34;dev-1\u0026#34;, \u0026#34;server\u0026#34;:12001, \u0026#34;dubbo\u0026#34;:12002 }, { \u0026#34;env\u0026#34;:\u0026#34;dev-2\u0026#34;, \u0026#34;server\u0026#34;:12201, \u0026#34;dubbo\u0026#34;:12202 } ] }, { \u0026#34;project\u0026#34;:\u0026#34;lucumt-idp\u0026#34;, \u0026#34;ports\u0026#34;:[ { \u0026#34;env\u0026#34;:\u0026#34;dev-1\u0026#34;, \u0026#34;server\u0026#34;:13001, \u0026#34;dubbo\u0026#34;:13002 }, { \u0026#34;env\u0026#34;:\u0026#34;dev-2\u0026#34;, \u0026#34;server\u0026#34;:13201, \u0026#34;dubbo\u0026#34;:13202 } ] } ] } 读取namespace 在Nacos Open Api中可知查询namespace的请求为/nacos/v1/console/namespaces，基于Groovy的读取代码如下：\n1 2 3 4 5 6 7 8 response = sh(script: \u0026#34;curl -X GET \u0026#39;http://xxx.xxx.xxx.xxx:8848/nacos/v1/console/namespaces\u0026#39;\u0026#34;, returnStdout: true) jsonData = readJSON text: response namespaces = jsonData.data for(nm in namespaces){ if(BUILD_TYPE==nm.namespaceShowName){ NACOS_NAMESPACE = nm.namespace } } 读取Nacos配置文件 在Nacos Open Api中可知查询配置文件的请求为/nacos/v1/cs/configs，基于Groovy的读取代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 response = sh(script: \u0026#34;curl -X GET \u0026#39;http://xxx.xxx.xxx.xxx:8848/nacos/v1/cs/configs?dataId=idp-custom-config.json\u0026amp;group=idp-custom-config\u0026amp;tenant=0f894ca6-4231-43dd-b9f3-960c02ad20fa\u0026#39;\u0026#34;, returnStdout: true) jsonData = readJSON text: response configs = jsonData.portConfig for(config in configs){ project = config.project if(project!=PROJECT_NAME){ continue } ports = config.ports for(port in ports){ if(port.env!=BUILD_TYPE){ continue } env.NODE_PORT = port.server } } 根据YAML文件 由于自己将项目中变化的部分已经单独抽取为了一个YAML文件，故只需要修改此单独配置文件即可，在修改过程中，处于简化考虑，自己先将原有的YAML文件删除，之后重新写入，相关代码如下\n1 2 3 4 5 6 7 8 yamlFile = \u0026#39;src/main/resources/bootstrap-dev.yml\u0026#39; yamlData = readYaml file: yamlFile yamlData.spring.cloud.nacos.discovery.group = BUILD_TYPE yamlData.spring.cloud.nacos.discovery.namespace = NACOS_NAMESPACE yamlData.spring.cloud.nacos.config.namespace = NACOS_NAMESPACE sh \u0026#34;rm $yamlFile\u0026#34; writeYaml file: yamlFile, data: yamlData 运行效果 上述的配置均需要在项目编译之前进行，配置完毕的流水线运行效果如下，程序可正常运行，改造目的实现。\n参考代码 前端Jenkins流水线，参见lucumt-system-web-new.groovy 后端Jenkins流水线，参见lucumt-system-new.groovy 参见lucumt-system.groovy\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n在个人项目中Jenkins流水线不需要修改，但需要修改Kubesphere中的默认输入配置，将新增的环境加到下拉列表中，便于使用\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/devops/using-nacos-and-kubesphere-to-create-multiple-environments/","tags":["kubesphere","jenkins","nacos"],"title":"利用Nacos与KubeSphere创建多套开发与测试环境"},{"categories":["位操作","Java编程"],"contents":"近期在工作中遇到由于HTTP返回的内容较多导致系统响应延迟的问题，最终自己结合gzip、Protocol Buffers、位运算等将HTTP响应返回的数据从15M减少到1M从而解决系统无卡顿问题。其中对于位运算部分自己是结合业务实际，将3个小型int转化为1个long，将数据量减少三分之一，简单记录下其实现(以Java实现为例)。\n背景 某个项目模块要将一系列的坐标数据返回给前端页面，坐标数据由x、y、z这3个维度来定义且用float表示，它们的约束条件如下：\n$|x|$\u0026lt;150、$|y|$\u0026lt;50、$|z|$\u0026lt;50\n示例文件如下：\n1 2 3 4 5 123.45\t34.56\t23.78 111.35\t-32.56\t21.78 103.77\t24.83\t-13.78 #...共有超过10万行数据 99.83\t21.35\t43.39 最开始自己是采用自己是将它们逐行读取并以String的形式封装到JSON中返回给前端，此种原始的方式很明显会导致返回给前端的数据量巨大从而严重影响性能。\n接下来自己从如下几个方面着手优化\n将返回的数据从String转化为float，减少整体响应的字节数 采用gzip压缩，将响应数据的体积缩小到原始的三分之一 采用Protocol Buffers在加快解析速度的同时进一步缩小请求响应的数据包体积 通过上述操作之后，响应速度从原来的4-5s缩短到1s之内，基本上达到优化目的，在后续的总结中发现请求响应慢的主要原因是由于响应头的体积过大造成的，于是继续寻找减少响应体积的办法。\n分析 在Java中int和float都占用4个字节共32bit位，将上述示例文件中的坐标数据从float转化为int并不会造成响应数据的体积变化，但由于业务的特殊性限制了x、y、z这3个坐标的取值范围(有前述所述的范围限制)，尝试分析它们的占用的最大bit位数：\n1 2 3 x = 14999 = 0b100100100111101111 // 占用18bit位 y = 4999 = 0b1100001101001111 // 占用16bit位 z = 4999 = 0b1100001101001111 // 占用16bit位 在不考虑负数的情况下，x、y、z累计占用的bit位数为50，而一个long类型占用8个字节共64bit位，理论分析是可以将3个int合并为1个long型数据。\n存储设计 考虑到坐标数据可能有负数,可用1个bit位专门记录对应的坐标数是否为负数，此时加上正负数的标记也总共只占用53个bit位，没有超过单个long型数据的最大bit位数。\n从便于编码的角度对x、y、z在long型中的存储做出如下划分:\n每个int占用20个bit位，最前面一个bit位记录正负数(为正数时该bit位为0，为负数时该bit位为1)\n移位操作 前述理论分析可能，但在实际操作过程中会遇到如下2个问题：\n如何在对应的正负数标识bit位上写入和读取值 如何给特定的坐标值准确写入对应的bit位且能准确读取 结合位运算本身特性以及实际业务需求，上述问题的解决方案如下：\n若特定坐标为负数，可将第20或40或60bit位设置为1\n为了准确记录各坐标数的值，需要将它们与一个类似0b1111111111111111111（十六进制表示为0x7ffff）的基准值进行\u0026amp;运算，由于要在单个long中记录下3个int的数值，此时就涉及到对坐标数据进行移位运算，如下图所示\n具体的分析如下：\nx为第3个存储，需要与0b10000000000000000000做|运算来记录正负数，需要与0b01111111111111111111做\u0026amp;来记录具体值 y为第2个存储，需要与0b1000000000000000000000000000000000000000做|运算来记录正负数，需要与0b0111111111111111111111111111111111111111做\u0026amp;来记录具体值 z为第1个存储，需要与0b100000000000000000000000000000000000000000000000000000000000做|运算来记录正负数，需要与0b011111111111111111111111111111111111111111111111111111111111做\u0026amp;来记录具体值 上述涉及到的6个基准数据用二进制表示太复杂，其精简表示如下：\n0b10000000000000000000 =\u0026gt; 1\u0026lt;\u0026lt;19 0b1000000000000000000000000000000000000000 =\u0026gt; 1L\u0026lt;\u0026lt;391 0b100000000000000000000000000000000000000000000000000000000000=\u0026gt; 1L\u0026lt;\u0026lt;59 0b01111111111111111111 =\u0026gt; 0x7ffff 0b0111111111111111111111111111111111111111 =\u0026gt; 0x7ffffL\u0026lt;\u0026lt;20 0b011111111111111111111111111111111111111111111111111111111111= \u0026gt;0x7ffffL\u0026lt;\u0026lt;40 若用position2表示第几个坐标数，则基准数据可进一步精简如下：\n正负数的记录位1L \u0026lt;\u0026lt; (position * 20 - 1) 数据值的记录位0x7ffffL \u0026lt;\u0026lt; ((position - 1) * 20) 实现 基于前述分析过程，坐标数据写入的代码如下，需要注意的是在写入过程中要传递一个类型为long的target3变量，通过target变量来记录对应的坐标的具体数据和正负数标识。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public static long bitWrite(int position, long original, long target) { // 记录是否为正负数的标识位 long typeBase = 1L \u0026lt;\u0026lt; (position * 20 - 1); // 记录具体的坐标数值 long valueBase = 0x7ffffL \u0026lt;\u0026lt; ((position - 1) * 20); // 若为负数，则需要将对应标识位记为1，同时将其变为正数 if (original \u0026lt; 0) { target = target | typeBase; original = -original; } // 坐标数与数据值bit位做或操作记录下其值 original = original \u0026lt;\u0026lt; (position - 1) * 20; original = original \u0026amp; valueBase; // 将坐标数写入long型结果中 target = target | original; return target; } 坐标数据的读取过程则是写入操作的反向操作，需要将\u0026amp;变为|，将|变为\u0026amp;，同写入操作类似，需要传入之前写入的target变量，以便程序反向识别出相关数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public static long bitRead(int position, long target) { long value; long typeBase = 1L \u0026lt;\u0026lt; (position * 20 - 1); //识别是否为负数 boolean isNegative = (target \u0026amp; typeBase) == typeBase; // 读取具体的数值，此时读取的均为正数 long valueBase = 0x7ffffL \u0026lt;\u0026lt; ((position - 1) * 20); value = target \u0026amp; valueBase; value = value \u0026gt;\u0026gt; (position - 1) * 20; // 若为负数，则要进行恢复操作 if (isNegative) { value = -value; } return value; } 基于上述方法利用如下代码进行测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 public static void testData() { int x = -14997; int y = 3349; int z = -2377; long target = 0; target = bitWrite(1, x, target); target = bitWrite(2, y, target); target = bitWrite(3, z, target); System.out.println(Long.toBinaryString(target)); System.out.println(bitRead(1, target)); System.out.println(bitRead(2, target)); System.out.println(bitRead(3, target)); } 测试结果如下，程序输出结果符合预期\n完整代码参见SmallIntBitCompressTest.java\n由于int型最大的位数为32位，左移39位时超过其限制会编译出错，故需要使用1L\u0026lt;\u0026lt;39替代1\u0026lt;\u0026lt;39\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n与Java中的下标表示保持一致，position从0开始，故其值只能为0、1、2三者之一\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ntarget变量的类型初始值需要设置为0\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/bit/merge-three-int-number-into-a-long-number/","tags":["bit"],"title":"将3个小int整数合并到1个long中从而缩小数据量"},{"categories":["持续集成"],"contents":"之前在公司内部推广KubeSphere用于持续集成和部署，取得了不错的反馈，考虑到大规模使用的便利性以及之前已有LDAP整合其它系统的成熟经验，很自然的想将LDAP集成到KubeSphere中。原以为会很容易，一番折腾下来费了不好功夫(KubeSphere要求使用LDAP时必须设置管理员账号和密码)，简单记录下。\n公司内部的LDAP系统支持匿名登录，在给其它系统(如yapi)集成LDAP时，只需要输入对应的host、uid、searchDN即可，整合起来十分便捷，类似如下：\n1 2 3 4 5 6 7 \u0026#34;ldapLogin\u0026#34;:{ \u0026#34;enable\u0026#34;:\u0026#34;true\u0026#34;, \u0026#34;server\u0026#34;:\u0026#34;ldap://192.168.0.2:389\u0026#34;, \u0026#34;searchDn\u0026#34;:\u0026#34;dc=lucumt,dc=info\u0026#34;, \u0026#34;searchStandard\u0026#34;:\u0026#34;uid\u0026#34;, \u0026#34;usernameKey\u0026#34;:\u0026#34;uid\u0026#34; } 公司内部的KubeSphere版本为v3.1.1，在集成LDAP之前先去官网查看了相关说明，在LDAP身份提供者中有如下说明：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 spec: authentication: jwtSecret: \u0026#39;\u0026#39; maximumClockSkew: 10s multipleLogin: true oauthOptions: accessTokenMaxAge: 1h accessTokenInactivityTimeout: 30m identityProviders: - name: LDAP type: LDAPIdentityProvider mappingMethod: auto provider: host: 192.168.0.2:389 managerDN: uid=root,cn=users,dc=nas managerPassword: ******** userSearchBase: cn=users,dc=nas loginAttribute: uid mailAttribute: mail 可以看出其默认多了managerDN和managerPassword这两个管理员属性，但由于公司的LDAP默认对外不提供管理员账号和密码，只能匿名登录认证，且自己之前在其它系统中匿名配置LDAP都很顺畅，于是通过匿名方式配置如下：\n1 2 3 4 5 6 7 provider: host: 192.168.1.22:389 #managerDN: uid=root,cn=users,dc=nas #managerPassword: ******** userSearchBase: dc=lucumt,dc=info loginAttribute: uid mailAttribute: mail 将官方文档中要求的managerDN和managerPassword屏蔽掉，接着重启KubeSphere系统，登录过程出现如下提示：\n错误信息提示说密码不能为空，但是我们登录的时候肯定有输入密码的，那只可能是managerPassword为空导致的。\n查找KubeSphere官网相关说明发现其对于managerDN和managerPassword没有说明是选填项，结合前面的报错信息，可得出如下结论\nKubeSphere不支持LDAP匿名登录\n于是只能找公司相关部门申请LDAP具有只读账号的管理员权限，配置类似如下，之后重启KubeSphere可正常集成LDAP登录。\n1 2 3 4 5 6 7 provider: host: 192.168.1.22:389 managerDN: admin=cn,dc=lucumt,dc=info managerPassword: ******** userSearchBase: dc=lucumt,dc=info loginAttribute: uid mailAttribute: mail 只能说KubeSphere在这方面做的不太好，已经在其官网反馈此问题!\n","permalink":"https://lucumt.info/post/devops/setting-ldap-for-kubesphere/","tags":["kubesphere","jenkins","LDAP"],"title":"Kubesphere集成LDAP踩坑记录"},{"categories":["个人博客"],"contents":"作为一名IT民工，善于利用各种工具提升工作效率才算合格，本文简单记录自己如何利用GitHub Actions实现个人Hugo博客在GitHub Pages中的自动化部署。\n传统方式 自己的个人博客创建于2016年，在这期间自己一直基于如下方式创建并部署更新博客：\n利用hugo命令创建对应的博客markdown文件\nhugo new post/hugo/using-github-action-to-auto-build-deploy.md\n利用下述命令开启hugo博客的动态监听展示，并进行编写\nhugo server -w -D\n博客内容编写完成后，利用下述命令将其切换到实际部署环境\nhugo server --baseUrl=\u0026quot;https://lucumt.info/\u0026quot; --watch=false --appendPort=false --renderToDisk --environment production\n执行下述命令提交到master分支\ngit add -A git commit -a -m \u0026quot;xxxx\u0026quot; git push origin master 利用下述命令将public目录中的内容从master 分支同步到gh-pages分支\ngit subtree push --prefix=public git@github.com:lucumt/ghblog.git gh-pages\n上述过程中的1,2,4阶段是编写博客的必经阶段，而3,5阶段其实没太多必要，完全可以用工具自动化实现。作为IT从业者，我们需要尽可能的减少不必要的操作。\n改进方式 结合网络上的相关资料，自己把实现方案定在了GitHub Actions和Travis CI二者之一，考虑到GitHub中已经内置了GitHub Actions ，最终解决采用其作为实现方案。\n在Hugo的官方文档Build Hugo With GitHub Action中也推荐采用GitHub Actions作为持续集成部署方案，并提供了相应的流水线配置代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 name: github pages on: push: branches: - main # Set a branch to deploy pull_request: jobs: deploy: runs-on: ubuntu-20.04 steps: - uses: actions/checkout@v2 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;latest\u0026#39; # extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 if: github.ref == \u0026#39;refs/heads/main\u0026#39; with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_dir: ./public 该配置代码已经很完善，个人根据实际情况对其做了如下修改：\n在Build阶段，将hugo命令改为适合个人环境的hugo -b \u0026quot;https://lucumt.info/\u0026quot; -e \u0026quot;production\u0026quot; 在个人GitHub中设置github_token 其中关于github_token的配置可按如下步骤配置：\n在个人GitHub页面，依次点击Settings-\u0026gt;Developer settings-\u0026gt;Personal access tokens进入如下页面：\n点击Generate new token出现如下界面，在Note中输入名称，在Select scopes选择workflow\n将生成的token复制出来为后续创建secret做准备，注意必须及时复制，一旦离开此页面后续就无法查看其值，只能重新创建新token：\n进入对应的GitHub项目下，依次点击Settings-\u0026gt;Secrets-\u0026gt;Actions进入添加Action secrets的界面，点击New repository secret按钮\n在出现的界面中name部分输入我们设置的值，Secret部分输入步骤3中记录的token值，然后点击Add secret按钮\n需要注意的是name的值不能以GITHUB_开头，否则创建会出错\n在流水线中将github_token值设置为步骤5中secret的名称，类似${{ secrets.GH_PAGE_ACTION_TOKEN }}s，至此github_token设置过程完毕。\n配置后完整的流水线代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 name: pages-auto-build-deploy on: # workflow_dispatch: push: branches: - master jobs: build-and-deploy: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 with: submodules: true fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;0.100.2\u0026#39; extended: true - name: Build Hugo run: hugo -b \u0026#34;https://lucumt.info/\u0026#34; -e \u0026#34;production\u0026#34; - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.GH_PAGE_ACTION_TOKEN }} publish_dir: ./public commit_message: ${{ github.event.head_commit.message }} 将该yaml文件放到对应GitHub项目下的.github/workflows目录下即完成全部配置。\n当执行git push origin master后，GitHub Actions会开启自动构建部署，运行结果如下，至此整个设置过程完毕！\n其它 由于GitHub Action支持定时语法，将流水线触发条件修改如下\n1 2 3 4 5 6 7 on: push: branches: - master schedule: # Runs everyday at 8:00 AM - cron: \u0026#34;0 8 * * *\u0026#34; 可实现每天上午8点自动触发构建，由于构建过程中会往gh-pages分支下提交代码，从而间接达成在GitHub中每天提交代码，在GitHub主页面展示时保持全绿的功能！1\n参考文档:\nhttps://www.ruanyifeng.com/blog/2019/09/getting-started-with-github-actions.html https://www.pseudoyu.com/zh/2022/05/29/deploy_your_blog_using_hugo_and_github_action/ 个人观点质量优于数量，不推荐这么做\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/hugo/using-github-action-to-auto-build-deploy/","tags":["hugo","github-pages","go"],"title":"利用GitHub Action实现Hugo博客在GitHub Pages自动部署"},{"categories":["Java编程"],"contents":"公司项目采用MinIO作为数据存储，最近遇到一个需求是将其中的某个文件夹的数据基于其原有的结构下载为ZIP文件，网上有很多下载为ZIP的代码，个人觉得其中好多不够精简，简单记录下自己的实现。\n文件夹下载 该文件夹在MinIO中存储的路径为2022-07/80/iodp-dataset-demo，其下包含多个文件夹\n在特定文件夹下包含多个数据文件\n由于在MinIO中是按照文件夹存储，一开始自己很显然的是想用直接去MinIO官网查看有没有直接下载文件夹的方式，在其官网java-client-api-reference中没有找到支持文件夹下载的方式。\n接下来自己通过ListObjectsArgs传入文件夹名称2022-07/80/iodp-dataset-demo的方式想一次性把文件都获取到，在此种方式下程序执行结果为空。\n至此，可知道 MinIO不支持原生的文件夹下载，只能按照文件挨个下载，为了获取所有文件，需要通过递归程序实现，相关代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 @Log4j2 @Service public class MinioServiceImpl implements IMinioService { @Autowired private MinioClient mClient; @Override public InputStream downloadFile(String fileName, String bucket) { GetObjectArgs getArgs = GetObjectArgs.builder().bucket(bucket).object(fileName).build(); try { InputStream is = mClient.getObject(getArgs); return is; } catch (ErrorResponseException | InsufficientDataException | InternalException | InvalidKeyException | InvalidResponseException | IOException | NoSuchAlgorithmException | ServerException | XmlParserException e) { throw new RuntimeException(e); } } @Override public List\u0026lt;String\u0026gt; listFolderFiles(String folderName, String bucket) { List\u0026lt;String\u0026gt; fileList = new ArrayList\u0026lt;\u0026gt;(); listFolderFiles(folderName, bucket, fileList); return fileList; } private void listFolderFiles(String folderName, String bucket, List\u0026lt;String\u0026gt; fileList) { ListObjectsArgs listArgs = ListObjectsArgs.builder().bucket(bucket).prefix(folderName).build(); Iterable\u0026lt;Result\u0026lt;Item\u0026gt;\u0026gt; results = mClient.listObjects(listArgs); try { for (Result\u0026lt;Item\u0026gt; result : results) { Item item = result.get(); String objectName = item.objectName(); if (item.isDir()) { // 采用递归的方式遍历文件夹 listFolderFiles(objectName, bucket, fileList); } else { fileList.add(objectName); } } } catch (ErrorResponseException | InsufficientDataException | InternalException | InvalidKeyException | InvalidResponseException | IOException | NoSuchAlgorithmException | ServerException | XmlParserException e) { throw new RuntimeException(e); } } } 基于上述代码从MinIO中返回的文件信息类似如下所示：\n写入ZIP文件 由于MinIO中返回的文件信息已经具有层级结构，故在进行ZIP压缩时可基于文件路径直接设置其存储位置1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @Override public void downloadDataset(int id, HttpServletResponse response) { DatasetModel dsModel = queryDataset(id); String path = dsModel.getPath(); int prefixLen = StringUtils.substringBeforeLast(path, \u0026#34;/\u0026#34;).length(); // 设置文件名 String zipFileName = StringUtils.substringAfterLast(path, \u0026#34;/\u0026#34;) + \u0026#34;.zip\u0026#34;; response.setCharacterEncoding(\u0026#34;UTF-8\u0026#34;); response.setContentType(\u0026#34;application/octet-stream\u0026#34;); try { response.addHeader(\u0026#34;Content-Disposition\u0026#34;, \u0026#34;attachment;filename=\u0026#34; + URLEncoder.encode(zipFileName, \u0026#34;UTF-8\u0026#34;)); } catch (UnsupportedEncodingException e) { throw new RuntimeException(e); } List\u0026lt;String\u0026gt; fileList = minioService.listFolderFiles(path, collectFilesBucket); try (OutputStream out = response.getOutputStream(); ZipOutputStream zs = new ZipOutputStream(new BufferedOutputStream(out))) { for (String filePath : fileList) { String fileName = filePath.substring(prefixLen + 1); InputStream is = minioService.downloadFile(filePath, collectFilesBucket); ZipEntry entry = new ZipEntry(fileName); zs.putNextEntry(entry); IOUtils.copy(is, zs); zs.closeEntry(); } zs.setMethod(ZipOutputStream.DEFLATED); //设置压缩方法 } catch (Exception e) { e.printStackTrace(); } } 下载后的ZIP文件如下所示，可见其层级结构与MinIO中原始存储的层级结构相同，功能正常实现。\n通过new ZipEntry(fileName)在fileName中指定其完整路径即可实现\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/minio/download-minio-folder-as-zip-file/","tags":["MinIO","Java"],"title":"将MinIO中的文件夹下载为ZIP文件"},{"categories":["持续集成","容器化"],"contents":"近期在公司内部搭建基于KubeSphere的持续集成平台时，发现其底层的Kubernetes默认的端口范围为30000-32767而公司有多个采用微服务模块的项目在使用，默认的端口范围不便于分配使用，在基于网上文档修改的过程中自己踩到了一个坑，简单记录下。\n一开始时自己也是从网上查找相关资料，查找出来的结果和修改NodePort的范围中的基本都相同，自己也是按照其对应的方法进行操作:\n将/etc/kubernetes/manifests/目录下的kube-apiserver.yaml在当前目录下备份一份kube-apiserver.yaml.bak作为备份文件\n在kube-apiserver.yaml中加入--service-node-port-range=1-65537\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 apiVersion: v1 kind: Pod metadata: creationTimestamp: null labels: component: kube-apiserver tier: control-plane name: kube-apiserver namespace: kube-system spec: containers: - command: - kube-apiserver - --service-node-port-range=1-65537 # other config 之后执行下述命令来重启api-server\n1 2 3 4 # 获得 apiserver 的 pod 名字 export apiserver_pods=$(kubectl get pods --selector=component=kube-apiserver -n kube-system --output=jsonpath={.items..metadata.name}) # 删除 apiserver 的 pod kubectl delete pod $apiserver_pods -n kube-system 然后执行kubectl describe pod $apiserver_pods -n kube-system | grep \u0026quot;service-node-port-range\u0026quot;却发现输出结果为空，也就是说自己添加的动态端口配置并没有生效！\n之后搜索网上的各种解决方案，都是和前述的操作类似，尝试后都不生效，没办法只能继续搜索，直到发现https://www.modb.pro/db/146676这篇文章，在其中有如下说明\n之后检查自己系统的/etc/kubernetes/manifests/目录，发现果然有备份文件!\n将备份文件删除后，重新执行kubectl delete pod $apiserver_pods -n kube-system，经过若干秒的等待后，发现service-node-port-range已经生效，至此问题解决!\n总结：\n虽然这次问题是由于备份文件引起的，但是在Linux中修改重要配置文件时提前进行备份是个好习惯，从这次修改过程中学到的经验是不要在同目录下备份，要去专门的目录下备份。 Kubernetes底层的动态加载配置文件的原理需要进一步学习！ 感谢https://www.modb.pro/db/146676的作者埋头过坎，由于其无私分享避免了我走更多的弯路。 ","permalink":"https://lucumt.info/post/k8s/service-node-port-range-config-not-working-in-k8s/","tags":["kubernetes"],"title":"在Kubernetes中配置service-node-port-range不生效的问题"},{"categories":["持续集成"],"contents":"目前公司的开发方式都是手工编译\u0026amp;部署，十分低效，最近将Web开发相关的项目都基于KubeSphere通过基于Jenkins的流水线方式实现了自动部署，在此过程中遇到了一些阻塞点，简单记录下它们的解决方案。\n在KubeSphere的Github仓库中有如下说明：\nKubeSphere是什么\nKubeSphere 愿景是打造一个以 Kubernetes 为内核的 云原生分布式操作系统，它的架构可以非常方便地使第三方应用与云原生生态组件进行即插即用（plug-and-play）的集成，支持云原生应用在多云与多集群的统一分发和运维管理。 KubeSphere 也是一个多租户容器平台，提供全栈的 IT 自动化运维的能力，简化企业的 DevOps 工作流\nKubernetes DevOps\n提供开箱即用的基于 Jenkins 的 CI/CD，并内置自动化流水线插件，包括 Binary-to-Image (B2I) 和 Source-to-Image (S2I)\n从上述描述可知KubeSphere的两大底层支柱为Kubernetes与Jenkins，本文也主要基于这两部分进行记录。\n流水线设计 基于部门现状以及参考网上资料，将产品部署环境划分为如下4种类型:\ndev，本地开发阶段 sit，前后端各模块联调阶段 test，软件功能测试阶段 prod，正式使用阶段 虽然通过上述划分方式可有效的避免不同环境的互相干扰，但由于目前部门大部分产品都采用了微服务实现，软件架构类似下图所示，每个微服务模块都有单独的代码管理，导致若给前后端的每个功能模块在不同环境下都配置一套Jenkins流水线则实际的流水线数目会十分庞大，不便于管理和维护。\n若对于每个功能模块在所有不同环境中都分别使用一套流水线，则其数量为功能模块数X环境种类数，造成流水线数目过大，使用不便同时也不利于后期的维护。\n基于此，我们对Jenkins流水线的构建和使用方式提出了如下要求：\n一套Gitlab代码库对应一条Jenkins流水线，实际上就是前后端的一个功能模块，使用时可动态选择分支 一套Jenkins流水线可以根据使用需求灵活的往dev、sit、test、prod这4套环境之一进行部署 dev、sit、test、prod对于同一套代码而言是分别部署的，即4套环境互不影响 动态参数 上图展示了Jenkins进行软件构建的主要流程，从中可知若达到上述精简流水线条目的要求，则需要进行动态参数配置，基于项目实际情况，整理出如下场景：\n软件版本，主要是后端基于Maven的项目需要正确的获取版本号 容器端口，SpringBoot应用程序对外暴露的端口，此部分需要在使用Dockerfile构建时动态对外暴露1 容器端口，Kubernetes中创建容器时对外暴露的端口，主要用于程序访问 镜像版本，前后端程序构建镜像时，对应tag的动态设置 在Jenkins中的脚本类型主要有shell脚本和script脚本2种类型，其中script是基于Grovvy实现的，而Groovy是基于JVM实现的，其在时使用上比shell更灵活，故在流水线实现时对于参数设置与获取确定了一个如下的大致原则:\n能通过Groovy脚本获取的变量与参数尽量通过Grovvy获取，Shell脚本只负责使用\nscript中定义参数 在script中输入符合 Groovy语法的代码即可，为了在多个steps之间实现参数共享，需要在定义参数时加上env.前缀2，类似如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 switch(PRODUCT_PHASE) { case \u0026#34;sit\u0026#34;: env.NODE_PORT = 13003 env.DUBBO_PORT = 13903 break case \u0026#34;test\u0026#34;: env.NODE_PORT = 14003 env.DUBBO_PORT = 14903 break case \u0026#34;prod\u0026#34;: env.NODE_PORT = 15003 env.DUBBO_PORT = 15903 break } env.DUBBO_IP = \u0026#34;10.30.5.170\u0026#34; script中读取参数 1 print env.DUBBO_IP shell中读取参数 需要采用$参数名(去掉env.前缀)的方式，类似如下\n1 2 3 4 5 6 docker build -f kubesphere/Dockerfile \\ -t idp-data:$BUILD_TAG \\ --build-arg PROJECT_VERSION=$PROJECT_VERSION \\ --build-arg NODE_PORT=$NODE_PORT \\ --build-arg DUBBO_PORT=$DUBBO_PORT \\ --build-arg PRODUCT_PHASE=$PRODUCT_PHASE . yaml文件中读取参数 在Kubernetes中需要一个yaml文件来配置要生成的pod，其参数的获取也是采用$参数名的方式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 spec: ports: - name: http port: $NODE_PORT protocol: TCP targetPort: $NODE_PORT nodePort: $NODE_PORT - name: dubbo port: $DUBBO_PORT protocol: TCP targetPort: $DUBBO_PORT nodePort: $DUBBO_PORT selector: app: lucumt-data-$PRODUCT_PHASE sessionAffinity: None type: NodePort Dockerfile中读取参数 当在docker的build阶段传递正确的参数后，在Dockerfile中需要采用${参数名}的方式获取参数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 基础镜像 FROM openjdk:8-jdk # author LABEL maintainer=luyunqiang # 创建目录 RUN mkdir -p /home/lucumt # 指定路径 WORKDIR /home/lucumt ARG PRODUCT_PHASE ARG NODE_PORT ARG DUBBO_PORT ENV PARAMS=\u0026#34;--server.port=${NODE_PORT} --spring.application.name=lucumt-data --spring.profiles.active=${PRODUCT_PHASE} --dubbo.protocol.port=${DUBBO_PORT}\u0026#34; RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \u0026amp;\u0026amp; echo \u0026#39;Asia/Shanghai\u0026#39; \u0026gt;/etc/timezone 编译与部署 由于公司研发环境与互联网隔离，故需要在前后端分别设置可用的镜像才能确保编译正常。\n前端 Nodejs版本号升级：\n由于KubeSphere中的Node.js的版本落后于项目中使用的版本，故需要通过如下命令升级其版本：\nnpm install node@16.13.1 --registry https://mirrors.xxx.com/repository/NPM/\nNginx默认的端口为80，且其默认的conf文件较为简陋，为了实现nginx的个性化配置，可以自己预先配置好一个conf文件，然后在docker构建时，将其覆盖即可\n1 2 3 4 5 6 7 8 9 10 FROM nginx RUN mkdir -p /usr/share/nginx/html/lucumt-web COPY dist /usr/share/nginx/html/lucumt-web # 采用自己定义的配置文件 COPY kubesphere/idp.conf /etc/nginx/conf.d/ EXPOSE 8080 后端 获取Maven版本号：\n1 mvn help:evaluate -Dexpression=project.version -q -DforceStdout 由于在shell中不方便定义全局变量，而Maven的版本号只能在执行相关命令时获取，为了实现版本号的共享，可将两者结合起来，在shell中利用maven命令获取版本号，然后再由Groovy脚本将其赋值为全局环境变量:\n1 2 3 env.PROJECT_VERSION = sh(script: \u0026#39;mvn help:evaluate -Dexpression=project.version -q -DforceStdout\u0026#39;, returnStdout: true) env.BUILD_TIME = new Date().format(\u0026#34;yyyyMMdd-HHmmss\u0026#34;) env.BUILD_TAG = PROJECT_VERSION + \u0026#34;-\u0026#34; + BUILD_TIME K8S容器探活 KubeSphere对于容器的启动、就绪和存活的探测依赖于Kubernetes的相关实现，实际使用中KubeSphere只需要能正常检测到就绪状态即可，现阶段项目中也只基于就绪探测来实现。\n后端 SpringBoot程序可基于Spring Boot Actuator中提供的actuator/health进行就绪检测，相关配置如下:\n1 2 3 4 5 6 7 8 9 containers: - image: \u0026#39;$REGISTRY/$DOCKERHUB_NAMESPACE/lucumt-system:${BUILD_TAG}\u0026#39; readinessProbe: httpGet: path: lucumt-system/actuator/health port: $NODE_PORT timeoutSeconds: 10 failureThreshold: 30 periodSeconds: 5 前端 由于前端没有单独的接口对外暴露，故可采用在Docker容器中执行linux命令的方式来检测是否就绪，个人采用uname，相关配置如下：\n1 2 3 4 5 6 7 8 9 containers: - image: \u0026#39;$REGISTRY/$DOCKERHUB_NAMESPACE/lucumt-system-web:${BUILD_TAG}\u0026#39; readinessProbe: exec: command: - uname timeoutSeconds: 10 failureThreshold: 30 periodSeconds: 5 运行效果 运行效果如下，可实现动态的指定测试阶段和代码分支：\n参考代码 前端部分: Dockerfile，参见lucumt-common-web.dockerfile depoly.yml，参见lucumt-common-web.yaml Jenkins流水线，参见lucumt-common-web.groovy Nginx配置文件，参见lucumt-common-web-nginx.conf 后端部分: Dockerfile，参见lucumt-system.dockerfile depoly.yml，参见lucumt-system.yaml Jenkins流水线，参见lucumt-system.groovy 参考:\nhttps://askubuntu.com/questions/76808/how-do-i-use-variables-in-a-sed-command 理论上来说此处的端口不用暴露，只需要在容器创建时进行对应的端口映射即可，不过由于公司项目采用nacos进行动态配置与服务发现，为了方便统一管理，故也将此处的端口做成动态配置\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n实际测试发现不加env.也能在其它的步骤中正常获取\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/devops/share-experiences-for-using-kubesphere/","tags":["kubesphere","jenkins"],"title":"KubeSphere使用心得"},{"categories":["容器化"],"contents":"由于公司的docker容器在运行一段时间后日志变得很大，通过shell脚本或者结合docker stop、docker rm和docker run来重新创建实例方式都觉得太麻烦，按照网络上的建议在/etc/docker/daemon.json中进行相关修改后却一直无法启动，同时错误信息一直提示unable to configure the Docker daemon with file /etc/docker/daemon.json: the following directives are specified both as a flag and in the config…e: json-file)，经过一番排查后终于找到原因，故记录下。\n问题复现 系统环境 操作系统，uname -a输出如下：\n1 Linux AEHPD 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux docker info输出的主要信息如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Containers: 0 Running: 0 Paused: 0 Stopped: 0 Images: 0 Server Version: 1.13.1 Storage Driver: overlay2 Backing Filesystem: xfs Supports d_type: true Native Overlay Diff: true Logging Driver: journald Cgroup Driver: systemd Plugins: Volume: local Network: bridge host macvlan null overlay Swarm: inactive Runtimes: docker-runc runc Default Runtime: docker-runc 操作过程 在/etc/docker/daemon.json的配置如下:\n1 2 3 4 5 6 7 8 { \u0026#34;registry-mirrors\u0026#34;:[\u0026#34;https://docker.hirain.com\u0026#34;], \u0026#34;log-driver\u0026#34;: \u0026#34;json-file\u0026#34;, \u0026#34;log-opts\u0026#34;: { \u0026#34;max-size\u0026#34;: \u0026#34;50m\u0026#34;, \u0026#34;max-file\u0026#34;:\u0026#34;3\u0026#34; } } 之后执行systemctl daemon-reload \u0026amp;\u0026amp; systemctl restart docker会提示docker启动失败，根据输出提示利用systemctl status docker.service获取详细的输出信息如下:\n从输出中可看见系统提示如下报错信息:\nunable to configure the Docker daemon with file /etc/docker/daemon.json: the following directives are specified both as a flag and in the config\u0026hellip;e: json-file)\n基于前述步骤的提示信息，在/etc/docker/daemon.json移除\u0026quot;log-driver\u0026quot;: \u0026quot;json-file\u0026quot;这行配置然后执行相关命令重启会发现 docker依旧启动失败！\n从输出中可看见如下提示信息:\ndockerd-current[14912]: Failed to set log opts: unknown log opt \u0026lsquo;max-size\u0026rsquo; for journald log driver\n在/etc/docker/daemon.json将log-opts相关配置移除后，发现docker能启动成功！至此可以得出如下2条结论:\nlog-driver配置由于与其它指令冲突了，导致docker服务无法启动，后续去docker官网查询也确实有此说明1 log-opts单独在/etc/docker/daemon.json也不生效 排查与解决 在可正常启动docker服务的环境下利用docker info --format '{{.LoggingDriver}}'命令发现其输出为journald，显然之前的log-driver配置与其冲突了，从而导致docker`服务无法启动\n前面的步骤中提示有/etc/docker/seccomp.json ，查看其中的内容没有发现有价值的信息\n通过systemctl status docker.service -l输出如下，在其中发现关键信息--log-driver=journald ，很明显是其它地方有对应设置\n查找网络资料，利用cat /lib/systemd/system/docker.service查看是由有其它配置文件，发现配置文件 /etc/sysconfig/docker\n输出 /etc/sysconfig/docker结果如下，发现关键信息--log-driver=journald ，它就是我们之前修改/etc/docker/daemon.json后一直无法启动的罪魁祸首！\n接下来在/etc/sysconfig/docker中的相关位置将--log-driver=journald 这条指令去掉，然后在/etc/docker/daemon.json中重新加上相关之后后docker容器可正常启动，问题解决！\nTroubleshoot conflicts between the daemon.json and startup scripts\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/docker/can-not-set-log-driver-and-log-opts-in-docker-daemon-json/","tags":["docker"],"title":"由于daemon.json中的配置与其它启动项冲突导致docker服务无法启动"},{"categories":["个人博客"],"contents":"自己一直特别羡慕博客园上某些博主的博文样式（如武培轩,JavaGuide)，这些博文样式第一眼看起来就很清爽,让人很有阅读的欲望，而我总感觉自己博客的样式特丑陋。即使不关注内容，只看排版布局和样式，有时候自己写完一篇文章自己都不想去看，何况别人！\n终于有一天我受不了自己的博客样式，决定对其升级一版，在这个过程中发现个人采用的博客主题Even功能很强大，基于上没做啥修改就达到了自己想要的效果，特此记录下。\n风格对比 个人博客基于Golang语言开发的Hugo最开始是采用hugo-redlounge主题来实现的，经过一段时间的使用之后感觉hugo-redlounge主题功能不丰富且左侧会固定占用一部分宽度来展示个人信息，而这部分其实并无太大意义，故后来将其切换为如今的Even样式。\nhugo-redlounge主题的博客：\nEven主题的博客\nEven主题的代码和引用样式\n切换后虽然相对于与hugo-redlounge主题当前博客的功能和界面美观性有一定提升，但是和博客园中的博文样式比起来直观感觉还是有一定差距，尤其是在包含代码段时淡黄色的背景看起来略微不舒服(如上图)。\n源码分析 个人对于Even主题最不满意的是在显示代码段时其样式不太符合自己预期，在浏览器中分析代码段对应的CSS样式，可看出是由如下CSS代码控制的：\n1 2 3 4 5 6 .post .post-content code, .post .post-content pre { padding: 7px; font-size: .9em; font-family: Consolas,Monaco,Menlo,dejavu sans mono,bitstream vera sans mono,courier new,monospace; background: #f8f5ec; } 分析Even主题的源码后发现其主要是基于Sass框架通过_code.scss和_content.scss联合实现的，其中背景设置是通过background: $code-background;实现\n由于Sass支持通过变量来动态的设置CSS属性值，故$code-background显然也是一个变量，查看源码后发现其在_variables.scss中有如下定义:\n1 2 // Color of the code background. $code-background: $deputy-color !default; 在_variables.scss中继续查找$deputy-color的定义，可找出在该文件开头有如下代码，其中$deputy-color是通过$theme-color-config在$theme-color-map中查找相关的颜色设置，自己博客之前默认淡黄色的代码块样式就是通过Default样式设置的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 // ============================== // Variables // ============================== // ========== Theme Color ========== // // Config here to change theme color // Default | Mint Green | Cobalt Blue | Hot Pink | Dark Violet $theme-color-config: \u0026#39;Mint Green\u0026#39;; // Default theme color map $theme-color-map: ( \u0026#39;Default\u0026#39;: #c05b4d #f8f5ec, \u0026#39;Mint Green\u0026#39;: #16982B #f5f5f5, \u0026#39;Cobalt Blue\u0026#39;: #0047AB #f0f2f5, \u0026#39;Hot Pink\u0026#39;: #FF69B4 #f8f5f5, \u0026#39;Dark Violet\u0026#39;: #9932CC #f5f4fa ); // Check theme color config. // if it does not exist, use default theme color. @if not(map-has-key($theme-color-map, $theme-color-config)) { $theme-color-config: \u0026#39;Default\u0026#39;; } $theme-color-list: map-get($theme-color-map, $theme-color-config); // Default theme color of the site. $theme-color: nth($theme-color-list, 1) !default; // Deputy theme color of the site. $deputy-color: nth($theme-color-list, 2) !default; 进一步分析后发现$deputy-color在_variables.scss中的多个地方都有使用，从而可以确定通过修改$theme-color-config的值就能达到动态更改博客主题样式的目的。\n1 2 3 4 5 6 7 8 9 10 11 // Deputy theme color of the site. $deputy-color: nth($theme-color-list, 2) !default; // Backgroud color of the post toc. $post-toc-backgroud: rgba($deputy-color, 0.6) !default; // Border color of the table. $content-table-border-color: darken($deputy-color, 3%) !default; // Color of the code background. $code-background: $deputy-color !default; 样式修改 由于SCSS文件需要编译成CSS文件后才能被使用，而Hugo默认版本是不支持SCSS编译的，故需要下载Hugo Extended版本\n下载完毕后，需将其添加到环境变量，其各种指令的用法与默认版Hugo的用法相同，根据实际情况在_variables.scss中修改$theme-color-config的值，然后调用hugo server -w -D等命令即可实时展示修改效果。\n结果展示 Default样式 Mint Green样式 Cobalt Blue样式 Hot Pink样式 Dark Violet样式 扩展 可根据个人喜好在_variables.scss动态的添加自己喜欢的颜色配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 // ========== Theme Color ========== // // Config here to change theme color // Default | Mint Green | Cobalt Blue | Hot Pink | Dark Violet $theme-color-config: \u0026#39;Mint Green\u0026#39;; // Default theme color map $theme-color-map: ( \u0026#39;Default\u0026#39;: #c05b4d #f8f5ec, \u0026#39;Mint Green\u0026#39;: #16982B #f5f5f5, \u0026#39;Cobalt Blue\u0026#39;: #0047AB #f0f2f5, \u0026#39;Hot Pink\u0026#39;: #FF69B4 #f8f5f5, \u0026#39;Dark Violet\u0026#39;: #9932CC #f5f4fa ); 致谢 https://github.com/olOwOlo/hugo-theme-even https://github.com/ahonn/hexo-theme-even ","permalink":"https://lucumt.info/post/hugo/change-hugo-style-in-even-theme/","tags":["hugo","Go"],"title":"在Hugo生成的博客中动态的修改样式"},{"categories":["Java编程","翻译"],"contents":"本文翻译自Same-threading。\n同线程系统(Same-threading)1 是由一个单线程横向扩展为N个线程系统并行执行的并发模型。\n同线程系统不是纯粹的单线程系统，因为它包含多个线程。 但其中每个线程都像单线程系统一样运，因此采用术语同线程而不是单线程。\n单线程和同线程设计视频教程 如果你更喜欢看视频，我也准备了一个相应的视频单线程和同线程设计。\n为什么选择单线程系统 你可能会很好奇为什么今天还有人设计并使用单线程系统，单线程系统之所以受欢迎，是因为它的并发模型比多线程系统简单的多，单线程系统并不同其它线程共享状态(数据/对象)，这使得单线程系统可以更好的利用非并发数据结构、CPU以及CPU缓存。\n不幸的是单线程系统没有重复利用现代CPU的特性，一颗现代CPU通常带有 2, 4, 6, 8或更多的内核，每个内核在功能上都可以当做一个单独的CPU，如下图所示，单线程系统只能利用这些内核中的一个。\n同线程系统\u0026ndash;单线程的横向扩展 为了利用CPU中的所有内核，可以通过横向扩展单线程系统来达到此目的。\n每个CPU一个线程 同线程系统，通常在每个CPU中运行一个线程，如果一台计算机包含4个CPU或者一个CPU包含4个内核，那么运行4个相同的线程实例(4个单线程系统)是正常的，下图展示了这一原理：\n无共享状态 由于一个同线程系统有多个线程在其中执行，其看起来与传统的单线程系统很相似，实际上它们有一些细微的差别。\n同线程系统和传统多线程系统的主要区别是同线程系统中不同线程间不共享状态，没有并发访问的共享内存，也没有并发数据结构等可以用来实现线程间的数据共享，下图展示了这种区别\n缺乏共享状态导致同线程系统的中每个线程看起来都像一个单线程系统，但是，由于一个同线程系统可以包含多个线程使得它们并不是真正的“单线程系统”。由于没有更好的名称，我认为将这样的系统称之为同线程系统(Same-threading )更准确，而不是“采用单线程设计的多线程系统”。\n同线程系统在本质上意味着数据都在同一个线程中处理，并且没有线程并发的共享数据，这种场景有时称之为无共享状态并发或者隔离的状态并发。\n负载分配 很显然，同线程系统需要在运行的单个线程之间分配工作负载，如果只有一个线程被分配工作负载，那么此系统实际上变成了一个单线程系统。\n如何在不同的线程间精准的分配工作负载取决于你的系统设计，以下部分将介绍一些相关内容。\n单线程微服务 如果系统由多个微服务组成，则每个微服务都能以单线程模式运行，当将多个微服务系统部署到一台服务器上时，其中的每个微服务都能以单线程的方式在单个CPU上执行。\n微服务系统本质上不共享任何数据，因而是同线程系统的一个很好的实例。\n服务间数据分片 如果系统间确实需要共享数据或者共享数据库，则可以对其进行分片，它意味着将数据在多个数据库之间进行划分。数据通常都被划分，以便彼此相关的数据都位于统一数据库中。例如，所有属于某个“所有者”的数据都将被插入同一个数据库中。不过，数据分片超出了本篇的范围，你需要自己去搜索相关教程。\n线程间通信 若同线程系统中的线程间需要通信，可通过传递消息来实现。如果线程 A 想要向线程 B 发送消息，线程 A 可以通过生成消息（字节序列）来实现。 然后线程 B 可以复制该消息（字节序列）并读取它。 通过复制消息，线程 B 确保线程 A 在线程 B 读取消息时不能修改消息，复制后线程 A 无法访问消息副本。\n下图展示了线程间通过消息传递实现通信\n线程间通信可以通过队列、管道、unix 套接字、TCP 套接字等进行，只要适合您的系统。\n更简单的并发模型 在同线程系统中每个线程中运行的系统都可以像单线程一样实现，这意味着其内部的线程共享模型比并发状态要更简单，因此也不用担心并发数据结构以及由此导致的各种问题。\n图示说明 以下是单线程、多线程和同线程的示例图解，以便我们可以更容易的了解它们之间的区别。\n首先展示的是单线程系统\n第二幅图展示的是线程间共享数据的多线程系统\n第三幅图展示了由2个包含隔离数据线程组成的同线程系统，它们之间通过传递消息进行通信\n在Java中使用Thread Ops Thread Ops for Java 是一个开源工具包，旨在帮助您更轻松地实现不同状态的同线程系统。 Thread Ops 包含用于启动和停止单个线程以及在单个线程中实现某种程度的并发的工具。 如果您对使用相同线程的应用程序设计感兴趣，那么看看 Thread Ops 可能会很有趣。 您可以在我的 Thread Ops for Java 教程中阅读有关 Thread Ops 的更多信息。\n注：原文为Same-threading，由于中文网络中没有合适的名词，故将其翻译为同线程系统，表示在一个系统中的相同相似的线程。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/translate/java-concurrency/same-threading/","tags":["Java","Java Concurrency"],"title":"5.[译]同线程系统"},{"categories":["web编程"],"contents":"项目中有个模块支持按文件夹选中批量上传，用户希望在真正上传之前能够在浏览器中实时预览选中的文件夹层级结构，本文基于Chrome浏览器为例，简要说明这一实现。\n若要Chrome浏览器中支持批量上传文件夹，需要在input控件中添加webkitdirectory属性，如下图所示\n1 2 3 \u0026lt;body\u0026gt; 上传文件夹 \u0026lt;input type=\u0026#34;file\u0026#34; webkitdirectory onchange=\u0026#34;getfolder(event)\u0026#34;\u0026gt; \u0026lt;/body\u0026gt; 以一个典型的Maven功能做为测试目录，其文件结构如下，用户希望选中SpringTest文件夹后在前端上传之前就能够在网页上展示出类似的结构\n当基于前述的HTML代码选中上面的工程目录上传时，Chrome浏览器会提示如下警告框，此警告框是浏览器出于安全原因提示1，可不用理会。\n结构分析 在getfolder方法中分析event变量时，可发现event.target.files属性下包含我们所上传的全部文件，将其打印输出的结果如下：\n进一步观察可发现其中的webkitRelativePath中包含文件的完整路径，类似SpringTest/target/classes/com/lucumt/bean/User.class，这个路径虽然包含了上传文件的完整路径，但其为一个字符串，无法直接用于展示层级结构，进一步分析event变量的其它属性也没有找到有用的信息，看来只能从webkitRelativePath着手更改。\n修改思路 为了展示层级结构，首先需要定义一个如下所示的Node结构，其中path用于存储对应的文件名(不含父路径)，children在为文件夹时存储子文件(文件夹)的信息：\n1 2 3 4 function Node(path){ this.path = path; this.children = []; } 最终的结果都是基于Node进行组合处理。\n逐层处理 如上图所示，由于通过JavaScript获取的都是节点的完整路径，从简化实现的角度考虑，系统按照文件夹层级自底向上逐级解析，解析到根目录时则停止。在此过程中，获取到的文件路径不断缩小，直至处理到根节点，以SpringTest/target/test-classes/com/lucumt/TestGetBean.class为例，其解析过程说明如下：\n初始路径为SpringTest/target/test-classes/com/lucumt/TestGetBean.class 将前述路径拆分为TestGetBean.class(为其创建节点node1)和SpringTest/target/test-classes/com/lucumt(为其创建节点node2)，node2的子节点包含node1 将node2的路径拆分为lucumt(更新node2节点的路径)和SpringTest/target/test-classes/com(为其创建node3节点)，node3节点的子节点包含node2 将node3节点的路径拆分为com(更新node3节点的路径)和SpringTest/target/test-classes(为其创建节点node4) 将node4节点的路径拆分为test-classes(更新node4节点的路径)和SpringTest/target(为其创建节点node5) 将node5节点的路径拆分为target(更新node5节点路径)和SpringTest(为其创建节点node6) 节点node6已经是根节点，整个过程完毕，至此从node6基于children属性可一直往下招到node1文件节点。 处理重复 基于上述实现方案时有一个问题待解决，如SpringTest/target/test-classes/com/lucumt/TestGetBean.class和SpringTest/target/classes/com/lucumt/TestApplication.class在拆分到第2层级时，都会识别到lucumt文件夹，若都去创建该文件夹节点数据则会导致重复。\n回顾前面的逐层处理实现方案可知，当处理SpringTest/target/classes/com/lucumt/TestApplication.class时，SpringTest/target/test-classes/com/lucumt/TestGetBean.class已经被处理完比，在这一过程中会给我们创建好lucumt目录，在接下来处理SpringTest/target/test-classes/com/lucumt/TestGetBean.class时我们只需要找到lucumt对应的父节点，然后检查父节点下有没有该目录即可。\n基于上述分析，要在逐级遍历的过程中添加如下处理：\n遍历到当前文件或文件夹节点时，需要查找其父节点，若父节点不存在则创建，同时将当前节点加入到父节点的子节点集合中去 若当前节点的父节点存在，则需要获取其所有的子节点，并与当前节点进行避免，判断当前节点是否存在，若存在则不需要重复创建 为了记录当前节点的父节点，可在JavaScript中采用Map数据结构，其中key为节点的路径，value为Node节点自身。\n代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 function getfolder(event) { let files = event.target.files; let map = {}; var rootPath = files[0].webkitRelativePath.split(\u0026#39;/\u0026#39;)[0]; // 循环遍历，检测所有的文件路径 for (var i in files) { var node = files[i]; var path = node.webkitRelativePath; if (!path) { continue; } while (true) { // 处理到最顶层文件夹时，就不用往上继续处理 if (!path || path.indexOf(\u0026#34;/\u0026#34;) == -1) { break; } var index = path.lastIndexOf(\u0026#34;/\u0026#34;); var parentPath = path.substring(0, index); var file = path.substring(index + 1); var node; if (!map[path]) { node = new Node(file); map[path] = node; } else { node = map[path]; } // 父节点没有则创建 if (!map[parentPath]) { var parentFile = parentPath.substring(parentPath.lastIndexOf(\u0026#34;/\u0026#34;) + 1) var pNode = new Node(parentFile); // 动态的更新父节点的子节点，为后续检查重复节点做准备 pNode.children.push(node); map[parentPath] = pNode; } else { var pNode = map[parentPath]; var children = pNode.children; var addNode = true; // 通过检查父节点下的子节点来避免重复创建 for (var k in children) { if (children[k].path == file) { addNode = false; break; } } if (addNode) { pNode.children.push(node); } } // 逐级缩短父节点的路径，直到回到最顶层 path = parentPath; } } console.log(map[rootPath]); } 执行上述代码后在Chrome控制台的输出如下，可见root中已能够正确的输出层级结构，进行到这一步后续在页面上展示就很容易了，此处不再叙述。\nJava版本实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 public class TestFilePathConvert { public static void main(String[] args) { String[] paths = { \u0026#34;a/b1/c1/d1.txt\u0026#34;, \u0026#34;a/b1/c1/d2.txt\u0026#34;, \u0026#34;a/b1/c1/d2/e1/f.txt\u0026#34;, \u0026#34;a/b2/c2/d1\u0026#34;, \u0026#34;a/b3/c1\u0026#34;, \u0026#34;a/b4/c1/d1/e1/f1\u0026#34;, \u0026#34;a/b4/c1/d1/e1/f2/g1.png\u0026#34;, \u0026#34;a/b5/c1\u0026#34; }; convertPathToTreeNode(paths); } public static void convertPathToTreeNode(String[] paths) { Map\u0026lt;String, Node\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); for (String path : paths) { while (true) { Node node, pNode; String nodeName; if (map.containsKey(path)) { node = map.get(path); nodeName = node.getName(); } else { int index = path.lastIndexOf(\u0026#34;/\u0026#34;); nodeName = path.substring(index + 1); node = new Node(nodeName); map.put(path, node); } String parentPath = StringUtils.substringBeforeLast(path, \u0026#34;/\u0026#34;); if (path.equals(parentPath)) { break; } // 处理父节点 if (map.containsKey(parentPath)) { pNode = map.get(parentPath); } else { int index = parentPath.lastIndexOf(\u0026#34;/\u0026#34;); String pName = parentPath.substring(index + 1); pNode = new Node(pName); map.put(parentPath, pNode); } //检查当前节点是否存在 boolean add = true; for (Node n : pNode.getChildren()) { if (nodeName.equals(n.getName())) { add = false; break; } } // 避免当前节点的重复添加 if (add) { pNode.getChildren().add(node); } path = parentPath; } } String root = StringUtils.substringBefore(paths[0], \u0026#34;/\u0026#34;); Node rootNode = map.get(root); Gson gson = new Gson(); System.out.println(gson.toJson(rootNode)); } static class Node { private String name; private List\u0026lt;Node\u0026gt; children = new ArrayList\u0026lt;\u0026gt;(); public String getName() { return name; } public void setName(String name) { this.name = name; } public List\u0026lt;Node\u0026gt; getChildren() { return children; } public void setChildren(List\u0026lt;Node\u0026gt; children) { this.children = children; } public Node(String name) { this.name = name; } @Override public String toString() { return \u0026#34;Node{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, children=\u0026#34; + children.size() + \u0026#39;}\u0026#39;; } } } https://stackoverflow.com/questions/50225019/how-to-remove-warning-message-in-chrome-when-uploading-a-directory\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/web/convert-folder-upload-data-to-tree-node-in-chrome/","tags":["html5","JavaScript"],"title":"在Chrome中将上传的文件夹数据转化为按树结构展示"},{"categories":["Spring系列"],"contents":"BeanFactory和FactoryBean的区别与使用场景是Spring面试中的高频题之一，本文基于网上资料和个人理解，简要说明他们之间的异同以及使用场景。\n组件说明 BeanFactory 在BeanFactory的API中，一开始就有如下一句描述\nThe root interface for accessing a Spring bean container\n这句话指明了BeanFactory在Spring家族中的地位，它是操作Spring容器、获取Spring Bean的根接口。从字面意思可以看出它是一个Bean工厂，其内部采用了工厂模式，通过它们我们可进行创建Bean、获取Bean等操作1。\n在学习与使用Spring过程中接触到的ApplicaitonContext、AnnotationConfigApplicastionContext、ClassPathXmlApplicationContext等都是其子接口和具体的实现类，它是我们在Spring框架中接触最多的系统接口，下图中的UML展示了BeanFactory及其子接口和实现类之间的关系2\n下述代码展示了BeanFactory所包含的全部15个接口方法，它们涵盖了Spring中对Bean对象的各种读取操作，若经常使用Spring这些接口方法看起来就会很熟悉。\nBeanFactory接口(点击可展开) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 public interface BeanFactory { String FACTORY_BEAN_PREFIX = \u0026#34;\u0026amp;\u0026#34;; Object getBean(String name) throws BeansException; \u0026lt;T\u0026gt; T getBean(String name, Class\u0026lt;T\u0026gt; requiredType) throws BeansException; Object getBean(String name, Object... args) throws BeansException; \u0026lt;T\u0026gt; T getBean(Class\u0026lt;T\u0026gt; requiredType) throws BeansException; \u0026lt;T\u0026gt; T getBean(Class\u0026lt;T\u0026gt; requiredType, Object... args) throws BeansException; \u0026lt;T\u0026gt; ObjectProvider\u0026lt;T\u0026gt; getBeanProvider(Class\u0026lt;T\u0026gt; requiredType); \u0026lt;T\u0026gt; ObjectProvider\u0026lt;T\u0026gt; getBeanProvider(ResolvableType requiredType); boolean containsBean(String name); boolean isSingleton(String name) throws NoSuchBeanDefinitionException; boolean isPrototype(String name) throws NoSuchBeanDefinitionException; boolean isTypeMatch(String name, ResolvableType typeToMatch) throws NoSuchBeanDefinitionException; boolean isTypeMatch(String name, Class\u0026lt;?\u0026gt; typeToMatch) throws NoSuchBeanDefinitionException; @Nullable Class\u0026lt;?\u0026gt; getType(String name) throws NoSuchBeanDefinitionException; @Nullable Class\u0026lt;?\u0026gt; getType(String name, boolean allowFactoryBeanInit) throws NoSuchBeanDefinitionException; String[] getAliases(String name); } 由于BeanFactory是操作Spring容器和对象的根接口，Spring官方要求它尽可能的支持Bean生命周期的各种接口，基于Spring官方API的描述，其完整的方法链和顺序如下：\nBeanNameAware\u0026rsquo;s setBeanName BeanClassLoaderAware\u0026rsquo;s setBeanClassLoader BeanFactoryAware\u0026rsquo;s setBeanFactory EnvironmentAware\u0026rsquo;s setEnvironment EmbeddedValueResolverAware\u0026rsquo;s setEmbeddedValueResolver ResourceLoaderAware\u0026rsquo;s setResourceLoader (only applicable when running in an application context) ApplicationEventPublisherAware\u0026rsquo;s setApplicationEventPublisher (only applicable when running in an application context) MessageSourceAware\u0026rsquo;s setMessageSource (only applicable when running in an application context) ApplicationContextAware\u0026rsquo;s setApplicationContext (only applicable when running in an application context) ServletContextAware\u0026rsquo;s setServletContext (only applicable when running in a web application context) postProcessBeforeInitialization methods of BeanPostProcessors InitializingBean\u0026rsquo;s afterPropertiesSet a custom init-method definition postProcessAfterInitialization methods of BeanPostProcessors 上述初始化链可很好的帮我们回答面试中另外几个常见的问题：\nSpring中Bean如何初始化 描述Spring中Bean的生命周期 FactoryBean FactoryBean从名字就能看出来是一个Bean，但不是普通的Bean，否则Spring作者为啥要单独的创建这个接口呢？FactoryBean也是一个接口，其源码如下，从中可以看出该接口只有3个方法，与BeanFactory相比数量大为减少，同时这3个接口方法的作用也同BeanFactory中的相关方法类似。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public interface FactoryBean\u0026lt;T\u0026gt; { String OBJECT_TYPE_ATTRIBUTE = \u0026#34;factoryBeanObjectType\u0026#34;; @Nullable T getObject() throws Exception; @Nullable Class\u0026lt;?\u0026gt; getObjectType(); default boolean isSingleton() { return true; } } 通过上述代码能够获取的信息依旧有限，在FactoryBean的官方API中有如下描述\nInterface to be implemented by objects used within a BeanFactory which are themselves factories for individual objects. If a bean implements this interface, it is used as a factory for an object to expose, not directly as a bean instance that will be exposed itself.\nNB: A bean that implements this interface cannot be used as a normal bean. A FactoryBean is defined in a bean style, but the object exposed for bean references (getObject()) is always the object that it creates.\n上述文档的主要结论如下：\nFactoryBean不是一个普通的Bean，它实际上是一个用于创建特定bean的工厂 通过实现FactoryBean接口，可通过暴露对象的方式创建特定bean对象，而这个bean对象本身不会暴露 到这里虽然二者的区别清楚了，但是FactoryBean的使用场景还是不清晰，在https://spring.io/blog/2011/08/09/what-s-a-factorybean这篇文章中，Spring的作者之一JOSH LONG用如下文字阐述了FactoryBean的使用场景\nA FactoryBean is a pattern to encapsulate interesting object construction logic in a class. It might be used, for example, to encode the construction of a complex object graph in a reusable way. Often this is used to construct complex objects that have many dependencies. It might also be used when the construction logic itself is highly volatile and depends on the configuration. A FactoryBean is also useful to help Spring construct objects that it couldn’t easily construct itself.\n从上述文字中可以看出FactoryBean主要用于构建一些实例化过程较为复杂或有配置依赖的对象(即非普通POJO)，并将其交给Spring容器管理。\nSpring框架本身就自带了实现FactoryBean的70多个接口，如ProxyFactoryBean、MapFactoryBean、PropertiesFactoryBean等，从个人角度来看它们要么理解起来较为复杂，要么使用较少不具有代表性，下面以MyBatis-Spring中的SqlSessionFactoryBean为例来了解其用法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @Override public SqlSessionFactory getObject() throws Exception { if (this.sqlSessionFactory == null) { afterPropertiesSet(); } return this.sqlSessionFactory; } // 参数校验与对象创建 public void afterPropertiesSet() throws Exception { notNull(dataSource, \u0026#34;Property \u0026#39;dataSource\u0026#39; is required\u0026#34;); notNull(sqlSessionFactoryBuilder, \u0026#34;Property \u0026#39;sqlSessionFactoryBuilder\u0026#39; is required\u0026#34;); state((configuration == null \u0026amp;\u0026amp; configLocation == null) || !(configuration != null \u0026amp;\u0026amp; configLocation != null), \u0026#34;Property \u0026#39;configuration\u0026#39; and \u0026#39;configLocation\u0026#39; can not specified with together\u0026#34;); this.sqlSessionFactory = buildSqlSessionFactory(); } // 基于配置文件创建具体的SqlSessionFactory protected SqlSessionFactory buildSqlSessionFactory() throws Exception { // 各种检查代码 return this.sqlSessionFactoryBuilder.build(targetConfiguration); } 在创建SqlSessionFactory时需要依赖数据库的配置等一些配置信息，但这些配置信息若通过BeanFactory以传统的实例化-\u0026gt;初始化的方式创建时是很难办到的，虽然可以通过BeanPostProcessors的接口中的回调方法来实现，但会导致代码复杂并且不能满足某些特殊场景下的需求，而通过FactoryBean我们只需要根据实际业务逻辑在getObject()方法中创建对应的对象并返回即可，由于对象的创建由我们自己把控，在达到代码简洁的同时，创建的对象也能被Spring容器管理。\n使用示例 假设有如下所示的Group类\n1 2 3 4 5 6 7 @Service public class Group { private String groupName; // getter setter } 在使用BeanFactory获取对象的方法如下\n1 2 3 4 5 public static void main(String[] args) { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class); Group group = context.getBean(Group.class); System.out.println(group.hashCode()); } 输出结果为Group@25d250c6，可以看到已经正确的获取到了Bean对象。\n定义一个实现了FactoryBean接口的GroupFactoryBean，其代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class GroupFactoryBean implements FactoryBean\u0026lt;Group\u0026gt; { @Override public Group getObject() throws Exception { return new Group(); } @Override public Class\u0026lt;?\u0026gt; getObjectType() { return Group.class; } } 测试代码如下：\n1 2 3 4 5 public static void main(String[] args) { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(GroupFactoryBean.class); Object object = context.getBean(\u0026#34;groupFactoryBean\u0026#34;); System.out.println(object); } 输出结果为Group@fdefd3f，如前面通过BeanFactory 创建的对象类似，接下来将groupFactoryBean添加一个\u0026amp;前缀，变为\u0026amp;groupFactoryBean后再次进行测试\n1 2 3 4 5 public static void main(String[] args) { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(GroupFactoryBean.class); Object object = context.getBean(\u0026#34;\u0026amp;groupFactoryBean\u0026#34;); System.out.println(object); } 输出结果为GroupFactoryBean@1990a65e，由此可得出如下结论 ：\n当直接通过FactoryBean实现类的接口名称获取对象时，得到的是该FactoryBean实现类中创建的对象本身，也是我们正常的使用方式 当在FactoryBean接口对象名前面加上\u0026amp;前缀时，得到的是FactoryBean实现类本身，一般用于调试分析。 二者之间的区别 相同点： 都是接口类，需要使用者自己实现相应的方法 接口中创建bean对象都能被Spring容器管理 不同点: BeanFactory提供的接口方法更多，更具有灵活性，如能获取别名、bean对象类型等 BeanFactory基于Spring规范实现，其创建的bean会在Spring容器中经历完整的生命周期，能够调用@PostConstruct、BeanPostProcessors等接口和方法 Spring容器只负责FactoryBean创建的bean对象的生命周期管理，不负责bean对象的创建和销毁(因为由我们自己实现了嘛!)，所以调用@PostConstruct和@PreDestroy方法不会生效，需要实现DisposableBean等接口来达到该目的 相关使用场景 BeanFactory: 项目中各种常规的POJO、Dao、Service等不涉及复杂构造的场景 FactoryBean: 对象的构造(实例化)较为复杂，通常是系统中的一些底层组件，如SqlSessionFactoryBean、ProxyFactoryBean等 参考文档 https://www.cnblogs.com/aspirant/p/9082858.html\nhttps://spring.io/blog/2011/08/09/what-s-a-factorybean\nhttps://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/beans/factory/FactoryBean.html\n实际上Bean的创建、销毁都是由容器来负责的，使用时更多关注的是Bean对象的配置以及如何获取Bean对象\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n出于篇幅的考虑，实际上这张UML类图展示的并不完整，可在IDEA中基于BeanFactory自己生成完整的UML图\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/spring/spring-core/difference-between-factorybean-and-beanfactory/","tags":["Spring"],"title":"Spring中BeanFactory和FactoryBean的区别以及使用场景"},{"categories":["Java编程","MyBatis系列"],"contents":"简单记录下如何在MyBatis中插入JSON，以备参考。\n基本信息 完整代码参见spring-mybatis-example，核心代码为JsonNodeTypeHandler配置类。\n项目结构 表结构 1 2 3 4 5 6 CREATE TABLE `user_info` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(100) COLLATE utf8_bin NOT NULL, `info` json NOT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin pom文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.lucumt\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-mybatis-test\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;SpringTest\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://lucumt.info\u0026lt;/url\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;maven.compiler.source\u0026gt;1.8\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;1.8\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;spring.boot.version\u0026gt;2.7.3\u0026lt;/spring.boot.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.spring.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.30\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.boot.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.boot.version}\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.boot.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.junit.platform\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-platform-launcher\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.9.0\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.18.24\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.fasterxml.jackson.core\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jackson-databind\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.13.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; 模型类 1 2 3 4 5 6 7 8 9 10 11 @Data @AllArgsConstructor @NoArgsConstructor public class UserModel { private Integer id; private String name; private JsonNode info; } Handler类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 @MappedTypes(JsonNode.class) public class JsonNodeTypeHandler extends BaseTypeHandler\u0026lt;JsonNode\u0026gt; { /** * 设置非空参数 * * @param ps * @param i * @param parameter * @param jdbcType * @throws SQLException */ @Override public void setNonNullParameter(PreparedStatement ps, int i, JsonNode parameter, JdbcType jdbcType) throws SQLException { ps.setString(i, parameter.toString()); } /** * 根据列名，获取可以为空的结果 * * @param rs * @param columnName * @return * @throws SQLException */ @Override public JsonNode getNullableResult(ResultSet rs, String columnName) throws SQLException { String sqlJson = rs.getString(columnName); return getResultFromJSON(sqlJson); } /** * 根据列索引，获取可以为内控的接口 * * @param rs * @param columnIndex * @return * @throws SQLException */ @Override public JsonNode getNullableResult(ResultSet rs, int columnIndex) throws SQLException { String sqlJson = rs.getString(columnIndex); return getResultFromJSON(sqlJson); } /** * @param cs * @param columnIndex * @return * @throws SQLException */ @Override public JsonNode getNullableResult(CallableStatement cs, int columnIndex) throws SQLException { String sqlJson = cs.getNString(columnIndex); return getResultFromJSON(sqlJson); } private JsonNode getResultFromJSON(String sqlJson) { if (sqlJson == null) { return null; } try { return new ObjectMapper().readTree(sqlJson); } catch (JsonProcessingException e) { throw new RuntimeException(e); } } } 配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 server: port: 8081 logging: level: root: info spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://10.10.2.98:3316/db_test?serverTimezone=UTC\u0026amp;useUnicode=true\u0026amp;characterEncoding=utf-8 username: root password: 654321 mybatis: mapper-locations: classpath:mapper/*.xml configuration: map-underscore-to-camel-case: true type-aliases-package: com.lucumt.model,com.lucumt.vo type-handlers-package: com.lucumt.handler.mybatis Mapper类 1 2 3 4 5 6 7 8 public interface UserMapper { void addUser(UserModel userModel); UserModel findById(Integer id); void deleteUser(Integer id); } Mapper文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.lucumt.mapper.UserMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;findById\u0026#34; parameterType=\u0026#34;Integer\u0026#34; resultType=\u0026#34;userModel\u0026#34;\u0026gt; SELECT id,name,info FROM user_info WHERE id=#{id} \u0026lt;/select\u0026gt; \u0026lt;insert id=\u0026#34;addUser\u0026#34; parameterType=\u0026#34;userModel\u0026#34; useGeneratedKeys=\u0026#34;true\u0026#34; keyProperty=\u0026#34;id\u0026#34; keyColumn=\u0026#34;id\u0026#34;\u0026gt; INSERT INTO user_info(name,info) VALUES (#{name},#{info}) \u0026lt;/insert\u0026gt; \u0026lt;delete id=\u0026#34;deleteUser\u0026#34; parameterType=\u0026#34;Integer\u0026#34;\u0026gt; DELETE FROM user_info WHERE id= #{id} \u0026lt;/delete\u0026gt; \u0026lt;/mapper\u0026gt; Service类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Service public class UserService { @Autowired private UserMapper userMapper; public void addUser(UserModel userModel) { userMapper.addUser(userModel); } public UserModel getUser(Integer id) { return userMapper.findById(id); } public void deleteUser(Integer id) { userMapper.deleteUser(id); } } 测试 测试类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 @SpringBootTest @TestMethodOrder(MethodOrderer.OrderAnnotation.class) public class TestUserService { @Autowired private UserService userService; private static Integer userId; @Order(1) @Test public void testAddUser() throws JsonProcessingException { String time = LocalDateTime.now().format(DateTimeFormatter.ofPattern(\u0026#34;yyyy-MM-dd_HH:mm:ss:SSS\u0026#34;)); String info = \u0026#34;{\\\u0026#34;city\\\u0026#34;:\\\u0026#34;beijing\\\u0026#34;,\\\u0026#34;location\\\u0026#34;:\\\u0026#34;jiuxianqiao__\u0026#34; + time + \u0026#34;\\\u0026#34;,\\\u0026#34;skills\\\u0026#34;:[\\\u0026#34;Java\\\u0026#34;,\\\u0026#34;Golang\\\u0026#34;,\\\u0026#34;Python\\\u0026#34;]}\u0026#34;; ObjectMapper mapper = new ObjectMapper(); JsonNode node = mapper.readTree(info); UserModel userModel = new UserModel(); userModel.setName(\u0026#34;lucumt\u0026#34;); userModel.setInfo(node); userService.addUser(userModel); userId = userModel.getId(); assertTrue(userId \u0026gt; 0); } @Order(2) @Test public void testGetUser() { UserModel user = userService.getUser(userId); JsonNode info = user.getInfo(); assertNotNull(info); System.out.println(info); } @Order(3) @Test public void testDeleteUser() { userService.deleteUser(userId); } } 测试结果 ","permalink":"https://lucumt.info/post/mybatis/insert-json-data-in-mybatis/","tags":["Java","MyBatis"],"title":"MyBatis中插入JSON格式数据"},{"categories":["Java编程"],"contents":"在多种方式实现在Java中用线程轮流打印ABC中自己本想用单个锁通过调用wait()实现轮流打印，但一直遇到全部等待并停止执行的死锁问题，经过网上求助和自己分析，最终找到问题原因，简单记录下。\n原始代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 public class ThreadPrint4Test { public static void main(String[] args) { new ThreadPrint4Test().testPrint(); } public void testPrint() { Object lock = new Object(); new Thread(new PrintThread(\u0026#34;A\u0026#34;,lock),\u0026#34;thread-A\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;B\u0026#34;,lock),\u0026#34;thread-B\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;C\u0026#34;,lock),\u0026#34;thread-C\u0026#34;).start(); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { throw new RuntimeException(e); } new Thread(() -\u0026gt; { synchronized (lock) { lock.notifyAll(); } }).start(); } class PrintThread implements Runnable { private Object lock; private String value; public PrintThread(String value, Object lock) { this.value = value; this.lock = lock; } public void run() { while (true) { try { synchronized (lock) { lock.wait(); System.out.println(LocalTime.now() + \u0026#34;\\t\u0026#34; + value); lock.notifyAll(); } } catch (InterruptedException e) { throw new RuntimeException(e); } } } } } 执行结果\u0026amp;状态查看 运行上述程序，可发现在输出若干字符后，程序处于阻塞状态，输出停止：\n利用jps和jstack命令查看，可发现3个进程都处于WAITING状态形成类似死锁的现象，由此导致程序停止输出。\n由于多次运行上述代码，均能出现此问题(只不过出现的时间间隔不同)，可知程序代码肯定编写不正确。\n原因分析 最开始检查代码时看起来一切正常:\n某线程首先通过wait()进入等待状态 只有被唤醒后才能继续往下执行输出代码 输出完毕后通过notifyAll() 被notifyAll()唤醒的线程从步骤2开始往下执行 之后该线程调用wait()进入等待状态，重复步骤1实现不间断的打印 1 2 3 4 5 6 7 8 9 10 11 12 13 public void run() { while (true) { try { synchronized (lock) { lock.wait(); System.out.println(LocalTime.now() + \u0026#34;\\t\u0026#34; + value); lock.notifyAll(); } } catch (InterruptedException e) { throw new RuntimeException(e); } } } 上述推理与代码看起来很完美，无懈可击，但程序执行时就是每次都不能一直打印下去，肯定是自己的理解有问题。\n为了便于定位问题，将run()方法修改为如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public void run() { while (true) { try { synchronized (lock) { String name = Thread.currentThread().getName(); System.out.println(name + \u0026#34;\\t\u0026#34; + LocalTime.now() + \u0026#34;\\t\u0026#34; + \u0026#34; will invoke wait\u0026#34;); lock.wait(); System.out.println(name + \u0026#34;\\t\u0026#34; + LocalTime.now() + \u0026#34;\\t\u0026#34; + \u0026#34; is notified\u0026#34;); System.out.println(name + \u0026#34;\\t\u0026#34; + LocalTime.now() + \u0026#34;\\t\u0026#34; + value); lock.notifyAll(); } } catch (InterruptedException e) { throw new RuntimeException(e); } } } } 之后多次重新执行该程序，执行结果类似如下：\n从上图可以看出中无法找出具体的问题复现规律，查看wait()的官方文档，有如下说明\nThe current thread must own this object\u0026rsquo;s monitor. The thread releases ownership of this monitor and waits until another thread notifies threads waiting on this object\u0026rsquo;s monitor to wake up either through a call to the notify method or the notifyAll method. The thread then waits until it can re-obtain ownership of the monitor and resumes execution.\n查看notifyAll()的官方文档，有如下说明：\nThe awakened threads will not be able to proceed until the current thread relinquishes the lock on this object. The awakened threads will compete in the usual manner with any other threads that might be actively competing to synchronize on this object;\n从上述说明中可获得如下信息：\n调用wait()方法后，程序会处于等待状态，同时释放锁 被notifyAll()唤醒的线程并不会立即执行，需要等当前调用notifyAll()的线程释放对应的锁 被notfiyAll()唤醒的线程需要与其它正在执行的线程一并去竞争获取锁，并没有区别对待 至此，可以大致找出问题原因\n三个线程在某个时间段先后调用了wait()方法都进入了WAITING状态，同时没有其它线程来唤醒它们，导致最终程序停止输出。\n以线程A造成死锁为例，其过程如下:\n线程A调用wait()方法进入WAITING状态并释放锁 线程B获得锁，进入synchronized代码块 线程B执行wait()方法进行WAITING状态并释放锁 线程C获得锁，进入synchronized代码块 线程C执行wait()方法进行WAITING状态并释放锁 至此线程A、线程B、线程C均处于WAITING状态，程序停止输出 图示说明如下：\n改进代码 找到问题原因后，要修复此问题也很容，只需要避免所有的线程同时调用wait()方法即可，可在调用wait()前加个判断，确保始终有一个线程不用进入WAITING状态，能够释放锁。\n消除死循环 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 public class ThreadPrint4Test { public static void main(String[] args) { new ThreadPrint4Test().testPrint(); } private volatile String runThread; public void testPrint() { Object lock = new Object(); new Thread(new PrintThread(\u0026#34;A\u0026#34;, lock), \u0026#34;thread-A\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;B\u0026#34;, lock), \u0026#34;thread-B\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;C\u0026#34;, lock), \u0026#34;thread-C\u0026#34;).start(); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { throw new RuntimeException(e); } new Thread(() -\u0026gt; { synchronized (lock) { lock.notifyAll(); } }).start(); } class PrintThread implements Runnable { private Object lock; private String value; public PrintThread(String value, Object lock) { this.value = value; this.lock = lock; } public void run() { while (true) { try { synchronized (lock) { boolean process = value.equals(runThread); if (!process) { lock.wait(); System.out.println(LocalTime.now() + \u0026#34;\\t\u0026#34; + value); runThread = value; } lock.notifyAll(); } } catch (InterruptedException e) { throw new RuntimeException(e); } } } } } 实现轮流打印 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 public class ThreadPrint4Test { public static void main(String[] args) { new ThreadPrint4Test().testPrint(); } private volatile int count = 0; public void testPrint() { Object lock = new Object(); new Thread(new PrintThread(\u0026#34;A\u0026#34;, lock), \u0026#34;thread-A\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;B\u0026#34;, lock), \u0026#34;thread-B\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;C\u0026#34;, lock), \u0026#34;thread-C\u0026#34;).start(); } class PrintThread implements Runnable { private Object lock; private String value; public PrintThread(String value, Object lock) { this.value = value; this.lock = lock; } public void run() { while (true) { try { synchronized (lock) { boolean process = \u0026#34;A\u0026#34;.equals(value) \u0026amp;\u0026amp; count % 3 == 0; if (process) { count = 0; } process = process || (\u0026#34;B\u0026#34;.equals(value) \u0026amp;\u0026amp; count % 3 == 1); process = process || (\u0026#34;C\u0026#34;.equals(value) \u0026amp;\u0026amp; count % 3 == 2); if (process) { lock.wait(); System.out.println(value); count++; Thread.sleep(500); } lock.notifyAll(); } } catch (InterruptedException e) { throw new RuntimeException(e); } } } } } ","permalink":"https://lucumt.info/post/java-concurrency/analysis-deadlock-in-multiple-threads-caused-by-wait/","tags":["Java","Java Concurrency"],"title":"一次由wait造成的死锁问题分析"},{"categories":["Java编程"],"contents":"在Java中采用3个线程不停的轮流打印ABC这3个字符，采用不同的方式实现。\n原理分析 实现思路如下：\n要在一个while循环中，实现不停的打印 多个线程间需要依次唤醒下一个线程，实现依次打印，此时会形成死循环 为了打破死循环，还需要一个启动线程延后调用 代码实现 基于wait\u0026amp;notify 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 public class ThreadPrint1Test { public static void main(String[] args) { new ThreadPrint1Test().testPrint(); } public void testPrint() { Object lockA = new Object(); Object lockB = new Object(); Object lockC = new Object(); new PrintThread(\u0026#34;A\u0026#34;, lockA, lockB).start(); new PrintThread(\u0026#34;B\u0026#34;, lockB, lockC).start(); new PrintThread(\u0026#34;C\u0026#34;, lockC, lockA).start(); try { Thread.sleep(500); } catch (InterruptedException e) { throw new RuntimeException(e); } new Thread(() -\u0026gt; { synchronized (lockA) { lockA.notify(); } }).start(); } class PrintThread extends Thread { private Object waitLock; private Object notifyLock; private String value; public PrintThread(String value, Object waitLock, Object notifyLock) { this.value = value; this.waitLock = waitLock; this.notifyLock = notifyLock; } public void run() { while (true) { synchronized (waitLock) { try { waitLock.wait(); Thread.sleep(500); System.out.println(value); } catch (InterruptedException e) { throw new RuntimeException(e); } synchronized (notifyLock) { notifyLock.notify(); } } } } } } 基于ReentrantLock\u0026amp;Condition 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 public class ThreadPrint2Test { public static void main(String[] args) { new ThreadPrint2Test().testPrint(); } public void testPrint() { Lock lock = new ReentrantLock(); Condition conditionA = lock.newCondition(); Condition conditionB = lock.newCondition(); Condition conditionC = lock.newCondition(); new Thread(new PrintThread(\u0026#34;A\u0026#34;, lock, conditionA, conditionB), \u0026#34;thread-a\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;B\u0026#34;, lock, conditionB, conditionC), \u0026#34;thread-b\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;C\u0026#34;, lock, conditionC, conditionA), \u0026#34;thread-c\u0026#34;).start(); try { Thread.sleep(500); } catch (InterruptedException e) { throw new RuntimeException(e); } new Thread(() -\u0026gt; { lock.lock(); conditionA.signal(); lock.unlock(); }, \u0026#34;init\u0026#34;).start(); } class PrintThread implements Runnable { private Lock lock; private Condition ca; private Condition cb; private String value; public PrintThread(String value, Lock lock, Condition ca, Condition cb) { this.value = value; this.lock = lock; this.ca = ca; this.cb = cb; } public void run() { while (true) { try { lock.lock(); ca.await(); System.out.println(value); Thread.sleep(500); cb.signal(); lock.unlock(); } catch (InterruptedException e) { throw new RuntimeException(e); } } } } } 基于Semaphore 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 public class ThreadPrint3Test { public static void main(String[] args) { new ThreadPrint3Test().testPrint(); } public void testPrint() { Semaphore sa = new Semaphore(1); Semaphore sb = new Semaphore(1); Semaphore sc = new Semaphore(1); try { sb.acquire(); sc.acquire(); Thread.sleep(500); } catch (InterruptedException e) { throw new RuntimeException(e); } new PrintThread(\u0026#34;A\u0026#34;, sa, sb).start(); new PrintThread(\u0026#34;B\u0026#34;, sb, sc).start(); new PrintThread(\u0026#34;C\u0026#34;, sc, sa).start(); } class PrintThread extends Thread { private Semaphore sa; private Semaphore sb; private String value; public PrintThread(String value, Semaphore sa, Semaphore sb) { this.value = value; this.sa = sa; this.sb = sb; } public void run() { while (true) { try { sa.acquire(); System.out.println(value); Thread.sleep(500); sb.release(); } catch (InterruptedException e) { throw new RuntimeException(e); } } } } } 单个锁\u0026amp;volatile变量 此种方式不需要唤醒线程，同时便于很方便的修改线程数目。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 public class ThreadPrint4Test { public static void main(String[] args) { new ThreadPrint4Test().testPrint(); } private volatile int count = 0; public void testPrint() { Object lock = new Object(); new Thread(new PrintThread(\u0026#34;A\u0026#34;, lock), \u0026#34;thread-A\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;B\u0026#34;, lock), \u0026#34;thread-B\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;C\u0026#34;, lock), \u0026#34;thread-C\u0026#34;).start(); } class PrintThread implements Runnable { private Object lock; private String value; public PrintThread(String value, Object lock) { this.value = value; this.lock = lock; } public void run() { while (true) { try { synchronized (lock) { boolean process = \u0026#34;A\u0026#34;.equals(value) \u0026amp;\u0026amp; count % 3 == 0; if (process) { count = 0; } process = process || (\u0026#34;B\u0026#34;.equals(value) \u0026amp;\u0026amp; count % 3 == 1); process = process || (\u0026#34;C\u0026#34;.equals(value) \u0026amp;\u0026amp; count % 3 == 2); if (process) { lock.wait(); System.out.println(value); count++; Thread.sleep(500); } lock.notifyAll(); } } catch (InterruptedException e) { throw new RuntimeException(e); } } } } } ","permalink":"https://lucumt.info/post/java-concurrency/print-a-b-c-in-turn-by-threads/","tags":["Java","Java Concurrency"],"title":"多种方式实现在Java中用线程轮流打印ABC"},{"categories":["Java编程","MyBatis系列"],"contents":"在进行Java开发时，NullPointerException是一个很常见的异常，在Java8中提供了Optional来避免此问题，而在MyBatis 3.5.0中也提供了对Optional的支持，本文简要叙述如何在MyBatis中使用Optional。\n完整代码参见spring-mybatis-example\n查询单条记录 由于在查询单条记录时，若数据库中不存在该记录，则会默认返回null，此时可用Optional进行避免。\n首先确保MyBatis的版本不低于3.5.0，在mapper中可以仿照如下定义接口\n1 2 3 4 public interface BookMapper { Optional\u0026lt;BookModel\u0026gt; findById(Integer id); } 之后在对应的service类中可以按照如下方式使用\n1 2 3 4 5 6 7 8 9 10 11 12 @Service public class BookService { @Autowired private BookMapper bookMapper; public BookModel getBook(Integer id) { Optional\u0026lt;BookModel\u0026gt; result = bookMapper.findById(id); BookModel book = result.orElse(new BookModel()); return book; } } 执行下述单元测试代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 @SpringBootTest public class TestBookService { @Autowired private BookService bookService; @Test public void testGetBook() { BookModel book = bookService.getBook(3); Assertions.assertNotNull(book); System.out.println(book); } } 其执行结果如下，可见Optional在Mapper接口中生效。\n查询多条记录 当查询的结果为List时，即使没有数据MyBatis也会返回一个空的List，其size为0但不为null，此时不需要我们进行非空判断。\n定义如下接口\n1 2 3 4 public interface BookMapper { List\u0026lt;BookModel\u0026gt; selectByType(Integer type); } mapper文件如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.lucumt.mapper.BookMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;findById\u0026#34; parameterType=\u0026#34;Integer\u0026#34; resultType=\u0026#34;bookModel\u0026#34;\u0026gt; SELECT id,name,price,type FROM book WHERE id=#{id} \u0026lt;/select\u0026gt; \u0026lt;select id=\u0026#34;selectByType\u0026#34; parameterType=\u0026#34;integer\u0026#34; resultType=\u0026#34;bookModel\u0026#34;\u0026gt; SELECT id,name,price FROM book WHERE type=#{type} \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; 业务类代码\n1 2 3 4 5 6 7 8 9 10 11 @Service public class BookService { @Autowired private BookMapper bookMapper; public List\u0026lt;BookModel\u0026gt; selectByType(Integer type){ List\u0026lt;BookModel\u0026gt; bookList = bookMapper.selectByType(type); return bookList; } } 执行下述单元测试代码时能测试通过，可见在查询集合列表是不需要判断是否为空。\n1 2 3 4 5 6 7 8 9 10 11 12 13 @SpringBootTest public class TestBookService { @Autowired private BookService bookService; @Test public void testSelectByType() { List\u0026lt;BookModel\u0026gt; bookList = bookService.selectByType(3); Assertions.assertTrue(bookList != null); Assertions.assertTrue(bookList.size() == 0); } } 从上述试验可知，当获取的结果为List时，不使用Optinal关键字也能避免空指针问题。\n","permalink":"https://lucumt.info/post/mybatis/using-optional-in-mybatis-mapper/","tags":["mybatis"],"title":"在MyBatis接口中使用Optional进行非空判断"},{"categories":["数据库"],"contents":"在给MySQL数据库进行配置时，对于mysql数据库表下的user表配置错误，导致无法通过命令登录进入MySQL数据库，查找网上的文档发现可通过安全模式进入，简单记录下。\n公司某个项目采用的MySQL数据库不支持远程连接，于是个人登录后在host表进入如下修改:\n由于将host修改为了%d而正常的写法是%,从而导致在重启MySQL后无法登录\n由于user表主要用于控制用户能否远程登录以及其权限，当此表配置错误时会出现无法通过常规的mysql -uroot -pxxx的方式登录数据库修改其配置，此时只能通过安全模式进行登录。首先在终端输入service mysql stop关闭MySQL服务，接下来输入mysqld_safe --skip-grant-tables以安全模式开启MySQL服务\n接下来在另一个终端中输入mysql -uroot -pxxx即可正常登录，登录之后重新修改mysql数据库下的user表中的相关配置并重启MySQL服务即可。\n参考文档:\nhttps://stackoverflow.com/questions/48246503/user-table-not-having-root-user ","permalink":"https://lucumt.info/post/mysql/mysql-can-not-login-due-to-incorrect-host-config/","tags":["mysql"],"title":"MySQL中由于user表中错误的host配置导入无法登录数据库"},{"categories":["java编程"],"contents":"在各种Java编程规范中都强调尽量不用java.util.Arrays.asList()方法以避免调用此方法生成的List无法进行修改操作，个人近期在使用过程中发现该方法的另外一个坑，简单记录下。\n问题描述 在程序中需要检测某个元素是否在数组中，处于缩短代码篇幅的考虑，自己采用了Arrays.asList方法将其转化为List然后调用contains方法来判断：\n1 2 3 4 public static boolean checkContains(int ele) { int[] data = {11, 12, 13, 14}; return Arrays.asList(data).contains(ele); } 但实际执行结果和自己预期的不一致，理论上的结果应该为true，而实际返回的结果为false\n问题分析 在Debug模式下查看Arrays.asList(data)返回的值，发现其返回的结果不是预期中的List\u0026lt;Integer\u0026gt;而是List\u0026lt;int[]\u0026gt;，从而导致调用List.contains()方法失效!\n在IDEA中将Arrays.asList(data)返回的结果单独赋值给一个变量，可发现其类型确实为List\u0026lt;int[]\u0026gt;，若将结果类型修改为List\u0026lt;Integer\u0026gt;则会报错，如下图所示：\n在上图右边的报错信息中有如下说明信息:\nno instance(s) of type variable(s) exist so that int[] conforms to Integer inference variable T has incompatible bounds: equality constraints: Integer lower bounds: int[]\n上述文字的核心内容为Arrays.asList需要获取Object类型，而int是原生类型，但int[]符合要求，因此Arrays.asList()方法会将原始的int数组视作一个int[]对象进行处理，从而导致此结果1。\n解决方案 找到问题原因后修改起来也很容易，按照通常的编程习惯，只需要把数组的定义从int修改为Integer即可\n1 2 3 4 5 public static boolean checkContains(int ele) { Integer[] data = {11, 12, 13, 14}; List\u0026lt;Integer\u0026gt; dataList = Arrays.asList(data); return dataList.contains(ele); } 执行结果符合预期\nUpdate:\n在Stackoverflow上找到一个类似问题2，在其回答中提供了一些其它实现方案：\nJDK8实现\n1 2 int[] ints = new int[] {1,2,3,4,5}; List\u0026lt;Integer\u0026gt; list11 =Arrays.stream(ints).boxed().collect(Collectors.toList()); JDK16实现\n1 2 int[] ints = new int[] {1,2,3,4,5}; Arrays.stream(ints).boxed().toList(); asList不可变原因分析 查看Arrays.asList返回结果中的List，发现其返回的是内部自己实现的ArrayList，但该ArrayList没有重写add方法。\n但AbstractList默认没有实现add()方法而是抛出一个异常，从而导致无法通过调用add()方法添加元素。\nhttps://stackoverflow.com/questions/27522741/incompatible-types-inference-variable-t-has-incompatible-bounds\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://stackoverflow.com/questions/2607289/converting-array-to-list-in-java\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/java-core/arrays-as-list-convert-result-in-java/","tags":["java"],"title":"Arrays.asList类型转换结果的坑"},{"categories":["数据库"],"contents":"在软件开发中采用LIMIT OFFSET对数据库进行分页是常见操作，但在数据量很大时直接使用LIMIT OFFSET查询尾部的数据会导致性能很慢，本文简要介绍2种改进方案。\n以system_user表为例，基于MySQL中快速创建大量测试数据一文中的介绍给其添加1000万的测试数据\n1 2 3 4 5 6 7 CREATE TABLE `system_user` ( `id` INT NOT NULL AUTO_INCREMENT, `name` VARCHAR(8) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL, `age` INT DEFAULT NULL, `tag` VARCHAR(8) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE = INNODB CHARSET = utf8; 基于查询SQLSELECT * FROM system_user LIMIT 9999990,10;进行优化分析。\n上述SQL在数据库中的查询耗时如下：\n利用explain分析其执行计划结果如下：\n上图中的rows这一例的数据为9722930，由于rows这一列的值是预估值，实际上MySQL会将数据offset+count的数据都获取到内存中，然后再进行过滤。在本例中即会将10000000条数据都获取到然后再进行过滤筛选，而获取这么多数据显然会导致查询速度变慢！\n问题根源为MySQL在执行LIMIT OFFSET时会将数据全部加载到内存中然后再进行过滤，实际上执行的是一种假分页！\n找到问题的根源后，要提高查询速度只能让MySQL查询时返回的数据尽可能小，接下来根据主键是否连续自增来分别叙述。\n自增主键过滤 若主键连续自增，则可从业务逻辑的角度先对数据用WHERE过滤，然后用LIMIT进行分页，类似SQL如下：\n1 SELECT * FROM `system_user` WHERE id\u0026gt;=9999990 LIMIT 10; 执行结果如下，可以看出时间明显缩短很多\n进一步分析其执行计划，发现rows这一列的值为11，只是获取了我们想要的数据，没有获取大批量数据。\n采用此种方式性能提升的原因如下：\nMySQL中的主键默认有索引，基于索引查询速度很快 WHERE优先于LIMIT执行，数据量相对之前，变得很小 其中最关键的是第2点，只要查询的数据量变小，查询速度自然会提升。\n覆盖索引过滤 基于自增主键过滤要求主键必须主键连续自增，若主键不连续(如主键采用UUID生成)则上述方案不可行，此时可基于覆盖索引来减少获取和传输的数据量大小。\n将查询sql修改为类似如下\n1 2 3 SELECT u1.* FROM `system_user` u1 JOIN (SELECT id FROM `system_user` LIMIT 9999990,10) u2 ON u1.id=u2.id; 执行结果如下，可以看出耗时只比最初的少1秒\n查看其执行计划，发现获取的数据量仍然很大\n由于MySQL在数据量为千万级时查询速度会变慢，将数据库表中的数据量缩小到500万，执行如下：\n问题的根源在SELECT id FROM system_user LIMIT 9999990,10，虽然此时只查询id，但是id的数量仍然很庞大，由此造成查询速度变慢。\n此时可通过在数据库表中添加一列num并对其创建唯一索引，之后基于num进行过滤查询\n1 2 3 4 5 6 7 -- 添加索引 ALTER TABLE `system_user` ADD COLUMN `num` INT NOT NULL DEFAULT 1; ALTER TABLE `system_user` ADD UNIQUE INDEX `user_num_index` (`num`); -- 重新制造数据 TRUNCATE TABLE `system_user`; CALL add_user_batch(10000000); 改进后的sql如下\n1 2 3 SELECT u1.* FROM `system_user` u1 JOIN (SELECT num FROM `system_user` WHERE num\u0026gt;=9999990 LIMIT 10) u2 ON u1.num=u2.num; 执行结果耗时如下：\n可以看出其耗时和采用自增连续主键时类似。对应的执行计划如下，从图中也能看出要获取的数据量明显变小。\n总结 上述两种方案归根到底均为要通过WHERE提前过滤不需要的数据，减少返回的数据量，总结如下：\n若主键连续且自增，则通过主键进行过滤 若主键不连续自增，可额外创建一个自增列或者采用覆盖索引的方式改写 ","permalink":"https://lucumt.info/post/mysql/limit-large-size-data-in-mysql/","tags":["mysql"],"title":"在MySQL中对大量数据进行limit offset分页查询的优化"},{"categories":["数据库"],"contents":"在学习MySQL索引和分库分表等知识的过程中，经常会涉及到创建大批量的测试数据，本文简要说明自己常用的几种创建方式以及各自的优劣对比。\n实现方式 以下述的system_user表为例分别说明在不同的方式下如何大批量的创建测试数据。\n1 2 3 4 5 6 7 CREATE TABLE `system_user` ( `id` INT NOT NULL AUTO_INCREMENT, `name` VARCHAR(8) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL, `age` INT DEFAULT NULL, `tag` VARCHAR(8) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE = INNODB CHARSET = utf8; 通过代码程序创建 工作中使用的编程语言主要是Java，在之前我不熟悉MySQL存储过程用法的时，主要采用JDBC的方式实现批量创建数据，代码类似如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 import lombok.extern.slf4j.Slf4j; import org.apache.commons.lang3.RandomStringUtils; import org.apache.commons.lang3.RandomUtils; import org.junit.jupiter.api.Test; import org.springframework.boot.test.context.SpringBootTest; import javax.annotation.Resource; import javax.sql.DataSource; import java.sql.Connection; import java.sql.PreparedStatement; import java.sql.SQLException; @Slf4j @SpringBootTest public class TestBatchInsertData { @Resource private DataSource dataSource; private int DATA_SIZE = 1000_0000; private int BATCH_SIZE = 100; @Test public void testAddBatchData() { String insertSQL = \u0026#34;insert into system_user(name,age,tag) VALUES(?,?,?)\u0026#34;; try (Connection conn = dataSource.getConnection(); PreparedStatement pstmt = conn.prepareStatement(insertSQL)) { conn.setAutoCommit(false); for (int i = 1; i \u0026lt;= DATA_SIZE; i++) { pstmt.setString(1, RandomStringUtils.randomAlphanumeric(8)); pstmt.setInt(2, RandomUtils.nextInt(18, 80)); pstmt.setString(3, RandomStringUtils.randomAlphabetic(8)); pstmt.addBatch(); if (i % BATCH_SIZE == 0) { pstmt.executeBatch(); conn.commit(); log.info(\u0026#34;执行一次批量提交:\\t\u0026#34; + i / BATCH_SIZE); } } pstmt.executeBatch(); conn.commit(); log.info(\u0026#34;完成数据批量插入\u0026#34;); } catch (SQLException e) { throw new RuntimeException(e); } } } 从上述代码可知，此种实现方式较为简洁，实际的业务代码只有20行左右，对于具有Java开发经验的人来说上手很快，不足之处是需要额外准备相应的执行环境。\n通过存储过程创建 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 DELIMITER $$ USE `test`$$ DROP PROCEDURE IF EXISTS `add_user_batch`$$ CREATE DEFINER=`root`@`%` PROCEDURE `add_user_batch`(IN COUNT INT) BEGIN DECLARE i INT; DECLARE t_name VARCHAR(8); DECLARE t_tag VARCHAR(20); DECLARE t_age INT(2); DECLARE t_sql_template VARCHAR(100); DECLARE t_sql TEXT; DECLARE t_tag_mod_val INT DEFAULT(25); DECLARE t_commit_mod_val INT DEFAULT(100); DECLARE t_start_time DATETIME; DECLARE t_end_time DATETIME; TRUNCATE TABLE `system_user`; SET t_start_time=NOW(); SET t_sql_template = \u0026#34;INSERT INTO `system_user`(NAME, age, tag) VALUES\u0026#34;; SET t_sql = t_sql_template; SET i = 1; WHILE i \u0026lt;= COUNT DO SET t_age = FLOOR(1 + RAND() * 60); SET t_name = LEFT(UUID(), 8); -- 给tag随机制造空值 IF MOD(i, t_tag_mod_val) = 0 THEN SET t_tag = \u0026#34;NULL\u0026#34;; ELSE SET t_tag = CONCAT(\u0026#34;\u0026#39;\u0026#34;,LEFT(UUID(), 8),\u0026#34;\u0026#39;\u0026#34;); END IF; SET t_sql = CONCAT(t_sql,\u0026#34;(\u0026#39;\u0026#34;,t_name,\u0026#34;\u0026#39;,\u0026#34;,t_age,\u0026#34;,\u0026#34;,t_tag,\u0026#34;)\u0026#34;); IF MOD(i,t_commit_mod_val) != 0 THEN SET t_sql = CONCAT(t_sql,\u0026#34;,\u0026#34;); ELSE SET t_sql = CONCAT(t_sql,\u0026#34;;\u0026#34;); -- 只要达到t_commit_mod_val要求的次数，就执行并提交 SET @insert_sql = t_sql; PREPARE stmt FROM @insert_sql; EXECUTE stmt; DEALLOCATE PREPARE stmt; COMMIT; SET t_sql=t_sql_template; END IF; SET i = i + 1; END WHILE; -- 不能被t_commit_mod_val整除时，余下的数据处理 IF LENGTH(t_sql) \u0026gt; LENGTH(t_sql_template) THEN SET t_sql=CONCAT(SUBSTRING(t_sql,1,LENGTH(t_sql)-1),\u0026#39;;\u0026#39;); SET @insert_sql = t_sql; PREPARE stmt FROM @insert_sql; EXECUTE stmt; DEALLOCATE PREPARE stmt; COMMIT; END IF; SET t_end_time=NOW(); SELECT CONCAT(\u0026#39;insert data success,time cost \u0026#39;,TIMEDIFF(t_end_time,t_start_time)) AS finishedTag; END$$ DELIMITER ; 调用过程类似如下:\n1 2 3 4 5 6 7 8 -- 清空原有记录 TRUNCATE TABLE `system_user`; -- 调用存储过程 CALL add_user_batch(1000); -- 验证查询结果 SELECT COUNT(*) FROM `system_user`; 可以看出虽然用存储过程也能实现批量提交，但相对于Java实现而言，其代码量更大更为复杂，上手门槛略高。不过其好处也很明显，只要有数据库环境就能执行1。\n通过SQL语句创建 此种方式需要通过SELECT INSERT INTO来实现，具体步骤如下：\n通过如下的SQL初始化表中的数据：\n1 2 INSERT INTO `system_user`(NAME,age,tag) VALUES (LEFT(UUID(), 8),FLOOR(1 + RAND() * 60),LEFT(UUID(), 8)); 根据实际需要多次执行下述SQL：\n1 2 INSERT INTO `system_user`(NAME,age,tag) SELECT LEFT(UUID(), 8),FLOOR(1 + RAND() * 60),LEFT(UUID(), 8) FROM `system_user`; 这种方式主要是利用了SELECT每次查询之前表中的全部数据，然后重新插入，每次SELECT时都会将表中已有的数据全部查询出来，获取出总的记录数，然后根据SELECT后面的条件重新对每一条插入的记录重新赋值插入，实际上相当于翻倍插入。\n由于每次执行SELECT INTO时都是将之前的数据量扩大1倍，故往数据库中插入的总数count与执行次数n的关系如下:\ncount = $2^n$\n更具体的信息如下：\n阶段 插入总数 第1次执行 2 第2次执行 4 第3次执行 8 \u0026hellip; 第10次执行 1024 \u0026hellip; 第20次执行 1048576 第21次执行 2097152 第22次执行 4194304 第23次执行 8388608 在MySQL中tmp_table_size为16M，innodb_buffer_pool_size的默认值是128M，当执行到一定次数后，会出现类似The total number of locks exceeds the lock table size的错误，此时需要根据实际情况调整这两个参数，参考如下：\n1 2 SET GLOBAL tmp_table_size =512*1024*1024; -- 512M SET global innodb_buffer_pool_size= 2*1024*1024*1024; -- 2G 此种方式虽然需要多次执行SQL语句，但其优点也很明显，只需要将SQL语句稍作修改，就能适用于不同的数据库表。\n对比\u0026amp;总结 各种方式的对比如下：\n优点 缺点 适用场景 代码程序创建 1.实现方便，有编程知识即可\n2.性能不受数据量大小的影响 1.需要具备相关的编程知识\n2.需要有专门的软件运行环境，移植性不好\n3.不具备通用性 需要反复的创建大批量数据 存储过程创建 1.由于直接操作数据库，速度最快\n2.编写完成后可重复使用\n3.性能不受数据量大小的影响 1.存储过程的编写耗时，调试不太方便\n2.不具备通用性 1.需要反复的创建大批量数据\n2.无法通过程序代码创建 SQL语句创建 1.使用最方便，只要有mysql环境就能上手\n2.具备通用性，适合各种数据库表 1.需要多次执行SQL语句\n2.越到后面单次数据量越大，影响性能 创建大批量测试数据的次数较少,通常1到2次 各自执行1000万条数据的粗略耗时对比如下：2\n代码程序创建，6小时 存储过程创建，11分钟 SQL语句创建，5分钟 从上述结果可以看出通过SQL语句创建耗时相对较少3，若只是单纯的插入数据，建议优先选择此种方式。\n说明\n由于代码程序创建和存储过程创建这2种方式与特定的数据表强相关，换做其它表后需要重新修改，故在没有特殊要求的情况下建议采用SQL语句创建。\n疑问\n按存储过程创建从理论上来说速度要比SQL语句创建快很多(存储过程可以控制每次提交的数据量大小)，但多次测试发现前者的耗时约为后者的1倍，原因待继续分析。\n前提是有创建存储过程的权限\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n基于相同的提交次数进行比较，且是在个人电脑环境，只做横向对比，不具有很强的参考价值\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n代码程序创建和存储过程创建中涉及到一些控制逻辑和随机数的生成，这些是造成其耗费时间较长的因素之一\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/mysql/mysql-create-massive-test-data-quickly/","tags":["mysql"],"title":"MySQL中快速创建大量测试数据"},{"categories":["数据库"],"contents":"在数据库中使用COUNT函数统计总数是常用操作，本文参考网上资料以及个人实际操作记录下MySQL中通过COUNT(列名)、COUNT(常量)以及COUNT(*)在相同查询条件下1 的区别以及使用场景。\n本文基于InnoDB和MyISAM这两种常见的MySQL引擎，利用名为add_user_batch的存储过程向system_user表中插入1000万数据，对比测试它们的查询结果和响应性能。\n1 2 3 4 5 6 7 CREATE TABLE `system_user` ( `id` INT NOT NULL AUTO_INCREMENT, `name` VARCHAR(8) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL, `age` INT DEFAULT NULL, `tag` VARCHAR(8) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE = INNODB CHARSET = utf8; 在add_user_batch中，采用循环的方式动态生成数据，每循环100次会将insert批量执行语句插入数据库中并提交，每循环25次其中的tag就会被置为空，故tag值为空的记录总共有400000个。\n结果对比 在MySQL的官网中对于COUNT()函数有如下说明：\nReturns a count of the number of non-NULL values of expr in the rows retrieved by a SELECT statement. The result is a BIGINT value.\nIf there are no matching rows,COUNT() returns 0. COUNT(NULL) returns 0.\nCOUNT(*)is somewhat different in that it returns a count of the number of rows retrieved, whether or not they contain NULL values.\n从中可以得出如下结论:\nCOUNT(expr)计算的是SELECT操作获取的数据行中expr不为空的总数 COUNT(*)计算的是SELECT操作获取的所有行数，不论其中是否有列为空 由于COUNT()主要是获取不为空的值，而在使用COUNT(常量)时其值恒为真，故其结果与COUNT(*)相同，同时由于主键不能为空，故COUNT(主键)的结果也与它们相同。基于上述理论分析可获知\nCOUNT(*)=COUNT(常量)=COUNT(主键)\u0026gt;=2COUNT(非主键列)\n采用前面存储过程生成的数据分别用上述4种方式去查询的结果如下，由于tag值为空的记录数为400000个，故COUNT(tag)返回的记录数为9600000，实际查询结果均符合理论预期。\n不同事务中的结果 由于InnoDB引擎支持事务，而在不同事务可能会导致数据库记录不一致，故在MySQL官网中对于InnoDB有如下文字说明，其主要说明的是COUNT()返回的是当前事务中可见的对应行数 ，即同样的查询SQL在不同的事务中其结果可能不相同3\nInnoDB does not keep an internal count of rows in a table because concurrent transactions might “see” different numbers of rows at the same time. Consequently, SELECT COUNT(*) statements only count rows visible to the current transaction.\n性能对比 说明\n由于测试环境以及MySQL查询缓存的原因，即使是同一条SQL查询多次查询的时间消耗也不完全相同，故在性能对比这块只做大致时间的对比，不会精确到毫秒级。\n继续从MySQL官方中寻找相关说明:\nInnoDB handles SELECT COUNT(*) and SELECT COUNT(1) operations in the same way. There is no performance difference.\nFor MyISAM tables, COUNT(*) is optimized to return very quickly if the SELECT retrieves from one table, no other columns are retrieved, and there is no WHERE clause.\nThis optimization only applies to MyISAM tables, because an exact row count is stored for this storage engine and can be accessed very quickly. COUNT(1) is only subject to the same optimization if the first column is defined as NOT NULL\n上述文字的要点如下：\nInnoDB对于COUNT(*)和COUNT(1)以相同的方式处理，它们没有性能上的区别 MyISAM对于COUNT(*)在 没有WHERE条件且只查询一张表 的情况下会进行优化，而COUNT(1)只有在 没有WHERE条件且第1列不为空 的情况下才会进行优化 对于第1点可从前面结果对比查询图中得到验证，其查询时间都近似为0.01s。\n下面分别展示MyISAM在有和没有WHERE过滤条件时COUNT()函数的查询耗时：\n没有WHERE条件执行如下，从中可以看出只有对于可能存在空值的tag列，其查询耗时为2.26s，其余的耗时均为0.01s，这其中的特例是name列，虽然不是主键，但是由于在建表时限制其非空，故InnoDB引擎会对其进行优化处理。\n有WHERE条件执行如下，从图中可以看出，此时由于InnoDB引擎优化不生效，故它们的查询时间都在秒级范围。\n给system_user表添加名为type的列并放在第1列，然后分别执行COUNT(1)与COUNT(*)发现耗时近似相，官方文档上说的只有在第1列不为空的限制条件在此处并不生效，原因待进一步分析。\n总结\u0026amp;建议 总结: SELECT COUNT(*)，查询特定表总行数时 SELECT COUNT(1)，查询特定表总行数，其结果同SELECT COUNT(*) SELECT COUNT(列名),查询指定列中符合条件得所有非空值 使用建议: SELECT COUNT(*)，查询总行数时使用，尤其是MyISAM引擎会在特定场景下进行优化 SELECT COUNT(1)，由于在MyISAM中只有在特定场景下优化才会生效，此种用法较为偏僻不符合SQL规范，不建议使用 SELECT COUNT(列名)，查询对应列的非空总行数 参考文档:\nhttps://segmentfault.com/a/1190000040733649 https://stackoverflow.com/questions/2710621/count-vs-count1-vs-countpk-which-is-better https://github.com/lucumt/myrepository/blob/master/mysql/add_user_batch.sql 即WHERE后面的过滤条件相同\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n相等的场景为SELECT返回的行中该列数据全部不为空\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n依赖于具体的事务隔离级别\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/mysql/difference-and-usage-for-various-select-count/","tags":["mysql"],"title":"MySQL中不同SELECT COUNT统计总数时的区别"},{"categories":["Java编程"],"contents":"ClassNotFoundException与NoClassDefFoundError是Java开发中经常会遇到的异常与错误，本文基于个人工作中遇到的场景以及网上的资料，简要总结它们的差异、出现场景以及规避方案。\nClassNotFoundException 分析 上图为ClassNotFoundException的类继承结构，从图中可看出它继承自Exception且没有继承自RuntimeException,基于Java语言规范它属于Checked Exception1，实际编程时必须在代码中利用try-catch显示的捕获处理或者利用throws将其抛出到上一层调用者处理，否则会导致编译器报错。\n产生原因 在ClassNotFoundException的官方API中对于其产生的原因有如下描述:\nThrown when an application tries to load in a class through its string name using:\nThe forName method in class Class. The findSystemClass method in class ClassLoader . The loadClass method in class ClassLoader. but no definition for the class with the specified name could be found.\n基于上述描述可知ClassNotFoundException产生的根本原因如下：\n在应用程序类中通过对应类的字符串名称去加载该类时找不到类的定义文件，即会抛出此异常\n上述描述实际上可分为2类:\n在Class类中通过forName方法去加载类时找不到类定义文件，由于该方式可在普通的Java类中使用故较为常见(如加载数据库驱动) 在ClassLoader类中通过findSystemClass或loadClass去加载类时找不到类定义文件，由于是在类加载器中使用，一般的业务涉及较少故不常见 问题复现 基于Class类的forName模拟复现:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class TestClassForName { public static void main(String[] args) { testForName(); } private static void testForName() { try { Class.forName(\u0026#34;com.jdbc.mysql.Driver\u0026#34;); System.out.println(\u0026#34;output info after Class.forName invoke inside try-catch\u0026#34;); } catch (ClassNotFoundException e) { e.printStackTrace(); } System.out.println(\u0026#34;output info after Class.forName invoke outside try-catch\u0026#34;); } } 输出结果如下，可见try-catch之后的代码块还能正常执行\n基于ClassLoader中的loadClass复现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class TestClassLoader { public static void main(String[] args) { testLoadClass(); } private static void testLoadClass() { try { ClassLoader.getSystemClassLoader().loadClass(\u0026#34;com.jdbc.mysql.Driver\u0026#34;); System.out.println(\u0026#34;output info after ClassLoader.loadClass invoke inside try-catch\u0026#34;); } catch (ClassNotFoundException e) { e.printStackTrace(); } System.out.println(\u0026#34;output info after ClassLoader.loadClass invoke outside try-catch\u0026#34;); } } 输出结果如下\n从上述结果可以看出ClassNotFoundException虽然会导致try-catch代码块里面位于异常发生点之后的代码无法执行，但是位于try-catch代码块外面的代码程序执行不受影响(这其实是Checked Exception自身的特性决定的)。\nNoClassDefFoundError 分析 上图为NoClassDefFoundError的类继承结构，从图中可看出它继承自Error,，在Java语言关于Exception的官方API中有如下描述：\nThe unchecked exception classes are the run-time exception classes and the error classes.\n故NoClassDefFoundError属于Unchecked Exception，而对于这类异常不需要在程序中显示的通过try-catch捕获，需要从代码和工程层面进行处理。\n产生原因 在NoClassDefFoundError的官方API中有如下描述：\nThrown if the Java Virtual Machine or a ClassLoader instance tries to load in the definition of a class (as part of a normal method call or as part of creating a new instance using the new expression) and no definition of the class could be found.\nThe searched-for class definition existed when the currently executing class was compiled, but the definition can no longer be found.\n基于上述描述可知NoClassDefFoundError产生的根本原因如下：\n程序在编译时该类存在，在调用过程中JVM虚拟机加载该类时找不到该类的Class文件\n由于Java类加载过程有如下图所示的5个阶段，在其中每个阶段都可能会出现问题，结合实际开发场景，最典型的两类场景如下：\n类加载阶段出错。如在编译时类存在，但执行时不存在，一个典型的场景是 jar包版本不匹配！ 这也是我们开发过程中最容易遇到的场景 类初始化阶段出错。此种场景下编译也能通过，但由于某种原因导致初始化失败，程序仍然无法调用类。 与之相似的错误为NoSuchMethodError，其产生原因为程序执行时类存在，但是当前程序调用的方法不存在。\n问题复现 类加载阶段出错，在编译后jar文件中删除要调用的class类即可实现：\n要编译为jar文件的代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 /* 类结构 +---src | +---main | | \\---java | | \\---com | | \\---lucumt | | \\---api | | InnerApi.java | | OuterApi.java */ public class OuterApi { public static void invoke() { InnerApi.hello(); } } public class InnerApi { public static void hello() { System.out.println(\u0026#34;hello\u0026#34;); } } 主执行类\n1 2 3 4 5 6 7 8 9 10 11 12 13 import com.lucumt.api.OuterApi; public class TestNoClassDefFoundError1 { public static void main(String[] args) { try { OuterApi.invoke(); } catch (NoClassDefFoundError e) { e.printStackTrace(); } System.out.println(\u0026#34;OutApi invoke\u0026#34;); } } 将上述工程编译打包为jar文件，然后在jar文件中去掉InnerApi，将其引入包含执行类的测试工程，此时其结构如下：\n输出结果如下，可以看出虽然抛出了异常，但在try-catch代码块之后的代码还是能够执行\n类初始化阶段出错，通过某种方式强制初始化出错：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class TestNoClassDefFoundError2 { public static void main(String[] args) { try { Demo.hello(); }catch(NoClassDefFoundError e){ e.printStackTrace(); } System.out.println(\u0026#34;invoke Demo.hello()\u0026#34;); } } class Demo { private static int val = 1 / 0; public static void hello() { System.out.println(\u0026#34;hello\u0026#34;); } } 输出结果如下，不同于前一个测试，此处的try-catch之后的代码没有机会执行\n从上面2个实验中可发现虽然都对NoClassDefFoundError进行了try-catch捕获，但第一个能继续执行，而第二个却直接终止。造成这种差异的主要原因是第一个测试中的Demo没能完成初始化，导致整个程序加载失败(实际上程序提示的错误为 ExceptionInInitializerError)，而第二个程序是在执行中才遇到类缺失2。\n基于Unchecked Exception我们通常不需要在代码中显示的利用try-catch捕获，更多的是修改代码本身和调整jar文件版本。\n总结 ClassNotFoundException NoClassDefFoundError 继承关系 java.lang.Exception java.lang.Error 类型 异常 错误 程序受影响程度 添加try-catch后可继续执行 基于产生于类加载的不同阶段，可能直接种植，也可能在try-catch之后继续执行 可能的场景 1.要加载的类不存在\n2.类名编写错误 1.jar包缺失或jar包版本不匹配\n2.类初始化失败 处理方法 1. 修改代码，添加缺失的jar文件\n2. 代码中添加try-catch捕获异常 修改代码业务逻辑 参考:\nhttps://segmentfault.com/a/1190000021292121\nhttps://stackoverflow.com/questions/28322833/classnotfoundexception-vs-noclassdeffounderror\nhttps://docs.oracle.com/javase/specs/jls/se7/html/jls-11.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n实际上应该有更科学更理论的解释，只不过自己目前找不到相关资料，暂时这么解释\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/java-core/difference-between-class-not-found-exception-and-no-class-def-found-error/","tags":["Java"],"title":"ClassNotFoundException与NoClassDefFoundError对比"},{"categories":["Java编程","Java多线程","翻译"],"contents":"本文翻译自 Dealing with InterruptedException\n这个故事可能很熟悉: 你正在编写一个测试程序，需要将程序暂停一段时间,于是你调用了Thread.sleep()来实现。 但此时编译器或IDE会立即提示你没有处理非运行时异常 InterruptedException。那么，什么是InterruptedException,为什么我们要必须处理它呢？\n最常见的处理方式是将该异常吞没掉: 通过try-catch捕获该异常然后不进行任何处理(或许会用日志来记录异常，但并没有改进多少)， 我们将在代码清单4中看见此方式的使用。不幸的是，这种方式丢弃了有关中断产生的重要信息，而这可能会影响应用程序及时取消执行或关闭的能力。\n阻塞方法 当一个方法抛出InterruptedException异常时，除了该异常之外它还会告诉你额外的一些信息。如果你问的好，它会告诉你这是一个阻塞方法， 它会尝试解除阻塞并且提前返回。\n阻塞方法不同于一个需要长时间返回的普通方法，普通方法的完成仅取决于你要求它做多少工作以及是否有足够的计算资源(CPU循环和内存)，另一方面，阻塞方法的完成度还取决于某些外部事件，例如计时器到期、I/O操作完成或另一个线程的操作(释放锁、设置标志位或将任务放到一个工作队列中等)。普通的方法只要其工作任务完成了该方法就完成，而阻塞方法由于它们依赖于外部事件而不太可预测。由于很难预测何时完成，阻塞方法会影响响应能力。\n由于阻塞方法可能由于等待的事件永远不发生而一直阻塞，所以通常能取消该方法对阻塞方法很有用(对于长时间运行的非阻塞方法，通常也是有用的)。可取消的操作是指能从外部提前结束一个需要它自己完成的任务。Object.wait()和Thread提供的Thread.sleep()即是一种取消机制，它允许一个线程请求另外一个线程提前停止它正在执行的任务。当一个方法抛出InterruptedException异常时，意味着如果执行该方法的线程被中断，它将通过抛出InterruptedException异常来尝试停止当前任务并且提前返回。一个设计良好的阻塞库方法应该及时响应中断并抛出InterruptedException异常，因而可以在可取消的任务中使用而不影响响应能力。\n线程中断 每个线程都一个与之关联的布尔属性来表示其中断状态。中断状态的初始值为false，当一个线程被其它线程调用Thread.interrupt()方法中断时，会根据实际情况做出响应: 如果该线程正在执行低级别的可中断方法(如Thread.sleep()、Thread.join()或Object.wait())，则会解除阻塞并抛出InterruptedException异常，否则Thread.interrupt()仅设置线程的中断状态，在该被中断的线程中稍后可通过轮询中断状态来决定是否要停止当前正在执行的任务。中断状态可通过Thread.isInterrupted()来读取，也可通过不规范命名的Thread.interrupted()在单个操作中读取和清除中断状态。\n中断是一种协作机制。当一个线程中断了另外一个线程时，被中断的线程没必要停止正在执行的任务，相反，中断只是礼貌的要求被中断的线程在它方便的时候停止它当前正在执行的任务。有些方法如Thread.sleep()会认真对待这个要求，而其它一些方法则不需要注意中断。不阻塞但需要长时间执行的方法也可通过轮询中断状态来提前返回，你也可以忽略中断求，但这样做可能会影响响应性。\n中断的协作特性的一个好处是它为安全的构建可取消的任务提供了更大的灵活性。实际上我们很少想要立即终止一个任务，如果任务在更新期间被取消，程序数据结构可能会处于不一致的状态。而中断操作允许我们在任务终止之前做其它的一些操作，如清理任何正在运行的任务、恢复不变量、将终端请求通知给其它任务等。\n处理InterruptedException 如果抛出InterruptedException异常意味着该方法是一个阻塞方法，那么调用一个阻塞方法意味着调用方法也是阻塞方法，我们应该有一个处理InterruptedException异常的策略。通过最简单的策略是直接抛出InterruptedException，如代码清单1中puskTask()和getTask()方法所示,这样做即可使方法响应中断，并且通常只需要在throws字句中添加InterruptedException。\n代码清单1： 通过向调用者传递InterruptedException来避免捕获\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class TaskQueue { private static final int MAX_TASKS = 1000; private BlockingQueue\u0026lt;Task\u0026gt; queue = new LinkedBlockingQueue\u0026lt;Task\u0026gt;(MAX_TASKS); public void putTask(Task r) throws InterruptedException { queue.put(r); } public Task getTask() throws InterruptedException { return queue.take(); } } 有时在传播异常之前需要进行一些清理，在这种情况下，你可以捕获InterruptedException，执行清理然后重新抛出异常。代码清单2，一种用于匹配在线游戏服务中玩家的机制展示了这种技术。matchPlayers()方法等待两个玩家到达后就开始一个新的游戏，如果在一个玩家到达后但在第二个玩家到达之前被中断，它会在重新抛出InterruptedException异常之前将该玩家放回队列，这样玩家的请求就不会丢失。\n代码清单2: 在重新抛出InterruptedException之前基于任务进行特定清理\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class PlayerMatcher { private PlayerSource players; public PlayerMatcher(PlayerSource players) { this.players = players; } public void matchPlayers() throws InterruptedException { Player playerOne, playerTwo; try { while (true) { playerOne = playerTwo = null; // 等两个玩家到达后开始一个新的游戏 playerOne = players.waitForPlayer(); // 可能抛出InterruptedException playerTwo = players.waitForPlayer(); // 可能抛出InterruptedException startNewGame(playerOne, playerTwo); } } catch (InterruptedException e) { //如果一个玩家达到后线程被中断，将这个玩家放回队列 if (playerOne != null) players.addFirst(playerOne); //重新抛出异常 throw e; } } } 不要吞没中断 有些时候抛出InterruptedException异常并不合适，例如在由Runnable定义的任务中调用一个可中断方法，在这种情形下，你不能抛出InterruptedException，但你也不想做其它任何事情。当阻塞方法检测到中断并抛出InterruptedException时，它会清除中断状态。如果捕获InterruptedException异常但无法重新抛出它，则应保留中断发生时的证据，以便调用堆栈上的代码可以了解中断并在必要时对其进行响应。如代码清单3所示，这个任务是通过调用interrupt()来 重新中断(reinterrupt) 当前线程完成的。每当你捕获InterruptedException并且不重新抛出它时，要在返回之前重新中断当前线程(即清除中断状态)。\n代码清单3: 捕获InterruptedException后恢复中断状态\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class TaskRunner implements Runnable { private BlockingQueue\u0026lt;Task\u0026gt; queue; public TaskRunner(BlockingQueue\u0026lt;Task\u0026gt; queue) { this.queue = queue; } public void run() { try { while (true) { Task task = queue.take(10, TimeUnit.SECONDS); task.execute(); } } catch (InterruptedException e) { //重新设置当前线程的中断状态 Thread.currentThread().interrupt(); } } } 对于InterruptedException最糟糕的处理是吞没它，在捕获它之后既不重新抛出它也不重新设置当前线程的中断状态。\n代码清单4: 吞下中断\u0026ndash;不要这样做\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 不要这么做 public class TaskRunner implements Runnable { private BlockingQueue\u0026lt;Task\u0026gt; queue; public TaskRunner(BlockingQueue\u0026lt;Task\u0026gt; queue) { this.queue = queue; } public void run() { try { while (true) { Task task = queue.take(10, TimeUnit.SECONDS); task.execute(); } } catch (InterruptedException swallowed) { /* 不要这么做 - 相反要恢复线程的中断状态 */ } } } 如果你无法重新抛出InterruptedException，不论你是否计划对中断请求进行响应，你仍然应该重新设置当前线程的中断状态，因为单个中断请求可能有多个接收人。标准线程池(ThreadPoolExecutor)中的工作线程实现了响应中断，因此中断线程池中运行的任务可能会同时影响到取消任务和通知执行线程当前线程池正在关闭。如果该任务吞下中断请求，则工作线程可能不会知道该中断被请求过，这可能会延迟应用程序或关闭服务。\n实现可取消的任务 在Java语言规范中没有任何内容可以中断任何特定语义，但在较大程序中，很难保持除了取消操作之外的任何中断语义。依赖于具体的业务活动，用户可以通过GUI或JMS、WebService服务等来请求取消操作。也可以由程序逻辑请求实现，例如，网络爬虫在检测到磁盘空间已满时自动关闭，或者并行算法可能会启动多个线程来搜索解决方案的不同区域并在其中一个找到解决方案后取消其余的。\n一个任务不能仅仅因为它可以取消而意味着它需要立即响应中断请求。对于通过代码循环执行的任务，通常是在每个循环中检查中断状态。根据循环执行的时间长短，在任务代码通知线程中断之前可能需要一些时间(通过调用Thread.isInterrupted()轮询中断中断或调用一个阻塞方法)。如果任务需要更具响应性，则可以更频繁的轮询中断状态。阻塞方法通常在进入该方法时立即轮询中断状态，如果要提高响应性，可以直接抛出InterruptedException异常。\n当你知道一个线程即将结束执行时，吞下一个中断是可接受的。只有当调用可中断方法的类是Thread的一部分而不是Runnable或通用库代码时才会出现此种情形，如代码清单5所示。它创建了一个枚举质数的线程，并且允许线程在中断时退出。这个寻找质数的循环在两个地方检查中断：一个通过轮迅while循环判断条件中的isInterrupted()方法，另一个则是通过调用阻塞的BlockingQueue.put()方法。\n代码清单5: 在知道线程将结束时可以吞下中断\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class PrimeProducer extends Thread { private final BlockingQueue\u0026lt;BigInteger\u0026gt; queue; PrimeProducer(BlockingQueue\u0026lt;BigInteger\u0026gt; queue) { this.queue = queue; } public void run() { try { BigInteger p = BigInteger.ONE; while (!Thread.currentThread().isInterrupted()) queue.put(p = p.nextProbablePrime()); } catch (InterruptedException consumed) { /* 允许线程退出 */ } } public void cancel() { interrupt(); } } 非中断阻塞 并非所有的阻塞方法都会抛出InterruptedException。输入流和输出流由于等待I/O操作完成而阻塞，但它们不会抛出InterruptedException异常，并且如果它们被中断，也不会提前返回。但在套接字I/O的情形下，如果一个线程关闭套接字，在其它线程中的阻塞I/O操作将会通过SocketException提早结束。java.nio包中的非阻塞I/O操作也不支持可中断的I/O操作，但可以通过关闭通道或请求唤醒Selector来实现类似的阻塞操作。类似的，尝试获取内部锁(进入一个同步块)不能被中断，但使用ReentrantLock能实现可中断的获取锁。\n非取消任务 有些任务只是简单的拒绝被中断从而导致它们无法取消。但即使是不可取消的任务也应该保留中断状态，以防在调用堆栈上的代码想要在不可取消的任务完成后响应中断。代码清单6显示了一个方法等待阻塞队列直到其中某个元素可用，无论它是否被中断。为了安分守己，该方法在完成后会清除最终代码块中的中断状态，以避免剥夺调用者发出的中断请求。由于会导致无限循环而不能在该方法中恢复中断状态。(BlockingQueue.take()可以在调用时立即轮询中断状态，如果发现有中断状态集则立即抛出InterruptedException异常。)\n代码清单6: 非取消的任务在返回之前恢复中断状态\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public Task getNextTask(BlockingQueue\u0026lt;Task\u0026gt; queue) { boolean interrupted = false; try { while (true) { try { return queue.take(); } catch (InterruptedException e) { interrupted = true; // 虽然发生中断，但是继续尝试 } } } finally { if (interrupted) Thread.currentThread().interrupt(); } } 总结 你可以使用Java平台提供的协作中断机制来构建灵活的取消策略。线程活动可以决定它们是否可以取消、如何响应中断，如果立即返回会影响应用程序的完整性时，它们可以推迟中断以执行特定于任务的清理活动。即是想完全忽略代码中的中断，也要确保在捕获InterruptedException时恢复中断状态，并且不要重新抛出它以便调用它的代码不会被剥夺对于中断发生的感知。\n\u0026lt;–翻译结束!–\u0026gt;\n","permalink":"https://lucumt.info/post/translate/java-concurrency/dealing-with-interrupted-exception/","tags":["Java"],"title":"[译]如何处理InterruptedException"},{"categories":["Java编程","Java多线程"],"contents":"volatile关键字在Java多线程编程中很常见，由于自己之前学习多线程时一度以为只要需确保线程可见性的代码都需要使用volatile关键字，后来发现并不是这样的，故简单记录下。\n典型使用场景 下面这段代码创建了两个线程threadA和threadB，threadA中运行display()方法，threadB中运行stop()方法，在threadA启动1秒后启动threadB。\n在stop布尔变量上分别注释和不注释volatile的运行结果如下：\n注释volatile关键字时，display()方法一直运行，程序不能终止； 不注释volatile关键字时，display()方法会在调用stop()方法后立即停止运行，程序终止； 注: 根据实际运行电脑的配置，有可能不注释volatile关键字时调用stop()方法也能让display()方法立即停止运行。\n代码清单1: volatile关键字的使用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 public class VolatileTest { //注释掉volatile关键字时display()方法会一直运行下去 private /*volatile*/ boolean stop = false; private void stop() { stop = true; } private void display() { while(!stop) { } System.out.println(LocalDateTime.now()); } public void test() { Thread threadA = new Thread(()-\u0026gt;{ this.display(); }); Thread threadB = new Thread(()-\u0026gt;{ this.stop(); }); threadA.start(); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } threadB.start(); } public static void main(String[] args) { VolatileTest vt = new VolatileTest(); vt.test(); } } 上述代码展示了volatile的典型使用场景:\n当有两个或以上的线程同时读取一个共享的可变变量时，为了确保每个线程都能获取到最新的值，应该使用volatile关键字对该变量进行修饰，确保该变量的可见性。\n关于volatile如何实现确保变量可见性，网上已经有很多资料，请自行查阅，如volatile和lock原理分析。\n有独占锁时不需要使用volatile 既然volatile变量确保的是在多个线程同时读取一个变量时确保内存可见性，如果有多个线程对共享变量进行读写时，由于排它锁(exclusive lock) 的存在导致任一时刻只能有一个线程对共享变量进行读写操作，此时是否还需要添加volatile关键字呢？答案是否定的，从字面意思可以看出，由于同一时刻只能有一个线程访问变量，所以变量可见性的问题不会存在，故没必要添加volatile关键字。\n以Java8为例，在Java语言规范中有关于volatile的说明volatile Fields中有如下片段:\nThe Java programming language allows threads to access shared variables (§17.1). As a rule, to ensure that shared variables are consistently and reliably updated, a thread should ensure that it has exclusive use of such variables by obtaining a lock that, conventionally, enforces mutual exclusion for those shared variables.\nThe Java programming language provides a second mechanism, volatile fields, that is more convenient than locking for some purposes.\nA field may be declared volatile, in which case the Java Memory Model ensures that all threads see a consistent value for the variable (§17.4).\n从这段文字可以看出volatile相对于独占锁提供了更加简便的方式让变量一致且可靠的更新，volatile只确保读取的值正确，对写入影响不大，而独占锁则限制了同时只能有一个读或写，导致出现性能问题以及在特定的场景下无法使用的问题(如代码清单1所示，若采用独占锁则同时只能有一个线程运行，违背了设计初衷)。\n下述代码展示了一个典型的生产者/消费者模式，由于独占锁的存在，即使没有使用volatile关键字，程序也能正常工作。\n代码清单2: 生产者/消费者模式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 public class ProducerConsumerTest { private static final int MAX_SIZE = 10; //这两个变量没必要使用volatile关键字修饰 private LinkedList\u0026lt;String\u0026gt; items = new LinkedList\u0026lt;\u0026gt;(); private int count; private Object lock = new Object(); private void produce(String ele) { synchronized (lock) { try { while (count \u0026gt;= MAX_SIZE) { lock.wait(); } } catch (InterruptedException e) { e.printStackTrace(); } items.add(ele); count++; System.out.println(Thread.currentThread().getName() + \u0026#34; 添加了元素 \u0026#34; + ele + \u0026#34; 当前元素总数为 \u0026#34; + count); lock.notifyAll(); } } private String consume() { String result = null; synchronized (lock) { try { while (count == 0) { lock.wait(); } } catch (InterruptedException e) { e.printStackTrace(); } result = items.pollLast(); count--; System.out.println(Thread.currentThread().getName() + \u0026#34; 获取了元素 \u0026#34; + result + \u0026#34; 当前元素总数为 \u0026#34; + count); lock.notifyAll(); } return result; } public void test() { for(int i=0;i\u0026lt;10;i++) { new Thread(() -\u0026gt; { for(int j=0;j\u0026lt;5;j++) { String ele = UUID.randomUUID().toString().replace(\u0026#34;-\u0026#34;, \u0026#34;\u0026#34;); this.produce(ele); } },\u0026#34;Producer_\u0026#34; + i).start(); } for(int i=0;i\u0026lt;5;i++) { new Thread(() -\u0026gt; { for(int j=0;j\u0026lt;10;j++) { this.consume(); } },\u0026#34;Consumer_\u0026#34; + i).start(); } } public static void main(String[] args) { new ProducerConsumerTest().test(); } } 利用volatile在单例模式中实现双重检查 volatile关键字不仅可以确保线程可见性，还能禁止重排序，它的一个典型应用是利用双重检查实现线程安全的单例设计模式，如代码清单3所示。在该程序中主要利用了volatile禁止重排序的功能，详细说明请参见Java并发编程的艺术P67中的 双重检查锁定与延迟初始化 。\n代码清单3: 利用双重检查实现线程安全的单例模式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class Singleton { private static volatile Singleton instance = null; private Singleton() { } public static Singleton getInstance() { if(instance == null) { synchronized(Singleton.class) { if(instance == null) { instance = new Singleton(); } } } return instance; } } 参考文章:\nJava并发编程的艺术 volatile和lock原理分析 Simplest and understandable example of volatile keyword in java Difference between volatile and synchronized in Java ","permalink":"https://lucumt.info/post/java-concurrency/how-to-use-volatile-in-java/","tags":["Java","Java Concurrency"],"title":"volatile关键字在Java程序中的使用"},{"categories":["Java编程"],"contents":"Java中字符串的比较在面试中很常见，我们都知道比较字符串是否相等要使用equals()而不是==。本文首先利用javap命令从class文件的角度来分析不同字符串比较的结果，然后分析下Tomcat中如何获取前端输入的字符串参数,并以此说明Java Web开发中该如何正确的进行字符串的比较。\n简单字符串比较 测试代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class StringTest { public static void main(String[] args) { String s1 = \u0026#34;Hello World\u0026#34;; String s2 = \u0026#34;Hello World\u0026#34;; String s3 = new String(\u0026#34;Hello World\u0026#34;); String s4 = new String(\u0026#34;Hello World\u0026#34;); System.out.println(\u0026#34;利用==比较\u0026#34;); System.out.println(s1 == s2); System.out.println(s1 == s4); System.out.println(s3 == s4); System.out.println(s1 == s4.intern()); System.out.println(s3.intern() == s4.intern()); System.out.println(\u0026#34;\\n利用equals()比较\u0026#34;); System.out.println(s1.equals(s2)); System.out.println(s1.equals(s4)); System.out.println(s3.equals(s4)); } } 程序运行的结果如下：\n从上图中可以看出: 利用equals()比较时返回的结果全为true,而利用==比较的结果只有部分为true。利用javap命令输出class文件内容如下(省略掉了System.out.println()相关的)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 Compiled from \u0026#34;StringTest.java\u0026#34; public class StringTest { public StringTest(); Code: 0: aload_0 1: invokespecial #8 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 4: return public static void main(java.lang.String[]); Code: 0: ldc #16 // String Hello World 2: astore_1 3: ldc #16 // String Hello World 5: astore_2 6: new #18 // class java/lang/String 9: dup 10: ldc #16 // String Hello World 12: invokespecial #20 // Method java/lang/String.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 15: astore_3 16: new #18 // class java/lang/String 19: dup 20: ldc #16 // String Hello World 22: invokespecial #20 // Method java/lang/String.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 25: astore 4 27: new #18 // class java/lang/String 30: dup 31: ldc #16 // String Hello World 33: invokespecial #20 // Method java/lang/String.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 36: invokevirtual #23 // Method java/lang/String.intern:()Ljava/lang/String; 39: astore 5 //...... 214: return } 为了能读懂其内容，可先从The Java® Virtual Machine Specification中了解相关的指令，本文将涉及到的指令列举如下\nldc，将字符串从运行时常量池压入操作栈中 astore，将一个数值从操作栈存入局部变量表 dup，复制栈顶的数值并将复制的数值重新压入栈中 invokespecial，调用实例构造器方法、私有方法和父类方法 invokevirtual，调用实例方法，基于类进行分发 基于上述命令我们可以发现字符串s1、s2、s5都是从常量池中的获取的，而s3、s4则是分别创建了两个String对象，如下图所示。\n在Java中==比较的是内存地址是否相同，而equals()比较的是其文本值是否相同，而从常量池中多次获取同一个常量其地址是相同的，新建的String对象JVM会为其重新分配内存地址。故在利用==进行比较时,1、2、5这三个都是基于常量池的比较，它们的结果都为true，而3、4种都包含有String对象，故其结果均为false。\n字符串相加后比较 将上述代码修改为如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public class StringTest { public static void main(String[] args) { String s1 = \u0026#34;Hello World\u0026#34;; String s2 = \u0026#34;Hello \u0026#34;; String s3 = s2 + \u0026#34;World\u0026#34;; String s4 = \u0026#34;Hello \u0026#34; + \u0026#34;World\u0026#34;; String s5 = \u0026#34;Hello \u0026#34; + new String(\u0026#34;World\u0026#34;); String s6 = \u0026#34;Hello \u0026#34; + new String(\u0026#34;World\u0026#34;).intern(); System.out.println(\u0026#34;利用==比较:\u0026#34;); System.out.println(s1 == s3); System.out.println(s1 == s4); System.out.println(s1 == s5); System.out.println(s1 == s6); System.out.println(\u0026#34;\\n利用equals()比较:\u0026#34;); System.out.println(s1.equals(s3)); System.out.println(s1.equals(s4)); System.out.println(s1.equals(s5)); System.out.println(s1.equals(s6)); } } 程序运行的结果如下:\n此时利用==比较的结果只有1个为true，为了探究原因需要继续分析class文件内容，用javap命令输出的class文件内容如下(省略掉了System.out.println()相关的)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 Compiled from \u0026#34;StringTest.java\u0026#34; public class StringTest { public StringTest(); Code: 0: aload_0 1: invokespecial #8 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 4: return public static void main(java.lang.String[]); Code: 0: ldc #16 // String Hello World 2: astore_1 3: ldc #18 // String Hello 5: astore_2 6: new #20 // class java/lang/StringBuilder 9: dup 10: aload_2 11: invokestatic #22 // Method java/lang/String.valueOf:(Ljava/lang/Object;)Ljava/lang/String; 14: invokespecial #28 // Method java/lang/StringBuilder.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 17: ldc #31 // String World 19: invokevirtual #33 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 22: invokevirtual #37 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 25: astore_3 26: ldc #16 // String Hello World 28: astore 4 30: new #20 // class java/lang/StringBuilder 33: dup 34: ldc #18 // String Hello 36: invokespecial #28 // Method java/lang/StringBuilder.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 39: new #23 // class java/lang/String 42: dup 43: ldc #31 // String World 45: invokespecial #41 // Method java/lang/String.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 48: invokevirtual #33 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 51: invokevirtual #37 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 54: astore 5 56: new #20 // class java/lang/StringBuilder 59: dup 60: ldc #18 // String Hello 62: invokespecial #28 // Method java/lang/StringBuilder.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 65: new #23 // class java/lang/String 68: dup 69: ldc #31 // String World 71: invokespecial #41 // Method java/lang/String.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 74: invokevirtual #42 // Method java/lang/String.intern:()Ljava/lang/String; 77: invokevirtual #33 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 80: invokevirtual #37 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 83: astore 6 //.... 215: return } 基于class文件的内容对s3、s4、s5、s6这4个字符串进行分析，可发现s4是编译器自动优化后从字符常量池中获取的之外，其余的3个字符串都是利用StringBuilder中的toString()方法生成的，toString()的源码如下，可以看出返回的是一个String对象。这正好解释了除了s1==s4输出值为true之外其余的输出值都为false的原因。\n1 2 3 4 @Override public String toString() { return new String(value, 0, count); } String是不可变的原因分析 在学习Java时我们一直被强调String是不可变的，而实际使用中我们又可以利用类似如下的代码对String进行拼接操作，看起来很矛盾。\n1 2 3 4 5 6 7 8 public class StringTest { public static void main(String[] args) { String s1 = \u0026#34;Hello\u0026#34;; s1 +=\u0026#34; Java\u0026#34;; s1 +=\u0026#34; Golang\u0026#34;; } } 同样可以通过阅读class文件来分析该问题，对应的class文件如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 Compiled from \u0026#34;StringTest.java\u0026#34; public class StringTest { public StringTest(); Code: 0: aload_0 1: invokespecial #8 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 4: return public static void main(java.lang.String[]); Code: 0: ldc #16 // String Hello 2: astore_1 3: new #18 // class java/lang/StringBuilder 6: dup 7: aload_1 8: invokestatic #20 // Method java/lang/String.valueOf:(Ljava/lang/Object;)Ljava/lang/String; 11: invokespecial #26 // Method java/lang/StringBuilder.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 14: ldc #29 // String Java 16: invokevirtual #31 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 19: invokevirtual #35 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 22: astore_1 23: new #18 // class java/lang/StringBuilder 26: dup 27: aload_1 28: invokestatic #20 // Method java/lang/String.valueOf:(Ljava/lang/Object;)Ljava/lang/String; 31: invokespecial #26 // Method java/lang/StringBuilder.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 34: ldc #39 // String Golang 36: invokevirtual #31 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 39: invokevirtual #35 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 42: astore_1 43: return } 分析class文件可发现利用+=操作实质上是通过StringBuilder来拼接并重新构建字符串，每次+=操作都会生成新的字符串，原始字符串的指向地址被丢失，String是不可变实际上指的是原有的字符串无法改变，前述的问题得以解决。\n同时通过分析上述class文件还能得出以下结论:\n对于类似String str=\u0026quot;Hello\u0026quot; + \u0026quot;World\u0026quot;的赋值，JVM会将其自动优化为一个字符串常量，除此之外的其它基于String的拼接都会生成新的String对象； 在字符串拼接时，若采用基于String的拼接操作，会频繁的创建StringBuilder对象，影响程序性能，应该采用StringBuilder替代以减少StringBuilder创建的次数; 需要确保线程安全时，可以使用StringBuffer替代StringBuilder Java Web程序中的字符串赋值 利用下述代码在Web页面输入用户名和密码，然后利用==在Servlet代码中和特定的字符串进行比较。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Type\u0026#34; content=\u0026#34;text/html; charset=UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;测试数据传递\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt; \u0026lt;form action=\u0026#34;addUser\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;table\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;用户名:\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;username\u0026#34;/\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;密码:\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;password\u0026#34;/\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026amp;nbsp;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;提交\u0026lt;/button\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 TestServlet.java public class TestServlet extends HttpServlet { private static final long serialVersionUID = 6174437812832777462L; @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { doPost(request, response); } @Override protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { String username = request.getParameter(\u0026#34;username\u0026#34;); System.out.println(username == \u0026#34;Rosen\u0026#34;); System.out.println(\u0026#34;Rosen\u0026#34;.equals(username)); request.getRequestDispatcher(\u0026#34;index.html\u0026#34;).forward(request, response); } } 在Tomcat7中的运行结果如下，可以看出其运行结果符合前面基于class文件的理论分析。 通过前面的分析可知通过Web服务器传递给Servlet的字符串参数肯定是一个String对象而非一个字符串常量。接下来通过在GitHub中分析Tomcat源码来了解其如何赋值。\n在Tomcat中，生成参数的相关代码位于Parameters.java类中private void processParameters(byte bytes[], int start, int len, Charset charset)方法中，该方法给参数赋值的核心代码如下： 1 2 3 4 5 6 7 8 9 if (valueStart \u0026gt;= 0) { if (decodeValue) { urlDecode(tmpValue); } tmpValue.setCharset(charset); value = tmpValue.toString(); } else { value = \u0026#34;\u0026#34;; } 继续查看可知tmpValue的类型为ByteChunk,其toString()核心代码如下： 1 2 3 4 5 6 7 8 public String toString() { if (isNull()) { return null; } else if (end - start == 0) { return \u0026#34;\u0026#34;; } return StringCache.toString(this); } 继续查看StringCache的toString()方法如下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 public static String toString(ByteChunk bc) { // If the cache is null, then either caching is disabled, or we\u0026#39;re // still training if (bcCache == null) { String value = bc.toStringInternal(); if (byteEnabled \u0026amp;\u0026amp; (value.length() \u0026lt; maxStringSize)) { // If training, everything is synced synchronized (bcStats) { // If the cache has been generated on a previous invocation // while waiting for the lock, just return the toString // value we just calculated if (bcCache != null) { return value; } // Two cases: either we just exceeded the train count, in // which case the cache must be created, or we just update // the count for the string if (bcCount \u0026gt; trainThreshold) { long t1 = System.currentTimeMillis(); // Sort the entries according to occurrence TreeMap\u0026lt;Integer,ArrayList\u0026lt;ByteEntry\u0026gt;\u0026gt; tempMap = new TreeMap\u0026lt;\u0026gt;(); for (Entry\u0026lt;ByteEntry,int[]\u0026gt; item : bcStats.entrySet()) { ByteEntry entry = item.getKey(); int[] countA = item.getValue(); Integer count = Integer.valueOf(countA[0]); // Add to the list for that count ArrayList\u0026lt;ByteEntry\u0026gt; list = tempMap.get(count); if (list == null) { // Create list list = new ArrayList\u0026lt;\u0026gt;(); tempMap.put(count, list); } list.add(entry); } // Allocate array of the right size int size = bcStats.size(); if (size \u0026gt; cacheSize) { size = cacheSize; } ByteEntry[] tempbcCache = new ByteEntry[size]; // Fill it up using an alphabetical order // and a dumb insert sort ByteChunk tempChunk = new ByteChunk(); int n = 0; while (n \u0026lt; size) { Object key = tempMap.lastKey(); ArrayList\u0026lt;ByteEntry\u0026gt; list = tempMap.get(key); for (int i = 0; i \u0026lt; list.size() \u0026amp;\u0026amp; n \u0026lt; size; i++) { ByteEntry entry = list.get(i); tempChunk.setBytes(entry.name, 0, entry.name.length); int insertPos = findClosest(tempChunk, tempbcCache, n); if (insertPos == n) { tempbcCache[n + 1] = entry; } else { System.arraycopy(tempbcCache, insertPos + 1, tempbcCache, insertPos + 2, n - insertPos - 1); tempbcCache[insertPos + 1] = entry; } n++; } tempMap.remove(key); } bcCount = 0; bcStats.clear(); bcCache = tempbcCache; if (log.isDebugEnabled()) { long t2 = System.currentTimeMillis(); log.debug(\u0026#34;ByteCache generation time: \u0026#34; + (t2 - t1) + \u0026#34;ms\u0026#34;); } } else { bcCount++; // Allocate new ByteEntry for the lookup ByteEntry entry = new ByteEntry(); entry.value = value; int[] count = bcStats.get(entry); if (count == null) { int end = bc.getEnd(); int start = bc.getStart(); // Create byte array and copy bytes entry.name = new byte[bc.getLength()]; System.arraycopy(bc.getBuffer(), start, entry.name, 0, end - start); // Set encoding entry.charset = bc.getCharset(); // Initialize occurrence count to one count = new int[1]; count[0] = 1; // Set in the stats hash map bcStats.put(entry, count); } else { count[0] = count[0] + 1; } } } } return value; } else { accessCount++; // Find the corresponding String String result = find(bc); if (result == null) { return bc.toStringInternal(); } // Note: We don\u0026#39;t care about safety for the stats hitCount++; return result; } } 该方法篇幅很长，但核心代码只有一行String value = bc.toStringInternal();而bc的类型为ByteChunk。\n继续在ByteChunk搜索toStringInternal()方法，其代码如下 1 2 3 4 5 6 7 8 9 10 public String toStringInternal() { if (charset == null) { charset = DEFAULT_CHARSET; } // new String(byte[], int, int, Charset) takes a defensive copy of the // entire byte array. This is expensive if only a small subset of the // bytes will be used. The code below is from Apache Harmony. CharBuffer cb = charset.decode(ByteBuffer.wrap(buff, start, end - start)); return new String(cb.array(), cb.arrayOffset(), cb.length()); } 查看该方法可知其使用new String(cb.array(), cb.arrayOffset(), cb.length())的方式来构造String对象，故利用==比较字符串时其返回值为false。\n分析了最基本的Servelt后，由于SpringMVC是基于Servlet实现的，故使用如下代码进行参数比较其值也为false。\n1 2 3 4 5 @RequestMapping(\u0026#34;addUser\u0026#34;) public String addUser(UserModel user) { System.out.println(user.getUsername() == \u0026#34;Rosen\u0026#34;); return StringConstant.SUCCESS; } 参考文章:\n轻松看懂Java字节码 The Java® Virtual Machine Specification ","permalink":"https://lucumt.info/post/java-core/java-string-equal-compare/","tags":["Java"],"title":"Java中利用==和equals()进行字符串比较的说明"},{"categories":["Java编程","Java多线程"],"contents":"最近复习Java多线程相关知识时，发现线程中断的interrupt()、interrupted()、isInterrupted()这3个方法容易让人产生混淆，结合官网的API以及实际代码验证，先简单记录下。\n相关使用说明 下表是根据JDK官网的API总结出的这3个方法的使用说明,从表中可以看出中断线程实际使用的是interrupt()，而interrupted()和isInterrupted()则用来检测线程是否中断，区别为前者会清除中断状态标记。\n方法 是否静态 返回值 作用 interrupt() 否 无 中断调用该方法的当前线程 interrupted() 是 有 检测当前线程是否被中断，如已被中断过则清除中断状态 isInterrupted() 否 有 检测调用该方法的线程是否被中断，不清除中断标记 下面这个程序展示通过2个线程展示了这3个方法的用法，首先启动threadA，间隔30毫秒后启动threadB并在threadB中调用interrupt()中断threadA,然后观察threadA的中断状态。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 public class InterruptedTest { @Test public void testThread() { Thread threadA = new Thread(() -\u0026gt; { while (!Thread.currentThread().isInterrupted()) { System.out.println(Thread.currentThread().getName() + \u0026#34;\\t\u0026#34; + LocalTime.now()); } System.out.println(Thread.currentThread().isInterrupted()); System.out.println(Thread.interrupted()); System.out.println(Thread.currentThread().isInterrupted()); }, \u0026#34;Thread_A\u0026#34;); Thread threadB = new Thread(() -\u0026gt; { System.out.println(Thread.currentThread().getName() + \u0026#34; interrupt ThreadA\u0026#34;); threadA.interrupt(); }, \u0026#34;Thread_B\u0026#34;); threadA.start(); try { Thread.sleep(30); } catch (InterruptedException e) { e.printStackTrace(); } threadB.start(); } } 根据前述的方法说明，程序的输出结果应改为true、true、false，实际运行结果类似如下,从图中可知其输出结果与理论分析相符。\n将上述代码修改如下,首先给threadA加上同步锁并调用wait()或sleep()方法，然后检测其中断状态。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 public class InterruptedTest { @Test public void testThread() { Object lock = new Object(); Thread threadA = new Thread(() -\u0026gt; { synchronized(lock) { try { Thread.sleep(1000); //lock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().isInterrupted()); System.out.println(Thread.interrupted()); System.out.println(Thread.currentThread().isInterrupted()); } }, \u0026#34;Thread_A\u0026#34;); Thread threadB = new Thread(() -\u0026gt; { System.out.println(Thread.currentThread().getName() + \u0026#34; will interrupt ThreadA\u0026#34;); threadA.interrupt(); }, \u0026#34;Thread_B\u0026#34;); threadA.start(); try { Thread.sleep(30); } catch (InterruptedException e) { e.printStackTrace(); } threadB.start(); } } 分别调用sleep()和wait()时的运行结果如下\n分析运行结果可知：无论调用哪种方法，在中断线程时都会抛出InterruptedException异常，其运行结果都为false则意味着中断状态也不会设置。\n以JDK1.8为例，关于调用interrupt()方法时中断状态的设置，可以从官网上看到如下描述：\nIf this thread is blocked in an invocation of the wait(), wait(long), or wait(long, int) methods of the Object class, or of the join(), join(long), join(long, int), sleep(long), or sleep(long, int), methods of this class, then its interrupt status will be cleared and it will receive an InterruptedException. If this thread is blocked in an I/O operation upon an InterruptibleChannel then the channel will be closed, the thread\u0026rsquo;s interrupt status will be set, and the thread will receive a ClosedByInterruptException.\nIf this thread is blocked in a Selector then the thread\u0026rsquo;s interrupt status will be set and it will return immediately from the selection operation, possibly with a non-zero value, just as if the selector\u0026rsquo;s wakeup method were invoked.\nIf none of the previous conditions hold then this thread\u0026rsquo;s interrupt status will be set.\n综上，interrupt()、intterupted()、isInterrupted()这3个方法的区别与作用总结如下：\ninterrupt(),中断调用该方法的当前线程，并设置其中断标记，具体而言分下述4种情况 若当前线程被wait()、join()、sleep()这些方法(含超时)阻塞时，调用该方法中断线程时会清除中断标记，同时抛出InterruptedException异常； 若当前线程被一个可中断的I/O操作阻塞，则会设置中断状态，同时关闭I/O通道并抛出ClosedByInterruptException异常； 若当前线程被一个异步I/O操作(Selector)阻塞，则会设置中断状态并立即返回，看起来异步I/O操作的唤醒方法被调用； 除以上3种情况外，其余情形下中断状态会被正常设置； interrupted(),检测当前线程是否被中断，如已被中断过则清除中断状态 isInterrupted(),检测调用该方法的线程是否被中断，不清除中断标记 线程中断的使用 在Oracle官网有关于interrupt的如下如说明\nAn interrupt is an indication to a thread that it should stop what it is doing and do something else. It\u0026rsquo;s up to the programmer to decide exactly how a thread responds to an interrupt, but it is very common for the thread to terminate.\n从上可知，当一个线程被中断时，JVM没有强制让当前线程立即中断,JVM只是要求我们在发生线程中断时应该停止当前正在执行的任务转而去执行其它任务。一个常用的场景是在循环体中利用isInterrupt()进行判断是否被中断，在没有被中断时在循环体中执行业务逻辑，当被中断时则跳出循环体然后执行其它业务逻辑，如下所示：\n1 2 3 4 while (!Thread.currentThread().isInterrupted()) { //do something when not been interrupted } //do other things when been interrupted 与LockSupport的比较 利用LockSupport方法重新修改上述代码，修改后的代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public void testThread() { Thread threadA = new Thread(() -\u0026gt; { LockSupport.park(); System.out.println(Thread.currentThread().isInterrupted()); System.out.println(Thread.interrupted()); System.out.println(Thread.currentThread().isInterrupted()); }, \u0026#34;Thread_A\u0026#34;); Thread threadB = new Thread(() -\u0026gt; { System.out.println(Thread.currentThread().getName() + \u0026#34; will unpark ThreadA\u0026#34;); LockSupport.unpark(threadA); }, \u0026#34;Thread_B\u0026#34;); threadA.start(); try { Thread.sleep(30); } catch (InterruptedException e) { e.printStackTrace(); } threadB.start(); } 程序运行结果如下：\n从上图中可以看出LockSupport中的方法来阻塞和唤醒线程时(更准确的说法是通过许可来觉得线程是否可运行)，既不修改线程的中断状态也不抛出InterruptedException异常。\n参考文章：\nhttps://stackoverflow.com/questions/3590000/what-does-java-lang-thread-interrupt-do https://docs.oracle.com/javase/tutorial/essential/concurrency/interrupt.html https://www.ibm.com/developerworks/library/j-jtp05236/ 关于如何处理InterruptedException异常，请参见本人翻译一篇文章 [译]如何处理InterruptedException\n","permalink":"https://lucumt.info/post/java-concurrency/difference-between-interrupt-interrupted-isinterrupted/","tags":["Java","Java Concurrency"],"title":"Java中interrupt()、interrupted()、isInterrupted()的区别"},{"categories":["Java编程"],"contents":"由于工作原因需要在阿里云中部署一个Web系统，该系统会调用邮箱服务器定时给相关人员发送通知邮件,在测试邮箱配置时，发现始终无法正确发送邮件，而之前在研发环境和测试环境都能正常工作。网上查找之后，发现是阿里云出于安全原因默认禁止了25端口的出方向访问，需要进行25端口解封申请，按照说明提交相应的申请后没想到不到一个小时就提醒申请未通过，同时提示使用465端口来发送加密邮件。基于此，本文简要说明如何使用126邮箱通过465端口在阿里云中发送邮件。\n邮箱配置 首先找到一个可用的126邮箱，进入邮箱设置选项，开启SMTP服务，如下图所示\n对于某些类型的邮箱完成上一步的操作后即可通过邮箱和密码发送邮件，但对于126邮箱还需要在“客户端授权密码”中设置相应的授权码。授权码的作用和邮箱密码类似，但授权码主要是供第三方客户端调用时使用，这样可达到即可让第三方软件调用，也不泄露自己邮箱密码的目的。\n代码编写 下述代码为使用25端口发送邮件的Java代码，其实现基于Java Mail 1.4.1。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 public void testSendMail() { final String sendUserName = \u0026#34;***@126.com\u0026#34;; final String sendUserPassword = \u0026#34;***\u0026#34;; // 收件箱 String receiveUser = \u0026#34;recevie@mail.com\u0026#34;; Properties props = new Properties(); props.put(\u0026#34;mail.smtp.auth\u0026#34;, \u0026#34;true\u0026#34;); props.put(\u0026#34;mail.smtp.host\u0026#34;, \u0026#34;smtp.126.com\u0026#34;); props.put(\u0026#34;mail.smtp.port\u0026#34;, \u0026#34;25\u0026#34;); Session session = Session.getDefaultInstance(props,new Authenticator() { @Override protected PasswordAuthentication getPasswordAuthentication() { return new PasswordAuthentication(sendUserName, sendUserPassword); } }); try { Message message = new MimeMessage(session); message.setFrom(new InternetAddress(sendUserName)); message.setRecipients(Message.RecipientType.TO, InternetAddress.parse(receiveUser)); message.setSubject(\u0026#34;Test Mail Send\u0026#34;); message.setText(\u0026#34;Hello World!\u0026#34;); Transport.send(message); System.out.println(\u0026#34;Send mail success\u0026#34;); } catch (MessagingException e) { e.printStackTrace(); } } 为了使用465端口发送邮件，除了在代码中修改端口之外，还需要将Mail Socket指定为SSL实现，实际使用中我发现通过props.put(\u0026quot;mail.smtp.socketFactory.class\u0026quot;, \u0026quot;javax.net.ssl.SSLSocketFactory\u0026quot;);即可实现，完整的代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public void testSendMail() { final String sendUserName = \u0026#34;***@126.com\u0026#34;; final String sendUserPassword = \u0026#34;***\u0026#34;; // 收件箱 String receiveUser = \u0026#34;recevie@mail.com\u0026#34;; Properties props = new Properties(); props.put(\u0026#34;mail.smtp.auth\u0026#34;, \u0026#34;true\u0026#34;); props.put(\u0026#34;mail.smtp.host\u0026#34;, \u0026#34;smtp.126.com\u0026#34;); props.put(\u0026#34;mail.smtp.port\u0026#34;, \u0026#34;465\u0026#34;); //指定使用基于SSL的套接字 props.put(\u0026#34;mail.smtp.socketFactory.class\u0026#34;, \u0026#34;javax.net.ssl.SSLSocketFactory\u0026#34;); Session session = Session.getDefaultInstance(props,new Authenticator() { @Override protected PasswordAuthentication getPasswordAuthentication() { return new PasswordAuthentication(sendUserName, sendUserPassword); } }); try { Message message = new MimeMessage(session); message.setFrom(new InternetAddress(sendUserName)); message.setRecipients(Message.RecipientType.TO, InternetAddress.parse(receiveUser)); message.setSubject(\u0026#34;Test Mail Send\u0026#34;); message.setText(\u0026#34;Hello World!\u0026#34;); Transport.send(message); System.out.println(\u0026#34;Send mail success\u0026#34;); } catch (MessagingException e) { e.printStackTrace(); } } 其他说明 Java Mail中关于邮件设置的选项请参见com.sun.mail.smtp,实际使用时我发现只需要添加props.put(\u0026quot;mail.smtp.socketFactory.class\u0026quot;, \u0026quot;javax.net.ssl.SSLSocketFactory\u0026quot;);即可，额外的添加其它一些配置反而可能会导致不能正常使用。\n如当参照Stackoverflow中的Using JavaMail with TLS这个问题的答案加上如下代码：\n1 2 3 props.put(\u0026#34;mail.smtp.starttls.enable\u0026#34;,\u0026#34;true\u0026#34;); props.put(\u0026#34;mail.smtp.auth\u0026#34;, \u0026#34;true\u0026#34;); props.put(\u0026#34;mail.smtp.socketFactory.fallback\u0026#34;, \u0026#34;false\u0026#34;); 程序运行的结果如下 此时只需将props.put(\u0026quot;mail.smtp.starttls.enable\u0026quot;,\u0026quot;true\u0026quot;);这行代码去掉或将其值设置为false即可正常发送邮件。\n参考说明:\nJavaMail 使用 163 发送邮件 Using JavaMail with TLS ","permalink":"https://lucumt.info/post/java-core/send-ssl-mail-with-126-in-aliyun/","tags":["Java"],"title":"利用126邮箱在阿里云中发送SSL/TSL加密邮件"},{"categories":["Web编程","Java编程"],"contents":"Quartz是软件开发中常用的任务调度框架，实际中通常结合 Spring 一起使用，并在Spring的配置文件中利用0 0 12 ? \\* WED这种方式以硬编码的方式配置定时任务的执行时间。有时候需要动态的设置定时任务的执行时间，如让用户自己选择何时备份数据，此时就需要采用动态设置其执行时间。\n为实现动态设置定时任务执行时间的功能，首先需要实现以硬编码的方式设置定时任务执行时间，然后在其基础上修改为可动态设置，本文基于这两分部分逐步介绍如何实现。\n硬编码设置定时时间 本文采用 Quartz + SpringMVC 的实现框架，同时基于 Maven运行，相关配置过程如下：\n1.首先在pom.xml文件中引入相应的依赖JAR包。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.quartz-scheduler\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;quartz\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.25\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.13.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context-support\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.13.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.13.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-webmvc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.13.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-tx\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.13.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.9\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javaee\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;javaee-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 2.创建一个定时任务测试类TestJob\n1 2 3 4 5 6 7 8 public class TestJob { private DateFormat df = new SimpleDateFormat(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); public void schedulerJob(){ System.out.println(\u0026#34;=========定时输出:\\t\u0026#34;+df.format(new Date())); } } 3.结合Spring进行定时任务的配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd \u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;testJob\u0026#34; class=\u0026#34;com.lucumt.quartz.TestJob\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;testJobDetail\u0026#34; class=\u0026#34;org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean\u0026#34;\u0026gt; \u0026lt;!-- 指定任务类 --\u0026gt; \u0026lt;property name=\u0026#34;targetObject\u0026#34; ref=\u0026#34;testJob\u0026#34; /\u0026gt; \u0026lt;!-- 指定任务执行的方法 --\u0026gt; \u0026lt;property name=\u0026#34;targetMethod\u0026#34; value=\u0026#34;schedulerJob\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;testJobTrigger\u0026#34; class=\u0026#34;org.springframework.scheduling.quartz.CronTriggerFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;jobDetail\u0026#34; ref=\u0026#34;testJobDetail\u0026#34; /\u0026gt; \u0026lt;!-- 每10秒运行一次 --\u0026gt; \u0026lt;property name=\u0026#34;cronExpression\u0026#34; value=\u0026#34;0/10 * * * * ?\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean class=\u0026#34;org.springframework.scheduling.quartz.SchedulerFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;triggers\u0026#34;\u0026gt; \u0026lt;list\u0026gt; \u0026lt;ref bean=\u0026#34;testJobTrigger\u0026#34; /\u0026gt; \u0026lt;/list\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 4.web.xml中配置如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;web-app version=\u0026#34;2.5\u0026#34; xmlns=\u0026#34;http://java.sun.com/xml/ns/javaee\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\u0026#34;\u0026gt; \u0026lt;display-name\u0026gt;Dynamic Quartz Scheduler\u0026lt;/display-name\u0026gt; \u0026lt;listener\u0026gt; \u0026lt;listener-class\u0026gt;org.springframework.web.context.ContextLoaderListener\u0026lt;/listener-class\u0026gt; \u0026lt;/listener\u0026gt; \u0026lt;context-param\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;classpath*:spring-context-*.xml\u0026lt;/param-value\u0026gt; \u0026lt;/context-param\u0026gt; \u0026lt;/web-app\u0026gt; 配置完成后，在eclipse中运行tomcat7:run运行结果如下，可以看出定时任务每隔10秒执行一次。\n上述的硬编码设置将 Quartz 的执行时间通过硬编码方式写入XML配置文件中，这是最常见的用法，但通过XML配置文件写入定时时间时无法动态的更改其执行时间。\n动态设置定时时间 为了便于演示，本文采用Web程序的方式展示相关操作过程。\n1.增加一个testScheduler.jsp展示操作界面:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 \u0026lt;%@ page language=\u0026#34;java\u0026#34; import=\u0026#34;java.util.*\u0026#34; pageEncoding=\u0026#34;UTF-8\u0026#34;%\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;content-type\u0026#34; content=\u0026#34;text/html; charset=UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;动态设置quartz\u0026lt;/title\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;js/jquery-2.1.1.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; type=\u0026#34;text/css\u0026#34; href=\u0026#34;js/bootstrap/css/bootstrap.min.css\u0026#34;/\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;js/bootstrap/js/bootstrap.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;style type=\u0026#34;text/css\u0026#34;\u0026gt; .container{ margin-top: 30px; margin-left: auto; margin-right: auto; padding: 10px; background-color: #d0d0d0; border-radius: 5px; min-height:400px; } .hidden{ display: none; } \u0026lt;/style\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; function changeScheduler(){ var hiddenId = $(\u0026#34;.hidden\u0026#34;).attr(\u0026#34;id\u0026#34;); var expression = null; if(hiddenId==\u0026#34;scheduler_one\u0026#34;){ $(\u0026#34;#scheduler_one\u0026#34;).removeClass(\u0026#34;hidden\u0026#34;); $(\u0026#34;#scheduler_two\u0026#34;).addClass(\u0026#34;hidden\u0026#34;); expression=\u0026#34;0/10 * * * * ?\u0026#34;; }else{ $(\u0026#34;#scheduler_one\u0026#34;).addClass(\u0026#34;hidden\u0026#34;); $(\u0026#34;#scheduler_two\u0026#34;).removeClass(\u0026#34;hidden\u0026#34;); expression=\u0026#34;0/30 * * * * ?\u0026#34;; } sendChangeRequest(expression); } function sendChangeRequest(expression){ $.ajax({ url:\u0026#34;changeScheduler\u0026#34;, type:\u0026#34;post\u0026#34;, data:{ expression:expression }, success:function(){ } }); } \u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container-fluid container\u0026#34;\u0026gt; \u0026lt;div id=\u0026#34;scheduler_one\u0026#34;\u0026gt; 当前定时任务的表达式为\u0026lt;b\u0026gt;0/10 * * * * ?\u0026lt;/b\u0026gt;,每隔10秒输出一次 \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;scheduler_two\u0026#34; class=\u0026#34;hidden\u0026#34;\u0026gt; 当前定时任务的表达式为\u0026lt;b\u0026gt;0/30 * * * * ?\u0026lt;/b\u0026gt;,每隔30秒输出一次 \u0026lt;/div\u0026gt; \u0026lt;button type=\u0026#34;button\u0026#34; class=\u0026#34;btn btn-primary btn-sm\u0026#34; onclick=\u0026#34;changeScheduler()\u0026#34;\u0026gt;切换定时时间\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 2.增加一个Controller类QuartzController用于响应前端重新设置定时任务时间的请求\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Controller(\u0026#34;/\u0026#34;) public class QuartzController { @Autowired private JobScheduler jobScheduler; @RequestMapping(\u0026#34;testScheduler\u0026#34;) public String testScheduler(){ return \u0026#34;testScheduler\u0026#34;; } @RequestMapping(\u0026#34;changeScheduler\u0026#34;) @ResponseBody public String changeScheduler(String expression){ System.out.println(\u0026#34;执行时间被修改为:\\t\u0026#34;+expression); jobScheduler.resetJob(expression); return \u0026#34;SUCCESS\u0026#34;; } } 3.在时任务测试类TestJob中添加一个resetJob方法，用于重新设置定时任务执行时间\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public class JobScheduler implements ServletContextAware { private DateFormat df = new SimpleDateFormat(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); private ServletContext context; @Override public void setServletContext(ServletContext context) { this.context=context;\t} public void schedulerJob() { System.out.println(\u0026#34;=========定时输出:\\t\u0026#34; + df.format(new Date())); } //通过此方法重新设置定时任务调度时间 public void resetJob(String expression){ ApplicationContext applicationContext = WebApplicationContextUtils.getRequiredWebApplicationContext(context); Scheduler scheduler = (Scheduler) applicationContext.getBean(\u0026#34;testScheduler\u0026#34;); CronTriggerImpl trigger = null; try { TriggerKey triggerKeys = TriggerKey.triggerKey(\u0026#34;testJobTrigger\u0026#34;,Scheduler.DEFAULT_GROUP); trigger = new CronTriggerImpl(); trigger.setCronExpression(expression); trigger.setKey(triggerKeys);//要确保key相同 scheduler.rescheduleJob(triggerKeys,trigger); } catch (ParseException | SchedulerException e) { e.printStackTrace(); } } } 4.其他配置文件保持不变，修改后的运行界面如下\n5.多次点击该按钮，控制台输出如下，可以看出实现了动态设置定时任务的功能\n上述代码是基于Quartz2.3.0来实现的，相关源代码请参见 quartz_demo ，其核心在于 resetJob 方法通过调用 CronTriggerImpl 来重新设置定时任务执行时间，需要注意的是要确保定时任务修改前后的triggerKey一致，这样才能修改生效，否则应用程序会在执行原有的定时任务时同时以新的时间来执行新的定时任务，即同时执行两个定时任务，达不到预期效果。\nQuartz1.7.2中的定时任务设置 在旧版的Quartz(1.7.2)中rescheduleJob的方法参数发生了变化，相应的Spring版本也发生了变化，需要用 CronTriggerBean替换 CronTriggerImpl，对应的实现代码可修改为如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public void resetJob(String expression){ ApplicationContext applicationContext = WebApplicationContextUtils.getRequiredWebApplicationContext(context); Scheduler scheduler = (Scheduler) applicationContext.getBean(\u0026#34;testScheduler\u0026#34;); try { CronTriggerBean trigger = new CronTriggerBean(); trigger.setCronExpression(expression); trigger.setName(\u0026#34;testJobTrigger\u0026#34;); trigger.setGroup(Scheduler.DEFAULT_GROUP); trigger.setJobName(\u0026#34;testJobDetail\u0026#34;); scheduler.rescheduleJob(\u0026#34;testJobTrigger\u0026#34;, Scheduler.DEFAULT_GROUP, trigger); } catch (SchedulerException | ParseException e) { e.printStackTrace(); } } 其运行结果和前面的一致。\n通过Spring获取Trigger导致的重复执行问题 将上述代码中的CronTriggerBean初始化从new*关键字实现变为通过Schduler获取原有的任务后重新更新，修改后的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 public void resetJob(String expression){ ApplicationContext applicationContext = WebApplicationContextUtils.getRequiredWebApplicationContext(context); Scheduler scheduler = (Scheduler) applicationContext.getBean(\u0026#34;testScheduler\u0026#34;); try { CronTriggerBean trigger = (CronTriggerBean) scheduler.getTrigger(\u0026#34;testJobTrigger\u0026#34;, Scheduler.DEFAULT_GROUP);//通过scheduler获取 trigger.setCronExpression(expression); trigger.setName(\u0026#34;testJobTrigger\u0026#34;); scheduler.rescheduleJob(\u0026#34;testJobTrigger\u0026#34;, Scheduler.DEFAULT_GROUP, trigger); } catch (SchedulerException | ParseException e) { e.printStackTrace(); } } 实际运行时会发现每次动态切换 Quartz 的执行时间时都会导致该定时任务被执行两次或错误执行的现象，如下图所示：\n初步上述问题产生的原因为通过Scheduler获取的是已有的Trigger而导致重复执行（不论 Quartz 新旧版本均有此问题 )，如果采用new关键字重新创建一个Trigger则此问题会消失，至于为何采用旧的Trigger会导致定时任务错误执行，还有待进一步分析。\n","permalink":"https://lucumt.info/post/quartz/update-quartz-scheduler-dynamic/","tags":["Quartz","Spring","SpringMVC"],"title":"在Quartz中动态设置定时任务的执行时间"},{"categories":["Java编程"],"contents":"这几天工作中遇到一个利用dom4j更新XML文件的任务，由于XML文件中部分属性包含有换行符，利用dom4j(1.6.1)默认的方法更新XML文件后换行符会丢失。 各种Google、StackOverflow折腾好久后终于解决该问题，简单记录下。\n对于修改XML文件，自己很自然的想到利用dom4j和 XPath来实现功能，使用的代码类似如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public static void updateXML() { SAXReader saxReader = new SAXReader(); File oldFile = new File(\u0026#34;D:\\\\test\\\\old_test.xml\u0026#34;); File newFile = new File(\u0026#34;D:\\\\test\\\\new_test.xml\u0026#34;); try { Document oldDoc = saxReader.read(oldFile); Element oldRoot = oldDoc.getRootElement(); Element oldEle = (Element) oldRoot.selectSingleNode(\u0026#34;//book[@id=\u0026#39;01001\u0026#39;]/name\u0026#34;); System.out.println(oldEle.attributeValue(\u0026#34;description\u0026#34;)); OutputFormat format = OutputFormat.createPrettyPrint(); format.setEncoding(\u0026#34;UTF-8\u0026#34;); format.setNewLineAfterDeclaration(false); //写入新文件 XMLWriter writer = new XMLWriter(new FileWriter(newFile), format); writer.write(oldDoc); writer.flush(); writer.close(); System.out.println(\u0026#34;\\n================分隔符==================\\n\u0026#34;); //从新文件中读取数据 Document newDoc = saxReader.read(newFile); Element newRoot = newDoc.getRootElement(); Element newEle = (Element) newRoot.selectSingleNode(\u0026#34;//book[@id=\u0026#39;01001\u0026#39;]/name\u0026#34;); System.out.println(newEle.attributeValue(\u0026#34;description\u0026#34;)); } catch (DocumentException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } } 对应的XML文件类似如下：\n1 2 3 4 5 6 7 8 9 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;books\u0026gt; \u0026lt;book id=\u0026#34;01001\u0026#34;\u0026gt; \u0026lt;name description=\u0026#34;New coverage includes:\u0026amp;#xD;\u0026amp;#xA;\u0026amp;#xD;\u0026amp;#xA;Functional interfaces, lambda expressions, method references, and streams\u0026amp;#xD;\u0026amp;#xA;Default and static methods in interfaces\u0026amp;#xD;\u0026amp;#xA;Type inference, including the diamond operator for generic types\u0026amp;#xD;\u0026amp;#xA;The @SafeVarargs annotation\u0026amp;#xD;\u0026amp;#xA;The try-with-resources statement\u0026#34;\u0026gt;Effective Java\u0026lt;/name\u0026gt; \u0026lt;price\u0026gt;50.6\u0026lt;/price\u0026gt; \u0026lt;author\u0026gt;Joshua Bloch\u0026lt;/author\u0026gt; \u0026lt;publishDate\u0026gt;2017-12-08\u0026lt;/publishDate\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;/books\u0026gt; 上述代码的逻辑很简单：首先从XML打开一个XML文件，然后输出某个书本的描述信息，将其写入新的XML文件，然后在新XML文件中读取相同的信息。理论上前后两次输出的结果应该一样，但实际运行后发现从新的XML文件中读取出的描述信息换行符都丢失了，前后两次输出的结果不一致！\n对比新旧XML文件后发现，产生此现象的原因是: dom4j 自作主张的在写入XML文件时将 \u0026amp;#xD;\u0026amp;#xA; 替换为了 \\r\\n ，而XML文件中标准的回车换行符是用 \u0026amp;#xD;\u0026amp;#xA; 来表示的 ，将它们替换后再次读取的结果很显然不符合要求。\n了解到问题产生的根源后，则其解决思路也很明确： 写入XML文件时，将 \\r\\n 再次替换为 \u0026amp;#xD;\u0026amp;#xA; 即可。最开始自己想采用如下的方法来简单替换，运行完毕后发现结果和前面的一致，问题依旧。\n1 2 3 String description = oldEle.attributeValue(\u0026#34;description\u0026#34;); description = description.replaceAll(\u0026#34;\\r\\n\u0026#34;,\u0026#34;\u0026amp;#xD;\u0026amp;#xA;\u0026#34;); oldEle.attributeValue(\u0026#34;description\u0026#34;,description); 进一步分析后发现dom4j不仅会在读取XML文件时对\u0026amp;#xD;\u0026amp;#xA;进行转义，而且在写入XML文件时也会对\u0026amp;#xD;\u0026amp;#xA;进行转义，前面的方法只是解决了读取的问题，写入时没有处理，所以问题依旧。\n写入时主要的操作类是OutputFormat和XMLWriter，自己一开始以为可以通过OutputFormat进行响应的设置实现，将代码修改如下，然并卵，问题依旧！\n1 2 3 4 5 OutputFormat format = OutputFormat.createPrettyPrint(); format.setNewlines(true); format.setLineSeparator(\u0026#34;\\r\\n\u0026#34;); format.setEncoding(\u0026#34;UTF-8\u0026#34;); format.setNewLineAfterDeclaration(false); OutputFormat不好使，只能从XMLWriter着手，调用writer.setEscapeText(false)方法也不能解决问题，看来只能放出大招，自己定义实现一个 XMLWriter类，将以及转义后的回车换行符又换回去，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class HRXMLWriter extends XMLWriter { public HRXMLWriter(Writer wr, OutputFormat format) { super(wr, format); } @Override protected String escapeAttributeEntities(String text) { text = super.escapeAttributeEntities(text); if (text.indexOf(\u0026#34;\\r\\n\u0026#34;) \u0026gt; -1) { text = text.replaceAll(\u0026#34;\\r\\n\u0026#34;, \u0026#34;\u0026amp;#xD;\u0026amp;#xA;\u0026#34;); } return text; } } 然后将写入时的代码修改如下：\n1 2 3 4 5 //採用定义写入类HRXMLWriter XMLWriter writer = new HRXMLWriter(new FileWriter(newFile), format); writer.write(oldDoc); writer.flush(); writer.close(); 运行结果如下，问题顺利解决！\n坑爹啊！\n","permalink":"https://lucumt.info/post/java-core/update-xml-file-has-line-breaks-using-dom4j/","tags":["Java","XML"],"title":"利用dom4j修改含有回车换行符的XML文件"},{"categories":["个人博客"],"contents":"越来越多的网站和个人博客都变成 HTTPS ，而自己的博客一直都是用的是 HTTP 协议，作为一个具有强迫症的人，每次用 Chrome 浏览器打开个人博客时看见浏览器地址栏显示的 都感觉很不舒服。趁着前段时间不太忙，将个人博客从HTTP迁移到了HTTPS ，先记录下。\n一开始我想直接通过在 GoDaddy 上直接购买HTTPS 服务来实现，去官网查看后发现费用太高，一年大约100美刀，果断弃之。 Google后发现很多人都用Cloudflare通过转发请求来实现HTTPS访问，操作起来也很快，自己便也采用Cloudflare实现， 本文主要是基于Cloudflare 的实现说明。\n操作过程 给博客添加自定义域名 本人使用的是GoDaddy来设置自定义域名，具体操作请参见 利用GoDaddy配置自定义域名， 核心的操作就是给CNAME 文件添加Github Pages给出的两条A记录IP地址，此处不再详述。\n利用Cloudflare修改DNS服务器 打开Cloudflare官网注册一个Cloudflare 账户。注册成功之后，点击页面右上角的add site 链接，添加一个网站，在下图输入框中输入自己的域名，点击 Begin Scan 按钮开始扫描。\n扫描完毕后点击 Contiue Setup ，在类似如下图所示的界面中选择Free Website，然后点击页面底部的Continue按钮。\n在下图所示的Cloudflare Nameservers说明界面中根据要求来修改自定义域名的DNS服务器。 登录GoDaddy，打开响应域名的Manage DNS界面，将Nameservers从Default修改为Custom 然后添加前一个步骤中的两个值分别加上并点击保存。\n回到Cloudflare网站，点击Overview按钮，查看域名的状态是否为如下所示的Active，若是则表示DNS服务器修改成功，若不是 Active请等待几分钟。\nCloudflare中开启HTTPS设置 在Cloudflare网站上点击顶部的Crypto按钮，将状态修改为Full。\n在顶部切换到Page Rules界面，点击Create Page Rule ，添加规则http://lucumt.info/* 并选择Always Use HTTPS来强制该域名下的所有请求都是用HTTPS实现，然后点击Save and Deploy来部署该规则，注意此处的规则是HTTP 而不是HTTPS 。\n执行完这一步后理论上通过HTTPS可以正常的访问个人博客，但还需对博客源码做一些修改。 将代码中所有HTTP修改为HTTPS 在执行完前面的步骤后，在浏览器中用HTTPS访问个人博客时，可能看到的还是而不是自己期望中的小绿锁，同时浏览器控制台可能会出现类似Mixed Content,The page at ...,The request has been blocked,the content must be serverd over HTTPS的错误信息。其原因是由于某些页面中存在混合内容，即部分请求还是以HTTP方式实现的，如加载 JavaScript ,CSS 等，解决方法也很简单，将所有的HTTP请求都改为HTTPS即可 。\n以我个人基于Hugo的博客为例，要进行如下几步操作：\n将个人Hugo源代码中所有的HTTP 请求都修改为HTTP,包括页面中的直接请求和 JavaScript 、CSS等文件中的间接请求。\n利用 hugo server -D --baseUrl=\u0026quot;https://lucumt.info\u0026quot; --appendPort=false 重新生成基于HTTPS的源文件页面。\n将生成的博客源代码重新上传到 Github 仓库中，经过1分钟左右以HTTPS的方式在浏览器中打开个人博客，期待中的小绿锁入愿出现，世界终于和谐了！\n注意事项 通过Cloudflare虽然可以快速的将自己的个人博客迁移到HTTPS，但基于以下两个方面的原因，在条件许可的情况下还是应该使用其他方式实现HTTPS:\n免费计划下的Cloudflare实际上相当于一个中介，我们的访问请求先被Cloudflare代理实现HTTPS 接收到然后将其转发给原始的服务器（如 Github Pages 服务器）。虽然浏览器与Cloudflare之间的通信是HTTPS加密，但是Cloudflare与实际服务器之间的通信不一定是加密的，存在被挟持和篡改的可能。Cloudflare之前也被爆出过 安全漏洞和敏感数据泄露，故商业网站通常不用Cloudflare免费计划，但个人博客出于增加搜索引擎收录和省钱等原因，可以使用Cloudflare免费计划。\n由于经过Cloudflare这层代码，访问速度肯定没有直接访问原始服务器那么快，对于响应速度要求高的用户不合适。 由于众所周知的原因，在天朝Cloudflare访问速度比国内慢，而且指不定哪天就被ban了。 利用Github Page原生HTTPS Github从2018年5月份开始支持自定义域名使用HTTPS1，具体操作说明请参见securing-your-github-pages-site-with-https，通过此种方式可以绕过Cloudflare作为中间层的问题，但是仍然无法解决由于qiang存在导致的访问缓慢的问题。\n由于自己之前采用的是Cloudflare，按照Github的官方文档进行操作时，在进行DNS检查时一开始会提示如下信息\n利用dig命令检查后结果如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [root@vm-16-6-centos ~]# dig +noall +answer lucumt.info lucumt.info. 60 IN A 185.199.110.153 lucumt.info. 60 IN A 185.199.111.153 lucumt.info. 60 IN A 185.199.108.153 lucumt.info. 60 IN A 185.199.109.153 [root@vm-16-6-centos ~]# dig www.lucumt.info +nostats +nocomments +nocmd ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.11.4-P2-RedHat-9.11.4-26.P2.el7_9.9 \u0026lt;\u0026lt;\u0026gt;\u0026gt; www.lucumt.info +nostats +nocomments +nocmd ;; global options: +cmd ;www.lucumt.info. IN A www.lucumt.info. 2280 IN CNAME lucumt.github.io. lucumt.github.io. 2280 IN A 185.199.109.153 lucumt.github.io. 2280 IN A 185.199.111.153 lucumt.github.io. 2280 IN A 185.199.110.153 lucumt.github.io. 2280 IN A 185.199.108.153 [root@vm-16-6-centos ~]# 发现已经切换过来，并且通过浏览器也能以HTTPS的方式正常访问，就是DNS检查结果一直失败，虽然不影响使用，但对于一个有强迫症的人来说页面上有一项检查失败还是很难受的。\n给Github官方发送Support Request后很快收到了回复2，原因为Cloudflare的缓存还没有清除干净，等待2-3后即可恢复正常。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 $ dig NS lucumt.info ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.10.3-P4-Debian \u0026lt;\u0026lt;\u0026gt;\u0026gt; NS lucumt.info ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 9195 ;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ;; QUESTION SECTION: ;lucumt.info. IN NS ;; ANSWER SECTION: lucumt.info. 23305 IN NS anirban.ns.cloudflare.com. lucumt.info. 23305 IN NS angela.ns.cloudflare.com. ;; Query time: 0 msec ;; SERVER: 10.127.5.10#53(10.127.5.10) ;; WHEN: Thu Jan 19 18:28:08 PST 2023 ;; MSG SIZE rcvd: 100 根据官方人员的反馈等待2-3天后再次检查，发现DNS检查通过!\n参考:\nhttps://bakumon.me/blog/p/github-pages-https-ssl.html https://help.github.com/articles/securing-your-github-pages-site-with-https/ https://github.blog/2018-05-01-github-pages-custom-domains-https/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://support.github.com/ticket/personal/0/1974028\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://lucumt.info/post/hugo/migrate-github-blog-from-http-to-https/","tags":["Github Pages","HTTPS"],"title":"将基于Github Pages的自定义域名博客迁移到HTTPS"},{"categories":["编程杂想"],"contents":"工作中有时候会遇到某些大段复杂代码出现Bug的情况，不同于一般行数较小或逻辑较简单的代码，对于大段复杂的代码进行分析可能会很耗时，本文介绍几种个人在工作中用到的方法，供大家参考。\n将Log级别开启到Debug 将Log的级别变为Debug后，会比INFO状态下看到更多的详细日志信息，仔细分析这些输出信息，有时候可以发现是哪一步不能按照预期工作，据此缩小查找范围，从而解决缺陷。\n实际使用中由于Debug级别的log输出信息庞大，查看输出log很耗时，在实际开发中用得不多，常用的场景如下：\n知道大致的代码范围，通过观察log输出来确定具体的原因 压根不知道问题出在哪里，通过观察log输出来获取有用信息，辅助以其它手段来分析 多线程等无法利用Debug调试的环境 利用IDE进行Debug 在IDE中开启Debug模式进行调试是开发过程中最常用的一种手段，通过Debug调试可以找出哪些代码被执行，哪些没有被执行，以及在执行过程中相关变量的值。Debug调试在大部分情况下都可以帮我们找出缺陷，但在多线程应用、 HTML页面样式调试等场景下并不适用Debug方式。\n在代码仓库中进行版本回溯 若已知出问题的代码在以前没有问题，只是最近的更改才出现问题，可以通过从代码仓库中找出历史版本与目前的版本进行对比，看看有哪些差异，通常问题都发生在这些有差异的地方。\n与其它方式相比此种方法耗时最少，通过这种方式找出的bug一般都是某些关键配置写错了或代码语法不正确时控制台没有输出完整的错误信息，如在Ajax方法中在某些配置项后面少写了一个 ,时，在某些浏览器中进行调试时只会出现 Uncaught SyntaxError: Unexpected identifier 这种错误消息，无法根据错误信息具体定位到哪一行代码出错。\n通过二分查找定位 我最喜欢用的方法之一，二分查找定位的操作和二分查找算法类似，先将一部代码注意掉或插入试探性代码，确定问题是在这一边或那一边，确定完大致的区域后，对该问题区域再次采用二分查找来定位，直到找到问题原因为止。此种方法和二分查找算法一样耗时较少。 此方法常用的场景如下：\n不方便利用Debug日志或Debug调试的地方 HTML 、JSP等View层的代码 刚上手某项技术，对其原理了解不深入 重新编写代码实现 若前面几种方法均不能凑效，可以采取终极大法： 重新编码实现！ ，不识庐山真面目，只缘身在此山中 ，有些代码的实现逻辑本身就有问题，若直接对其进行Debug调试或分析，可能会陷入该代码错误的陷阱中。如我们可能认为某段代码代码是没有问题的，然后基于该代码进行进一步的分析调试，却无论如何都得不到自己想要的结果，问题的原因就在于该段代码本身就是错误的。起始点选错了，无论后面怎么做，都无济于事。\n根据原始的需求，在不参照现有代码实现方式的基础上，以白板的方式重新编程实现功能，在对比旧的代码，就能发现问题产生的原因。若这种方式还不能凑效，可以让其他同事协助审查自己的代码，或者审核原有的需求本身是否有问题，通常这种情形意味着我们的代码必须要重构。\n总结 好的代码会自己说话，平时编码时要注意细节、符合规范，必要时对代码进行重构，将复杂的代码进行抽取简化。代码重构虽然对我们的工作产出不会有立竿见影的效果，但也绝不是白白浪费我们的时间，不断重构后的实现良好的代码，不仅有利于调试分析，也有利于他人顺利接手。\n在一些成立时间较长的公司或多或少都会存在一些炸弹代码，此处说的炸弹代码是指那些功能很重要实现又很复杂的代码，最开始开发该功能的人离职后，后面接手的人看不懂该代码，由于各种原因无法对其进行重构，在后续开发时，只能不断的在其后面添加新的业务逻辑，而不敢修改已有的，导致代码量越来越臃肿，越臃肿就越看不懂，陷入恶性循环。这样的代码在后续每次调试分析时都是大坑，而如果一开始就进行适当的重构，或许不会发生这种情况。\nOrz~ 我承认炸弹代码 这个词是我自己发明的！\n","permalink":"https://lucumt.info/post/other/different-ways-find-bug-in-complex-code/","tags":null,"title":"从复杂代码中找出Bug的几种方法"},{"categories":["Java编程","MyBatis系列"],"contents":"项目中ORM框架用的是 MyBatis，最近由于业务上的需求将MyBatis从3.1.1升级到3.4.5，发现升级后通过Log4j显示SQL的配置方式发生了变化，由于变化较大，故先记录下。\n假设我们测试的sql文件为UserMapper.xml ， 对应的代码如下，其命名空间为com.lucumt.mapper.UserMappper\n1 2 3 4 5 6 7 8 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.lucumt.mapper.UserMappper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;getUsers\u0026#34; parameterType=\u0026#34;String\u0026#34; resultType=\u0026#34;com.lucumt.model.UserModel\u0026#34;\u0026gt; SELECT id,username,password,create_time AS createTime FROM system_users WHERE username!=#{username} \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; 对应的执行代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 @Test public void testMybatis(){ String resource = \u0026#34;mybatis-config.xml\u0026#34;; InputStream is = AppTest.class.getClassLoader().getResourceAsStream(resource); SqlSessionFactory sessionFactory = new SqlSessionFactoryBuilder().build(is); SqlSession session = sessionFactory.openSession(); String statement = \u0026#34;com.lucumt.mapper.UserMappper.getUsers\u0026#34;; List\u0026lt;UserModel\u0026gt; userList = session.selectList(statement, \u0026#34;admin\u0026#34;); for(UserModel u:userList){ System.out.println(u.toString()); } } 本文会基于上述代码说明不同版本下如何利用Log4j在MyBatis中配置打印日志以及其实现原理。\nMyBatis3.1.1分析 Log4j相关配置 在MyBatis3.1.1及以前的版本中若我们想通过Log4j配置来打印实际执行的SQL，log4j.properties的配置通常类似如下\n1 2 3 4 5 # 在不开启log4j DEBUG模式下显示mybatis中运行的SQL语句 log4j.logger.java.sql.Connection=DEBUG log4j.logger.java.sql.Statement=DEBUG log4j.logger.java.sql.PreparedStatement=DEBUG log4j.logger.java.sql.ResultSet=DEBUG 原理分析 以log4j.logger.java.sql.Connection=DEBUG这个配置为例，分析源码可知其sql日志来源于ConnectionLogger，查看 ConnectionLogger的代码可知ConnectionLogger以硬编码的方式生成了一个log对象,当DEBUG模式开启时该log对象会打印sql语句等信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 public final class ConnectionLogger extends BaseJdbcLogger implements InvocationHandler { //生成一个Connection的log private static final Log log = LogFactory.getLog(Connection.class); private Connection connection; private ConnectionLogger(Connection conn, Log statementLog) { super(statementLog); this.connection = conn; if (isDebugEnabled()) { debug(\u0026#34;ooo Using Connection [\u0026#34; + conn + \u0026#34;]\u0026#34;); } } public Object invoke(Object proxy, Method method, Object[] params) throws Throwable { try { if (\u0026#34;prepareStatement\u0026#34;.equals(method.getName())) { if (isDebugEnabled()) {//打印执行的SQL语句 debug(\u0026#34;==\u0026gt; Preparing: \u0026#34; + removeBreakingWhitespace((String) params[0])); } PreparedStatement stmt = (PreparedStatement) method.invoke(connection, params); stmt = PreparedStatementLogger.newInstance(stmt, getStatementLog()); return stmt; } //... other code } catch (Throwable t) { throw ExceptionUtil.unwrapThrowable(t); } } //... other code } 运行结果如下\n从上述代码可知在Mybatis3.1.1中通过Log4j实现打印执行SQL的操作很简单，实现原理也易懂，但其存在的一个缺点: 当开启打印SQL日志后，会打印所有正在执行的SQL语句，不能实现针对特定SQL的打印 ，基于此MyBatis从3.2.0版本之后重新实现了相关功能。\nMyBatis3.4.5分析 Log4j相关配置 在MyBatis3.2.0及以后的版本中若我们想通过Log4j配置来打印实际执行的SQL，log4j.properties的配置通常类似如下\n1 2 # 在不开启log4j DEBUG模式下显示mybatis中运行的SQL语句 log4j.logger.com.lucumt.mapper=DEBUG 在本文写作时，mybatis官网上已有关于这方面更 详细的说明 。\n原理分析 同样以log4j.logger.java.sql.Connection=DEBUG为例，其sql日志来源于ConnectionLogger，对应代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public final class ConnectionLogger extends BaseJdbcLogger implements InvocationHandler { private final Connection connection; //通过注入的方式生成log对象 private ConnectionLogger(Connection conn, Log statementLog, int queryStack) { super(statementLog, queryStack); this.connection = conn; } @Override public Object invoke(Object proxy, Method method, Object[] params) throws Throwable { try { if (Object.class.equals(method.getDeclaringClass())) { return method.invoke(this, params); } if (\u0026#34;prepareStatement\u0026#34;.equals(method.getName())) { if (isDebugEnabled()) { debug(\u0026#34; Preparing: \u0026#34; + removeBreakingWhitespace((String) params[0]), true); } } //... other code } catch (Throwable t) { throw ExceptionUtil.unwrapThrowable(t); } } //... other code } 从上述代码可知，其日志生成是调用BaseJdbcLogger的构造方法生成的，BaseJdbcLogger 代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public abstract class BaseJdbcLogger { protected Log statementLog; protected int queryStack; public BaseJdbcLogger(Log log, int queryStack) { this.statementLog = log; if (queryStack == 0) { this.queryStack = 1; } else { this.queryStack = queryStack; } } //... other code } DEBUG模式下查看ConnectionLogger的调用堆栈如下\n从其调用堆栈可知log对象是通过MappedStatement生成的，如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class SimpleExecutor extends BaseExecutor { //... other code @Override public \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; doQuery(MappedStatement ms,Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException { Statement stmt = null; try { Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); //log对象通过MappedStatement生成 stmt = prepareStatement(handler, ms.getStatementLog()); return handler.\u0026lt;E\u0026gt;query(stmt, resultHandler); } finally { closeStatement(stmt); } } } 查看MappedStatement的源码，发现log的生成是在Builder方法中，如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public final class MappedStatement { public static class Builder { private MappedStatement mappedStatement = new MappedStatement(); public Builder(Configuration configuration, String id, SqlSource sqlSource, SqlCommandType sqlCommandType) { mappedStatement.configuration = configuration; mappedStatement.id = id; mappedStatement.sqlSource = sqlSource; mappedStatement.statementType = StatementType.PREPARED; mappedStatement.parameterMap = new ParameterMap.Builder(configuration, \u0026#34;defaultParameterMap\u0026#34;, null, new ArrayList\u0026lt;ParameterMapping\u0026gt;()).build(); mappedStatement.resultMaps = new ArrayList\u0026lt;ResultMap\u0026gt;(); mappedStatement.sqlCommandType = sqlCommandType; mappedStatement.keyGenerator = configuration.isUseGeneratedKeys() \u0026amp;\u0026amp; SqlCommandType.INSERT.equals(sqlCommandType) ? Jdbc3KeyGenerator.INSTANCE : NoKeyGenerator.INSTANCE; String logId = id; //可以通过设置logPrefix的方法来生成log对象 if (configuration.getLogPrefix() != null) { logId = configuration.getLogPrefix() + id; } //通过logId生成log对象 mappedStatement.statementLog = LogFactory.getLog(logId); mappedStatement.lang = configuration.getDefaultScriptingLanguageInstance(); } } 通过上面的代码可知log对象是由logId生成的，进一步debug发现logId是由 namespace+方法id 组成，在本例中为com.lucumt.mapper.UserMappper.getUsers，而前面的配置为log4j.logger.com.lucumt.mapper=DEBUG ，由于Log4j中的log示例的继承关系，相当于com.lucumt.mapper.UserMappper.getUser也开启了DEBUG模式，故在实际执行时可以显示打印SQL语句，运行结果如下\n利用新版MyBatis的这一特性，我们可以实现类似如下的不同粒度sql打印\n1 2 3 log4j.logger.com.xxx.mapper=DEBUG #打印xxx包下所有的执行SQL log4j.logger.com.yyy.mapper.PersonMapper=DEBUG #打印PersonMapper下所有的执行SQL log4j.logger.com.zzz.mapper.GroupMapper.getGroups=DEBUG #只打印getGroups对应的执行SQL 由前面的代码可知MappedStatement的Build方法在生成log对象时会检测是否有logPrefix配置，若有则用logPrefix来生成log对象，于是可以通过设置logPrefix以另外一种方式配置打印sql。 可在MyBatis配置文件中添加如下配置\n1 2 3 4 \u0026lt;settings\u0026gt; \u0026lt;setting name=\u0026#34;logPrefix\u0026#34; value=\u0026#34;dao.\u0026#34;/\u0026gt; \u0026lt;!-- 设置前缀为dao --\u0026gt; \u0026lt;setting name=\u0026#34;logImpl\u0026#34; value=\u0026#34;log4j\u0026#34;/\u0026gt; \u0026lt;!-- 设置使用log4j为日志实现类 --\u0026gt; \u0026lt;/settings\u0026gt; 然后将 log4j.properties的配置修改为\n1 log4j.logger.dao=DEBUG 执行结果与前面相同，通过 logPrefix可以在有些时候简化sql打印配置。\n待分析问题 若将MyBatis的版本变3.3.0时，通过Log4j配置打印SQL时，如下所示的配置方式只有部分生效，原因待分析\n1 2 3 4 log4j.logger.com.xxx=DEBUG #可以打印SQL log4j.logger.com.xxx.mapper=DEBUG #可以打印SQL log4j.logger.com.xxx.mapper.UserMapper=DEBUG #不能打印SQL log4j.logger.com.xxx.mapper.UserMapper.getUsers=DEBUG #不能打印SQL ","permalink":"https://lucumt.info/post/mybatis/print-sql-in-different-mybatis-version/","tags":["Java","MyBatis"],"title":"在不同版本的MyBatis中通过Log4j打印实际执行的SQL"},{"categories":["Java编程"],"contents":"Java程序实际上执行的是Java文件编译后的Class文件，这是任何一个Java开发人员都了解的基本知识。若Java程序执行的结果不符合要求，通常的解决方法是先修改Java文件，重新编译成Class文件后再次执行。但有时候我们不能直接修改Java文件（如只有包含class文件的jar包），此时我们就只能直接修改Class文件，本文将展示在基于不同的需求通过可视化工具和Javassist库来直接对Class文件进行修改的方法。\n注：由于直接修改class文件会涉及到class文件结构的相关知识，所以利用此种方式时最好对class文件结构有一定的了解\n修改Class文件中的变量 下面的代码为一个典型的输出Hello World的Java小程序\n1 2 3 4 5 6 7 8 9 10 11 12 package com.lucumt; public class Test { public static String language = \u0026#34;Java\u0026#34;; public static void main(String[] args) { sayHello(); } public static void sayHello() { System.out.println(\u0026#34;=====Hello \u0026#34;+language+\u0026#34; World!======\u0026#34;); } } 在cmd命令行中运行该程序的结果如下\n若想将运行结果从Hello Java World修改为Hello Golang China，除了通过修改源代码重新编译运行这个方法之外我们还可以利用工具直接修改原有的class文件来实现。\n首先从 JBE下载 JBE(Java Bytecode Editor),JBE是一个用于浏览和修改Java Class文件的开源软件，在其官网上可以看到如下图所示的说明信息\n下载完该软件后，在该软件中打开我们要修改的Class文件\n首先我们需要将静态变量language的值从Java修改为Golang, 由于language是一个静态变量，故我们需要在class文件的clinit方法中找到该变量并修改其值。如下图所示，展开clinit并切换到Code Editor页，可以看到language的值为Java ，在Code Editor部分将Java修改为Golang然后点击Save method即可完成静态变量值的修改。\n接着展开sayHello方法，同样切换到Code Editor页，将World修改为China后点击Save method，至此整个修改操作完成。\n在命令行中重新执行该程序，输出结果为Hello Golang China，符合我们的要求。\n修改Class文件中的方法 对于较为简单的修改需求我们可以利用JBE等工具来直接修改，若要对class文件进行较为复杂的修改，如增加新方法，修改已有方法的实现逻辑等，对于此种需求虽然也可以用JBE实现目的，但工作量很大，容易出错，此时JBE已经不太适合使用，需要寻找其它更快捷的方法。\n由于Java文件后生成的class文件是一个包含Java字节码的二进制文件，程序最终执行的就是二进制文件中的字节码，我们的需求可以归纳为如何修改Java字节码文件。前一部分通过JBE来修改class文件只不过是将这个过程进行了图形化封装，我们需要找到更底层的实现方法来适应我们的需求。\n此时Javassist闪亮登场！在Javassit官网关于其的第一句介绍为Javassist (Java Programming Assistant) makes Java bytecode manipulation simple. It is a class library for editing bytecodes in Java 。Javassist天生就是为修改Java字节码而来的，它提供了源代码和字节码两种级别的API接口，为了实现的简便性，本文主要介绍利用源代码API来修改class文件。\n下面的代码为一个计算两个整数相加的程序\n1 2 3 4 5 6 7 8 9 10 11 12 13 package com.lucumt; public class Test1 { public static void main(String[] args) { Test1 t1 = new Test1(); int result = t1.addNumber(3, 5); System.out.println(\u0026#34;result is: \u0026#34;+result); } public int addNumber(int a,int b){ return a+b; } } 正常情况下，其输出结果如下\n若我们想将addNumber的返回结果从两个数之和变为两个数立方后求和，则可以利用Javassist提供的API通过Java程序来直接修改class文件。关于如何使用Javassist请直接参看相应的 入门教程，本文不再详细说明，利用Javassist修改 addNumber的Java代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 package com.lucumt.test; import java.io.IOException; import javassist.CannotCompileException; import javassist.ClassPool; import javassist.CtClass; import javassist.CtMethod; import javassist.NotFoundException; public class UpdateMethod { public static void main(String[] args) { updateMethod(); } public static void updateMethod(){ try { ClassPool cPool = new ClassPool(true); //如果该文件引入了其它类，需要利用类似如下方式声明 //cPool.importPackage(\u0026#34;java.util.List\u0026#34;); //设置class文件的位置 cPool.insertClassPath(\u0026#34;D:\\\\Java\\\\eclipse\\\\newworkspace\\\\test\\\\bin\u0026#34;); //获取该class对象 CtClass cClass = cPool.get(\u0026#34;com.lucumt.Test1\u0026#34;); //获取到对应的方法 CtMethod cMethod = cClass.getDeclaredMethod(\u0026#34;addNumber\u0026#34;); //更改该方法的内部实现 //需要注意的是对于参数的引用要以$开始，不能直接输入参数名称 cMethod.setBody(\u0026#34;{ return $1*$1*$1+$2*$2*$2; }\u0026#34;); //替换原有的文件 cClass.writeFile(\u0026#34;D:\\\\Java\\\\eclipse\\\\newworkspace\\\\test\\\\bin\u0026#34;); System.out.println(\u0026#34;=======修改方法完=========\u0026#34;); } catch (NotFoundException e) { e.printStackTrace(); } catch (CannotCompileException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } } } 运行该代码后重新执行后的结果如下，从图中可以看出运行结果符合预期\n关于UpdateMethod工具类有如下几点说明：\n如果要修改的class文件中引入了其它类，需要调用ClassPool中的importPackage方法引入该类，否则程序会报错\n修改完后，一定要调用CtClass中的 writeFile方法覆盖原有的class文件，否则修改不生效\n在修改方法的过程中若要引用方法参数，不能在修改程序代码中直接写该参数，否则程序会抛出javassist.CannotCompileException: [source error] no such field:异常。在本例中addNumber的两个参数分别为a和 b，在修改时不能写成cMethod.setBody(\u0026quot;{ return a*a*a+b*b*b; }\u0026quot;)需要修改为cMethod.setBody(\u0026quot;{ return $1*$1*$1+$2*$2*$2; }\u0026quot;)\n在Javassist的 Introspection and customization部分有如下一段话\nThe parameters passed to the target method are accessible with $1, $2, \u0026hellip; instead of the original parameter names. $1 represents the first parameter, $2 represents the second parameter, and so on. The types of those variables are identical to the parameter types. $0 is equivalent to this. If the method is static, $0 is not available.\n从中可知，方法中的参数从$1开始，若该方法为非static方法，可以用$0来表示该方法实例自身，若该方法为static方法，则 $0 不可用\n在Class文件中增加方法 Javassist不仅可以修改已有的方法，还可以给class文件增加新的方法。仍以前面的 Test1 Java代码中为例，现要求增加一个名为showParameter的方法并在addNumber方法中调用，其主要功能是输出addNumber中传入的参数。利用Javassist修改class文件实现该功能的代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 package com.lucumt.test; import java.io.IOException; import javassist.CannotCompileException; import javassist.ClassPool; import javassist.CtClass; import javassist.CtMethod; import javassist.CtNewMethod; import javassist.NotFoundException; public class AddMethod { public static void main(String[] args) { addMethod(); } public static void addMethod(){ try { ClassPool cPool = new ClassPool(true); cPool.insertClassPath(\u0026#34;D:\\\\Java\\\\eclipse\\\\newworkspace\\\\test\\\\bin\u0026#34;); CtClass cClass = cPool.get(\u0026#34;com.lucumt.Test1\u0026#34;); CtMethod cMethod = cClass.getDeclaredMethod(\u0026#34;addNumber\u0026#34;); //增加一个新方法 String methodStr =\u0026#34;public void showParameters(int a,int b){\u0026#34; +\u0026#34; System.out.println(\\\u0026#34;First parameter: \\\u0026#34;+a);\u0026#34; +\u0026#34; System.out.println(\\\u0026#34;Second parameter: \\\u0026#34;+b);\u0026#34; +\u0026#34;}\u0026#34;; CtMethod newMethod = CtNewMethod.make(methodStr, cClass); cClass.addMethod(newMethod); //调用新增的方法 cMethod.setBody(\u0026#34;{ showParameters($1,$2);return $1*$1*$1+$2*$2*$2; }\u0026#34;); cClass.writeFile(\u0026#34;D:\\\\Java\\\\eclipse\\\\newworkspace\\\\test\\\\bin\u0026#34;); } catch (NotFoundException e) { e.printStackTrace(); } catch (CannotCompileException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } } } 运行该代码后重新执行Test1后的结果如下，从图中可以看出运行结果符合预期 从上述代码可以看出，利用Javassist增加方法比修改方法更简单，先将要新增的方法内容赋值到字符串，然后分别调用相关类的make和 addMethod方法即可。\n后记 利用JBE或Javassist虽然可以实现直接修改class文件的内容，但毕竟属于不正规的做法，可能会导致后续版本不一致等问题，在条件允许的情况下还是要尽量通过修改Java文件然后重新编译的方式来实现目的。\n","permalink":"https://lucumt.info/post/java-core/modify-java-class-file-content-directly/","tags":["Java","JVM"],"title":"在不重新编译的情况下直接修改Java Class文件中的内容"},{"categories":["Web编程"],"contents":"相对于传统的用HTML中TABLE实现的表格，利用EasyUI中的DataGrid实现的表格具有很多优点，如可以对列宽进行拖动调整、列冻结、行冻结、自定义格式化等功能，故而在Web开发中得到了广泛的应用。最近自己在使用DataGrid的列冻结功能时遇到了由于某些单元格中的内容较多导致该行无法对齐的问题，由于当前在EasyUI官网中无法找到该问题的解决方案，自己研究DataGrid的实现原理后，找到了变通的解决方案，故先记录下。\nEasyUI DataGrid正常情况下的列冻结 下图为一个常见的DataGrid使用示例，该图展示了我们在使用EasyUI DataGrid时经常会遇到的一个问题：由于某个列的长度很长导致表格出现滚动条\n对应的代码为\n1 2 3 4 5 6 7 8 \u0026lt;thead\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th data-options=\u0026#34;field:\u0026#39;name\u0026#39;\u0026#34;\u0026gt;\u0026lt;b\u0026gt;书名\u0026lt;/b\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;th data-options=\u0026#34;field:\u0026#39;price\u0026#39;,align:\u0026#39;center\u0026#39;,width:70\u0026#34;\u0026gt;\u0026lt;b\u0026gt;价格\u0026lt;/b\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;th data-options=\u0026#34;field:\u0026#39;pubdate\u0026#39;,align:\u0026#39;center\u0026#39;,width:90\u0026#34;\u0026gt;\u0026lt;b\u0026gt;出版日期\u0026lt;/b\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;th data-options=\u0026#34;field:\u0026#39;description\u0026#39;,width:800\u0026#34;\u0026gt;\u0026lt;b\u0026gt;简要介绍\u0026lt;/b\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; 得益于EasyUI DataGrid强大的功能，当表格中列的宽度太长时，它会自动加上横向滚动条，避免像传统的HTML TABLE表格在内容过多时会自己挤成一团，通过拖动滚动条，我们可以很方便的查看表格中各列的内容。\n但有时候我们会运到另外一个问题，拖动滚动条时前面的某些列就不见了，如本例中的书名，在某些情况下可能会对我们的使用带来不便。\n此时DataGrid的列冻结功能就可以派上用场了，只需要将需要固定的列冻结即可，在本例中我想把书名列冻结，在需要修改代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;thead frozen=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th data-options=\u0026#34;field:\u0026#39;name\u0026#39;\u0026#34;\u0026gt;\u0026lt;b\u0026gt;书名\u0026lt;/b\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th data-options=\u0026#34;field:\u0026#39;price\u0026#39;,align:\u0026#39;center\u0026#39;,width:70\u0026#34;\u0026gt;\u0026lt;b\u0026gt;价格\u0026lt;/b\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;th data-options=\u0026#34;field:\u0026#39;pubdate\u0026#39;,align:\u0026#39;center\u0026#39;,width:90\u0026#34;\u0026gt;\u0026lt;b\u0026gt;出版日期\u0026lt;/b\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;th data-options=\u0026#34;field:\u0026#39;description\u0026#39;,width:800\u0026#34;\u0026gt;\u0026lt;b\u0026gt;简要介绍\u0026lt;/b\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; 其对应的运行效果如下：\nEasyUI DataGrid非正常情形下的列冻结效果 大多数情况下这种列冻结都能满足我们的需求，但上述冻结列正常显示有一个前提：表格中每一行各列的高度一致，若表格中某些行中存在列高超出DataGrid正常高度的情形(25px)，在进行列冻结时就会出现冻结行和非冻结行无法对齐的问题。\n下图为一个列超出正常高度的DataGrid显示效果，从图中可以看出由于描述信息中的文字较多，导致正常的高度都比DataGrid默认的高度要很多，直观的显示就是不同行的高度不一致。 此时若对该表格进列冻结，同样会出现出现如前所述的冻结效果，但如果我们在一开始就将描述信息这列隐藏掉，之后通过点击等方式让该列显示，则会出现冻结行和非冻结行无法对齐的情况，如下图所示 对应的关键代码如下，也可以点击jsfiddle.net/wch9rnr2/8/查看完整的代码\n1 2 3 4 5 6 7 8 9 10 \u0026lt;button type=\u0026#34;button\u0026#34; onclick=\u0026#34;toggleDescription()\u0026#34;\u0026gt;隐藏或显示描述信息\u0026lt;/button\u0026gt; function toggleDescription(){ var colOptions = $(\u0026#34;#dg\u0026#34;).datagrid(\u0026#34;getColumnOption\u0026#34;,\u0026#34;description\u0026#34;); var isHidden = !!colOptions.hidden; if(isHidden){ $(\u0026#34;#dg\u0026#34;).datagrid(\u0026#34;showColumn\u0026#34;,\u0026#34;description\u0026#34;); }else{ $(\u0026#34;#dg\u0026#34;).datagrid(\u0026#34;hideColumn\u0026#34;,\u0026#34;description\u0026#34;); } } 从上图可以看出此时书名列和其余列已经无法对齐，严重印象了我们的使用效果。\n解决方案 要想解决该问题，首先需要找出该问题产生的根源，利用Chrome或其它浏览器调试工具可知，当有部分列冻结时，DataGrid表格被分成了两个不同的表格，一个是冻结的表格，一个是未冻结的表格。进一步分析发现导致无法对齐的问题根源为 由于两个表格中同一行的高度不同，导致实际显示时看起来表格行没有对齐。\n找到问题根源后，要解决该问题，我们只需要让表格中每一行高度保持一致即可，具体来说就是 要在EasyUI DataGrid渲染表格之前将同一行的每一个单元格的高度保持一致即可。问题转化为寻找适当的方法切入点来修改单元格高度，即对单元格的高度进行校验。\n为了修正单元格的高度，我们需要首先找出特定行已冻结单元格和未冻结单元格的高度，而要找出它们的高度必须要等EasyUI DataGrid渲染完毕之后才能获取到其实际高度。本列中由于点击按钮时会对最后一列进行隐藏或显示，所以我们可以在toggleDescription方法的最后执行相应的校验逻辑。\n进一步调试分析后发现，对于DataGrid中的某一个数据行而言，冻结列的单元格高度都一样，非冻结列的单元格高度也一样，为了保持整行对齐，我们只需要高度较小的单元格的高度设置为高度较高的单元格的高度即可。考虑到有些影响列，同时为了简化实现，可以将及解决方案从设置单元格的高度更改为设置特定行在冻结和非冻结部分的行高即可。至于如何设置EasyUI DataGrid中数据行的高度，请参见EasyUI作者stworthy大神在datagrid dynamically set / reset row height中的回复，在该问题中stworthy给出的解决方案如下：\n1 2 3 4 5 var dg = $(\u0026#39;#dg\u0026#39;); dg.datagrid(\u0026#39;options\u0026#39;).rowHeight = 40; for(var i=0; i\u0026lt;dg.datagrid(\u0026#39;getRows\u0026#39;).length; i++){ dg.datagrid(\u0026#39;refreshRow\u0026#39;, i); } 基于此，我们可以将toggleDescription方法改进如下，完整的代码请参见jsfiddle.net/wch9rnr2/9/\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 function toggleDescription(){ var dg = $(\u0026#34;#dg\u0026#34;); var colOptions = dg.datagrid(\u0026#34;getColumnOption\u0026#34;,\u0026#34;description\u0026#34;); var isHidden = !!colOptions.hidden; if(isHidden){ dg.datagrid(\u0026#34;showColumn\u0026#34;,\u0026#34;description\u0026#34;); }else{ dg.datagrid(\u0026#34;hideColumn\u0026#34;,\u0026#34;description\u0026#34;); } var dgOptions = dg.datagrid(\u0026#34;options\u0026#34;); var rows = dg.datagrid(\u0026#34;getRows\u0026#34;); var row = null; var tr = null; var height1 =0; var height2 =0; for(var i in rows){ row = rows[i]; tr = dgOptions.finder.getTr(dg[0],i); height1 = $(tr[0]).height();//冻结行的高度 height2 = $(tr[1]).height();//非冻结行的高度 if((isHidden\u0026amp;\u0026amp;height2\u0026gt;height1)||(!isHidden\u0026amp;\u0026amp;height1\u0026gt;height2)){ //冻结部分在显示时的高度取较大的那个 $(tr[0]).css(\u0026#34;height\u0026#34;,height2+\u0026#34;px\u0026#34;); } } } 此时当我们点击按钮来显示描述信息时，DataGrid中的每一行都已经对齐，如下图所示，至此问题获得解决！\n在实际使用中，我发现有时候上述JavaScript校验代码还是不能正常工作，其原因为在执行校验代码时，EasyUI DataGrid还没有完全渲染完毕，此时可以利用setTimeout函数来延后校验代码的执行，修改后的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 function toggleDescription(){ var dg = $(\u0026#34;#dg\u0026#34;); var colOptions = dg.datagrid(\u0026#34;getColumnOption\u0026#34;,\u0026#34;description\u0026#34;); var isHidden = !!colOptions.hidden; if(isHidden){ dg.datagrid(\u0026#34;showColumn\u0026#34;,\u0026#34;description\u0026#34;); }else{ dg.datagrid(\u0026#34;hideColumn\u0026#34;,\u0026#34;description\u0026#34;); } var dgOptions = dg.datagrid(\u0026#34;options\u0026#34;); var rows = dg.datagrid(\u0026#34;getRows\u0026#34;); var row = null; var tr = null; var height1 =0; var height2 =0; setTimeout(function(){ for(var i in rows){ row = rows[i]; tr = dgOptions.finder.getTr(dg[0],i); height1 = $(tr[0]).height();//冻结行的高度 height2 = $(tr[1]).height();//非冻结行的高度 if((isHidden\u0026amp;\u0026amp;height2\u0026gt;height1)||(!isHidden\u0026amp;\u0026amp;height1\u0026gt;height2)){ //冻结部分在显示时的高度取较大的那个 $(tr[0]).css(\u0026#34;height\u0026#34;,height2+\u0026#34;px\u0026#34;); } } },1000);//延后一秒执行 } 考虑到实际使用中EasyUI DataGrid的渲染时间无法确定，用setTimeout并非最优解，希望EasyUI官方后续能为该问题提供更合理的解决方案!\n","permalink":"https://lucumt.info/post/web/easyui-datagrid-row-not-align-when-column-frozen/","tags":["JavaScript","EasyUI"],"title":"解决EasyUI DataGrid中的行在列冻结时无法对齐的问题"},{"categories":["Java编程","翻译"],"contents":"本文翻译自Java Concurrency / Concurrency Models\n并发系统可以使用不同的并发模型来实现，并发模型是指线程在系统中如何写作来完成给定的任务。不同的并发模型以不同的方式拆分任务，线程间以不同的方式协作和通信，本文将深入研究在撰写本文时最流行并发模型(2015年)。\n并发模型和分布式系统相似之处 本文中描述的并发模型与分布式系统中使用的架构类似，在一个并发系统中，不同的线程之间互相通信，在一个分布式系统中，不同的进程间彼此通信（这些进程可能在不同的电脑上）。线程和进程在本质上时非常相似的，这就是为什么不同的并发模型与不同的分布式系统架构通常看起来相似。\n虽然分布式系统还有额外的挑战，如网络故障、远程计算机或进程关闭等，但一个运行在大型服务器上的并发系统也可能会遇到类似的问题，如CPU故障、网卡故障、硬盘故障等，虽然其发生的概率较低，但理论上仍然可以发生。\n由于并发模型和分布式系统架构类似，它们通常可以相互借鉴，比如在线程中分配工作的模型通常与分布式系统中的负载均衡类似，它们的错误处理手段也类似，例如日志（logging）、故障切换（fail-over）和等幂性任务（idempotency of jobs）等。\n并行工作者模型(Parallel Workers model) 并行工作者模型是本文要说明的第一个并发模型，该模型会将系统中到来的任务分配给不同的工作者，如下图所示：\n并发模型中有一个“委托者”将到来的任务分配给不同的工作者，每个工作者完成整个任务，每个工作者在不同的线程中（也有可能在不同的CPU）并行工作。\n如果一个汽车厂采用了并行工作者模型，那么每辆汽车将由一个工人根据说明书从头到尾来制造。\n并行工作者模型是Java应用程序中使用最广泛的并发模型（尽管这种情形正在发生变化），java.util.concurrent 中的许多包都被设计用于此模型，你也可以在Java企业级服务器的设计中找到此模型的应用踪迹。\n并行工作者模型的优点 并行工作者模型的优点是理解容易，当要增加应用程序的并行能力时我们只需添加更多的工作者即可。\n例如，假设你想实现一个网络爬虫，你可以使用不同数量的工作者线程来爬取制定数量的页面，根据结果来决定使用多少个工作者线程具有最短的抓取时间（同时意味着最优性能）。由于网络爬虫是IO密集型工作，在等待下载数据时会浪费大量时间，若每个CPU只运行一个线程时效率不高，所以最终的结果可能会是在电脑中一个CPU/内核运行多个线程。\n并行工作者模型的缺点 并行工作者模式在其简单外表之下还有若干缺点，我将在以下部分说明其中最为明显的几个。\n状态共享将使复杂性增加 实际上并行工作者模型比上面说明的还要复杂一些，并行工作者通常需要访问一些共享数据，它们可能存储在内存中也可能存在数据库中，下面的图标展示了这种情形是如何是的并行工作者模型变得复杂的。\n其中的一些共享状态可能在类似于任务队列的通信过程中，但是另外一些共享状态可能是商业数据、缓存数据、数据库的连接池等。一旦共享状态引入到了并行工作者模型，问题就开始变得复杂。线程需要一种方式来访问共享数据以确保一个线程对共享数据的更改对其它线程是可见的（将其推送到主内存中，而不是仅停留在执行线程的CPU缓存中）。线程间需要避免竞争条件、死锁和其它共享状态相关的问题。\n另外，当线程间在等待彼此访问共享数据结构时，会降低应用程序的并行性。许多并发数据结构都是阻塞式的，这意味着在给定时间只有一个或一组有限的线程可以访问它们，这可能导致线程对这些共享数据的竞争，高度竞争将会导致访问共享数据的代码从本质上变为串行执行。\n现代的非阻塞并行算法(non-blocking concurrency algorithms )可能会减少竞争和提高性能，但是非阻塞算法很难实现。\n持久化数据结构是另外一种选择，一个持久化数据在自身被修改时会始终保留之前的值。因此，如果多个线程同时操作一个持久化数据并且其中一个修改了该数据，该线程会得到新数据的引用，而其它线程在则保持着对未修改的旧数据的引用，从而依旧保持一致。在Scala编程中包含若干个持久化的数据结构。\n虽然持久化数据结构是并发修改共享数据的一种看似优雅的解决方案，但其执行性能并不理想。例如，一个持久化的列表会把新元素加入其首部并且返回对该新增元素的引用（它将会指向列表的其余元素）。所有其它的线程仍然保持着对先前列表中第一个元素的引用，对这些线程而言该列表并没有发生修改，它们看不见新增加的元素。\n这种持久化的列表可以用链表来实现，不幸的是，现在的硬件并不能很好的支持链表，链表中的每一个元素都是一个单独的对象，这些对象可以遍布计算机的内存。现在的CPU在访问连续的内存地址时速度更快，因此实现为数组(Array)结构会获得更高的性能。对于一个以数组方式存储的数据而言，CPU缓存可以一次将更大的数组块加载到缓存中，一旦数据加载完毕，CPU可以直接在缓存中访问这些数据，而这对于元素分散在RAM中的链表而言是不太可能实现的。\n无状态的工作者 共享状态可以被系统中的其它线程修改，因此工作者(workers)在每次需要它们时都必须重新读取该状态，以确保它在最新的副本上工作，无论共享状态是保存在内存还是外部数据库中，都是如此。一个工作者不在其内部保存状态（而是在每次需要时都重新读取），我们称之为无状态。\n任务顺序的不确定 并行工作者模型的另一个缺点是任务执行的顺序无法确定。没有办法来确保某个任务最先执行或最后执行，任务A在任务B之前分配给一个工作者，但是任务B可能先于任务A执行。\n并能工作者模型的不确定性使得很难在任何给定的时间点推理系统的状态，它同样使得确保一个任务在另外一个任务之前执行变得更难（如果可能）。\n流水线模型（Assembly Line） 第二种并发模型我称之为流水线模型，我选择名称以符合早期“并行工作者”的含义。在不同的平台/社区中，其他的开发人员或许使用其它的名称，如反应式系统(reactive systems)，或事件驱动系统(event driven systems)，下图是流水线并发模型的一个展示\n这些工作者就像工厂里的工人一样组织起来，每个工作者只完成整个任务的一部分，当该部分任务完成时，该工作者将任务转移到下一个工作者。每个工作者都在自己的线程中运行，并且没有与其它的工作者共享状态，因此流水线模型有时也被称之为无共享的并发模型。\n流水线模型通常用于系统中的非阻塞IO操作，非阻塞IO意味着当一个工作者(worker)开始一个IO操作时(如从网络读取文件或数据)，该工作者(worker)不必等待IO操作结束。IO操作通常较慢，因此等待IO操作完成是对CPU时间的浪费，CPU可以在此时做一些其它事情。当IO操作完成时，IO操作的结果（如数据状态读取或输入写入）会传给下一个工作者(worker)。\n使用非阻塞IO时，IO操作的结果决定了工作者(worker)之间的边界，一个工作者(worker)在不得不开始IO操作之前可以尽可能的完成任务，然后放弃对该任务的控制，当IO操作结束时，在流水线上的另一个工作者(worker)以类似的方式继续完成该任务，直到它不得不开始IO操作。\n实际中，上述这些任务可能不会沿着一条流水线流动，因为大多数操作系统可以同时运行多个任务，这些任务根据实际需求沿着流水线逐个的被工作者处理。在实际使用中可能会有多个虚拟流水线同时运行，下图展示了在实际使用中任务如何在这种流水线上流转。\n任务甚至可以转发给多个工作者进行并发处理，例如，一个任务可以被同时转发给一个任务执行器和一个任务日志记录器。下图展示了如何将三条装配线的中任务转发给同一个工作者完成（中间装配线上的最后一个工人）：\n流水线甚至可以做的比上面展示的更复杂。\n响应式、事件驱动系统 使用流水线并发模型的系统有时候也被称之为 响应式系统 或 事件驱动系统 。系统工作者在事件发生时做出对应的响应：从外部接收消息或转发给其它工作者等。事件驱动的例子可能是传入的HTTP请求，也可能是某个文件完成加载到内存中等。\n在写作本文时，已经有一些有趣的响应式/事件驱动平台可以使用，并且在将来会出现更多的。其中一些比较受欢迎的如下：\nVert.x Akka Node.JS (JavaScript) 对我个人而言，我发现Vert.x十分有趣(尤其是像我这种对Java/JVM落伍的人)。\n参与者(Actors)与管道(Channels)对比 参与者（Actors）和管道（Channels）是两种类似的流水线（响应式/事件驱动）模型。\n在参与者模型中，每个工作者被称之为一个参与者，参与者之间可以直接发消息给对方，这些消息以异步方式来发送和处理。参与者可以用于处理如前所述的一个或多个流水线任务，下图展示了这种模型：\n在管道(Channel)模型中，工作者之间不直接互相沟通，相反地，他们会将消息发布到不同的管道中，其他的工作者可以在这些管道上收听消息，同时消息发送者不必知道谁在收听消息。下图展示了该模型：\n在写作本文时，管道模型对我而言似乎更灵活：一个工作者不必知道在流水线上的哪个工作者要处理接下来的任务，它只需要知道需要将任务转发到哪个管道（或发送消息哪个管道等），在管道中的收听者可以订阅和取消订阅而不会影响到往管道中正在写入的工作者，这允许工作者之间有某种程度的低耦合。\n流水线模型（Assembly Line）的优点 相对于并行工作者模型，流水线模型有一些优点，在接下来的部分，我会叙述其中最突出的几个优点。\n无共享状态 工作者之间不共享状态的情形意味着它们可以在实现时不必考虑在状态共享时所遇到的各种并发问题，这让工作者的实现变得更加容易，在实现工作者时可以假设只有一个线程在处理该工作，本质上就是一个单线程实现。\n有状态的工作者 由于工作者知道没有其它线程修改它们的数据，这些工作者可以具有状态。在说有状态时我的意思是它们可以保留在内存中操作所需的数据，只有写入才会改变最终的外部存储系统。因此，一个有状态的工作者通常比无状态的工作者执行更快。\n更好的硬件协同 单线程代码的优点在于它通常更符合底层硬件的工作原理。首先你通常可以创建更优化的数据结构和算法当你能假定代码会以单线程模式执行。\n其次,如前所述单线程有状态的工作者可以在内存中缓存数据，当数据在内存中缓存时，有很大的概率该数据也会被缓存到CPU缓存中，这样数据获取变得更快。\n当代码以一种自然受益于底层硬件工作原理的方式编写时，我称之为 硬件协调，有些开发者称之为mechanical sympathy，我更倾向于硬件协同因为计算机只有很少的机械部件，同时单词sympathy在这种情况下被用作比喻“更高的匹配”，而我认为单词conform能更高的传达其含义。不管怎么说，这些都是吹毛求疵，可以使用你喜欢的任何术语来描述。\n任务可排序 根据流水线模型实现的并发系统使得排序变得可能，任务排序使得在任何给定时间点更容易理解系统的状态。此外，你可以将所有传入的任务写入日志，如果系统的任何部分发生故障，则可以使用该日志从头重建系统的状态。这些任务以某种顺序写入日志，这个顺序称为该任务顺序，下图展示了这种设置如何实现： 确保一个任务的顺序实现起来不一定容易，但通常是可能的。如果你可以实现的话，它将会大大简化类似于数据备份、恢复数据、复制数据等的任务，这些都可以通过日志文件来完成。\n流水线模型（Assembly Line）的缺点 流水线模型的最主要缺点是通常将执行一个任务分配到多个工作者，因此，当项目中有多个类时，将难以准确的看出哪段代码在执行给定的任务。\n代码编写也可能会变得更难，工作者代码有时候被写作回调处理器(callback handlers)。在代码中有太多嵌套的回调处理器时可能会导致某些开发人员所谓的 回调陷阱(callback hell) 。回调陷阱简单的说就是在所有的回调中很难追踪代码真正在干啥以及确保每个回调都可以访问它需要的数据。\n而使用并行工作者模型，这往往很容易。你可以打开对应的工作者代码，并从头到尾读取要执行的代码。当然，并行工作者模型也可能传播到不同的类中，但是要执行的序列通常更容易从代码中读取。\n功能并行(Functional Parallelism)模型 功能\\函数并行模型是第三种并发模型，最近谈论得很多(2015)。\n功能\\函数并行性的基本思想是通过函数调用实现程序，功能可以被看作是发送消息到彼此的“代理”或“角色”，就像流水线并发模型（AKA反应或事件驱动系统）一样，当一个函数调用另一个函数时，类似于消息发送。\n传递给函数的所有参数都被复制，所以在接收函数之外没有任何实体可以操纵数据，这种复制对于对于避免共享数据的条件竞争至关重要，它使得函数执行类似于原子操作，每个函数调用都可以独立于任何其他函数调用执行。\n当每个函数调用可以独立执行时，可以在单独的CPU上执行每个函数调用，这意味着，在多个CPU上可以并行执行功能实现的算法。\n使用Java 7，我们得到了包含ForkJoinPool模型的 java.util.concurrent 包，可以帮助您实现类似于功能并行性的功能，而使用Java 8，我们将得到并行流，可以帮助您并行化大型集合的迭代。请记住，有开发人员批评ForkAndJoinPool模型（您可以在我的ForkAndJoinPool教程中找到一个相应的批评链接）。\n关于功能\\函数并行的难点在于知道哪个函数调用需要并行化，跨CPU的协调功能调用带来了一定的开销。只有由功能/函数完成的工作单位具有一定的大小，才能值得这个开销，如果函数调用非常小，尝试并行化它们可能比单个线程的单个CPU执行更慢。\n从我的理解（事实上根本不完美），您可以使用事件响应驱动模型来实现实现算法，并实现与功能并行性相似的工作分解。在我看来，通过事件响应驱动模型，你可以掌握如何来实现并行化。\n另外，只有当前任务是程序执行的唯一任务时，将任务分配给多个CPU，协调开销才有意义。然而，如果系统同时执行多个其他任务（如Web服务器，数据库服务器和许多其它系统），则无需尝试并行化单个任务。计算机中的其它CPU可能正在忙于处理其它任务，所以没有理由试图用较慢的功能并行任务来打扰他们。如有可能，你最好使用流水线并发模型，因为它在以单线程模式顺序执行的程序中具有更少的开销，并且更好的符合底层硬件的工作原理。\n孰优孰劣 那么，哪种并发模型更好呢？\n通常情况下，答案取决于你的系统应该做什么。 如果你的工作自然并行，独立，无需共享状态，则可以使用并行工作模型来实现系统。但许多任务不是自然并行和独立的，对于这些类型的系统，我相信流水线并发模型比缺点有更多的优点，比并行工作模型更有优势。你甚至不需要自己编写所有的流水线路基础设施，像Vert.x这样的现代平台为你已经实现了很多。 就个人而言，我将探索在Vert.x等平台上运行的设计，以便我的下一个项目。我个人感觉JavaEE没有尽头。\n\u0026lt;–翻译结束!–\u0026gt;\n","permalink":"https://lucumt.info/post/translate/java-concurrency/concurrency-models/","tags":["Java","Java Concurrency"],"title":"4. [译]并发的模型"},{"categories":["Web编程","工具使用"],"contents":"由于业务要求，需要在利用MyEclipse中开发的Web项目中添加Birt报表统计功能，新建完一个report.rptdesign文件后双击该文件出现如下错误:\n错误信息提示MyEclipse无法打开Birt报表编辑器，对于此种情况，网上搜索相应的解决方案后一般都让我们给该项目添加报表支持，即选中该项目，然后右键MyEclipse -\u0026gt; Add Report Capabilities来对该项目添加Birt报表支持。此种方式虽能解决问题，但却同时额外的引入了系统内置的Birt jar包和相应的report文件夹，给我们的项目造成了一定的干扰。\n分析上述添加完Birt报表支持的项目文件后，可发现与普通的Java Web项目相比 .project文件在natures下面多了一个 com.genuitec.eclipse.reporting.reportnature的配置项，而该配置项正是用于在项目中支持Birt报表操作。据此，我们可以采用另外一个方式来解决在MyEclipse中无法打开Birt报表的问题：\n将 com.genuitec.eclipse.reporting.reportnature配置项添加到当前项目.project文件的natures配置项下面\n如下所示:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;projectDescription\u0026gt; \u0026lt;name\u0026gt;teq\u0026lt;/name\u0026gt; \u0026lt;comment\u0026gt;\u0026lt;/comment\u0026gt; \u0026lt;projects\u0026gt; \u0026lt;/projects\u0026gt; \u0026lt;buildSpec\u0026gt; ... \u0026lt;/buildSpec\u0026gt; \u0026lt;natures\u0026gt; \u0026lt;!--添加报表支持 --\u0026gt; \u0026lt;nature\u0026gt;com.genuitec.eclipse.reporting.reportnature\u0026lt;/nature\u0026gt; \u0026lt;nature\u0026gt;com.genuitec.eclipse.j2eedt.core.webnature\u0026lt;/nature\u0026gt; \u0026lt;nature\u0026gt;org.eclipse.jdt.core.javanature\u0026lt;/nature\u0026gt; \u0026lt;nature\u0026gt;org.eclipse.wst.jsdt.core.jsNature\u0026lt;/nature\u0026gt; \u0026lt;/natures\u0026gt; \u0026lt;/projectDescription\u0026gt; 利用此种方式既可解决无法打开Birt报表问题，又能避免添加冗余的jar文件和文件夹，给我们的开发省去不必要的麻烦。\n","permalink":"https://lucumt.info/post/web/cannot-open-birt-report-in-myeclipse-project/","tags":["Birt"],"title":"在MyEclipse项目中不能打开birt报表的解决方法"},{"categories":["Java编程","翻译"],"contents":"本文翻译自Java Concurrency / Multithreading Costs\n从一个单线程程序切换为多线程程序在给我们带来好处的同时也会产生一些额外的成本，不要因为会使用多线程就将一个程序变为多线程实现。在准备使用多线程时，我们应该有一个清楚的认识：使用多线程带来的好处大于其成本，当有不确定时，我们应该尝试度量应用程序的性能和响应性来决定是否采用多线程，而不是靠猜来决定。\n更复杂的设计 尽管多线程应用程序的某些部分比单线程应用程序更简单，但其它部分却更为复杂。在执行通过多线程访问共享数据时需要特别注意，同时多线程间的交互也不是那么简单,由不正确的线程同步引起的错误可能会非常难以检测、复现和修复。\n上下文切换开销 当CPU从执行一个线程切换到执行另外一个线程时，CPU需要保存当前线程的本地数据，程序指针等，并加载下一个线程的本地数据，程序指针等来执行线程，这种切换被称作上下文切换，CPU从一个线程的上下文中执行切换到在另一个线程的上下文中执行。\n上下文切换的代价并不便宜，在线程间要避免不必要的切换。可以在维基百科上阅读 Context switch来了解更多关于上下文切换的知识。\n加重资源消耗 线程需要计算机的一些资源才能运行，除了CPU时间之外，线程需要一些内存来维护其本地堆栈，它也可能会占用操作系统的一些资源来管理该线程。我们可以尝试创建100个什么操作也没有的等待线程来看看在运行这些线程时应用程序需要多少内存。\n\u0026lt;–翻译结束!–\u0026gt;\n","permalink":"https://lucumt.info/post/translate/java-concurrency/multithreading-costs/","tags":["Java","Java Concurrency"],"title":"3. [译]多线程的成本"},{"categories":["Java编程","翻译"],"contents":"本文翻译自Java Concurrency / Multithreading Benefits\n尽管多线程给程序实现带来了挑战，但由于多线程的一些优点我们仍然在使用它，其中的一些优点如下：\n更好的资源利用 在某些场景可以简化程序设计 提高程序响应 更好的资源利用 假设我们有一个程序从本地磁盘中读取和处理文件，若读取和处理一个文件的耗时分别为5秒钟和2秒钟，则读取处理2个文件的耗时如下：\n1 2 3 4 5 6 5 seconds reading file A 2 seconds processing file A 5 seconds reading file B 2 seconds processing file B ----------------------- 14 seconds total//串行读取时总共耗时14秒 当从磁盘读取文件时CPU的大部分时间都花费在等待从磁盘读取数据，在此期间CPU大部分时间都处于空闲状态。这些空闲时间可以做一些其它的事情，通过改变操作顺序，CPU可以被更好的利用，如下面的列子：\n1 2 3 4 5 5 seconds reading file A 5 seconds reading file B + 2 seconds processing file A 2 seconds processing file B ----------------------- 12 seconds total//并行读取时总共耗时12秒 在上面的例子中，CPU先等待读取第一个文件，然后开始读取第二个文件，在读取第二个文件的同时，CPU可以同时处理第一个文件。请记住，当等待从磁盘读取数据时，CPU大部分时间处于空闲状态！\n通常情况下，CPU在等待IO响应时可以做一些其它事情，这不仅适用于磁盘IO操作，也适用于网络IO操作，或者读取用户输入,网络和磁盘IO操作通常比CPU和内存IO操作慢很多。\n简化程序设计 如果在单线程应用程序中编程实现上述读取和处理文件的功能，就必须跟踪每个文件的读取和处理状态。相反的，在多线程程序中我们可以开启两个线程，每个线程读取和处理同一个文件。每个线程在等待从磁盘读取文件时都会被阻塞，但在等待的同时，其它线程可以利用CPU来处理已经读取的文件。这样能够是的CPU和磁盘都被更好的使用，而且由于每个线程只需要跟踪一个文件，编程实现也会变得更简单。\n提高程序响应 将单线程应用变为多线程应用的另一个常见目的是获得更快的响应。假设有一个服务器程序在某个端口监听请求，当接收到一个请求后，服务器处理该请求，处理完后再继续监听，该循环监听服务器的设计草图如下：\n1 2 3 4 while(server is active){ listen for request //监听请求 process request//处理请求 } 如果某个请求需要花费很长的时间来处理，那么在此期间其它的客户端就不能向此服务器发送请求，只有当服务器处于监听状态时才能够接收请求。\n一种替代方案是让监听线程将接收到的请求发送给worker线程处理，然后立即恢复监听，worker线程对请求进行处理并给客户端发送回复，此种服务器的设计草图如下：\n1 2 3 4 while(server is active){ listen for request //监听请求 hand request to worker thread//将接收到的请求发送给worker线程处理 } 在这种方式下，服务器线程会迅速返回监听，因而更多的客户端可以给服务器发送请求，服务器的响应也得以提高。\n该方法同样适用于桌面应用程序，如果你点击一个按钮来开启一个长任务，而执行该任务的线程是更新窗口、按钮等部件的线程，那么在该任务运行期间，该桌面程序将无法响应其它操作。相反的，可以将该任务移交给一个worker线程，当worker线程处理该任务时，更新窗口的线程处于空闲状态，可以响应其它用户请求，当worker线程执行完任务时通知更新窗口线程，该窗口线程根据执行结果来更新程序。因而利用worker线程设计实现的程序对用户更具有响应性。\n\u0026lt;–翻译结束!–\u0026gt;\n","permalink":"https://lucumt.info/post/translate/java-concurrency/multithreading-benefits/","tags":["Java","Java Concurrency"],"title":"2. [译]多线程的优点"},{"categories":["Java编程","翻译"],"contents":"本文翻译自Java Concurrency / Multithreading Tutorial\n最开始一台电脑只有单个CPU，只能一次运行一个任务，之后出现的多任务处理则意味着计算机在同一时间可以处理多个程序（也可以称之为任务或进程），虽然它们并不是真正的并发。由于单个CPU被不同的程序共用，操作系统需要在程序运行过程中不停地切换CPU，在短暂的执行一个程序后就立即切换到下一个程序。\n多任务处理给软件开发人员提出了新的挑战，程序不能再假定拥有CPU所有的可用时间、内存和其它计算机资源，一个好的程序应该及时释放所有不需要使用的资源，以便其它程序可以使用它们。 之后出现的多线程则意味着可以在同一个程序里面执行多个线程，每一个执行的线程可以被认为是CPU在执行当前程序，当在同一个程序里面执行多个线程时，看起来像是拥有多个CPU在执行该程序。\n多线程虽然是提高某些类型程序性能的良方，但是多线程比多任务更具有挑战性。由于这些线程执行的是相同的程序，因此它们同时读写相同的内存，这可能会导致在单线程中不会出现的错误结果。某些错误结果不会出现在单CPU中机器中是由于两个线程不可能同时执行。现在的电脑大都拥有多核甚至多CPU，这意味着多个不同的线程可以被不同的内核或CPU同时执行。\n如果一个线程读取一个内存地址同时另一个线程向其写入信息，第一个线程在读取完成时会得到什么值呢？旧的值还是被第二个线程写入的新值？亦或是这两个值得混合？若两个线程同时向一个内存地址写入信息，当这两个线程运行完毕时，最终的值会是什么呢？是第一个线程写入的值还是第二个线程写入的值？亦或是这两个线程写入值的混合？\n在缺少适当措施的情况下，上述的任意一种结果都可能出现，程序的运行结果甚至不可预测，每一次的执行结果可能都不同。因此怎么处理多线程对于软件开发人员很重要，这意味着我们需要学习如何控制线程来访问共享资源如内存、文件、数据库等，而这正是本系列教程所要阐述的主题之一。\nJava中的多线程和并发 Java是最先让多线程对开发人员变得简单的程序语言之一，Java在最开始的时候就已经具备了多线程的能力，因此Java开发人员经常面临上文所述的并发问题。这正是我编写本系列Java并发教程的原因，作为自己的笔记以及其他可能从中获益的Java开发人员。\n本教程将主要关注于Java中的多线程，但其中的一些多线程问题与多任务和分布式系统系统中出现的问题类似，因此在本教程中可能会出现对多任务和分布式系统的引用。并发不等于多线程，它们是不同的概念。\nJava并发在2015的现状和展望 自从第一本Java并发书籍问世之后，关于并发架构和设计领域已经发生了很多变化，Java5甚至提供了concurrency工具包。新的类似于Vert.x、Play/Akka和Qbit的异步无共享平台和API已经出现。这些平台使用了一个不同于标准Java/JEE并发的模型来处理线程、共享内存和锁。新的无阻塞并发算法已经公开，类似于LMax Disrupter这样的非阻塞工具也已经添加到我们的工具箱。在Java7中通过Fork和Join框架引入了并行性功能编程，并在Java8中引入了流相关的API。\n所有这些新的进展让我觉得是时候编更新本系列的Java并发教程，因此本教程再一次处于编写中状态，新的教程会在时间允许编写时发布。\n\u0026lt;–翻译结束!–\u0026gt;\n","permalink":"https://lucumt.info/post/translate/java-concurrency/java-concurrency-multithreading-tutorial/","tags":["Java","Java Concurrency"],"title":"1. [译]Java多线程与并发教程"},{"categories":["Go编程","工具使用"],"contents":"在学习Golang时，自己最开始用的是Eclipse中的goclipse插件来进行Golang编程，但其对Golang的支持不是太好，如代码格式化、自动导入引用包等都无法直接在Eclipse中使用，并且其自动提示功能也没有像Java那么强，于是转用Intellij IDEA安装Golang插件来替代使用，安装完插件后的Intellij IDEA对Golang的支持在各方面都很令人满意，唯独引入本地包的支持不太好用。经过一阵摸索自己找出了解决方案，先记录下。\n在Eclipse中引用Golang本地包 若我们采用的是goclipse来开发Golang ,则在其中引用本地包很简单，和引用Java包类似。如下图所示，假设 src是源代码所在的目录，在src的sec文件夹下有一个名为calculate.go的文件，其中有一个名为Add的函数用于计算两个整数的相加之和。\n若要在主程序main方法中调用Add方法，先通过import引入该文件的包名import service，然后通过包名调用该方法service.Add(1,2)，如下图所示，可以看出在eclipse中引用Golang本地包与引用Java包没有太大的区别，都是将包文件放到src源文件夹下，然后通过包名来引用。\n也可以通过直接导入该包所在的文件夹的名称来调用该方法，此时需要将import service改为import sec，如下图所示\n可以看出在Eclipse中导入Golang本地包时有两种方法： 通过import导入包名或通过import导入该包对应的文件夹，这两种方法均可使程序正常运行。\n在Intellij IDEA中引用Golang本地包 下面2张图为在IDEA中建立的对应项目，图中gproject是一个项目，gotest是一个模块，我们在gotest下建立相关的测试文件。\n在上述代码中我们是通过import service的方式来导入相应包的，由于IDEA对Golang很强，从图中可以看出service的颜色与其它导入包的颜色不一致，当把鼠标移动到service上时会提示Cannot resolve file 'service' ，直接运行时，会出现如下图所示cannot find package错误，将import service修改为import sec时，会出现同样的错误，可以看出在idea中默认不支持直接导入本地 Golang包。 从报错信息可以看出，程序在运行时先去 GOROOT 去搜索导入包，然后去 GOPATH 寻找导入包，最后在当前项目模块下寻找导入包，但实际上不存在D:\\program\\IntelliJ IDEA 2016.2.1\\workspace\\gproject\\gotest\\src\\service这个目录，故而程序报错，不能正常运行。\n解决该问题的关键是明白GOROOT和GOPATH的作用，根据官方文档的解释GOPATH的主要作用是存放文件以便Golang程序编译时可以进行搜索引用，GOPATH可以设置一个值或多个值，多个值之间以分号隔开。很明显只要我们将本地Golang加入到GOPATH中即可在IDEA中正常运行该程序。\n如下图所示，在IDEA中依次选择 File-\u0026gt;Settings-\u0026gt;Language\u0026amp;Frameworks-\u0026gt;Go-\u0026gt;Go Libraries ，会出现如下图所示的配置Golang 库的界面，在该界面可以添加Golang本地包所在的路径，该界面包含3个不同作用范围的配置方式：Global libraries、Project libraries和 Module libraries，其中Global libraries的配置对所有项目生效为全局配置，Project libraries的配置对整个项目生效，Module libraries的配置只对模块生效，可以看出在Global libraries默认包含了GOPATH。根据实际使用的需求我们可Z选择把本地包设置在Project libraries还是Module libraries中。\n本文的程序都是在gotest模块下，故将其添加到Module libraries下，添加完的结果如下所示：\n将本地包添加到模块库之后，还需要在go文件中将导入包的语句设置为import sec，不能设置为import service，然后该Golang程序即可正常运行。\n可以看出，不同于goclipse，在IDEA中只能使用通过import导入该包对应的文件夹来导入本地Golang包，至于原因还需要进一步研究。\n利用Goclipse时无法运行程序的解决方法 在使用goclipse运行 Golang程序时，偶尔会出现程序无法编译和运行的情况，这种情形一般都是src没有被设置成源代码目录造成的，此时可以通过如下图所示的方法，将src目录添加源代码目录。在Eclipse中选中该项目然后点击 Properties ，会出现项目属性配置界面，点击 Go Project Configuration ，通过 Add Folder 可以将src添加到源代码中，之后程序即可正常运行。\n更新 在本文写作的时(2017年3月份)，jetbrain官方出版了GoLand，建议在条件许可的情况下优先使用GoLand\n支持正版，从我做起！\n","permalink":"https://lucumt.info/post/golang/import-local-package-in-intellij-idea/","tags":["Go","Intellij IDEA"],"title":"在Intellij IDEA中引用Golang本地包"},{"categories":["算法","Java编程"],"contents":"之前面试时遇到一个算法题:\n假定两个矩形各条边都是平行于坐标轴，已知k、l、m、n分别为其中一个矩形左下角和右上角x轴、y轴坐标，p、q、r、s分别为另一个矩形的左下角和右上角x轴、y轴坐标，求这两个矩形的总面积，当矩形相交时要减去相交的面积。\n此题利用常规的枚举法很复杂，但利用排除法和归纳法却能很快解决，故先记录下。\n很明显，此题的重点在于如何判断矩形是否相交以及检测相交形成的新矩形面积，当不相交时总面积直接为两个矩形的面积之和，当相交时需要减去相交矩形的面积，由于题目已经告诉了矩形的左下角和右上角坐标已知，问题又转化为在相交时如何计算相交矩形的左下角和右上角的坐标。\n最开始我想通过常规的枚举法把矩形相交的所有情况都列出来，在稿纸上简单的比划后，发现采用枚举的方式太复杂，矩形相交理论上有下图所示的16种组合方式，短时间内很难一一列举出来，实际编程中不仅代码量大还很容易产生遗漏:\n两个矩形边角相交以及完全包含\n矩形横向相交\n矩形纵向相交\n矩形被完全包含\n排除枚举方法之后，只能对其进行分析找出通用的处理方式。下图展示了在相交矩形的左下角和右上角的位置，仔细分析后便可发现相交矩形的左下角x,y坐标是两个矩形左下角x,y坐标中取较大值，相交矩形的右上角x,y坐标是两个矩形右上角x,y坐标中取较小值。\n通过分析归纳之后，我们将之前的16种相交情况统一为1个表达式，而这个表达式在编程时是很容易实现的，下面的代码展示了如何利用该表达式计算相交矩形的坐标以及其面积。\n1 2 3 4 5 6 7 8 public static int calculateIntersectArea(int k, int l, int m, int n, int p,int q, int r, int s) { int leftDownX = 0, leftDownY = 0, rightUpX = 0, rightUpY = 0; leftDownX = k \u0026gt; p ? k : p; leftDownY = l \u0026gt; q ? l : q; rightUpX = m \u0026lt; r ? m : r; rightUpY = n \u0026lt; s ? n : s; return (rightUpX - leftDownX) * (rightUpY - leftDownY); } 寻找出如何计算相交矩形的面积之后，还需要解决一个问题:上述实现只有在矩形相交时才正确，当矩形不相交时计算结果错误，为此需要找出一个方法判定两个矩形是否相交。若利用枚举方法同样会有前述的16种情形需要考虑，同样很复杂，显然枚举方法不适合使用。换一种思路：如果把矩形不相交的情形排除掉，那么剩下的情形就是矩形相交了！，而矩形不相交则相对容易多了，假设这两个矩形分别为A和B，则它们不相交一共有如下图所示的4种情况：\n相应的代码实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public static boolean isIntersect(int k, int l, int m, int n, int p, int q, int r, int s) { boolean nointersect = false; // B在A的上面 nointersect = q \u0026gt; n; // B在A的下面 nointersect = l \u0026gt; s; // B在A的左侧 nointersect = r \u0026lt; k; // B在A的右侧 nointersect = m \u0026lt; p; return !nointersect; } 利用上述2个判断方法，可以方便准确的计算出两个矩形在相交时的总面积，相应的代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public static int solution(int k, int l, int m, int n, int p, int q, int r, int s) { int widthA = m - k; int heightA = n - l; int areaA = widthA * heightA; int widthB = r - p; int heightB = s - q; int areaB = widthB * heightB; int totalArea = areaA + areaB; boolean hasIntersect = isIntersect(k, l, m, n, p, q, r, s); if (hasIntersect) { totalArea -= calculateIntersectArea(k, l, m, n, p, q, r, s); } return totalArea; } 分析解决这个问题给我最深的感触是：有时候若某一类问题用枚举实现很复杂时，尝试去分析其中的规律，找出通用的解决方法，不仅在算法方面，或许在生活中其它方面也适用吧！\n","permalink":"https://lucumt.info/post/algorithm/calculate-total-area-of-two-rectangles/","tags":null,"title":"计算两个平行于坐标轴的矩形相交的面积"},{"categories":["Web编程"],"contents":"由于项目需要，最近使用了在html5中播放视频的功能，期间遇到了几个坑，先简单记录下。\n在html5页面中播放视频 如何在html5页面中嵌入视频的代码在网上很容易直接搜索到，典型的代码如下所示：\n1 2 3 4 \u0026lt;video width=\u0026#34;320\u0026#34; height=\u0026#34;240\u0026#34; controls=\u0026#34;controls\u0026#34;\u0026gt; \u0026lt;source src=\u0026#34;movie.mp4\u0026#34; type=\u0026#34;video/mp4\u0026#34;/\u0026gt; Your browser does not support the video tag. \u0026lt;/video\u0026gt; 之后的效果显示如下，从图中我们可以看出该视频播放界面包含快进 、音量调整 和全屏播放这几个按钮\n在iframe中不能全屏播放视频 项目中好多地方都用iframe来嵌套html页面，最开始我是用类似如下代码在被iframe包含的页面中嵌入前面的视频播放代码， 发现显示出来的视频播放器没有全屏播放按钮，通过升级浏览器版本和清除缓存等方法依然不奏效。搜索stackoverflow找到一个类似的问题How to make a video fullscreen when it is placed inside an iframe?，阅读后发现只需要将iframe修改成\u0026lt;iframe … allowfullscreen=\u0026quot;true\u0026quot; webkitallowfullscreen=\u0026quot;true\u0026quot; mozallowfullscreen=\u0026quot;true\u0026quot;\u0026gt;即可\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;iframe\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head /\u0026gt; \u0026lt;body\u0026gt; \u0026lt;video width=\u0026#34;320\u0026#34; height=\u0026#34;240\u0026#34; controls=\u0026#34;controls\u0026#34;\u0026gt; \u0026lt;source src=\u0026#34;movie.mp4\u0026#34; type=\u0026#34;video/mp4\u0026#34;/\u0026gt; Your browser does not support the video tag. \u0026lt;/video\u0026gt; \u0026lt;body\u0026gt; \u0026lt;/html\u0026gt; \u0026lt;/iframe\u0026gt; 隐藏声音调整按钮 有些演示视频只有图像没有声音，为了避免对使用者造成不必要的干扰，可以将声音播放按钮屏蔽掉，由于自己项目只支持基于webkit内核的Chrome浏览器访问，通过Google之后在 stackoverflow找到 Why do no user-agents implement the CSS cursor style for video elements这篇文章，其中列出了播放视频时相关控制按钮的css类：\nvideo::-webkit-media-controls-panel video::-webkit-media-controls-play-button video::-webkit-media-controls-volume-slider-container video::-webkit-media-controls-volume-slider video::-webkit-media-controls-mute-button video::-webkit-media-controls-timeline video::-webkit-media-controls-current-time-display video::-webkit-full-page-media::-webkit-media-controls-panel video::-webkit-media-controls-timeline-container video::-webkit-media-controls-time-remaining-display video::-webkit-media-controls-seek-back-button video::-webkit-media-controls-seek-forward-button video::-webkit-media-controls-fullscreen-button video::-webkit-media-controls-rewind-button video::-webkit-media-controls-return-to-realtime-button video::-webkit-media-controls-toggle-closed-captions-button 为了屏蔽掉声音播放按钮，我们只需使用video::-webkit-media-controls-volume-slider和video::-webkit-media-controls-mute-button这两个属性即可，相应的css代码如下：\n1 2 3 4 5 6 7 8 9 /**隐藏视频音量大小调整控件**/ .no_sound_style\u0026gt;video::-webkit-media-controls-volume-slider{ display:none; } /**隐藏视频音量喇叭**/ .no_sound_style\u0026gt;video::-webkit-media-controls-mute-button{ display:none; } 对应的显示效果如下图所示，可以看到音量喇叭和音量调整空间都消失不见\n","permalink":"https://lucumt.info/post/web/show-video-in-html5-page/","tags":["html5"],"title":"在iframe嵌套的html5中播放视频时全屏显示和取消音量调整"},{"categories":["算法","Java编程","位运算"],"contents":"变量交换是编程中经常使用的功能，本文记录几种不通过不添加第三方变量来交换两个变量的实现方式。\n交换变量通常采用类似如下代码：\n1 2 3 4 5 6 int a = 3, b = 4, temp; temp = a; a = b; b = temp; System.out.println(a); System.out.println(b); 上述代码实现和理解起来都很容易，除此之外还有其它的实现方式，本文以非0的int变量为例，简单记录下自己了解的相关实现。\n加减法实现 1 2 3 4 5 6 int a = 3, b = 4; a = a + b; b = a - b; a = a - b; System.out.println(a); System.out.println(b); 上述代码可以进一步精简如下:\n1 2 3 4 int a = 3, b = 4; a = a + b - (b = a); System.out.println(a); System.out.println(b); 乘除法实现 1 2 3 4 5 6 int a = 3, b = 4; a = a * b; b = a / b; a = a / b; System.out.println(a); System.out.println(b); 位运算实现 1 2 3 4 5 6 int a = 3, b = 4; a = a ^ b; b = a ^ b; a = a ^ b; System.out.println(a); System.out.println(b); ","permalink":"https://lucumt.info/post/algorithm/swap-two-variables-without-temp-variable/","tags":["bit"],"title":"不通过第三方变量来交换两个变量的值"},{"categories":["Java编程","MyBatis系列"],"contents":"在利用 MyBatis进行多条数据插入时，为了提高性能我们可能会使用批量插入的功能来实现。示例代码如下:\nSQL配置文件:\n1 2 3 4 5 6 7 \u0026lt;insert id=\u0026#34;addAuthorityRoleBatch\u0026#34; parameterType=\u0026#34;List\u0026#34;\u0026gt; INSERT INTO system_authority_role(role_id,authority_id) VALUES \u0026lt;foreach collection=\u0026#34;list\u0026#34; item=\u0026#34;authRole\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; (#{authRole.roleId},#{authRole.authorityId}) \u0026lt;/foreach\u0026gt; \u0026lt;/insert\u0026gt; Java代码:\n1 2 3 4 5 6 7 8 9 public void adjustRoleAuth(String roleId, String authIdsStr) { authRoleDao.deleteAuthorityRoleByRole(roleId); String[] authIds=authIdsStr.split(\u0026#34;;\u0026#34;); List\u0026lt;AuthorityRoleModel\u0026gt; authRoleList=new ArrayList\u0026lt;AuthorityRoleModel\u0026gt;(); for(String authId:authIds){ authRoleList.add(new AuthorityRoleModel(roleId,authId)); } authRoleDao.addAuthorityRoleBatch(authRoleList); } 上面的代码大多数时候可以正常运行，但是偶尔会出现如下异常：\n1 2 3 4 ### SQL: INSERT INTO system_authority_role(role_id,authority_id) VALUES ### Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \u0026#39;\u0026#39; at line 2 ; bad SQL grammar []; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \u0026#39;\u0026#39; at line 2 at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:233 上面的异常堆栈信息显示现在执行的MySQL语句发生了语法错误，INSERT VALUE后面的值为空，由于该问题有时候发生，有时候不发生，给我们分析该问题造成了一定的困扰。该问题产生的根源为批量插入时的集合数据为空，使得SQL配置文件中的foreach循环没有执行，从而导致SQL语句不完整，进而产生该异常。 为了解决该问题我们可以批量插入之前先检查List数据集合是否为空，只有在不为空的情况下才进行插入，如下所示：\n1 2 3 4 5 6 7 8 9 10 11 public void adjustRoleAuth(String roleId, String authIdsStr) { authRoleDao.deleteAuthorityRoleByRole(roleId); String[] authIds=authIdsStr.split(\u0026#34;;\u0026#34;); List\u0026lt;AuthorityRoleModel\u0026gt; authRoleList=new ArrayList\u0026lt;AuthorityRoleModel\u0026gt;(); for(String authId:authIds){ authRoleList.add(new AuthorityRoleModel(roleId,authId)); } if(authRoleList.size()\u0026gt;0){//只有在List不为空时才进行插入 authRoleDao.addAuthorityRoleBatch(authRoleList);\t} } ","permalink":"https://lucumt.info/post/mybatis/mybatis-batch-insert-exception/","tags":["Java","MyBatis"],"title":"mybatis batch insert exception的解决方法"},{"categories":["Java编程","Spring系列"],"contents":"文件的上传和下载是Web系统中的一个很普通的功能，实现的方式也有很多种，如利用 java.io下面的各种IO类自己实现，或者利用 Commons IO包中的FileUtils、 IOUtils 类中封装好的方法直接调用。由于目前我所开发的系统采用了 SpringMVC来作为项目的MVC实现，所以很自然的采用 SpringMVC内置的API进行文件的下载，但在实际使用过程中发现其对大文件的下载支持不太好，现把解决方案记录如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 @RequestMapping(\u0026#34;downloadRequireDocument\u0026#34;) public ResponseEntity\u0026lt;byte[]\u0026gt; downloadRequireDocument(String fileId,String fileName,String fileType, HttpServletRequest request) throws IOException{ String filePath=fileName+fileId+\u0026#34;.\u0026#34;+fileType; HttpHeaders headers=new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_OCTET_STREAM); headers.setContentDispositionFormData(\u0026#34;attachment\u0026#34;,URLEncoder.encode(fileName,\u0026#34;UTF-8\u0026#34;)+\u0026#34;.\u0026#34;+fileType); File downloadFile=new File(request.getSession().getServletContext().getRealPath(File.separator)+filePath); return new ResponseEntity\u0026lt;byte[]\u0026gt;(FileUtils.readFileToByteArray(downloadFile),headers,HttpStatus.CREATED); } 该段代码在下载小文件时可以正常工作，但是当要下载的文件很大时（如几百M或上G），就会发生如下错误：\n1 2 3 4 java.lang.OutOfMemoryError: Java heap space at org.apache.commons.io.output.ByteArrayOutputStream.toByteArray(ByteArrayOutputStream.java:271) at org.apache.commons.io.IOUtils.toByteArray(IOUtils.java:219) at org.apache.commons.io.FileUtils.readFileToByteArray(FileUtils.java:1136) 去网上搜索java.lang.OutOfMemoryError: Java heap space 这个错误时，一般都建议我们在tomcat中添加如下类似设置来提高JVM的配置:\nset JAVA_OPTS=%JAVA_OPTS% -server -Xms800m -Xmx800m -XX:MaxNewSize=256m -XX:MaxPermSize=256m\n但即使按照把上面的参数配置都扩大一倍，在下载更大的文件时还是会遇到java.lang.OutOfMemoryError: Java heap space这个错误，上面的解决方法治标不治本。分析下异常堆栈可以发现问题产生的根源在于at org.apache.commons.io.FileUtils.readFileToByteArray(FileUtils.java:1136)这行代码，FileUtils.readFileToByteArray会把文件一次性读入内存中，要下载的文件越大，需要占用的内存也越大，当文件的大小超过JVM和Tomcat的内存配置时，OutOfMemoryError这个问题就会不可避免的发生。\n弄清产生该问题的原因之后，解决的方法也很简单：不利用Commons IO把文件一次性读入内存，而是利用普通的文件输出流按字节分段写入文件，把占用的内存固定在一个指定的范围内，从根本上避免内存占用过高的问题,替代的代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @RequestMapping(\u0026#34;downloadRequireDocument\u0026#34;) public void downloadRequireDocument(String fileId,String fileName,String fileType, HttpServletRequest request,HttpServletResponse response) throws IOException { String filePath = request.getSession().getServletContext().getRealPath(File.separator)+fileName+\u0026#34;.\u0026#34;+fileType; fileName = URLEncoder.encode(fileName.trim(),\u0026#34;UTF-8\u0026#34;)+\u0026#34;.\u0026#34;+fileType; response.setHeader(\u0026#34;Content-Disposition\u0026#34;,\u0026#34;attachment;filename=\u0026#34;+fileName); InputStream is = new FileInputStream(filePath); int read =0; byte[] bytes = new byte[2048]; OutputStream os = response.getOutputStream(); while((read = is.read(bytes))!=-1){//按字节逐个写入，避免内存占用过高 os.write(bytes, 0, read); } os.flush(); os.close(); is.close(); } ","permalink":"https://lucumt.info/post/spring/spring-mvc/download-big-file-using-springmvc/","tags":["Java","Spring","SpringMVC"],"title":"利用SpringMVC下载大文件时内存溢出的处理"},{"categories":["Java编程","Spring系列","单元测试"],"contents":"在进行Java程序开发时，我们偶尔会被要求使用JUnit进行单元测试来确保我们所写的程序逻辑是正确的。一个良好的单元测试应该具备 覆盖度高，可重复执行,单一性等特点。本文主要关注可重复执行，在Web开发中，大部分方法都会使数据库的记录发生变化，为了能够重复执行，必须利用数据库事务来进行回滚从而达到重复执行的目的。最原始的方法是利用 java.sql.Connection类的 commit() 或 rollback() 方法来在每个单元测试方法中手动的进行提交或回滚，此种方式使得单元测试代码嵌入了与实际业务逻辑无关的数据库操作事务控制代码。利用Spring和JUnit通过注解的方式我们可以很容易的对单元测试中的数据库操作进行事务控制。\n所有方法都回滚 在该单元测试类的开头加上 @TransactionConfiguration(defaultRollback=true) 可以确保该类中的所有方法在执行完毕之后默认都进行回滚。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 package com.hirain.testmanagement.service.test; import static org.junit.Assert.assertEquals; import java.util.Date; import javax.inject.Inject; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.test.context.ContextConfiguration; import org.springframework.test.context.junit4.SpringJUnit4ClassRunner; import org.springframework.test.context.transaction.TransactionConfiguration; import org.springframework.transaction.annotation.Transactional; import com.hirain.testmanagement.common.util.StringUtil; import com.hirain.testmanagement.model.ProjectModel; import com.hirain.testmanagement.service.IProjectService; @RunWith(SpringJUnit4ClassRunner.class) @Transactional @TransactionConfiguration(defaultRollback=true) @ContextConfiguration(\u0026#34;classpath:spring/spring-context-*.xml\u0026#34;) public class ProjectServiceTest{ @Inject private IProjectService projectService; @Test @Transactional public void testAddProject(){ ProjectModel pModel=new ProjectModel(); String projectId=StringUtil.getUUID(); pModel.setId(projectId); pModel.setName(\u0026#34;汽车电子测试管理系统\u0026#34;); pModel.setAlias(\u0026#34;INTA\u0026#34;); pModel.setLastModifyTime(new Date()); pModel.setLastModifyUser(\u0026#34;6e518d0819d14148ae489f76dad80967\u0026#34;); pModel.setCreateTime(new Date()); pModel.setCreateUser(\u0026#34;cface18d5fac11e28c68c89cdca4c015\u0026#34;); projectService.addProject(pModel); assertEquals(\u0026#34;Add project failed!\u0026#34;,projectService.getProject(projectId).getName(),pModel.getName()); } } 指定方法回滚 若想只对某个特定的方法进行回滚，需要在该单元测试类的开头去掉 @TransactionConfiguration(defaultRollback=true) ，同时在对应的方法上加上注解声明 @Rollback(true) 即可达到目的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 package com.hirain.testmanagement.service.test; import static org.junit.Assert.assertEquals; import java.util.Date; import javax.inject.Inject; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.test.annotation.Rollback; import org.springframework.test.context.ContextConfiguration; import org.springframework.test.context.junit4.SpringJUnit4ClassRunner; import org.springframework.transaction.annotation.Transactional; import com.hirain.testmanagement.common.util.StringUtil; import com.hirain.testmanagement.model.ProjectModel; import com.hirain.testmanagement.service.IProjectService; @RunWith(SpringJUnit4ClassRunner.class) @Transactional @ContextConfiguration(\u0026#34;classpath:spring/spring-context-*.xml\u0026#34;) public class ProjectServiceTest{ @Inject private IProjectService projectService; @Test @Rollback(true) public void testAddProject(){ ProjectModel pModel=new ProjectModel(); String projectId=StringUtil.getUUID(); pModel.setId(projectId); pModel.setName(\u0026#34;汽车电子测试管理系统\u0026#34;); pModel.setAlias(\u0026#34;INTA\u0026#34;); pModel.setLastModifyTime(new Date()); pModel.setLastModifyUser(\u0026#34;6e518d0819d14148ae489f76dad80967\u0026#34;); pModel.setCreateTime(new Date()); pModel.setCreateUser(\u0026#34;cface18d5fac11e28c68c89cdca4c015\u0026#34;); projectService.addProject(pModel); assertEquals(\u0026#34;Add project failed!\u0026#34;,projectService.getProject(projectId).getName(),pModel.getName()); } } ","permalink":"https://lucumt.info/post/spring/spring-core/using-junit-in-spring/","tags":["Java","JUnit"],"title":"利用Spring和JUnit对数据库操作进行单元测试"},{"categories":["Java编程","Spring系列"],"contents":"利用Spring Security来管理我们的web程序时，通常需要在UserDetailsService接口中的loadUserByUsername方法中来初始化权限信息,但UserDetailsService一般用于登录验证，这也意味着用户的权限在登录过程中就会被计算出来。通常情况下由于用户的权限很少发生变化，在登录过程中计算出用户权限是合理的，但有些情况下，我们需要在中途来动态的改变用户的权限，此时我们可以利用Spring Security提供的API来实现。\n以我自己的项目为例，UserDetailsService接口中的loadUserByUsername具体实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { UserModel userModel=userDao.getUserByUsername(username); if(userModel==null){ throw new UsernameNotFoundException(username+\u0026#34; not exist!\u0026#34;); } List\u0026lt;GrantedAuthority\u0026gt; userAuthList=new ArrayList\u0026lt;GrantedAuthority\u0026gt;(); //查询出用户相关的所有权限并放入List中 List\u0026lt;AuthorityVO\u0026gt; authList=authorityDao.queryAuthorityByUserId(userModel.getId()); for(AuthorityVO authVO:authList){ userAuthList.add(new SimpleGrantedAuthority(authVO.getAuthName())); } //将查询出来的权限赋予用户 UserDetails userDetails=new User(userModel.getUsername(),userModel.getPassword(),true,true,true,true,userAuthList); return userDetails; } 上述代码会一次性的把用户权限查询出来然后放入特定的session中，但是UserDetailService方法一般只在用户登录web系统成功时才会被调用一次，使用范围较为局限，有时候我们需要在用户使用的过程中动态的改变用户的权限（譬如在我自己的项目中，当用户选中不同的项目之后，不同的项目对应不同的权限）。利用 Spring Security来管理权限信息时，用户的权限本质上是存储在一个 session中，只不过被Spring Security进行了进一步的封装而已。所以若想动态的改变用户的权限，我们只需要将用户的信息重新存储到 session中即可，具体代码如下所示：\n1 2 3 4 5 6 7 8 9 10 List\u0026lt;GrantedAuthority\u0026gt; authList=new ArrayList\u0026lt;GrantedAuthority\u0026gt;();//用于存储修改之后的权限列表 authList.add(new SimpleGrantedAuthority(\u0026#34;addUser\u0026#34;)); authList.add(new SimpleGrantedAuthority(\u0026#34;editUser\u0026#34;)); SecurityContext context=SecurityContextHolder.getContext(); UserDetails userDetails=(UserDetails) context.getAuthentication().getPrincipal(); Authentication auth=new UsernamePasswordAuthenticationToken(userDetails,userDetails.getPassword(),authList); context.setAuthentication(auth); //重新设置上下文中存储的用户权限 ","permalink":"https://lucumt.info/post/spring/update-authority-dynamic-using-spring-security/","tags":["Java","Spring","Spring Security"],"title":"利用Spring Security动态改变登录用户的权限"},{"categories":["Java编程","Spring系列","单元测试"],"contents":"编写单元测试时的注意事项 根据软件开发过程中的TDD理论，在我们编写自己的代码时，要尽量使得该代码能够进行单元测试。为了能够使得代码可以进行单元测试，我们在给接口或方法传入参数时要尽量传入简单参数，避免传入HttpServletRequest , ServletContext等和web上下文相关的复杂对象。但仍有部分情况下基于代码简洁性和可维护性的考虑，我们需要传入HttpServletRequest对象，此时对此类方法进行JUnit单元测试时会较为困难，本文介绍一种在Spring中通过Mock来模拟HttpServletRequest对象进行JUnit单元测试的方法。\n假设在HttpServletRequest中有一个userId字符串对象，我们想在queryUserById方法中调用该参数来获取用户信息，则正确的做法应如下所示:\n1 2 3 4 5 6 7 String userId = request.getAttribute(\u0026#34;userId\u0026#34;).toString();//先获取userId对象 queryUserById(userId);//然后将获取的userId传入对应方法 public User queryUserById(String userId){//相关该方法 User userModel = userDao.findById(userId); return userModel; } 请尽量避免使用第二种方式\n1 2 3 4 5 6 7 8 queryUserById(request);//直接传入request对象 public User queryUserById(HttpServletRequest request){//相关方法 String userId = request.getAttribute(\u0026#34;userId\u0026#34;).toString();//在该方法内部获取userId User userModel = userDao.findById(userId); return userModel; } 若采用第一种方法，我们在进行单元测试时，可以很容易的自己制造一个String字符串来代表userId进行测试，但当采用第二种方法后，在进行单元测试时我们是比较难以模拟一个HttpServletRequest对象，从而影响我们的测试。\nSpring和Mock在单元测试中的使用 在某些方法中，为了减少代码量和提高程序的可读性，我们有时候需要直接传入HttpServletRequest或ServletContext对象，如果我们想对这种方法进行测试，可以利用Mock来模拟相关的对象。\n由于Spring自身已经整合了Mock相关的类，故在此处展示一个示例代码，以供参考:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import java.io.File; import org.junit.Test; import org.springframework.mock.web.MockHttpServletRequest; import org.springframework.mock.web.MockServletContext; public class SpringMockTest { @Test public void testHttpServletRequest(){ String realPath =\u0026#34;file:D:\\\\Java\\\\apache-tomcat-7.0.23\\\\webapps\\\\tmn\u0026#34;; //模拟ServletContext,同时初始化realPath，注意要有file:前缀否则会报错 MockServletContext context = new MockServletContext(realPath); //获取realPath System.out.println(context.getRealPath(File.separator)); //模拟HttpServletRequest MockHttpServletRequest request = new MockHttpServletRequest(context); //通过HttpServletRequest来获取realPath System.out.println(request.getSession().getServletContext().getRealPath(File.separator)); } } 注意:请在上下文路径的字符串前面加上file:前缀，否则程序会报错。如上面的程序，realPath的值应为 file:D:\\Java\\apache-tomcat-7.0.23\\webapps\\tmn ，若去掉file:前缀，改为 D:\\Java\\apache-tomcat-7.0.23\\webapps\\tmn ，则程序会报错。\n","permalink":"https://lucumt.info/post/spring/spring-mvc/using-mock-test-http-servlet-request/","tags":["Java","Spring","SpringMVC","JUnit"],"title":"在Spring中利用Mock对HttpServletRequest进行单元测试"},{"categories":["其它"],"contents":"Mediawiki是维基百科系统所采用的框架，适合于需要快速搭建知识分享的场合。采用Mediawiki生成的知识共享平台和维基百科的操作与使用类似，都支持采用Markdown语法来编辑。在有些时候，某些词条的内容很长，使得浏览器出现了滚动条，如果能仿照微博等网站添加一个回到顶部的功能，将会给我们的使用带来很大的便利，本文介绍一种实现方法：\n以 Mediawiki 管理员身份登录mediawiki,在搜索栏输入MediaWiki:Common.js,然后输入如下代码并保存：\n1 2 3 4 5 6 7 8 /* 此处的JavaScript将加载于所有用户每一个页面。 */ $(window).scroll(function(){ if($(window).scrollTop()\u0026gt;100){ $(\u0026#34;.back-to-top\u0026#34;).fadeIn(1000); }else{ $(\u0026#34;.back-to-top\u0026#34;).fadeOut(1000); } }); 在mediawiki\\skins\\Vector.php中的第252行添加如下代码：\n1 2 3 \u0026lt;div class=\u0026#34;back-to-top\u0026#34; onClick=\u0026#34;$(\u0026#39;html,body\u0026#39;).animate({scrollTop:0},500);\u0026#34;\u0026gt; \u0026lt;span\u0026gt;返回顶部\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; 在mediawiki\\skins\\vector\\screen.css的最后添加如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 .back-to-top { position: fixed; bottom: 6em; right: 3em; background-color: rgba(46, 46, 46, 0.8); text-align: center; padding: 5px 6px; color: #eee; -webkit-border-radius: 3px; -moz-border-radius: 3px; border-radius: 3px; cursor: pointer; display: none; } .back-to-top:hover { background: rgba(0, 221, 255, 0.8); } 当页面的高度超出限制时，就会出现“返回顶部”的悬浮框，效果图如下：\n","permalink":"https://lucumt.info/post/web/mediawiki-back-to-top/","tags":["Mediawiki"],"title":"Mediawiki添加回到顶部的方法"},{"categories":["Java编程","翻译"],"contents":"本文翻译自 Java Volatile Keyword\nJava关键字volatile用于将一个Java变量标记为在主内中存储，更准确的解释为：每次读取一个volatile变量时将从电脑的主内存中读取而不是从CPU缓存中读取，每次对一个volatile变量进行写操作时，将会写入到主内存中而不是写入到CPU缓存中。\n事实上，从Java5之后，volatile关键字不仅仅可以用来确保volatile变量是写入到主内存和从主内存读取数据，我会在下面的章节进行详细的介绍：\nVolatile变量可见性保证 Java中的volatile关键字确保了 volatile变量的修改在多线程中是可见的。这听起来有些抽象，接下来我将详细说明。\n在一个对非volatile变量进行操作的多线程应用，由于性能的关系，当对这些变量进行读写时，每个线程都可能从主线程中拷贝变量到CPU缓存中。如果你的电脑不止一个CPU，每个线程可能会在不同的CPU上运行。这意味着，每个线程都可能将变量拷贝到不同的CPU的CPU缓存中，如下图所示：\n对于非volatile变量而言，Java虚拟机(JVM)不能确保什么时候将数据从主内存读取到CPU缓存以及什么时候将CPU缓存的数据写入到主内存中。而这可能会引起一些问题，我将稍后解释。\n假设两个或更多的线程对下面这个包含一个计数器的共享变量拥有访问权限：\n1 2 3 public class SharedObject { public int counter = 0; } 再次假设，只有Thread1会增加counter变量的值，但是Thread1和Thread2都能在任意时刻读取counter变量的值。\n如果couner变量没有声明为volatile将无法保证在何时把CPU缓存中的值写入主内存中。这意味着counter变量在CPU缓存中的值可能会与主内存中的值不一样，如下所示：\n造成线程不能获取变量最新值得原因为变量值没有被其它线程及时写回主内存中，这就是所谓的可见性问题。某个线程的更新对其它线程不可见。\n将counter变量声明为volatile之后，所有对counter变量的写操作会立即写入主内存中，同样，所有对counter变量的读操作都会从主内存中读取数据。下面的代码块展示了如何将counter变量声明为volatile ：\n1 2 3 public class SharedObject { public volatile int counter = 0; } 因此定义一个volatile变量可以保证写变量的操作对于其它线程可见。\nVolatile先行发生原则 从Java5之后volatile关键字不仅能用于确保变量从主内存中读取和写入，事实上volatile关键字还有如下作用：\n如果线程A写入了一个volatile变量然后线程B读取了这个相同的volatile变量，那么所有在线程A写之前对其可见的变量，在线程B读取这个 volatile之后也会对其可见。 volatile变量的读写指令不能被JVM重排序（出于性能的考虑，JVM可能会对指令重排序如果JVM检测到指令排序不会对程序运行产生变化）。前后的指令可以重排序，但是volatile变量的读和写不能与这些重排序指令混在一起。任何跟随在volatile变量读写之后的指令都会确保只有在变量的读写操作之后才能执行。 上述说明需要更进一步的解释。\n当一个线程向一个volatile变量写操作，此时不仅这个volatile变量自身会写入主内存，所有这个volatile变量写入之前受影响发生改变的变量也会刷写入主内存。当一个线程向一个volatile变量读操作时它同样也会从主内存中读取所有和这个volatile变量一起刷写入主内存的变量。\n看看下面这个示例：\n1 2 3 4 5 6 7 Thread A: sharedObject.nonVolatile = 123; sharedObject.counter = sharedObject.counter + 1; Thread B: int counter = sharedObject.counter; int nonVolatile = sharedObject.nonVolatile; 由于线程A在写操作volatile变量sharedObject.counter之前写操作非volatile变量sharedObject.nonVolatile，因而当线程A写操作变量sharedObject.counter后,变量sharedObject.nonVolatile和sharedObject.counter都被写入主内存。\n由于线程B以读取volatile变量sharedObject.counter开始，因而变量sharedObject.counter和变量sharedObject.nonVolatile都会被写入线程B所使用的CPU缓存中。当线程B读取sharedObject.nonVolatile变量时，它将能看见被线程A写入的变量。\n开发人员可以利用这个扩展的可见性来优化线程之间变量的可见性。不同于把每个变量都设置为volatile ，此时只有少部分变量需要声明为volatile 。下面是一个利用此规则编写的简单示例程序Exchanger ：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class Exchanger { private Object object = null; private volatile hasNewObject = false; public void put(Object newObject) { while(hasNewObject) { //等待，不覆盖已经存在的新对象 } object = newObject; hasNewObject = true; //volatile写入 } public Object take(){ while(!hasNewObject){ //volatile读取 //等待，不获取旧的对象（或null对象） } Object obj = object; hasNewObject = false; //volatile写入 return obj; } } 线程A随时可能会通过调用put()方法增加对象，线程B随时可能会通过调用 take()方法获取对象。只要线程A只调用 put() ，线程B只调用take() ,这个Exchanger就可以通过一个volatile变量正常工作（排除 synchronized代码块的使用）。\n然而，JVM可能会重排序Java指令来优化性能，如果JVM可以通过不改变这些重排序指令的语义来实现此功能。如果JVM调换了put()和 take()中的读和写的指令，会发生什么呢？如果put()真的像下面这样执行会出现什么情况呢？\n1 2 3 4 5 while(hasNewObject) { //等待，不覆盖已经存在的新对象 } hasNewObject = true; //volatile写入 object = newObject; 请注意此时对于volatile变量hasNewObject的写操作会在新变量的实际设置前先执行，而这在JVM看来可能会完全合法。两个写操作指令的值不再依赖于对方。\n但是，对于执行指令重排序可能会损害object变量的可见性。首先，线程B可能会在线程A对object真实的写入一个值到object之前读取到hasNewObject的值为true。其次,现在甚至不能保证什么时候写入object的新值会刷写入主内存（好吧，下次线程A在其它地方写入 volatile变量。。。）\n为了阻止上面所述的这种情况发生，volatile关键字提供了一个 先行发生原则。先行发生保证确保对于volatile变量的读写指令不会被重排序。程序运行中前后的指令可能会被重排序，但是volatile读写指令不能和它前后的任何指令重新排序。\n看看下面这个例子：\n1 2 3 4 5 6 7 8 9 sharedObject.nonVolatile1 = 123; sharedObject.nonVolatile2 = 456; sharedObject.nonVolatile3 = 789; sharedObject.volatile = true; //a volatile variable int someValue1 = sharedObject.nonVolatile4; int someValue2 = sharedObject.nonVolatile5; int someValue3 = sharedObject.nonVolatile6; JVM可能会重新排序前3条指令，只要它们都先发生于volatile写指令（它们都必须在volatile写指令之前执行）。\n同样的，JVM可能会重新排序最后3条指令，只要volatile写指令先行发生于它们，这3条指令都不能被重新排序到volatile指令的前面。\n这就是volatile先行发生原则的基本含义。\nVolatile并不是万能的 尽管volatile关键字确保了所有对于volatile变量的读操作都是直接从主内存中读取的，所有对于volatile变量的写操作都是直接写入主内存的，但仍有一些情况只定义一个volatile变量是不够的。\n在前面的场景中，线程1对共享变量counter写入操作，声明counter变量为volatile之后就能够确保线程2总是可以看见最新的写入值。\n事实上，如果写入该变量的值不依赖于它前面的值，多个线程甚至可以在写入一个共享的volatile变量时仍然能够持有在主内存中存储的正确值。换句话解释为，如果一个线程在写入volatile共享变量时，不需要先读取该变量的值以计算下一个值。\n一旦一个线程需要首先读取一个volatile变量的值，然后基于该值产生volatile共享变量的下一个值，那么该 volatile 变量将不再能够完全确保正确的可见性。在读取volatile变量和写入它的新值这个很短的时间间隔内，产生了一个 竞争条件 :多个线程可能会读取 volatile变量的相同值，然后产生新值并写入主内存，这样将会覆盖互相的值。\n这种多个线程同时增加相同计数器的场景正是volatile变量不适用的地方，接下来的部分进行了更详细的解释。\n假设线程1读取一个值为0的共享变量counter到它的CPU缓存中，将它加1但是并没有将增加后的值写入主内存中。线程2可能会从主内存中读取同一个counter变量，其值仍然为0，同样不将其写入主内存中，就如下面的图片所展示的那样：\n线程1和线程2现在都没有同步，共享变量counter的真实值应该是2，但是在每个线程的CPU缓存中，其值都为1，并且主内存中的值仍然是0。它成了一个烂摊子，即使这些线程终于它们对共享变量counter的计算值写入到主内存中，counter的值仍然是错的。\nVolatile的适用场景 就如在前面提到的那样，如果两个线程同时对一个共享变量进行读和写，那么仅用volatile变量是不够的。在这种情况下，你需要使用 synchronized来确保关于该变量的读和写都是原子操作。读或写一个volatile变量时并不会阻塞其它线程对该变量的读和写。在这种情况下必须用synchronzied关键字来修饰你的关键代码。\n除了使用synchronzied之外，你也可以使用 java.util.concurrent包中的一些原子数据类型，如 AtomicLong ， AtomicReference等。\n当只有一个线程对一个volatile变量进行读写而其它线程只读取该变量时， volatile可以确保这些读线程读取到的是该变量的最新写入值。如果不声明该变量为volatile ，则不能这些读线程保证读取的是最新写入值。\nvolatile关键字适用于32位变量和64位变量。\nVolatile性能思考 由于volatile变量的读和写都是直接从主内存中进行的，相对于CPU缓存，直接对主内存进行读写代价更高， 访问一个volatile变量也会阻止指令重新排序，而指令排序也是一个常用的性能增强技术。因此，你应该在只有当你确实需要确保变量可见性的时候才使用volatile变量。\n\u0026lt;\u0026ndash;终于翻译完了!\u0026ndash;\u0026gt;\n","permalink":"https://lucumt.info/post/java-concurrency/java-volatile-keyword/","tags":["Java","Java Concurrency"],"title":"[译] Java Volatile 关键字详解"},{"categories":["Java编程","数据库"],"contents":"项目中用到了MySQL数据库的备份功能，通过调用Java程序中的Runtime来执行mysqldump命令自动的生成相关的MySQL数据库文件以供恢复之用。相关的代码如下:\n1 2 3 4 Runtime runtime = Runtime.getRuntime(); String mysqlCmd = \u0026#34;mysqldump\u0026#34; + \u0026#34; -u\u0026#34; + username + \u0026#34; -p\u0026#34; + password + \u0026#34; -h \u0026#34; + databaseAddress + \u0026#34; \u0026#34; +databaseName; Process process = runtime.exec(mysqlCmd); 但是在客户那里实际使用时，有时候会出现在cmd中MySQL命令可以正常识别但是程序不能正常执行的情况，报错信息如下:\n1 2 3 4 5 java.io.IOException: Cannot run program \u0026#34;mysqldump\u0026#34;: CreateProcess error=2, The system cannot find the file specified at java.lang.ProcessBuilder.start(ProcessBuilder.java:460) at java.lang.Runtime.exec(Runtime.java:593) at java.lang.Runtime.exec(Runtime.java:431) at java.lang.Runtime.exec(Runtime.java:328) Google之后，在Stackoverflow发现两个相关的问题：\nError when backing up MYSQL database backup mysql database java code 阅读之后，发现上面说问题产生的原因是mysqldump命令无法识别，把mysqldump可执行文件的路径加入PATH环境变量中即可解决问题。但当我在cmd中无论执行mysql或mysqldump命令时，都显示这两个命令可以正常执行：\n在cmd中输出PATH环境变量时，也显示MySQL的bin目录已经添加:\n即使重启电脑，上述通过Java备份MySQL的代码还是不能正常执行，但当在cmd中执行mysql、mysqldump命令或输出PATH环境变量时，结果任何上面图片中显示的一致。\n这下让我感到很困惑:\n通过Java代码来执行mysqldump导出操作时去不能正常执行原因是MySQL的执行路径没有加到PATH环境变量中,但实际检查发现MySQL的环境变量设置正常，在命令行通过mysqldump导出sql文件可以成功操作!\n继续在网上搜索该问题的解决方案，得到的答案也都是MySQL的执行路径没有加到PATH环境变量中去，问题依旧。。。\n正当我在为这个问题发愁时，测试部门有个同事的新Win7电脑上利用我们的软件执行MySQL备份时也出现了类似的问题，之前我还猜有可能是由于客户服务器的操作系统版本太低或某些DLL文件不存在导致的。但现在居然在刚装好的Win7电脑上也出现此问题，基本可以排除操作系统的问题。由于在我自己的笔记本和台式研发机上都没出现这个问题，无奈之下我只好把同事的电脑拿过来和我自己的电脑进行对比，看看哪里设置不一样。通过Win7中高级系统设置查看PATH环境变量，很快就发现了问题的根源：\nMySQL的执行路径被设置到了用户变量中的PATH变量里，系统变量中的PATH变量里却没有MySQL的执行路径，而Java代码是匿名执行的，无法获取到用户变量，只能去系统变量中寻找相关的可执行命令,因而程序会出错！\n这下问题原因变得很清楚了，我们在cmd中执行mysql和mysqldump命令以及输出PATH环境变量时，系统会把当前用户的用户变量中的PATH和操作系统的系统变量中的PATH变量整合到一块，所以我们在cmd中操作时一切正常。但是当我们在Java程序中执行mysqldump命令时，由于Java程序的运行和用户无关，无法获取到用户变量中的PATH值，所以当我们在Java程序中执行mysqldump命令时会出错。这也正好和Stackoverflow中说明的原因一致。\n由于有的电脑上会出现此问题，有的电脑上没有此问题，进一步的深究问题的根源，发现发生问题的电脑和服务器在安装MySQL数据库时都是通过我们自己写的bat脚本来安装的。而bat脚本中设置环境变量的代码如下:\n1 2 3 @echo %Path% setx PATH \u0026#34;%Path%;C:\\INTA\\Database\\bin;\u0026#34; @echo %Path% 问题的关键就在于setx PATH \u0026quot;%Path%;C:\\INTA\\Database\\bin;\u0026quot;这行代码，这样写的话只会把MySQL的执行路径加入到当前执行该脚本的用户变量中，不会加入到环境变量中。而那些没有出问题的电脑都是我自己手动在系统变量中设置MySQL执行路径的！该问题的解决方法也很简单，在setx后面加上-m即可，这样bat脚本执行时会把MySQL的执行路径写入系统变量的PATH变量中，不会写入用户变量的PATH变量中：\n1 2 3 @echo %Path% setx -m PATH \u0026#34;%Path%;C:\\INTA\\Database\\bin;\u0026#34; @echo %Path% Orz~\n想不到由于一个-m而让自己郁闷了这么久!\n","permalink":"https://lucumt.info/post/mysql/can-not-run-program-mysqldump/","tags":["MySQL","Java"],"title":"Cannot run program \"mysqldump\": CreateProcess error=2, The system cannot find the file specified"},{"categories":["Go编程","个人博客"],"contents":"一直以来都想拥有一个属于自己的博客，前段时间在学习Go ，于是利用Hugo 和Github Pages 搭建了一个简易的个人博客，先简单记录下。\n环境准备 Go1.18.3+ Hugov0.100+ Github账号 GoDaddy域名 过程概要 在Github上创建一个自己的项目 在Github上创建一个项目，本文中该项目名为blog\n由于Github Pages强制要求在托管博客时该项目必须有一个名为gh-pages的分支，所以要预先给该项目创建一个名为gh-pages的分支 在Github中打开blog项目主页面，点击 Settings按钮\n在 Github Pages这个区域可以看见本项目的发布链接为https://fox321.github.io/blog/ ，点击该链接可以访问该项目对应的静态页面\n利用Hugo作为博客生成器 由于Github Pages只支持静态的HTML页面托管，所以需要采用Jekyll 、Logdown 等静态博客生成器来快速生成HTML页面，避免纯手动编写时的费时费力。由于自己近期一直在学习Go，为了加深自己对于Go的运用，于是便选择 Hugo作为自己的博客生成器。 Hugo是一个基于Go开发的静态生成器，它采用Markdown语法来编写博客生成，然后生成相应的HTML页面。\n安装Go 访问Golang下载页根据自己电脑的操作系统选择是Linux版本或Windows版本，同时注意是选择32位还是64位，一定要与自己的操作系统相匹配。以我自己的64位win7系统为例，安装过程如下：\n下载Go安装文件\n双击安装，默认是安装在C盘下，由于windows操作系统的特性，我通常不倾向于安装在C盘，故需要设置PATH、GOPATH和GOROOT这三个环境变量，我自己把Go安装在D:\\code\\go下，这三个变量相应的设置为:\n1 2 3 PATH=\u0026#39;D:\\code\\go\\bin\u0026#39;;%PATH% GOPATH=\u0026#39;D:\\code\\gopath\u0026#39; GOROOT=\u0026#39;D:\\code\\go\u0026#39;、 安装完成之后，重新打开cmd窗口，输入go version之后按Enter键，若出现如下信息，则表示Go安装成功\n1 2 C:\\Users\\Administrator\u0026gt;go version go version go1.18.3 windows/amd64 安装Hugo Hugo的安装过程与Go的类似.\n首先在Hugo下载页根据自己操作系统的类型和位数下载相应的安装包，然后设置对应的PATH环境变量即可。我的安装在 D:\\program\\hugo所以相应的环境变量设置为\n1 PATH=\u0026#39;D:\\program\\hugo\u0026#39;;%PATH% 重新打开cmd窗口，输入hugo version，若出现如下信息，则表示 Hugo安装成功\n1 2 C:\\Users\\Administrator\u0026gt;hugo version hugo v0.100.2-d25cb2943fd94ecf781412aeff9682d5dc62e284+extended windows/amd64 BuildDate=2022-06-08T10:25:57Z VendorInfo=gohugoio 关于Hugo的基本操作命令，可以参见Hugo快速入门，此处不再详述。\n在Github Pages上托管Hugo 安装命令 虽然官方文档在Github Pages上托管Hugo上有相应的说明,个人总感觉其说明信息不够详细，故将自己的实现过程记录如下：\n将之前在Github上创建的blog项目clone到本地目录\n切换到blog目录并利用hugo new site命令创建一个名为person_blog的Hugo站点，然后将其内容移入到blog目录下并删除 person_blog目录\n利用hugo new命令创建一个md文件用于存储我们的第一篇博客\n在 blog 目录下创建一个名为themes的文件夹用于存储Hugo样式，并将自己选中的样式下载到本地\n输入hugo server --theme=hugo-redlounge --buildDrafts在本地启动Hugo，启动正常后命令行输出如下\n此时在浏览器中输入http://127.0.0.1:1313会看到如下输出，该页面意味着本地博客创建成功，接下来要将其上传到Github Pages中托管 我们需要将相关的链接地址修改为https://fox321.github.io/blog，同时将端口号去掉，相关的命令为 hugo server -D --theme=hugo-redlounge --baseUrl=\u0026quot;https://fox321.github.io/blog\u0026quot; --appendPort=false，运行截图如下 修改完链接地址之后，需要将生成的页面提交到Github中才能被访问，首先需要将页面提交到master，由于我是在Windows操作系统上进行的，而CMD对Git的支持不是很好，故从此步开始切换为在Git Bash进行相关操作 利用subtree命令将master中public目录下的内容同步到gh-pages目录下\n此时访问该项目的设置页面，在Github Pages部分会看见如下信息\n访问 https://fox321.github.io/blog ，出现如下页面，至此Hugo博客托管到Github Pages成功！\n相关命令 生成绑定到指定域名的页面 hugo server -D --baseUrl=\u0026quot;http://lucumt.info\u0026quot; --appendPort=false 新版本的命令为hugo server --baseUrl=\u0026quot;https://lucumt.info/\u0026quot; --watch=false --appendPort=false --renderToDisk --environment production 将 master的public目录同步到分支 git subtree push --prefix=public git@github.com:fox321/blog.git gh-pages 利用GoDaddy配置自定义域名 在Using a custom domain with GitHub Pages中有详细的说明，我自己配置的时候主要是按照Setting up an apex domain中的说明在GoDaddy上的说明来设置的。\n在public目录下创建一个名为 CNAME的文件，并在该文件中写入我们要自定义的域名，我自己的域名为 http://lucumt.info ，故填入lucumt.info\n登陆Godaddy，然后在页面右上角点击自己的用户名，出现如下图所示的页面，选择Manage My Domains\n选择完Manage My Domains之后会出现如下图所示的界面，选择Manage DNS\n选择完Manage DNS之后会出现如下图所示的界面，点击Add按钮会出现下拉框让我们增加A记录\n在Type部分选择 A ，Host部分选择 @， Poinst to根据Setting up an apex domain中的说明在GoDaddy中Configuring A records with your DNS provider部分的说明添加 192.30.252.153 ,点击Save即完成一条A记录的添加\n再次点击Add添加，按照步骤5添加第二条A记录，除了Points to设置为 192.30.252.154 之外，其它的配置都相同 在Github项目中点击Settings按钮查看Github Pages区域的设置信息，若出现类似如下图所示的设置信息，则表示我们自定义域名添加成功\n至此利用GoDaddy来配置自自定义域名的过程完成，输入 http://lucumt.info 即可访问自己的博客！\nPS:吐槽下让人觉得不爽的几个地方：\n域名续费几乎没有折扣，所以建议第一次买的时间长一点。 取消订单功能消失了，现在只能打人工客服电话取消。 如果大家有GoDaddy之外更好的域名服务网站，欢迎给我留言，当然国内的域名服务商除外！\n开启自定义域名的HTTPS访问 请参见本人写的另外一篇文章 将基于Github Pages的自定义域名博客迁移到Https ，此处不再详述。\n\u0026lt;\u0026ndash;待续\u0026ndash;\u0026gt;\n","permalink":"https://lucumt.info/post/hugo/create-website-with-hugo/","tags":["Go","Hugo","Github Pages"],"title":"利用Github Pages和基于Go的Hugo搭建个人博客"}]