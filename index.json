[{"categories":["翻译"],"contents":"本文翻译自Git Worktree\n我们或许会面临这样的情形：正在开发某个功能时一个bug出现并且需要及时修复、处于一个耗时的构建过程中突然需要在另外一个分支做快速修复、发现了一个不相关的bug想在不污染当前分支的前提下修复。不论哪种情况，通常我们都想再次clone一个仓库到本地，然而Git已经提供了对应的工具。\n这就是worktree，通过它我们可在不必多次clone的前提下通过不同的分支创建不同的工作空间。\n可通过git worktree add ../my_second_worktree the_other_branch来创建一个新的worktree，该指令会生成一个名为my_second_worktree的新文件夹并使用``the_other_branch分支中的代码，之后可在里面独立运行并使用各种常规的git`指令。\n可通过下述指令来快速查看创建的所有worktree\n$ git worktree list /Users/charlesfeval/git/my_repo bd502b1 [user/chfeval/240614_that_feature] /Users/charlesfeval/git/my_repo--other_worktree 15d0988 [user/chfeval/240616_fix_versionin] /Users/charlesfeval/git/my_repo--bugfix_2 9c26708 [user/chfeval/240617_fix_rockin] 如果已经用worktree完成了相关操作，可使用类似 git worktree remove ../my_second_worktree来删除。\n下面是官方文档上关于该指令的说明\nusage: git worktree add [-f] [--detach] [--checkout] [--lock [--reason \u0026lt;string\u0026gt;]] [-b \u0026lt;new-branch\u0026gt;] \u0026lt;path\u0026gt; [\u0026lt;commit-ish\u0026gt;] or: git worktree list [-v | --porcelain [-z]] or: git worktree lock [--reason \u0026lt;string\u0026gt;] \u0026lt;worktree\u0026gt; or: git worktree move \u0026lt;worktree\u0026gt; \u0026lt;new-path\u0026gt; or: git worktree prune [-n] [-v] [--expire \u0026lt;expire\u0026gt;] or: git worktree remove [-f] \u0026lt;worktree\u0026gt; or: git worktree repair [\u0026lt;path\u0026gt;...] or: git worktree unlock \u0026lt;worktree\u0026gt; ","date":"2024-08-23T13:17:18+08:00","permalink":"https://lucumt.info/post/translate/git/git-worktree/","tags":["Git"],"title":"[译]Git Worktree使用说明"},{"categories":["工具使用","持续集成"],"contents":"在给公司内部搭建的KubeSphere整合LDAP时，发现一开始整合后并不能立即使用LDAP登录，一直提示无效的用户名或密码，经过多次折腾后找到一些规律，简单记录下。\n仿照Kubesphere集成LDAP踩坑记录一文配置好LDAP后，使用对应的账号去登录时，发现类似如下的报错\n可能的问题原因：\na) 确保yaml文件格式正常，可采用YAML Formatter将ks-install配置文件格式化后与官网的进行对比\nb) 配置完毕后需要重启相关pod，个人经常忘记这个步骤导致出错，来源参见kubesphere 3.3.0配置LDAP之后不生效\n# 按顺序依次执行下述指令 kubectl -n kubesphere-system rollout restart deploy/ks-installer kubectl -n kubesphere-system rollout restart deploy/ks-apiserver c) 若KubeSphere的版本为3.4.0或以上，由于登录界面发生变化，需要显示选择通过Ldap登录1(个人觉得这种设计简直是多此一举)，默认是普通账户登录，此时也会给人造成错觉，以为登陆失败。\n参见 https://ask.kubesphere.io/forum/d/8260-330-ldap/24\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-07-03T19:37:01+08:00","permalink":"https://lucumt.info/post/devops/ldap-integration-not-working/","tags":["kubesphere","ldap"],"title":"KubeSphere中整合LDAP后不生效的原因分析"},{"categories":["工具使用"],"contents":"简要说明如何给GitBook中的SVG图像提供缩放和下载功能，实现可对复杂的SVG图像进行缩放和下载。\n背景 在项目开发流程中个人习惯采用Mermaid中的Sequence diagrams组件通过画时序图的方式来描述复杂的业务逻辑并将其用GitBook呈现出来便于共享阅读，类似如下\nsequenceDiagram par Alice to Bob Alice-\u003e\u003eBob: Hello guys! and Alice to John Alice-\u003e\u003eJohn: Hello guys! end Bob--\u003e\u003eAlice: Hi Alice! John--\u003e\u003eAlice: Hi Alice! 随着使用的增多发现一个问题，当用该图表来描述复杂的业务逻辑时，由于参与者和相互调用流程特别多，生成的时序图特别密集，根本无法查看，类似如下\n由于Mermaid生成的图表都是以SVG形式呈现的，而SVG图像的特性是不管放大多少倍都不会失真，如果能通过某种方式将对应的SVG下载下来，之后用浏览器即可进行放大缩小来查看具体的细节，则岂不是能解决此问题？\n更进一步的，如果直接在页面上提供放大缩小功能，就能避免将对应SVG文件下载到本地，使用起来岂不是更方便？而SVG的缩放功能GitHub上有很多已有的实现，理论分析完全可行！\n实现 缩放功能 在GitHub上对比相关的SVG组件后，最终选定svg-pan-zoom作为SVG功能扩展度的实现，正好自己之前改进过一个基于Mermaid的GitBook插件gitbook-plugin-mermaid-fox，可将svg-pan-zoom相关的功能整合到该插件中，后续GitBook中升级插件版本即可。\n在svg-pan-zoom的官方文档中可找到该组件的用法，十分简单\nvar panZoomTiger = svgPanZoom(\u0026#39;#demo-tiger\u0026#39;); // or var svgElement = document.querySelector(\u0026#39;#demo-tiger\u0026#39;) var panZoomTiger = svgPanZoom(svgElement) 调用svgPanZoom时还可根据实际情况添加各种配置\nsvgPanZoom(\u0026#39;#demo-tiger\u0026#39;, { viewportSelector: \u0026#39;.svg-pan-zoom_viewport\u0026#39;, panEnabled: true, controlIconsEnabled: false, zoomEnabled: true, dblClickZoomEnabled: true, mouseWheelZoomEnabled: true, preventMouseEventsDefault: true, zoomScaleSensitivity: 0.2, minZoom: 0.5, maxZoom: 10, fit: true, contain: false, center: true, refreshRate: \u0026#39;auto\u0026#39;, beforeZoom: function(){}, onZoom: function(){}, beforePan: function(){}, onPan: function(){}, onUpdatedCTM: function(){}, customEventsHandler: {}, eventsListenerElement: null }); 之后要找到Mermaid渲染图表结束时的回调方法，在其官网上没有找到相关的说明，但通过Google发现在GitHub上有相关说明，核心代码如下\nimport mermaid from \u0026#39;${src}\u0026#39;; mermaid.run({ querySelector: \u0026#39;.mermaid\u0026#39;, postRenderCallback: (id) =\u0026gt; { console.log(id); } }); 很显然可通过在postRenderCallback回调方法中添加我们自己的逻辑，相关的代码如下\nmermaid.run({ querySelector: \u0026#39;.mermaid\u0026#39;, postRenderCallback: (id) =\u0026gt; { let ele = document.getElementById(id); let svg = ele.getBBox(); let height = svg.height; let aHeight = height \u0026gt; 800 ? 800 : height; ele.setAttribute(\u0026#39;style\u0026#39;,\u0026#39;height: \u0026#39;\u0026#43;aHeight\u0026#43;\u0026#39;px;overflow:scroll;\u0026#39;); let panZoomTiger = svgPanZoom(\u0026#39;#\u0026#39;\u0026#43;id,{ zoomEnabled: true, controlIconsEnabled: true }); panZoomTiger.resize(); panZoomTiger.updateBBox(); } }); 至此SVG缩放功能整合完毕，接下来需要研究下载功能。\n下载功能 由于SVG图像一般都是以源码的方式直接嵌入HTML页面中，故其下载功能较为简单，只需要找到对应的DOM节点，通过JavaScript相关的技术获取到其完整的内容，然后下载到本地即可。\n首先自己基于网络上的相关资料找到如下代码，本地验证下载txt时能正常工作。\nfunction downloadURI(uri, name) { var link = document.createElement(\u0026#34;a\u0026#34;); link.download = name; link.href = uri; link.click(); } 但当用其测试SVG下载时，下载的文件一直为空且浏览器也没提示任何错误，多次搜索发现Chrome出于安全考虑，默认情况下不允许通过JavaScript下载SVG文件，需要做一些特殊处理来规避此限制， 继续查找后找到一篇说明，其中给出了如下的解决方案，经本地测试可行。\nfunction downloadSvg() { var svg = document.getElementById(\u0026#34;svg\u0026#34;); var serializer = new XMLSerializer(); var source = serializer.serializeToString(svg); source = source.replace(/(\\w\u0026#43;)?:?xlink=/g, \u0026#39;xmlns:xlink=\u0026#39;); // Fix root xlink without namespace source = source.replace(/ns\\d\u0026#43;:href/g, \u0026#39;xlink:href\u0026#39;); // Safari NS namespace fix. if (!source.match(/^\u0026lt;svg[^\u0026gt;]\u0026#43;xmlns=\u0026#34;http\\:\\/\\/www\\.w3\\.org\\/2000\\/svg\u0026#34;/)) { source = source.replace(/^\u0026lt;svg/, \u0026#39;\u0026lt;svg xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34;\u0026#39;); } if (!source.match(/^\u0026lt;svg[^\u0026gt;]\u0026#43;\u0026#34;http\\:\\/\\/www\\.w3\\.org\\/1999\\/xlink\u0026#34;/)) { source = source.replace(/^\u0026lt;svg/, \u0026#39;\u0026lt;svg xmlns:xlink=\u0026#34;http://www.w3.org/1999/xlink\u0026#34;\u0026#39;); } var preface = \u0026#39;\u0026lt;?xml version=\u0026#34;1.0\u0026#34; standalone=\u0026#34;no\u0026#34;?\u0026gt;\\r\\n\u0026#39;; var svgBlob = new Blob([preface, source], { type: \u0026#34;image/svg\u0026#43;xml;charset=utf-8\u0026#34; }); var svgUrl = URL.createObjectURL(svgBlob); var downloadLink = document.createElement(\u0026#34;a\u0026#34;); downloadLink.href = svgUrl; downloadLink.download = name; document.body.appendChild(downloadLink); downloadLink.click(); document.body.removeChild(downloadLink); } 缩放与下载功能分别验证完毕后，接下来只需将其整合到对应的GitBook插件中即可，完整代码参见gitbook-plugin-mermaid-fox。\n显示效果 添加缩放和下载按钮后后默认显示效果如下，其中下载按钮位于右上角，缩放按钮位于右下角\n通过图中的按钮或鼠标滚轮放大后的效果如下，可以看出基本满足需求\n相关代码 修改过程中主要涉及到index.js和plguin.js这两个文件，同时需要把svg-pan-zoom.js文件放到相关目录下以方便加载\nindex.js用于文件加载\nfunction processMermaidBlockList(page) { const mermaidRegex = /^[ \\t]*```\\s*mermaid[ \\t]*$([^`]*(?:`[^`]\u0026#43;)*)```$/igm; let download=\u0026#39;\u0026lt;svg width=\u0026#34;15\u0026#34; height=\u0026#34;15\u0026#34; viewBox=\u0026#34;0 0 8 8\u0026#34; fill=\u0026#34;#707070\u0026#34; xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34;\u0026gt;\u0026lt;path d=\u0026#34;m3 0v3h-2l3 3 3-3h-2v-3zm-3 7v1h8v-1z\u0026#34;/\u0026gt;\u0026lt;/svg\u0026gt;\u0026#39;; page.content = page.content.replace(mermaidRegex, \u0026#39;\u0026lt;div\u0026gt;\u0026lt;div class=\u0026#34;download\u0026#34; style=\u0026#34;float:right;padding-right:35px;cursor:pointer\u0026#34;\u0026gt;\u0026#39; \u0026#43;download\u0026#43;\u0026#39;\u0026lt;/div\u0026gt;\u0026lt;div class=\u0026#34;mermaid\u0026#34;\u0026gt;$1\u0026lt;/div\u0026gt;\u0026lt;/div\u0026gt;\u0026#39;); return page; } module.exports = { website: { assets: \u0026#39;dist\u0026#39;, css: [ \u0026#39;mermaid/mermaid.css\u0026#39; ], js: [ \u0026#39;book/plugin.js\u0026#39;, \u0026#39;book/svg-pan-zoom.js\u0026#39; ] }, hooks: { \u0026#39;page:before\u0026#39;: processMermaidBlockList } }; plugin.js核心代码\nrequire([ \u0026#39;gitbook\u0026#39; ], function (gitbook) { gitbook.events.bind(\u0026#39;page.change\u0026#39;, function () { mermaid.run({ querySelector: \u0026#39;.mermaid\u0026#39;, postRenderCallback: (id) =\u0026gt; { let ele = document.getElementById(id); let svg = ele.getBBox(); let height = svg.height; let aHeight = height \u0026gt; 800 ? 800 : height; ele.setAttribute(\u0026#39;style\u0026#39;,\u0026#39;height: \u0026#39;\u0026#43;aHeight\u0026#43;\u0026#39;px;overflow:scroll;\u0026#39;); let panZoomTiger = svgPanZoom(\u0026#39;#\u0026#39;\u0026#43;id,{ zoomEnabled: true, controlIconsEnabled: true }); panZoomTiger.resize(); panZoomTiger.updateBBox(); let download = ele.parentNode.previousSibling; download.addEventListener(\u0026#39;click\u0026#39;,e =\u0026gt; { downloadData(id, ele); }); } }); }); }); function downloadData(id,ele) { let svg = ele.cloneNode(true); // remove svg-pan-zoom-controls for the download file svg.getElementById(\u0026#34;svg-pan-zoom-controls\u0026#34;).remove(); let serializer = new XMLSerializer(); let source = serializer.serializeToString(svg); source = source.replace(/(\\w\u0026#43;)?:?xlink=/g, \u0026#39;xmlns:xlink=\u0026#39;); // Fix root xlink without namespace source = source.replace(/ns\\d\u0026#43;:href/g, \u0026#39;xlink:href\u0026#39;); // Safari NS namespace fix. if (!source.match(/^\u0026lt;svg[^\u0026gt;]\u0026#43;xmlns=\u0026#34;http\\:\\/\\/www\\.w3\\.org\\/2000\\/svg\u0026#34;/)) { source = source.replace(/^\u0026lt;svg/, \u0026#39;\u0026lt;svg xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34;\u0026#39;); } if (!source.match(/^\u0026lt;svg[^\u0026gt;]\u0026#43;\u0026#34;http\\:\\/\\/www\\.w3\\.org\\/1999\\/xlink\u0026#34;/)) { source = source.replace(/^\u0026lt;svg/, \u0026#39;\u0026lt;svg xmlns:xlink=\u0026#34;http://www.w3.org/1999/xlink\u0026#34;\u0026#39;); } let preface = \u0026#39;\u0026lt;?xml version=\u0026#34;1.0\u0026#34; standalone=\u0026#34;no\u0026#34;?\u0026gt;\\r\\n\u0026#39;; let svgBlob = new Blob([preface, source], { type: \u0026#34;image/svg\u0026#43;xml;charset=utf-8\u0026#34; }); let svgUrl = URL.createObjectURL(svgBlob); let downloadLink = document.createElement(\u0026#34;a\u0026#34;); let name = id \u0026#43; \u0026#39;.svg\u0026#39;; downloadLink.download = name; downloadLink.href = svgUrl; document.body.appendChild(downloadLink); downloadLink.click(); document.body.removeChild(downloadLink); } ","date":"2024-06-27T20:35:45+08:00","permalink":"https://lucumt.info/post/gitbook/add-zoom-and-export-feature-for-svg-inside-gitbook/","tags":["gitbook"],"title":"给GitBook中的SVG图像提供缩放和下载功能"},{"categories":["Web编程"],"contents":" A brief descripton about how to embed multiple google trends chart into single html page to make them working fine.\nIssue Sometimes we need to use Google Trends to find the search trends for key words and embed the result into our own html page,we can click \u0026lt;\u0026gt; icon on the right top of each chart to get the embed source code that can be integrated into html page:\nFor example, we can use it to find the search trends for key words: Podman,Docker and Kubernetes in the past 5 years worldwide,below are the screenshots for them:\nPodman search trend\nresult:\nembed code:\n\u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;https://ssl.gstatic.com/trends_nrtr/3728_RC01/embed_loader.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; trends.embed.renderExploreWidget(\u0026#34;TIMESERIES\u0026#34;, {\u0026#34;comparisonItem\u0026#34;:[{\u0026#34;keyword\u0026#34;:\u0026#34;Podman\u0026#34;,\u0026#34;geo\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;today 5-y\u0026#34;}],\u0026#34;category\u0026#34;:0,\u0026#34;property\u0026#34;:\u0026#34;\u0026#34;}, {\u0026#34;exploreQuery\u0026#34;:\u0026#34;date=today%205-y\u0026amp;q=Podman\u0026#34;,\u0026#34;guestPath\u0026#34;:\u0026#34;https://trends.google.com:443/trends/embed/\u0026#34;}); \u0026lt;/script\u0026gt; Docker search trend\nresult:\nembed code:\n\u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;https://ssl.gstatic.com/trends_nrtr/3728_RC01/embed_loader.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; trends.embed.renderExploreWidget(\u0026#34;TIMESERIES\u0026#34;, {\u0026#34;comparisonItem\u0026#34;:[{\u0026#34;keyword\u0026#34;:\u0026#34;Docker\u0026#34;,\u0026#34;geo\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;today 5-y\u0026#34;}],\u0026#34;category\u0026#34;:0,\u0026#34;property\u0026#34;:\u0026#34;\u0026#34;}, {\u0026#34;exploreQuery\u0026#34;:\u0026#34;date=today%205-y\u0026amp;q=Docker\u0026#34;,\u0026#34;guestPath\u0026#34;:\u0026#34;https://trends.google.com:443/trends/embed/\u0026#34;}); \u0026lt;/script\u0026gt; Kubernetes search trend\nresult:\nembed code:\n\u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;https://ssl.gstatic.com/trends_nrtr/3728_RC01/embed_loader.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; trends.embed.renderExploreWidget(\u0026#34;TIMESERIES\u0026#34;, {\u0026#34;comparisonItem\u0026#34;:[{\u0026#34;keyword\u0026#34;:\u0026#34;Kubernetes\u0026#34;,\u0026#34;geo\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;today 5-y\u0026#34;}],\u0026#34;category\u0026#34;:0,\u0026#34;property\u0026#34;:\u0026#34;\u0026#34;}, {\u0026#34;exploreQuery\u0026#34;:\u0026#34;date=today%205-y\u0026amp;q=Kubernetes\u0026#34;,\u0026#34;guestPath\u0026#34;:\u0026#34;https://trends.google.com:443/trends/embed/\u0026#34;}); \u0026lt;/script\u0026gt; If we put the embed codes into single page, usually we can put these three code blocks into html page directly:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Google Trends Charts Embed Test\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- Podman --\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;https://ssl.gstatic.com/trends_nrtr/3728_RC01/embed_loader.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; trends.embed.renderExploreWidget(\u0026#34;TIMESERIES\u0026#34;, {\u0026#34;comparisonItem\u0026#34;:[{\u0026#34;keyword\u0026#34;:\u0026#34;Podman\u0026#34;,\u0026#34;geo\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;today 5-y\u0026#34;}],\u0026#34;category\u0026#34;:0,\u0026#34;property\u0026#34;:\u0026#34;\u0026#34;}, {\u0026#34;exploreQuery\u0026#34;:\u0026#34;date=today%205-y\u0026amp;q=Podman\u0026#34;,\u0026#34;guestPath\u0026#34;:\u0026#34;https://trends.google.com:443/trends/embed/\u0026#34;}); \u0026lt;/script\u0026gt; \u0026lt;!-- Docker --\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;https://ssl.gstatic.com/trends_nrtr/3728_RC01/embed_loader.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; trends.embed.renderExploreWidget(\u0026#34;TIMESERIES\u0026#34;, {\u0026#34;comparisonItem\u0026#34;:[{\u0026#34;keyword\u0026#34;:\u0026#34;Docker\u0026#34;,\u0026#34;geo\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;today 5-y\u0026#34;}],\u0026#34;category\u0026#34;:0,\u0026#34;property\u0026#34;:\u0026#34;\u0026#34;}, {\u0026#34;exploreQuery\u0026#34;:\u0026#34;date=today%205-y\u0026amp;q=Docker\u0026#34;,\u0026#34;guestPath\u0026#34;:\u0026#34;https://trends.google.com:443/trends/embed/\u0026#34;}); \u0026lt;/script\u0026gt; \u0026lt;!-- Kubernetes --\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;https://ssl.gstatic.com/trends_nrtr/3728_RC01/embed_loader.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; trends.embed.renderExploreWidget(\u0026#34;TIMESERIES\u0026#34;, {\u0026#34;comparisonItem\u0026#34;:[{\u0026#34;keyword\u0026#34;:\u0026#34;Kubernetes\u0026#34;,\u0026#34;geo\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;today 5-y\u0026#34;}],\u0026#34;category\u0026#34;:0,\u0026#34;property\u0026#34;:\u0026#34;\u0026#34;}, {\u0026#34;exploreQuery\u0026#34;:\u0026#34;date=today%205-y\u0026amp;q=Kubernetes\u0026#34;,\u0026#34;guestPath\u0026#34;:\u0026#34;https://trends.google.com:443/trends/embed/\u0026#34;}); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; However,if we test it inside a web server we will find only the first one can works fine,the others are not.\nLet\u0026rsquo;s modify the code and make only one chart left,we will find that it will works fine where there are only one chart!\nWe can check it at live demo with three charts not working and live demo with one chart working.\nSolution When the page has three charts,we can check the browser console and will find that there are no error inside it, there must be something wrong with my code!\nAfter search on the Internet I found a solution1,the reason is that we have imported duplicatedembed_loader.js,it only needs imported one!\nChange code as below\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Google Trends Charts Embed Test\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- Podman --\u0026gt; \u0026lt;!-- embed_loader.js only needs to be import once --\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;https://ssl.gstatic.com/trends_nrtr/3728_RC01/embed_loader.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; trends.embed.renderExploreWidget(\u0026#34;TIMESERIES\u0026#34;, {\u0026#34;comparisonItem\u0026#34;:[{\u0026#34;keyword\u0026#34;:\u0026#34;Podman\u0026#34;,\u0026#34;geo\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;today 5-y\u0026#34;}],\u0026#34;category\u0026#34;:0,\u0026#34;property\u0026#34;:\u0026#34;\u0026#34;}, {\u0026#34;exploreQuery\u0026#34;:\u0026#34;date=today%205-y\u0026amp;q=Podman\u0026#34;,\u0026#34;guestPath\u0026#34;:\u0026#34;https://trends.google.com:443/trends/embed/\u0026#34;}); \u0026lt;/script\u0026gt; \u0026lt;!-- Docker --\u0026gt; \u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; trends.embed.renderExploreWidget(\u0026#34;TIMESERIES\u0026#34;, {\u0026#34;comparisonItem\u0026#34;:[{\u0026#34;keyword\u0026#34;:\u0026#34;Docker\u0026#34;,\u0026#34;geo\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;today 5-y\u0026#34;}],\u0026#34;category\u0026#34;:0,\u0026#34;property\u0026#34;:\u0026#34;\u0026#34;}, {\u0026#34;exploreQuery\u0026#34;:\u0026#34;date=today%205-y\u0026amp;q=Docker\u0026#34;,\u0026#34;guestPath\u0026#34;:\u0026#34;https://trends.google.com:443/trends/embed/\u0026#34;}); \u0026lt;/script\u0026gt; \u0026lt;!-- Kubernetes --\u0026gt; \u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; trends.embed.renderExploreWidget(\u0026#34;TIMESERIES\u0026#34;, {\u0026#34;comparisonItem\u0026#34;:[{\u0026#34;keyword\u0026#34;:\u0026#34;Kubernetes\u0026#34;,\u0026#34;geo\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;today 5-y\u0026#34;}],\u0026#34;category\u0026#34;:0,\u0026#34;property\u0026#34;:\u0026#34;\u0026#34;}, {\u0026#34;exploreQuery\u0026#34;:\u0026#34;date=today%205-y\u0026amp;q=Kubernetes\u0026#34;,\u0026#34;guestPath\u0026#34;:\u0026#34;https://trends.google.com:443/trends/embed/\u0026#34;}); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Test it again we will find all the charts working fine,that\u0026rsquo;s all!\nWe can check it at live demo with three charts working\nGoogle Trends embed graphs not working in WordPress 6.2.2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-06-14T11:07:55+08:00","permalink":"https://lucumt.info/post/web/embed-multiple-google-trends-charts-into-single-html-page/","tags":["html"],"title":"Embed Multiple Google Trends Charts Into Single Html Page"},{"categories":["工具使用"],"contents":"简要记录如何在Windows操作系统中通过批处理脚本来给复杂的命令添加别名以简化使用。\n背景 自己使用Hugo进行博客开发已经有年头了，最近由于需要搭建新的网站1需要使用特定的模板，而该模板对Hugo的版本有要求，故对Hugo版本进行了升级，从v0.100升级到v0.126。\n升级之后虽然在搭建新网站时没有问题，但个人发现新版本的Hugo有一个特性让人用起来不太方便：\n通过hugo server -w -D在本地启动Hugo环境时，默认会在本地public文件夹下生成全部的静态文件，从而导致通过Git提交时会提交大量无用的文件，在国内这种网络环境下容易push失败。\n而之前自己使用Hugo时，若要手工生成静态文件需要在参数中显示指定，类似hugo server --renderToDisk，升级后的版本将其作为了默认选项。\n进一步查看资料，发现该特性是在v0.123版本中引入的2，具体原因参见3，在该版本之后若想默认不在public目录下生成静态文件则需要在启动时手工添加相关指令，类似hugo server -w -D --renderToMemory。\n尽管Hugo作者这么做肯定是有其原因的，但我习惯了只有在托管到GitHub Pages时才生成静态文件，同时我也是一个懒人，每次使用时都要添加--renderToMemory参数对我来说简直是一种折磨。\n能否仿照Linux中的alias指令对前述命令进行封装，从而简化使用呢？\n分析 我们知道在Windows的默认附带了很多指令，如mspaint、mstsc、calc等指令，可在运行窗口或cmd中输入这些指令直接使用，其原因为这些指令都位于C:\\Windows\\System32目录下，而该目录是系统目录，在启动时会进行加载。\n而对于非Windows系统自带指令或软件，在我们安装过程中通常会提示我们是否要将该软件添加到Path环境变量中去，典型的如Python，当选择添加到Path环境变量中后，可重新打开一个cmd窗口，然后输入python指令进行相关的操作。即我们如果想要在cmd中能直接使用某个自定义指令，则该指令必须添加到Path环境变量中去。\n在Linux中有bash、zsh等脚本可用于封装复杂的指令，同样在Windows中可使用batch脚本来封装复杂的指令，最终问题变为如下：\n是否可通过batch脚本封装复杂的Hugo指令，并将该脚本添加到Path环境变量中来实现在cmd中直接使用封装后的指令？\n实现 理论分析完毕后，接下来进行实际操作验证：\n新建一个名为hugo_server.bat的脚本，内容如下\n@echo off hugo server -w -D --renderToMemory 仿照下图，将hugo_server.bat的位置添加到Path环境变量中去\n重新打开一个cmd窗口，输入hugo_server(batch脚本的名称)，显示结果如下，可看出hugo_server别名正常工作，目的达到！\n参见创建多个GitHub Pages并且利用GoDaddy分别配置子域名\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n参见Some breaking changes planned for Hugo 0.123.0\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMake the server flag \u0026ndash;renderToDisk into \u0026ndash;renderToMemory\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-06-12T13:26:28+08:00","permalink":"https://lucumt.info/post/other/add-alias-to-commands-on-windows/","tags":["windows"],"title":"给Windows中的命令添加别名"},{"categories":["个人博客","其它"],"contents":"简要记录如何基于同一个GitHub账号创建多个GitHub Pages并基于GoDaddy配置多个子域名。\n背景 自己当前的博客是采用GitHub Pages+GoDaddy实现，已经使用了七八年，在此过程中除了感觉GoDaddy的域名续费有点小贵之外，没有遇到其它问题。\n不过每年接近200元的域名费用，只用来托管自己质量和数量都不高的个人博客实在有些浪费，能否最大限制的挖掘其价值呢？\n经过一番调研后最终决定采用GitHub Pages+GoDaddy子域名来托管多个项目供自己与展示使用。\n多个GitHub Pages 在GitHub的官网中有关于GitHub Pages类型和使用限制的详细说明1:\n基于用户，访问方式为http(s)://\u0026lt;username\u0026gt;.github.io 基于组织，访问方式为http(s)://\u0026lt;organization\u0026gt;.github.io 基于项目，访问方式为http(s)://\u0026lt;username\u0026gt;.github.io/project 很显然，在基于用户的方式时只能创建一个GitHub Pages站点，虽然单个用户可以创建多个组织，但是GitHub官方限制同一个账户只能创建一个基于组织的GitHub Pages站点，且不能与基于用户方式的同时存在。\n故此要想实现创建多个GitHub Pages站点只能采用基于项目的方式，相关操作步骤如下：\n进入个人的GitHub主页，切换到Repositories菜单下，点击右上角的New菜单创建一个新的仓库。需要注意的是此处选择的为Repositories而不是Projects，这是由于GitHub中的Repositories主要是用来管理代码，而Projects则是对项目进行管理，侧重非代码。\n在出现的界面中输入一个不冲突的仓库名称，之后点击下方的Create repository按钮进行创建\n创建完毕后进入该项目，依次点击Settings-\u0026gt;Pages菜单，出现如下页面，选择对应的分支和根目录，之后点击Save按钮，即可完成初步配置\n将该仓库clone到本地，在根目录添加一个名为index.html的文件，内容如下，之后提交并推送到仓库\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;b\u0026gt;Book Test\u0026lt;/b\u0026gt; \u0026lt;div id=\u0026#34;time\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; const date = new Date(); const year = date.getFullYear(); const month = String(date.getMonth() \u0026#43; 1).padStart(2, \u0026#39;0\u0026#39;); // Month is 0-based const day = String(date.getUTCDate()).padStart(2, \u0026#39;0\u0026#39;); const hour = String(date.getHours()).padStart(2, \u0026#39;0\u0026#39;); const minute = String(date.getMinutes()).padStart(2, \u0026#39;0\u0026#39;); const second = String(date.getSeconds()).padStart(2, \u0026#39;0\u0026#39;); const strDate = year \u0026#43; \u0026#34;-\u0026#34; \u0026#43; month \u0026#43; \u0026#34;-\u0026#34; \u0026#43; day \u0026#43; \u0026#34; \u0026#34; \u0026#43; hour \u0026#43; \u0026#34;:\u0026#34; \u0026#43; minute \u0026#43; \u0026#34;:\u0026#34; \u0026#43; second; document.getElementById(\u0026#34;time\u0026#34;).innerHTML = strDate; \u0026lt;/script\u0026gt; \u0026lt;/html\u0026gt; 之后在浏览器中输入https://lucumt.github.io/book或http://lucumt.github.io/book，出现类似如下界面，表示基于项目的GitHub Pages站点创建成功。\n可以看出虽然测试正常，但上述访问方式需要将项目名包含进去，不太美观也不便于后续的统计扩展等操作，接下来需要配置GoDaddy有针对性的设置子域名。\n创建与配置子域名 在GoDaddy的官网上有关于子域名的相关说明2：\n一个域名最多支持500个子域名 子域名可以嵌套，如在子域名book.lucumt.info下面创建嵌套的子域名it.book.lucumt.info 非嵌套子域名最长可以有255个字符，嵌套子域名则不能超过63个 从上可知我们完全可在GoDaddy上给自己购买的域名，添加多个子域名，相关操作步骤如下：\n使用个人账号登录GoDaddy主页，在右上角点击我的产品，出现类似如下界面，在对应域名后面点击DNS链接\n在出现的界面中点击DNS记录菜单下的添加新纪录按钮\nGoDaddy中添加域名记录支持两种类型：A记录与CNAME，其中A记录指向具体的IP地址，CNAME指向其它的域名，本例中我们希望用来替代lucumt.github.io/book，故需要选择CNAME。\n仿照下述界面，填入相关信息并点击保存按钮，至此GoDaddy中的相关配置操作完毕，GoDaddy官网说需要1-48小时生效，但个人实际测试发现操作完毕后一分钟即能生效\n在对应的GitHub项目中创建一个名为CNAME的文件，并只写入book.lucumt.info，然后提交推送到GitHub\n提交完毕之后待其默认构建完毕后，在GitHub中进入对应项目，依次点击Settings-\u0026gt;Pages，可以看见DNS正在校验我们设置的二级域名，此过程可能需要3-15分钟左右才能检查完毕，在此期间无法开启HTTPS支持\n根据不同检查完毕后的输出类似如下，此时虽然开启HTTPS选项仍不可用，但可用HTTP协议测试\n在浏览器中输入http://book.lucumt.info会出现类似如下界面，表示我们的子域名绑定操作基本成功\n若在步骤6中的开启HTTPS按钮一直不可用，可在浏览器中刷新该页面，之后出现的界面即可让我们选中开启HTTPS\n之后在浏览器中输入https://book.lucumt.info，结果类似如下，可发现HTTPS支持也生效。\n至此，整个操作过程完毕！\nAbout GitHub Pages - GitHub Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n什麼是子網域？ | 網域 - GoDaddy 說明 HK\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-05-20T09:44:44+08:00","permalink":"https://lucumt.info/post/github/create-multiple-github-pages-and-config-godaddy-subdomain/","tags":["GitHub","Github Pages"],"title":"创建多个GitHub Pages并且利用GoDaddy分别配置子域名"},{"categories":["容器化","翻译"],"contents":"本文翻译自Podman vs Docker: What are the differences?\n容器编排技术是目前最重要的Web开发技术之一，而目前在该领域的许多强有力的框架技术正在争夺主导地位。\nPodman是Red Hat公司的一款产品，以类似Kubernetes方式构建、运行和管理容器，其旨在给主流的容器使用人员提供一个可靠的替代。\n接下来我们会比较Podman与近十年事实上的容器标准Docker，因为这两种技术有本质上的区别，但同时也非常适合协同工作。\n什么是容器编排 容器是包含代码和类库、工具、设置、运行等依赖项的标准软件包，由于它们提供了更快的部署和扩展能力，同时在开发和交付准备阶段能保持一致性，因此业界迅速采用了容器作为容器化架构的核心组件。\n容器是轻量级、安全、可移植的，提供了与任何环境兼容的隔离空间。通过将软件从操作系统分离出来，容器可移植到任何地方(如从Linux到Windows)，同时可避免阻碍其正常运行的缺陷和错误。\n一些最知名的容器编排技术包括Docker、Docker Swarm、Kubernetes和Nomad，我们已经在相关博客中对它们进行了详细的分析和比较。\n什么是Docker Docker是标准的容器管理技术，它在业界具有如此重要的地位，以至于大多数人想到容器时就会想到Docker。\nDocker作为容器编排领域的瑞士军刀，包含了许多其它替代品出现之前的强大功能，它已经成长为一个标准的、自给自足的功能，随着容器管理复杂性的提升，能满足所有开发人员的需求。\nDocker很快的成为了一个一体化解决方案，包含用于特定任务的各种工具，其中一个是Docker Swarm，一个原生的Docker特性用于集群和调度Docker引擎，以及其它的用于创建和管理一大堆容器的工具。\nDocker的附带工具可用于处理容器编排领域的所有任务，从负载均衡到网络，使得其成为业界的首先，同时也是成熟的参考技术。\n不过这种自给自足也有问题，尽管Docker是软件开发各阶段创建和运行容器的强有力工具，但其它工具与其交互很困难。近年来随着许多解决特定任务的专用工具出现，Docker成为许多专业开发人员将一些操作转移到其它平台和工具的分水岭。\n什么是Podman 那Podman又是什么呢? Podman是一个基于开放容器标准(Open Container Initiative,OCI)设计的用于开发、管理和运行容器和pod的开源，Linux原生的工具。它是Red Hat开发的用户友好的容器编排器，在RedHat 8和Centos 8中作为默认的容器引擎。\nPodman是一系列的命令行工具集合，用于以模块化框架的方式处理容器化过程中的各种不同任务，这些集合包括：\nPodman，pod和容器的镜像管理 Buildah，容器构建器 Skopeo，容器镜像检查管理器 runc，Podman和Buildah使用的容器运行和功能构建器 crun，运行时可选，为无root权限容器提供更大的灵活性、控制与安全性 这些工具也可与任何兼容OCI标准的容器引擎协作，如Docker，使得很容易 过渡到Podman 或者在已安装的Docker环境中使用。那Kubernetes能否使用Podman？当然可以，事实上它们在某些方面是相似的。\nPodman对容器有一套不同的概念，正如其名称所暗示的那样，Podman可以创建协同工作的容器pods，类似于Kubernetes中的pod功能。Pods将多个不同的容器组合到一个共同的名称下以单个单元的形式来管理它们。\n这样做的好处是开发人员可以共享资源，在pod内为同一个应用程序使用不同的容器：一个用于前端，一个用于后端，另一个用于数据库。Pod的定义可以导出为兼容Kubernetes的yaml文件并运行用于Kubernetes集群中，使得容器能够更快的投入实际使用。\nPodman的另一个显示特征是其没有守护进程，守护进程是在后台运行的程序，用于处理没有用户界面的服务、进程和请求。其对容器引擎进行了独特的改进，因为它实际上并不依赖于守护进程，而是将容器和 Pod 作为子进程启动。\n或许你会问 为啥我要用Podman? 这是由于它作为开发和管理工具具有独特的优势，使其成为在适当的环境下成为可行且有趣的Docker替代品，也可作为与Docker协同工作的强有力补充，因为它支持与Docker兼容的CLI标准接口。\nPodman与Docker的差异对比 根据 Google Trends 的数据，过去五年Docker和Podman的关注度一直在波动，但Docker相对更受欢迎，截止到目前，这两个容器编排工具都获得了用户极大的关注度。\nPodman过去五年的搜索趋势\nDocker过去五年的搜索趋势\nPodman和Docker有许多共同的特性，但也存在一些根本上的区别，这并不意味着一个比另一个好，而是要根据具体项目做出合适的选择。\n架构 Docker使用守护线程，一个后台持续运行的程序来创建镜像和容器，Podman则使用无守护线程的架构，这意味着它可以在启动容器的用户下运行容器，Docker拥有由守护进程管控的客户端-服务器交互逻辑，另外一个则没有。\nRoot权限 Podman由于不需要守护进程来管理其活动，同样不需要对容器分配root权限，Docker最近在其守护进程配置中添加了无root模式，但Podman首先使用了这种方法，并将其推广为一项基本特性，接下来会具体说明。\n安全 Podman是否比Docker更安全？Podman允许容易以非root的方式运行，相对于具有root权限的容器而言无root容器通常更安全。在Docker中守护线程拥有root权限，使得其成为攻击者的理想入口。Podman中的容器默认情况下没有root权限，从而在root和非root级别添加了一个天然的屏障来提高安全性，同时，它也能同时运行有root权限和无root权限的容器。\nSystemd 由于没有守护线程，Podman需要其它的工具在后台来管理服务和支持容器运行，Systemd可用于为已有容器创建控制单元或创建新容器，Systemd还可以与Podman集成，允许它运行默认启用基于Systemd的容器且无需任何修改。\n通过使用Systemd，供应商可以以容器的形式安装、运行和管理他们的应用程序，因为现在大多数应用程序都是以这种方式打包和交付的。\n镜像构建 作为一个自给自足的工具，Docker可自行构建容器镜像，而Podman则需要一个名为Buildah工具的协助，这正好表明了Podman的一个特点：用于运行容器而不是用于构建容器。\nDocker Swarm Podman不支持Docker Swarm,由于使用Docker Swarm会产生操作，这会将其排除在使用Docker Swarm特定的项目之外。Podman近期添加了Docker Compose的支持，使其与Swarm兼容，从而解决这一限制。Docker则很自然的可以与 Swarm良好配合使用。\n一体化与模块化 这是这两个工具的另外一个关键差异：Docker是一个体式、功能强大且独立的工具，包含各种优点和缺点，可处理整个周期内的所有容器化任务，Podman 则采用模块化的方式，对于特定的任务依赖特定的工具来实现。\n结论 Podman和Docker都是功能强大的容器编排工具，各有优势和区别，尽管Docker已成为近十年的容器行业标准，但Podman的创新架构和容器管理方法使其成为开发人员（尤其是在Linux环境中工作的开发人员）的可靠选择。\n不论你选择哪一种，抑或是两者都用，了解它们的差别和共同点有助于对项目做出最佳的决定。\n常见问题 Podman能否替代Docker 是的，Podman可以在许多场景下替换Docker，它提供了与Docker类似的容器运行时环境和工具，并且在某种程度上，能提供额外好处，如更高的安全性和灵活性。\nPodman与Docker有何不同 Podman相对于Docker的一个主要区别是它不需要单独的守护进程，使得其更轻量级和更安全，同样也为非root容器运行提供了更好的支持以提升安全。除此之外，Podman可在不需要类似Docker Compose这种工具的支持下原生运行Kubernetes中的pods。\n想了解更多吗？可以按照Docker+Kubernetes去查找。\nPodman是否比Docker更安全 Podman有时被认为比Docker更安全，这是由于它不需要单独的守护进程来运行容器，从而减少了潜在安全漏洞的攻击面，同时还更好地支持以非root 用户身份运行容器，从而可以提高安全性。\n哪种更合适：Podman还是Docker Podman 和 Docker哪个更好呢？Podman是否比Docker更好取决于具体的场景和需求。有时Podman可能提供更好的安全性和灵活性，但Docker可能更适合某些环境或应用程序。这两个考量点很重要，因为可用于确定哪个最能满足项目的需求。\n","date":"2024-04-26T10:46:34+08:00","permalink":"https://lucumt.info/post/docker/difference-between-docker-and-podman/","tags":["docker"],"title":"[译]Docker和Podman的差异"},{"categories":["工具使用"],"contents":"简单记录下自己在使用Grafana过程中的一点点经验总结：通过修改sql的方式来消除柱状图中多余的0值。\n问题 通过Grafana基于MySQL查询系统监控统计数据时，发现在柱状图中有很多0值，严重影响使用体验。\n解决 一开始自己想通过Grafana面板的过滤这些0值，搜索一番后并没有找到基于Grafana的解决方案，给出的答案是通过修改sql来规避此问题1，对比该答案，还发现自己遇到的问题类似。\n原始查询sql：\nSELECT DATE_FORMAT(t.start_time,\u0026#39;%Y-%m-%d\u0026#39;) AS `taskDate`, SUM(IF(t.instance_status = 0,1,0)) AS `未知`, SUM(IF(t.instance_status = 1,1,0)) AS `等待触发`, SUM(IF(t.instance_status = 2,1,0)) AS `队列中`, SUM(IF(t.instance_status = 3,1,0)) AS `开始执行`, SUM(IF(t.instance_status = 4,1,0)) AS `执行中`, SUM(IF(t.instance_status = 5,1,0)) AS `成功`, SUM(IF(t.instance_status = 6,1,0)) AS `失败`, SUM(IF(t.instance_status = 7,1,0)) AS `终止`, SUM(IF(t.instance_status = 8,1,0)) AS `超时`, SUM(IF(t.instance_status = 9,1,0)) AS `拒绝执行`, SUM(IF(t.instance_status = 10,1,0)) AS `已访问` FROM t_work_flow_instance t WHERE t.start_time\u0026gt; DATE_SUB(NOW(), INTERVAL 14 DAY) GROUP BY taskDate ORDER BY taskDate mysql中查询结果：\n为了解决该问题，需要将IF中的默认值从0修改为null。\n改进后的sql:\nSELECT DATE_FORMAT(t.start_time,\u0026#39;%Y-%m-%d\u0026#39;) AS `taskDate`, SUM(IF(t.instance_status = 0,1,null)) AS `未知`, SUM(IF(t.instance_status = 1,1,null)) AS `等待触发`, SUM(IF(t.instance_status = 2,1,null)) AS `队列中`, SUM(IF(t.instance_status = 3,1,null)) AS `开始执行`, SUM(IF(t.instance_status = 4,1,null)) AS `执行中`, SUM(IF(t.instance_status = 5,1,null)) AS `成功`, SUM(IF(t.instance_status = 6,1,null)) AS `失败`, SUM(IF(t.instance_status = 7,1,null)) AS `终止`, SUM(IF(t.instance_status = 8,1,null)) AS `超时`, SUM(IF(t.instance_status = 9,1,null)) AS `拒绝执行`, SUM(IF(t.instance_status = 10,1,null)) AS `已访问` FROM t_work_flow_instance t WHERE t.start_time\u0026gt; DATE_SUB(NOW(), INTERVAL 14 DAY) GROUP BY taskDate ORDER BY taskDate mysql中查询结果如下，可看出除了将0值修改为null之外，其余的查询数据是一致的。\n在Grafana中查看显示效果类似如下，可发现0值已经消失，问题初步解决。\n后记 虽然前述问题被解决，但当我们用鼠标查询对应的柱状条时，可发现tooltip中会显示所有的类别，即使该类别值为0或不存在也会显示，同样很影响使用体验。\n在网上搜索一番后，发现已经有人在Grafana的GitHub主页上提出了对应的issue2, 遗憾的是该问题在2015年初被提出，到现在快10年了都没解决，Grafana官方的开发人员明确回复了没有该问题的修复计划，并且不认为其是一个issue，看来只能一直凑合用着！\nhttps://community.grafana.com/t/hiding-0s-from-charts-when-data-is-not-all-0s/100820\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/grafana/grafana/issues/1381\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-04-19T17:21:43+08:00","permalink":"https://lucumt.info/post/devops/hidden-zero-value-in-grafana-bar-chart/","tags":["devops","grafana","mysql"],"title":"在基于MySQL的Grafana的柱状中不显示0值"},{"categories":["个人博客","编程杂想"],"contents":"简要记录下由于自己手机格式化刷机后，GitHub两阶段认证失败导致最终无法完整登录，尝试过多种方式后最终通过github-recovery-codes.txt恢复自己GitHub账号的过程。只是单纯的作为记录，对其他遇到类似的问题的人不具有参考价值。\n问题背景 自己的GitHub账号注册了有些年头，之前一直是通过账号密码直接登录即可，但GitHub官网1从2023年3月份到2023年末对提交代码的用户逐步开启两阶段认证(2FA,全称为two-factor authentication)，由于那段时间每次登录时GitHub都会强制提示开启2FA功能，影响正常的使用，且2FA是大趋势，为了减少麻烦自己准备2FA功能。\nGitHub官网提供了包括TOTP、SMS、passkey、security key、GitHub Mobile这5种方式来实现2FA，自己一开始想用的是SMS，但实际操作时发现其不支持中国大陆的手机号码(哎，又是一个简中特供)，而GitHub Mobile不能单独使用，只能在配置了其它2FA的前提下使用，可选的范围变小。综合考虑后自己决定采用Authy作为TOTP实现，按照官网的描述很快就配置完成，且正常的使用了半年多。\n由于Authy是安装在个人手机上，而个人手机用了几年之后频繁提示手机存储空间不足(此处必须吐槽下微信)，严重影响使用，于是自己在春节期间将相关的文件备份后对自己的安卓手机进行了格式化与刷机(但是没有对GitHub与Authy进行备份设置)，以确保手机中有足够的存储空间。\n之后自己通过git依旧能正常的给GitHub提交并推送代码，让我误以为一切正常，知道前段时间自己想登录网页版的GitHub,当我输入完正确的邮箱和密码后，GitHub提示要求输入2FA相关的认证码\n此时我的手机已经格式化重刷系统有一段时间了，Authy和GitHub Mobile随着手机刷机已经消失不见了! 一开始我以为只要把Authy在手机上安装好，然后重新获取对应的认证码即可，但事实证明，我大意了！\nAuthy尝试 由于国内特殊的网络环境，自己首先确保了手机可以正常科学上网。\n之后便迫不及待的在手机上安装了Authy，不过打开该软件之后，其首先要求我通过短信或电话输入验证码，之后才能登录。\n一开始我尝试通过发短信的方式获取验证码，但一直提示无法识别手机号，开启科学上网也是如此。\n接下来选择给我拨打语音电话，但无论是否开启科学上网，手机一直都无法接听到对应呼叫。\n为了排除是否是自己手机问题，用其他同事的苹果手机安装Authy并进行测试，依旧无法获取到认证码！\nGitHub尝试 通过Authy获取验证码这条路暂时无法走通，接下来尝试绕过Authy，看看GitHub上有没有其它方式。\n在前述的GitHub登录页面上点击 Having problems? 下面的Use a recovery code or begin 2FA account recovery链接，出现如下界面\n上图中提供了三种方式：\n使用authenticator app，我之前的设置为Authy，目前无法登录\n使用recovery code,官方文档上说该文件的名称为github-recovery-codes.txt，但多次全局搜索自己的笔记本电脑，均为找到该文件，此路也不通\n点击下方的 Try 2FA account recovery, or unlink your account email address(es) 链接，出现类似如下界面\n点击确认按钮之后，出现如下界面\n该界面上虽然有多个选项，但具体到我自己的账号时只有 Personal access token 和 Start unlinking email 这2个选项，其中Start unlinking email表示在尝试各种方法之后都无法找回账号时，将注册邮箱与当前账号解除绑定关系，使用此种方式意味着已经放弃治疗，只能保留邮箱，而账号无法恢复，只能fork非private的仓库，不到万不得已，此种方式不考虑。\n翻看自己的电脑磁盘和博客记录，在编写利用GitHub Action实现Hugo博客在GitHub Pages自动部署这篇文章时，自己记录过相关的personal access token，然而自己之前为了方便在博客中展示，将对应信息进行了马赛克处理，而我本地又没保存相关的token值，此条路也走不通！\nAuthy邮件 在GitHub上折腾了一圈后还是没能找到有效的解决办法，只能给Authy 官方发邮件咨询为啥在手机上无法收到短信或电话，给Authy发邮件时，需要在其官网上先注册登录之后才能进行，奇怪的是在其网页版的官网上登录时，同样的手机号能收到验证码，就是用手机APP时死活收不到验证码。\n相对于下文要说的GitHub官方的技术支持邮件回复的慢吞吞，Authy官方的技术支持邮件回复还算及时，我发了邮件之后等了2天就有回复了，在我告知必要的信息之后告知我是由于个人的Authy账号被它们的系统判定有异常，给blocked了，才导致自己手机上的Authy一直无法正常登录。\n在收到Authy账号恢复的邮件后，我立马在手机上登录Authy期望能出现自己预想中的Authentication code，然而现实又给了我一次重击，虽然成功登陆了Authy，但是里面空空如也，没有地方可以获取Authentication code！\n可是我自己之前明明在Authy中关联过GitHub相关的认证，最开始配置的时候还用过里面生成的Authentication code，为何现在啥都没有了？无奈之下只好继续给Authy技术支持人员写邮件寻求帮助，而得到的结果却让我更加郁闷，我之前没有在Authy中开启备份功能，所以重新安装Authy后需要重新关联GitHub认证配置！\nGitHub邮件 为了登录GitHub需要获取Authy中的Authentication code，而为了获取Authy中的Authentication code需要登录GitHub后重新配置，陷入死循环了！\n此时的我已经感到一丝紧张，难道我的GitHub账号真的要丢失？\n虽然里面没啥有价值的东西，关注和被关注人也不多，重新创建一个账号后fork迁移也不是很麻烦，但是我的GitHub开启了GitHub Pages并且绑定了个人域名，而个人域名不久前才续费了5年，牵一发而动全身。\n不到万不得已，我是不会走到Start unlinking email这一步的。\n查看网上的资料，发现其他遇到类似问题的人可以通过ssh -vT git@github.com verify来获取之前设置好的token，之后让GitHub官方人员协助解决，前提是git能正常连接访问GitHub。\n我测试了下自己的电脑，发现在git中可以正常的commit和push代码，但是ssh -vT git@github.com verify却不好使。\n既然git能正常的commit和push，那我本地肯定有相关的token或key信息，事情还有一丝转机。\n一开始自己想找GitHub Support的人工客服，找了一会发现并没有，只有如下所示的一个虚拟机器人\n其回答问题只有简单的yes or no,要是都不满足条件，最后给你来一句there are unfortunately xxx,卵用没有！\n只能给GitHub Support写邮件咨询，这个过程中又遇到很操蛋的事情：\n要给GitHub Support写邮件需要先登录GitHub，但我就是无法完全登录GitHub才想写邮件求助的，又陷入死循环了！\nWhat a fuck!\n只能又在网上搜索相关资料，好不容易找了一个可以非登录发邮件的入库，结果还要给自己绑定的邮箱发临时验证码，不得不说GitHub这块确实挺操蛋的，还好我自己密码没忘记，总算找到了一个反馈入口。\n为了避免像之前咨询Authy时反复咨询回复邮件的问题，我给GitHub官方的技术支持人员写了一封很详细的邮件，添加了各种截图以及之前Authy官方回复的附件，重点是说明我本地通过git可以正常的commit和push，同时说明了我本地有打马赛克的Personal access token，看看GitHub Support能否基于这些判断我是账号的拥有者并协助登录。\n在我邮件发送之后GitHub Support立马给我自动回复了一封很机械的邮件，重点是说我们的业务量很大，所以你要多等一段时间。\n没关系，等就等呗。\n让我想不到的是，这一等就等了十多天，即使我中途又补发了两封邮件来更详细的描述和催促，依旧没有响应，没办法只能等了。\n等了十多天之后，终于收到邮件回复，但其内容又是毫无营养的官样回复。\n虽然我的邮件里面写的特别详细，并提出了不少问题，但这封邮件只回复了两个问题：\n我们记录到你在2023年8月份下载过github-recovery-codes.txt文件，建议你再仔细找找该文件，但我的电脑已经搜索过N次，都没找到 虽然你提供了Personal access token，但打了马赛克无法使用，需要提供完整的，同时根据已有的截图显示，该token的后缀不正常，就算有完整的，也不能作为恢复凭据。 看起来通过GitHub Support邮件咨询的这条路也走不通，此时我已经做好账号丢失的心理准备了。\n找回恢复码 在解除GitHub邮箱绑定之前，我有些不死心，于是又给GitHub Support回复了如下的邮件，主要内容有2点：\n既然你们记录到我已经下载过github-recovery-codes.txt文件，但是我本地并没有找到，请说下具体日期，方便我进一步排查 想具体了解下为啥通过git可以正常的commit和push，但是ssh -vT git@github.com verify不好使。 还好，这次发完邮件后第2天他们就给我回复了\n虽然依旧是机械回复，并没有解决我的实际问题，但GitHub Support的支持人员这么肯定我下载过github-recovery-codes.txt文件并且精确到了分钟，那就表示我肯定下载过。\n于是在笔记本上再次全局搜索，无果后，去自己不常用的台式机上搜索，废了九牛二虎之力在回收站里面找到了那个文件，赶紧还原，打开该文件一看，数据都在，然后就是按照GitHub官方的说明基于recovery code进行恢复。\n至此，GitHub账号恢复的事情告一段落。\n总结\u0026amp;教训 遇到事情一定要尝试各种可能的解决方案，不到最后一步，千万不要放弃 做人做事要仔细认证，不要走马观花，如果一开始设置完2FA后就仔细阅读GitHub官方发的邮件，及时做好备份，也不会这么折腾 AI时代，人工客户越来也少,机器人客服越来越多，对资本家是好事，对普通用户不一定是好事，要学会适应潮流与大趋势。 https://docs.github.com/en/authentication/securing-your-account-with-two-factor-authentication-2fa/about-mandatory-two-factor-authentication\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-04-03T10:12:47+08:00","permalink":"https://lucumt.info/post/github/recovery-github-code-when-2fa-not-working/","tags":["github","git","ssh"],"title":"[杂谈]记一次个人GitHub账号的找回过程"},{"categories":["工具使用","容器化"],"contents":"简要记录如何基于docker-compose的方式安装Pinpoint，以及基于Dockerfile与Jenkins流水线将项目添加到Pinpoint中进行实时监控。\ndocker-compose安装 按照下述指令安装docker-compose:\n# 下载安装docker-compose curl -L https://get.daocloud.io/docker/compose/releases/download/1.29.2/docker-compose-`uname -s`-`uname -m` \u0026gt; /usr/local/bin/docker-compose # 将其设置为可执行 chmod \u0026#43;x /usr/local/bin/docker-compose # 验证是否安装正确 docker-compose version Pinpoint安装与测试 在终端执行下述指令下载Pinpoint全家桶并解压该文件\nwget https://github.com/pinpoint-apm/pinpoint-docker/archive/refs/tags/2.2.2.tar.gz tar -zxvf 2.2.2.tar.gz 进入该目录，可发现其把相关的组件都下载完毕\n在该目录下创建一个名为start.sh的脚本文件，写入如下内容\n#!/bin/bash docker-compose up -d zoo1 zoo2 zoo3 pinpoint-quickstart pinpoint-hbase pinpoint-agent pinpoint-web pinpoint-collector 执行下述命令启动Pinpoint全套的服务\nbash start.sh 若一切正常约5-10秒左右就会启动完毕，执行输出类似如下(第一次执行时会下载相关的镜像，此时耗时较长)\nPinpoint默认的服务器端口在pinpoint-web下的.env配置文件中，默认值为8079，可根据实际情况修改\n在浏览器中输入http://IP:8079若出现类似如下界面，则表示Pinpoint安装成功！\n若想关闭Pinpoint服务，同样可在该目录下创建一个名为stop.sh的脚本，写入如下内容，然后执行该脚本即可\n#!/bin/bash docker-compose down zoo1 zoo2 zoo3 pinpoint-quickstart pinpoint-hbase pinpoint-agent pinpoint-web pinpoint-collector 将新系统接入Pinpoint 目前的接入方案是在通过Jenkins部署时，通过脚本的方式自动替换相关的文件，然后打包部署，流程图如下\nflowchart LR start_deploy((开始部署)) --\u003e clone_code[下载代码] git[(代码仓库)] --\u003e |Git|clone_code[下载代码] clone_code[下载代码] --\u003e compile_code[编译代码] compile_code --\u003e|shell脚本| repalce_dockerfile[替换Dockerfile] nginx_folder[(Nginx目录)] --\u003e |直接访问文件地址|download_pinpoint download_pinpoint[下载Pinpoint] --\u003e|通过wget下载| config_pinpoint[修改Pinpoint配置] config_pinpoint --\u003e|移动到当前代码目录|repalce_dockerfile repalce_dockerfile --\u003e docker_build[镜像构建] docker_build --\u003e docker_deploy[服务部署] docker_deploy --\u003e deploy_finish((部署完毕)) style start_deploy fill:#75efb9,stroke:#333 style deploy_finish fill:#75efb9,stroke:#333 相关的参考配置如下：\n利用Nginx搭建一个静态的文件下载服务器，核心配置如下\nserver { listen 8788; server_name zip-download; location ~.*\\.(gz|zip)$ { root /root/idp/; # 自动创建目录文件列表为首页 autoindex on; # 自动首页的格式为html autoindex_format html; # 关闭文件大小转换 autoindex_exact_size off; # 按照服务器时间显示文件时间 autoindex_localtime on; default_type application/octet-stream; # 开启零复制。默认配置中，文件会先到nginx缓冲区，开启零复制后，文件跳过缓冲区，可以加快文件传输速度。 sendfile on; # 限制零复制过程中每个连接的最大传输量 sendfile_max_chunk 1m; # tcp_nopush与零复制配合使用，当数据包大于最大报文长度时才执行网络发送操作，从而提升网络利用率。 tcp_nopush on; # 启用异步IO，需要配合direcio使用 # aio on; # 大于10MB的文件会采用直接IO的当时进行缓冲读取 directio 10m; # 对齐文件系统块大小4096 directio_alignment 4096; # 启用分块传输标识 chunked_transfer_encoding on; # 文件输出的缓冲区大小为128KB output_buffers 4 32k; } location / { root html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; } 在Docker镜像构建时，添加上Pinpoint相关的配置，Dockerfile内容如下\nFROM openjdk:8-jdk LABEL maintainer=lucumt@gmail.com RUN mkdir -p /home/xxxx WORKDIR /home/xxxx ARG DEPLOY_NAME ARG PRODUCT_PHASE ARG NODE_PORT ENV PARAMS1=\u0026#34;${DEPLOY_NAME}.jar\u0026#34; ENV PARAMS2=\u0026#34;--server.port=${NODE_PORT} --spring.application.name=${DEPLOY_NAME} --spring.profiles.active=${PRODUCT_PHASE}\u0026#34; RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \u0026amp;\u0026amp; echo \u0026#39;Asia/Shanghai\u0026#39; \u0026gt;/etc/timezone ARG PROJECT_VERSION ENV BUILD_FILE=\u0026#34;${DEPLOY_NAME}/target/${DEPLOY_NAME}-${PROJECT_VERSION}.jar\u0026#34; RUN echo \u0026#34;build file version: ${BUILD_FILE}\u0026#34; COPY ${BUILD_FILE} /home/xxxx/${PARAMS1} COPY pinpoint /home/xxxx/pinpoint RUN ls # 添加Pinpoint相关的依赖 ENV AGENT=\u0026#34;-javaagent:/home/xxxx/pinpoint/pinpoint-bootstrap-1.8.5.jar -Dpinpoint.agentId=${PRODUCT_PHASE} -Dpinpoint.applicationName=${DEPLOY_NAME}\u0026#34; ENTRYPOINT [\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;java ${AGENT} -Dfile.encoding=utf8 -jar ${PARAMS1} ${PARAMS2}\u0026#34;] 在Jenkins中采用Shell脚本对Dockerfile进行替换并打包，对应的流水线代码如下，其核心为通过profiler.collector.ip指定Pinpoint服务器的IP地址，对于SpringBoot项目，将actuator健康检查的接口屏蔽掉，避免在Kubernetes等环境下干扰使用\nstage(\u0026#39;镜像构建\u0026#39;) { agent none steps { container(\u0026#39;maven\u0026#39;) { sh \u0026#39;\u0026#39;\u0026#39; if [ ${PRODUCT_PHASE} = \u0026#39;dev-8\u0026#39; ]; then echo \u0026#34;部署的脚本模块为comm 且需要下载pinpoint\u0026#34; wget -nv http://aeectss.xxxx.local:8788/pinpoint/pinpoint-agent-1.8.5.tar.gz mkdir pinpoint tar -xf pinpoint-agent-1.8.5.tar.gz -C pinpoint rm -rf pinpoint-agent-1.8.5.tar.gz sed -i \u0026#34;s/profiler.collector.ip=127.0.0.1/profiler.collector.ip=10.0.18.119/g\u0026#34; pinpoint/pinpoint.config sed -i \u0026#34;s/profiler.tomcat.excludeurl=\\\\/aa\\\\/test.html, \\\\/bb\\\\/exclude.html/profiler.tomcat.excludeurl=\\\\/comm\\\\/actuator\\\\/health/g\u0026#34; pinpoint/pinpoint.config #cat pinpoint/pinpoint.config cd kubesphere rm Dockerfile mv Dockerfile_Pinpoint Dockerfile cd .. fi \u0026#39;\u0026#39;\u0026#39; script { deployNameList.each{ env.DEPLOY_NAME = it env.NODE_PORT = nodePortMapp[it] env.JAVA_OPTS = javaOptsMapp[it] sh \u0026#39;\u0026#39;\u0026#39;docker build -f kubesphere/Dockerfile \\\\ -t $DEPLOY_NAME-$PRODUCT_PHASE:$BUILD_TAG \\\\ --build-arg DEPLOY_NAME=$DEPLOY_NAME \\\\ --build-arg PROJECT_VERSION=$PROJECT_VERSION \\\\ --build-arg NODE_PORT=$NODE_PORT \\\\ --build-arg JAVA_OPTS=\u0026#34;$JAVA_OPTS\u0026#34; \\\\ --build-arg PRODUCT_PHASE=$PRODUCT_PHASE .\u0026#39;\u0026#39;\u0026#39; } } } } } 实际访问效果如下，可发现在主页中能够显示相关项目\n","date":"2024-03-13T18:10:19+08:00","permalink":"https://lucumt.info/post/docker/install-pinpiont-via-docker/","tags":["docker"],"title":"通过Docker快速安装Pinpoint"},{"categories":["工具使用","持续集成"],"contents":"近期有个项目组有个Vue项目需要在基于KubeSphere的Jenkins流水线中用高版本的nodejs进行编译，自己一开始尝试通过在流水线中直接升级nodejs版本，但并未成功，后来参考KubeSphere论坛上的相关说明才解决该问题，简单记录下。\n问题\u0026amp;尝试 项目中使用的KubeSphere版本为v3.3.1，基于nodejs环境对某个 Vue3项目进行编译打包时，KubeSphere提示构建过程出错。Google搜索一番过后，大部分都说要升级nodejs版本，自己当前的版本为v10.16.3，确实有些低，于是尝试用如下指令升级版本\nrm -rf node_modules package-lock.json yarn.lock npm cache clean --force npm config set registry https://mirrors.xxx.com/repository/NPM/ npm install node@16.16.0 npm install node -v npm run build:qiankun 重新执行后依旧报错，同时node -v输出的结果依然是v10.16.3，版本不是预期的升级后版本。\n为啥npm install node@16.16.0这条指令执行正常，而node -v输出的仍然为旧版本呢？\n在构建之前添加如下两条指令进行分析\n$PWD/node_modules/node/bin/node -v node config list 输出结果如下\n可以看出npm install node@16.16.0只是升级当前工程的nodejs版本，但是全局的版本还是旧的而编译时使用的是全局版本，导致问题出现。\n将该指令变为npm install node@16.16.0 -g再次执行，结果提示权限不足\n至于为什么权限不足，原因也很简单，因为我们是在Jenkins流水线中执行该指令的，Jenkins每次执行都会创建一个临时目录，其出于安全考虑并没有赋予执行过程全部的权限。\n通过Jenkins升级nodejs版本这条路走不通，那能否通过对相关工程源码进行修改，让其兼容低版本呢？内部讨论后出于下述考量，此方案也不可行：\n降低工程依赖的nodejs 版本会涉及到大量的功能逻辑，需要进行全面的测试，确保没有引入新问题 后续其它工程模块可能也会使用高版本的nodejs，从出于扩展的角度考虑此问题早晚都要解决 软件开发领域理论上要求 高版本要能兼容低版本，能否通过统一升级Jenkins中所用的nodejs版本来解决此问题呢？虽然理论分析确实可行，不过此种方式只能升级到特定版本，无法同时兼容多个版本，同时所有的前端项目构建都会受到影响，灵活性不高。\n既然遇到了这个问题，个人希望一次性解决，最好能在流水线中指定所需的版本，与其它的流水线完全隔离！\n解决 由于自己采用的是KubeSphere来集成Jenkins，其他人是否遇到了类似问题？通过相关关键词搜索后发现一篇文章kubesphere3.1.1，devops工程如何升级node.js，其遇到的问题和我自己的很类似。\n根据该问题中的回复，需要对Jenkins流水线文件头部的配置进行修改\n原始配置如下\nagent { node { label \u0026#39;nodejs\u0026#39; } } 修改为\nagent { kubernetes { inheritFrom \u0026#39;nodejs base\u0026#39; containerTemplate { name \u0026#39;nodejs\u0026#39; image \u0026#39;node:16.16.0\u0026#39; } } } 同时将前端构建指令修改如下\nrm -rf node_modules package-lock.json yarn.lock npm cache clean --force npm config set registry https://mirrors.xxx.com/repository/NPM/ npm install node -v npm run build:qiankun 再次执行相关构建，输出类似如下，可以看出nodejs版本已经修改为我们希望的版本，且能正常编译通过\n基于上述方式修改后，初次执行时可能会出现类似如下错误，出错的原因是相关镜像还没下载下来，多执行几次即可。\n当流水线全部执行完毕时，发现无法识别docker指令，导致无法进行编译构建。\n继续在该问题下寻找答案，发现KubeSphere官方的技术支持人员有给出答案\n将docker构建阶段的容器从nodejs修改为base即可，重新执行流水线可正常执行1，至此问题解决完毕。\nstage(\u0026#39;镜像构建\u0026#39;) { agent none steps { container(\u0026#39;base\u0026#39;) { sh \u0026#39;\u0026#39;\u0026#39;echo $NODE_PORT cat cicd/Dockerfile docker build -f cicd/Dockerfile --build-arg PRODUCT_PHASE=$PRODUCT_PHASE -t orienlink-evaluator-web:$BUILD_TAG .\u0026#39;\u0026#39;\u0026#39; } } } } 后记 虽然此文以nodejs举例，但对于其它的语言也可适用，假设使用的是Golang，对应的Jenkins流水线文件头部可修改如下\nagent { kubernetes { inheritFrom \u0026#39;go base\u0026#39; containerTemplate { name \u0026#39;go\u0026#39; image \u0026#39;go:1.22.2\u0026#39; } } } 通过上述方式可实现基于流水线级别的版本变更与隔离，使用起来更加方便。\n完整的Jenkins流水线参见lucumt-nodejs-version-change.groovy\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-01-11T10:17:42+08:00","permalink":"https://lucumt.info/post/devops/switch-nodejs-version-in-jenkins-pipeline/","tags":["kubesphere","jenkins"],"title":"在基于KubeSphere的Jenkins的流水线中切换nodejs版本"},{"categories":["工具使用"],"contents":"在在Docker中构建GitBook并整合GitLab Runner的使用经验分享一文中，自己在Docker环境下基于GitLab Runner实现了GitBook的自动构建，同时基于实际使用需求添加了很多GitBook插件，在此过程中积累了一些GitBook插件的开发与使用经验。\n本文简要介绍自己在GitBook插件定制化修改过程中如何实现从多个不同的文件夹下加载js和css文件的实现过程。\n问题背景 由于GitBook官方默认的代码高亮插件highlight使用的是highlightjs，其功能没有prismjs完善，故最初将GitBook的代码高亮采用prismjs实现，对应的插件为gitbook-plugin-prism，其使用方式也很简单，只需要在book.json中添加如下配置:\n{ \u0026#34;plugins\u0026#34;: [\u0026#34;prism\u0026#34;, \u0026#34;-highlight\u0026#34;] } 该插件使用起来一切正常，由于部门GitBook的一大用途是记录设计方案与实现的代码，经常会有多个功能相似的对比代码进行展示，占用了大量的空间篇幅且阅读也不是很方便，需要添加一个tab效果对其进行分组归类。\n在网上搜索相关的GitBook插件后，主要有gitbook-plugin-codegroup以及gitbook-plugin-codetabs，它们的对比如下：\ngitbook-plugin-codegroup gitbook-plugin-codetabs 代码高亮实现 highlight prism 代码写入方式 进行markdown中代码块原生语法，typora展示更方便 GitBook代码块，typora展示不友好 插件改造难度 高 低 综合对比后，决定采用gitbook-plugin-codetabs结合gitbook-plugin-prism两者结合，同时代码块的输入还是采用类似 ``` 包裹的方式以便与markdown和typora的使用方式保持一致。\n确定好方案后，接下来就需要将这两个插件组合到一起，查看它们的源码，发现都各自引入了静态文件\n自己首先想到的是添加多个assets然后在js和css使用完整路径，类似如下：\nmodule.exports = { book: { assets: [\u0026#39;./assets1\u0026#39;,\u0026#39;./assets2\u0026#39;], css: [ \u0026#39;codetabs1.css\u0026#39;,\u0026#39;codetabs2.css\u0026#39; ], js: [ \u0026#39;codetabs1.js\u0026#39;,\u0026#39;codetabs2.js\u0026#39; ] }, 但此种方式明显不可行，通过gitbook serve启动之后，终端控制台提示类似如下错误\nTypeError [ERR_INVALID_ARG_TYPE]: The \u0026#34;path\u0026#34; argument must be of type string. Received an instance of List 很明显assets的值只能为单个字符串，不能为数组。\n接下来尝试将assets 配置去掉，改为类似如下代码\nbook: { css: [ \u0026#39;./assets1/codetabs1.css\u0026#39;,\u0026#39;./assets2/codetabs2.css\u0026#39; ], js: [ \u0026#39;./assets1/codetabs1.js\u0026#39;,\u0026#39;./assets2/codetabs2.js\u0026#39; ] }, 此时通过gitbook serve启动时，终端控制台提示一切正常，但访问对应的页面时，显示效果不正常，通过Chrome调试工具可发现上述的js和css都显示为404，都未能正常加载，导致页面显示不正常。\n看来assets属性不能省略，且不能以数组方式配置，此时很容易想到的是将这些静态资源文件都放置到一个文件夹下，不就解决了此问题？\n理论上确实可行，但是理想很丰满，现实很骨感，此种方式并不能满足自己的实际需求！\n原因为gitbook-plugin-prism插件的index.js中有如下代码，通过此代码可知gitbook-plugin-prism中是通过去npm仓库中获取prismjs的源文件，而不是直接将primsjs下载到该插件的资源文件目录下，通过这种方式可实现gitbook-plugin-prism与prismjs的解耦，且能快速的升级prismjs，是一个合理且优秀的设计！\n作为一个对代码编写要求很高的人，当前要将别人优秀的习惯保持下来，这样的话就不能将代码分组的静态文件与prismjs代码高亮相关的文件混合在一起，问题产生！\nfunction getAssets() { var cssFiles = getConfig(this, \u0026#39;pluginsConfig.prism.css\u0026#39;, []); var cssFolder = null; var cssNames = []; var cssName = null; if (cssFiles.length === 0) { cssFiles.push(\u0026#39;prismjs/themes/prism.css\u0026#39;); } cssFiles.forEach(function(cssFile) { var cssPath = require.resolve(cssFile); cssFolder = path.dirname(cssPath); cssName = path.basename(cssPath); cssNames.push(cssName); }); return { assets: cssFolder, css: cssNames }; } 解决方案 既不能同时支持多个assets属性，自己又不想破坏prismjs本身的结构，怎么办？\n一开始自己通过Google和GitHub去查找相关的资料，没有找到自己想要的东西，后来用ChatGPT连续切换了好几次提示词，结果答案都是错的.\nPS:个人鄙视在编程中遇到问题无脑使用ChatGPT,个人观点是要明白其底层原理，找到合适的使用方法。ChatGPT是基于训练的，网络上相关资料越丰富，ChatGPT训练的材料也就越多，其给出的答案也就越准确，反之，对于新出现的技术，网上资料很少或者ChatGPT来不及训练，此时就不能给出准确的答案了。\n通过前述方式没有找到自己想要的答案，没办法只能在Stackoverflow上用英文提问，希望能有人给回复，遗憾的提出问题之后一周也没人回复，只能另想它法了。\n分析GitBook中插件的生成结果，发现要想某个静态资源文件能够被访问到，其必须在_book目录下对应的插件中存在，之前的去掉assets后gitbook serve不报错，但是js和css 加载出现404即是这个原因。\n找到问题原因后，接下来自己尝试手工把相关的js和css文件加到_book下对应的插件目录中，此时可通过浏览器地址直接访问，不会出现404问题，但是相关的静态资源文件仍然没有加载，在生成的html源码中也没有看见。\n问题原因为我们没有在下述代码中引入对应的js和css文件。\nbook: { assets: \u0026#39;./assets\u0026#39;, css: [ \u0026#39;codetabs.css\u0026#39; ], js: [ \u0026#39;codetabs.js\u0026#39; ] }, 要想文件被加载，则必须要引入相关文件，要想文件能被正常访问，在_book下对应的插件目录中必须要有对应的文件。\n至此，问题的解决方案找到！\n引入文件很容易实现，直接在数组中添加对应的文件即可，但如何引入相关文件呢？经过多处查看代码后，自己在index.js中找到了答案\ntry { fs.writeFileSync(outputFile, fs.readFileSync(inputFile)); } catch (e) { console.warn(\u0026#39;Failed to write prism-ebook.css. See https://git.io/v1LHY for side effects.\u0026#39;); console.warn(e); } 利用相关的JavaScript API手工将文件写入_book下对应插件的目录中！之后将assets的值设置为对应插件的名称，既能同时访问多个文件！\n经过多次测试，最终捣鼓出可用的代码，在不破坏prismjs完整性的同时还能加载插件自身的js和css文件，完整代码参见gitbook-plugin-prism-codetab-fox\n核心的index.js代码如下，主要是通过syncFile函数进行文件写入：\nvar Prism = require(\u0026#39;prismjs\u0026#39;); var languages = require(\u0026#39;prismjs\u0026#39;).languages; var path = require(\u0026#39;path\u0026#39;); var fs = require(\u0026#39;fs\u0026#39;); var cheerio = require(\u0026#39;cheerio\u0026#39;); var mkdirp = require(\u0026#39;mkdirp\u0026#39;); var codeBlocks = require(\u0026#39;gfm-code-blocks\u0026#39;); var trim = require(\u0026#39;lodash/trim\u0026#39;); const includes = require(\u0026#39;lodash/includes\u0026#39;); const get = require(\u0026#39;lodash/get\u0026#39;); var DEFAULT_LANGUAGE = \u0026#39;markup\u0026#39;; var DEFAULT_CODE_TAB_SEPERATOR = \u0026#39;::\u0026#39;; var MAP_LANGUAGES = { \u0026#39;py\u0026#39;: \u0026#39;python\u0026#39;, \u0026#39;js\u0026#39;: \u0026#39;javascript\u0026#39;, \u0026#39;rb\u0026#39;: \u0026#39;ruby\u0026#39;, \u0026#39;cs\u0026#39;: \u0026#39;csharp\u0026#39;, \u0026#39;sh\u0026#39;: \u0026#39;bash\u0026#39;, \u0026#39;html\u0026#39;: \u0026#39;markup\u0026#39; }; // Base languages syntaxes (as of prism@1.6.0), extended by other syntaxes. // They need to be required before the others. var PRELUDE = [ \u0026#39;markup-templating\u0026#39;, \u0026#39;clike\u0026#39;, \u0026#39;javascript\u0026#39;, \u0026#39;markup\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;ruby\u0026#39;, \u0026#39;css\u0026#39;, // The following depends on previous ones \u0026#39;java\u0026#39;, \u0026#39;php\u0026#39; ]; PRELUDE.map(requireSyntax); /** * Load the syntax definition for a language id */ function requireSyntax(lang) { require(\u0026#39;prismjs/components/prism-\u0026#39; \u0026#43; lang \u0026#43; \u0026#39;.js\u0026#39;); } function getConfig(context, property, defaultValue) { var config = context.config ? /* 3.x */ context.config : /* 2.x */ context.book.config; return config.get(property, defaultValue); } function isEbook(book) { // 2.x if (book.options \u0026amp;\u0026amp; book.options.generator) { return book.options.generator === \u0026#39;ebook\u0026#39;; } // 3.x return book.output.name === \u0026#39;ebook\u0026#39;; } function getAssets() { var cssFiles = getConfig(this, \u0026#39;pluginsConfig.prism.css\u0026#39;, []); var cssFolder = null; var cssNames = []; var cssName = null; if (cssFiles.length === 0) { cssFiles.push(\u0026#39;prismjs/themes/prism.css\u0026#39;); } cssFiles.forEach(function(cssFile) { var cssPath = require.resolve(cssFile); cssFolder = path.dirname(cssPath); cssName = path.basename(cssPath); cssNames.push(cssName); }); cssNames.push(\u0026#39;codetab/codetab.css\u0026#39;); return { assets: cssFolder, css: cssNames, js: [\u0026#39;codetab/codetab.js\u0026#39;] }; } function syncFile(book, outputDirectory, outputFile, inputFile) { outputDirectory = path.join(book.output.root(), \u0026#39;/gitbook/gitbook-plugin-prism-codetab-fox/\u0026#39; \u0026#43; outputDirectory); outputFile = path.resolve(outputDirectory, outputFile); inputFile = path.resolve(__dirname, inputFile); mkdirp.sync(outputDirectory); try { fs.writeFileSync(outputFile, fs.readFileSync(inputFile)); } catch (e) { console.warn(\u0026#39;Failed to write \u0026#39; \u0026#43; inputFile); console.warn(e); } } module.exports = { book: getAssets, ebook: function() { // Adding prism-ebook.css to the CSS collection forces Gitbook // reference to it in the html markup that is converted into a PDF. var assets = getAssets.call(this); assets.css.push(\u0026#39;prism-ebook.css\u0026#39;); return assets; }, blocks: { code: // xxxx codetab: // xxxx }, hooks: { // Manually copy prism-ebook.css into the temporary directory that Gitbook uses for inlining // styles from this plugin. The getAssets() (above) function can\u0026#39;t be leveraged because // ebook-prism.css lives outside the folder referenced by this plugin\u0026#39;s config. // // @Inspiration https://github.com/GitbookIO/plugin-styles-less/blob/master/index.js#L8 init: function() { var book = this; syncFile(book, \u0026#39;codetab\u0026#39;, \u0026#39;codetab.js\u0026#39;, \u0026#39;./codetab/codetab.js\u0026#39;); syncFile(book, \u0026#39;codetab\u0026#39;, \u0026#39;codetab.css\u0026#39;, \u0026#39;./codetab/codetab.css\u0026#39;); // If failed to write prism-ebook.css. See https://git.io/v1LHY for side effects. if (isEbook(book)) { syncFile(book, \u0026#39;\u0026#39;, \u0026#39;prism-ebook.css\u0026#39;, \u0026#39;./prism-ebook.css\u0026#39;); } }, page: // xxx } }; 自己改造后的插件名为gitbook-plugin-prism-codetab-fox，将该插件在book.json中启用并运行gitbook install \u0026amp;\u0026amp; gitbook serve命令后，可以看见在对应的GitBook工程下分别将prismjs和codetab相关的插件都安装到node modules模块下。\n分别检查这两个js模块，可发现其内容都正常\n检查_book目录，发现生成的插件同时包含prismjs以及 codetab相关的文件，此时该插件已经将相关的内容合并了。\n查看GitBook中生成的HTML页面源码，可发现相关的静态文件均正常加载，至此问题解决！\n","date":"2023-12-10T16:21:12+08:00","permalink":"https://lucumt.info/post/gitbook/gitbook-plugin-load-css-and-js-from-multiple-folder/","tags":["gitbook"],"title":"GitBook插件中实现从多个不同的文件夹下加载css和js文件"},{"categories":["个人博客"],"contents":"介绍如何在Hugo的Even主题中添加基于Fuse.js的搜索功能。\n本文主要参考给hugo添加搜索功能实现并基于个人需求做了适当的改进，相关操作步骤如下：\n输出索引文件 在config.toml中添加如下内容，确保可输出JSON格式的数据\n[outputs] home = [\u0026#34;HTML\u0026#34;, \u0026#34;RSS\u0026#34;, \u0026#34;JSON\u0026#34;] 在layouts/_default下面创建一个index.json并写入如下内容\n{{- $.Scratch.Add \u0026#34;index\u0026#34; slice -}} {{- range .Site.RegularPages -}} {{- $.Scratch.Add \u0026#34;index\u0026#34; (dict \u0026#34;title\u0026#34; .Title \u0026#34;tags\u0026#34; .Params.tags \u0026#34;categories\u0026#34; .Params.categories \u0026#34;date\u0026#34; .Params.date \u0026#34;contents\u0026#34; .Plain \u0026#34;permalink\u0026#34; .Permalink) -}} {{- end -}} {{- $.Scratch.Get \u0026#34;index\u0026#34; | jsonify -}} 此步骤执行完毕后可通过http://IP:1313/index.json查看输出的JSON文件，结果类似如下\n此步骤较为关键，后续的检索即是对index.json的内容进行检索，其中包含了title、tag等属性，作用如下\n属性 作用 title 文章标题，关键字检索 tags 文章标签，用于关键字检索 categories 文章类别，用于关键字检索 contents 文章内容，用于关键字检索 permalink 在搜索结果中打开对应的页面 date 对搜索结果进行排序，新发布的排在前面1 创建索引页面 在content目录下创建一个名为search.md的文件，需要添加layout: \u0026quot;search\u0026quot;配置来确保其内容是通过模板文件生成，同时在菜单部分添加如下配置，确保搜索功能能展示出来\n[[menu.main]] name = \u0026#34;搜索\u0026#34; weight = 50 identifier = \u0026#34;search\u0026#34; url = \u0026#34;/search/\u0026#34; 在layouts/_default下创建一个名为search.html的文件，并写入如下内容，确保前一个步骤中的模板文件引入能生效\n{{ define \u0026#34;main\u0026#34; }} \u0026lt;section\u0026gt; \u0026lt;div\u0026gt; \u0026lt;form action=\u0026#34;{{ \u0026#34;search\u0026#34; | absURL }}\u0026#34;\u0026gt; \u0026lt;input id=\u0026#34;search-query\u0026#34; name=\u0026#34;s\u0026#34;/\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;div id=\u0026#34;search-results\u0026#34;\u0026gt; \u0026lt;h3 id=\u0026#34;search-results-info\u0026#34;\u0026gt;Matching pages\u0026lt;/h3\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;script id=\u0026#34;search-result-template\u0026#34; type=\u0026#34;text/x-js-template\u0026#34;\u0026gt; \u0026lt;div id=\u0026#34;summary-${key}\u0026#34; class=\u0026#34;search_list\u0026#34;\u0026gt; \u0026lt;h4\u0026gt;\u0026lt;a href=\u0026#34;${link}\u0026#34;\u0026gt;${title}\u0026lt;/a\u0026gt;\u0026lt;/h4\u0026gt; \u0026lt;p\u0026gt;${snippet}\u0026lt;/p\u0026gt; \u0026lt;small\u0026gt; ${ isset tags }\u0026lt;div\u0026gt;\u0026lt;b\u0026gt;标签:\u0026lt;/b\u0026gt; ${tags}\u0026lt;/div\u0026gt;${ end } ${ isset categories }\u0026lt;div\u0026gt;\u0026lt;b\u0026gt;类别:\u0026lt;/b\u0026gt; ${categories}\u0026lt;/div\u0026gt;${ end } \u0026lt;span class=\u0026#34;post-time\u0026#34;\u0026gt;\u0026lt;b\u0026gt;时间:\u0026lt;/b\u0026gt; ${date}\u0026lt;/span\u0026gt; \u0026lt;/small\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/script\u0026gt; {{ end }} 在layouts/partials/scripts.html中添加如下代码，引入对应的js文件\n\u0026lt;!-- search function --\u0026gt; {{ if eq (trim .Page.RelPermalink \u0026#34;/\u0026#34;) \u0026#34;search\u0026#34;}} \u0026lt;script src=\u0026#34;https://code.jquery.com/jquery-3.3.1.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.0/fuse.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;{{ \u0026#34;lib/search/search.js\u0026#34; | absURL }}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; {{- end }} 在static/lib/search下创建一个名为search.js的文件，并写入如下内容，它是我们的搜索核心，至此整个搜索功能添加完毕\nsummaryInclude=60; var fuseOptions = { shouldSort: true, includeMatches: true, threshold: 0.0, tokenize:true, location: 0, distance: 100, maxPatternLength: 32, minMatchCharLength: 1, keys: [ {name:\u0026#34;title\u0026#34;,weight:0.8}, {name:\u0026#34;contents\u0026#34;,weight:0.5}, {name:\u0026#34;tags\u0026#34;,weight:0.3}, {name:\u0026#34;categories\u0026#34;,weight:0.3} ] }; var searchQuery = param(\u0026#34;s\u0026#34;); if(searchQuery){ $(\u0026#34;#search-query\u0026#34;).val(searchQuery); executeSearch(searchQuery); }else { $(\u0026#39;#search-results\u0026#39;).append(\u0026#34;\u0026lt;p\u0026gt;请在上面输入一个词或词组\u0026lt;/p\u0026gt;\u0026#34;); } // sort by date function sortResult(a,b){ let time1 = new Date(b.item.date).getTime(); let time2 = new Date(a.item.date).getTime(); return time1 - time2; } function formatDate(date){ return date.split(\u0026#39;T\u0026#39;)[0]; } function executeSearch(searchQuery){ $.getJSON( \u0026#34;/index.json\u0026#34;, function( data ) { var pages = data; var fuse = new Fuse(pages, fuseOptions); var result = fuse.search(searchQuery); if(result.length \u0026gt; 0){ $(\u0026#39;#search-results-info\u0026#39;).html(\u0026#34;共检索到\u0026#34; \u0026#43; result.length \u0026#43; \u0026#34;条记录\u0026#34;).show(); result.sort(sortResult); populateResults(result); }else{ $(\u0026#39;#search-results-info\u0026#39;).html(\u0026#34;没有搜索到结果!\u0026#34;).show(); } }); } function populateResults(result){ $.each(result,function(key,value){ var contents= value.item.contents; var snippet = \u0026#34;\u0026#34;; var snippetHighlights=[]; var tags =[]; if( fuseOptions.tokenize ){ snippetHighlights.push(searchQuery); }else{ $.each(value.matches,function(matchKey,mvalue){ if(mvalue.key == \u0026#34;tags\u0026#34; || mvalue.key == \u0026#34;categories\u0026#34; ){ snippetHighlights.push(mvalue.value); }else if(mvalue.key == \u0026#34;contents\u0026#34;){ start = mvalue.indices[0][0]-summaryInclude\u0026gt;0?mvalue.indices[0][0]-summaryInclude:0; end = mvalue.indices[0][1]\u0026#43;summaryInclude\u0026lt;contents.length?mvalue.indices[0][1]\u0026#43;summaryInclude:contents.length; snippet \u0026#43;= contents.substring(start,end); snippetHighlights.push(mvalue.value.substring(mvalue.indices[0][0],mvalue.indices[0][1]-mvalue.indices[0][0]\u0026#43;1)); } }); } if(snippet.length\u0026lt;1){ snippet \u0026#43;= contents.substring(0,summaryInclude*2); } //pull template from hugo templarte definition var templateDefinition = $(\u0026#39;#search-result-template\u0026#39;).html(); //replace values var output = render(templateDefinition,{key:key,title:value.item.title,link:value.item.permalink,tags:value.item.tags,categories:value.item.categories,date:formatDate(value.item.date),snippet:snippet}); $(\u0026#39;#search-results\u0026#39;).append(output); $.each(snippetHighlights,function(snipkey,snipvalue){ $(\u0026#34;#summary-\u0026#34;\u0026#43;key).mark(snipvalue); }); }); } function param(name) { return decodeURIComponent((location.search.split(name \u0026#43; \u0026#39;=\u0026#39;)[1] || \u0026#39;\u0026#39;).split(\u0026#39;\u0026amp;\u0026#39;)[0]).replace(/\\\u0026#43;/g, \u0026#39; \u0026#39;); } function render(templateString, data) { var conditionalMatches,conditionalPattern,copy; conditionalPattern = /\\$\\{\\s*isset ([a-zA-Z]*) \\s*\\}(.*)\\$\\{\\s*end\\s*}/g; //since loop below depends on re.lastInxdex, we use a copy to capture any manipulations whilst inside the loop copy = templateString; while ((conditionalMatches = conditionalPattern.exec(templateString)) !== null) { if(data[conditionalMatches[1]]){ //valid key, remove conditionals, leave contents. copy = copy.replace(conditionalMatches[0],conditionalMatches[2]); }else{ //not valid, remove entire section copy = copy.replace(conditionalMatches[0],\u0026#39;\u0026#39;); } } templateString = copy; //now any conditionals removed we can do simple substitution var key, find, re; for (key in data) { find = \u0026#39;\\\\$\\\\{\\\\s*\u0026#39; \u0026#43; key \u0026#43; \u0026#39;\\\\s*\\\\}\u0026#39;; re = new RegExp(find, \u0026#39;g\u0026#39;); templateString = templateString.replace(re, data[key]); } return templateString; } 索引功能验证 在页面右上角的一级菜单中有一个名为搜索的链接，点击进入后会展示类似如下界面\n在搜索框中输入对应的关键字并点击Enter键后，经过1-2s的等待，会出现类似如下的页面，展示相关的搜索结果\n参考来源中的排序结果是无序的，不便于使用，故本文添加基于发布时间的排序，使得结果更直观。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-11-30T10:35:48+08:00","permalink":"https://lucumt.info/post/hugo/enable-search-in-even-theme/","tags":["hugo"],"title":"给Hugo中的Even主题添加搜索功能"},{"categories":["Web编程"],"contents":"基于create-foxglove-extension一文简要说明自己如何基于RTSP协议给Foxglove开发一款插件并应用于实际项目的流程。\n相关源码参见rtsp-player-extension。\n问题背景 Foxglove官方虽然支持十几种类型的数据播放格式，但却没有对视频流播放的支持(截至到本文写作时)1，而自动驾驶等相关的汽车研发领域对于视频文件的播放却是一个刚需，且通常需要播放多路视频。\n由于Foxglove官方支持图片、压缩图片、压缩帧这几种格式的播放，故一开始自己想的是将视频按照特定的频率抽取成多帧图片，在UI端按照时间顺序连续播放形成类似动画的效果，以间接实现视频播放的目的。\n在个人实际项目中，视频的来源是RTSP，故而最初的处理逻辑如下，需要自己实现的核心逻辑为将视频流抽帧为图片\nstart=\u003estart: 开始 end=\u003eend: 结束 connect_rtsp=\u003eoperation: 连接RTSP视频流 | pink extract_images=\u003eoperation: 抽帧为图片 | peru convert_images=\u003eoperation: 转化为Foxglove格式 | pink send_data=\u003eoperation: WebSocket发送 | pink display_data=\u003eoperation: UI端展示 | pink start-\u003econnect_rtsp(right)-\u003eextract_images(right)-\u003econvert_images(right)-\u003esend_data(right)-\u003edisplay_data-\u003eend 相关的代码如下，采用了基于Bytedeco提供的类库以FFmpeg的形式对视频进行处理。\nprivate void sendImageByRTSP() { FFmpegFrameGrabber grabber = null; try { grabber = FFmpegFrameGrabber.createDefault(rtsp); grabber.setOption(\u0026#34;rtsp_transport\u0026#34;, \u0026#34;tcp\u0026#34;); // 使用tcp的方式，不然会丢包很严重 grabber.setOption(\u0026#34;stimeout\u0026#34;, \u0026#34;500000\u0026#34;); //设置缓存大小，提高画质、减少卡顿花屏 grabber.setOption(\u0026#34;buffer_size\u0026#34;, \u0026#34;1024000\u0026#34;); grabber.start(); Java2DFrameConverter converter = new Java2DFrameConverter(); int frequency = 2; Frame frame; long startTime = System.currentTimeMillis(); long frameCount = 0; while ((frame = grabber.grabImage()) != null) { // 按照指定频率处理帧 if ((System.currentTimeMillis() - startTime) \u0026lt; (frameCount * 1000 / frequency)) { continue; } CompressedImage compressedImage = new CompressedImage(); Timestamp timestamp = new Timestamp(); int nano = Instant.now().getNano(); long second = Instant.now().getEpochSecond(); timestamp.setSec((int) second); timestamp.setNsec(nano); BufferedImage image = converter.getBufferedImage(frame); ByteArrayOutputStream baos = new ByteArrayOutputStream(); ImageIO.write(image, \u0026#34;jpeg\u0026#34;, baos); byte[] encode = Base64.getEncoder().encode(baos.toByteArray()); String data = new String(encode); compressedImage.setData(data); compressedImage.setFormat(\u0026#34;jpeg\u0026#34;); compressedImage.setFrameId(\u0026#34;main\u0026#34;); compressedImage.setTimestamp(timestamp); JSONObject jsonObject = (JSONObject) JSON.toJSON(compressedImage); byte[] bytes = getFormatedBytes(jsonObject.toJSONString().getBytes(), compressedImage.getTimestamp().getNsec(), index); this.session.sendBinary(bytes); // long类型不用担心溢出 frameCount\u0026#43;\u0026#43;; if (frameCount % 100 == 0) { log.info(LocalDateTime.now() \u0026#43; \u0026#34;----------------持续发送RTSP视频-------------------\u0026#34;); } } } catch (FFmpegFrameGrabber.Exception e) { throw new RuntimeException(e); } catch (IOException e) { throw new RuntimeException(e); } finally { try { grabber.stop(); } catch (Exception e) { e.printStackTrace(); } } } 上述代码的逻辑虽然不复杂，但在实际使用时却发现播放效果很不流畅，详细定位后发现下述代码耗时较多\nImageIO.write(image, \u0026#34;jpeg\u0026#34;, baos); // 此行单次执行需要60-70ms 表面上看60ms-70ms耗时不算很多，但若加上后续的格式转化、数据发送、数据播放等阶段，单帧图片在整合流程中的耗时就比较多了，导致实际播放时会有肉眼可见的明显卡顿。\n上述代码耗时的原因是由于涉及到IO操作，一开始自己想寻找更高效的替代实现，Google好久之后没有找到更合适的方案，为了满足实际使用需求，此问题又不得不解决。\n看来只能另想它法了。\n由于RTSP视频流可以在浏览器中直接播放，若仿照下图省略掉抽帧、转换、发送等流程，在Foxglove中通过浏览器直接播放，岂不会节省很多时间？\nstart=\u003estart: 开始 end=\u003eend: 结束 connect_rtsp=\u003eoperation: 连接RTSP视频流 | pink display_data=\u003eoperation: UI端展示 | pink start(right)-\u003econnect_rtsp(right)-\u003edisplay_data(right)-\u003eend 由于Foxglove中尚没有类似的面板可直接使用，若要实现类似功能，只能自己开发相关插件，在此之前还需进行可行性验证。\n初步验证 由于Foxglove的播放工作主要是UI端实现的，首先需要验证能否在HTML页面中直接播放RTSP视频流。\n为了模拟RTSP视频流，首先需确保安装有ffmpeg和mediamtx环境，首先在命令行中启动mediamtx，其输出界面类似如下\n在命令行中执行类似如下指令\nffmpeg -re -i E:\\foxglove\\usa_drive_2.mp4 -vcodec libx264 -acodec aac -f flv rtmp://127.0.0.1:1935/demo1 若输出结果类似如下，则表示RTSP视频流环境搭建成功\n此时在浏览器中输入http://127.0.0.1:8888/demo1即可正常播放该RTSP视频流\n创建一个HTML文件，在其中加入如下内容2，之后用浏览器打开该文件，发现视频内容也能正常播放\n\u0026lt;iframe src=\u0026#34;http://127.0.0.1:8888/demo1\u0026#34; scrolling=\u0026#34;no\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt; 至此可行性验证完毕，实际开发插件时只需要模仿步骤4即可。\n插件开发 Foxglove中开发插件的教程请参见create-foxglove-extension，本章节以RTSP播放为例简要展示开发步骤：\n首先确保自己本地安装了nodejs3和npm环境，之后执行类似下述指令，来初始化工程\nnpm init foxglove-extension@latest rtsp-player-extension cd rtsp-player-extension npm install 若上述指令执行正常，查看其源码结构类似如下，在开发插件时，只需要修改src目录下的源码，其它的基本上不用改动\n进一步的查看src目录，发现其下只有两个文件: index.ts和ExamplePanel.tsx，各自内容如下\nindex.ts内容如下：\nimport { ExtensionContext } from \u0026#34;@foxglove/studio\u0026#34;; import { initExamplePanel } from \u0026#34;./ExamplePanel\u0026#34;; export function activate(extensionContext: ExtensionContext): void { extensionContext.registerPanel({ name: \u0026#34;example-panel\u0026#34;, initPanel: initExamplePanel }); } ExamplePanel.tsx内容如下:\nimport { Immutable, MessageEvent, PanelExtensionContext, Topic } from \u0026#34;@foxglove/studio\u0026#34;; import { useEffect, useLayoutEffect, useState } from \u0026#34;react\u0026#34;; import ReactDOM from \u0026#34;react-dom\u0026#34;; function ExamplePanel({ context }: { context: PanelExtensionContext }): JSX.Element { const [topics, setTopics] = useState\u0026lt;undefined | Immutable\u0026lt;Topic[]\u0026gt;\u0026gt;(); const [messages, setMessages] = useState\u0026lt;undefined | Immutable\u0026lt;MessageEvent[]\u0026gt;\u0026gt;(); const [renderDone, setRenderDone] = useState\u0026lt;(() =\u0026gt; void) | undefined\u0026gt;(); // We use a layout effect to setup render handling for our panel. We also setup some topic subscriptions. useLayoutEffect(() =\u0026gt; { // The render handler is run by the broader studio system during playback when your panel // needs to render because the fields it is watching have changed. How you handle rendering depends on your framework. // You can only setup one render handler - usually early on in setting up your panel. // // Without a render handler your panel will never receive updates. // // The render handler could be invoked as often as 60hz during playback if fields are changing often. context.onRender = (renderState, done) =\u0026gt; { // render functions receive a _done_ callback. You MUST call this callback to indicate your panel has finished rendering. // Your panel will not receive another render callback until _done_ is called from a prior render. If your panel is not done // rendering before the next render call, studio shows a notification to the user that your panel is delayed. // // Set the done callback into a state variable to trigger a re-render. setRenderDone(() =\u0026gt; done); // We may have new topics - since we are also watching for messages in the current frame, topics may not have changed // It is up to you to determine the correct action when state has not changed. setTopics(renderState.topics); // currentFrame has messages on subscribed topics since the last render call setMessages(renderState.currentFrame); }; // After adding a render handler, you must indicate which fields from RenderState will trigger updates. // If you do not watch any fields then your panel will never render since the panel context will assume you do not want any updates. // tell the panel context that we care about any update to the _topic_ field of RenderState context.watch(\u0026#34;topics\u0026#34;); // tell the panel context we want messages for the current frame for topics we\u0026#39;ve subscribed to // This corresponds to the _currentFrame_ field of render state. context.watch(\u0026#34;currentFrame\u0026#34;); // subscribe to some topics, you could do this within other effects, based on input fields, etc // Once you subscribe to topics, currentFrame will contain message events from those topics (assuming there are messages). context.subscribe([{ topic: \u0026#34;/some/topic\u0026#34; }]); }, [context]); // invoke the done callback once the render is complete useEffect(() =\u0026gt; { renderDone?.(); }, [renderDone]); return ( \u0026lt;div style={{ padding: \u0026#34;1rem\u0026#34; }}\u0026gt; \u0026lt;h2\u0026gt;Welcome to your new extension panel!\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt; Check the{\u0026#34; \u0026#34;} \u0026lt;a href=\u0026#34;https://foxglove.dev/docs/studio/extensions/getting-started\u0026#34;\u0026gt;documentation\u0026lt;/a\u0026gt; for more details on building extension panels for Foxglove Studio. \u0026lt;/p\u0026gt; \u0026lt;div style={{ display: \u0026#34;grid\u0026#34;, gridTemplateColumns: \u0026#34;1fr 1fr\u0026#34;, rowGap: \u0026#34;0.2rem\u0026#34; }}\u0026gt; \u0026lt;b style={{ borderBottom: \u0026#34;1px solid\u0026#34; }}\u0026gt;Topic\u0026lt;/b\u0026gt; \u0026lt;b style={{ borderBottom: \u0026#34;1px solid\u0026#34; }}\u0026gt;Datatype\u0026lt;/b\u0026gt; {(topics ?? []).map((topic) =\u0026gt; ( \u0026lt;\u0026gt; \u0026lt;div key={topic.name}\u0026gt;{topic.name}\u0026lt;/div\u0026gt; \u0026lt;div key={topic.datatype}\u0026gt;{topic.datatype}\u0026lt;/div\u0026gt; \u0026lt;/\u0026gt; ))} \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt;{messages?.length}\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ); } export function initExamplePanel(context: PanelExtensionContext): () =\u0026gt; void { ReactDOM.render(\u0026lt;ExamplePanel context={context} /\u0026gt;, context.panelElement); // Return a function to run when the panel is removed return () =\u0026gt; { ReactDOM.unmountComponentAtNode(context.panelElement); }; } 可以看出index.ts的作用为注册要开发的面板，而ExamplePanel.tsx则是具体业务逻辑实现，同时该文件中有详细的注释辅助我们理解。\n同时通过ExamplePanel.tsx也可发现 Foxglove中的插件开发本质上是开发新的面板。\n将ExamplePanel.tsx修改为RTSPPanel.tsx，并将其内容修改如下：\nimport { Immutable, MessageEvent, PanelExtensionContext} from \u0026#34;@foxglove/studio\u0026#34;; import { useEffect, useLayoutEffect, useState } from \u0026#34;react\u0026#34;; import ReactDOM from \u0026#34;react-dom\u0026#34;; interface Timestap{ sec:number; nsec:number; } interface RtspInfo { rtsp_url: string; chassis_code: string; timestamp: Timestap; } const frameStyle = { overflow:\u0026#39;hidden\u0026#39;, height:\u0026#39;100%\u0026#39;, width:\u0026#39;100%\u0026#39;, }; function RTSPPanel({ context }: { context: PanelExtensionContext }): JSX.Element { const [messages, setMessages] = useState\u0026lt;undefined | Immutable\u0026lt;MessageEvent[]\u0026gt;\u0026gt;(); const [rtspUrl, setRtspUrl] = useState\u0026lt;string\u0026gt;(); const [renderDone, setRenderDone] = useState\u0026lt;(() =\u0026gt; void) | undefined\u0026gt;(); useLayoutEffect(() =\u0026gt; { context.onRender = (renderState, done) =\u0026gt; { setRenderDone(() =\u0026gt; done); setMessages(renderState.currentFrame); }; context.watch(\u0026#34;currentFrame\u0026#34;); context.subscribe([{ topic: \u0026#34;/drive/chassis_code\u0026#34; }]); }, [context]); let rtsp_url:string = \u0026#39;http://127.0.0.1:8888/demo1\u0026#39;; useEffect(() =\u0026gt; { if (messages) { messages.forEach(m =\u0026gt; { let info = m.message as RtspInfo; rtsp_url = info.rtsp_url; setRtspUrl(rtsp_url) }) } }, [messages]); // invoke the done callback once the render is complete useEffect(() =\u0026gt; { renderDone?.(); }, [renderDone]); return ( \u0026lt;iframe style={ frameStyle } src = { rtspUrl as string } allow=\u0026#34;autoplay\u0026#34;\u0026gt; \u0026lt;/iframe\u0026gt; ); } export function initRTSPPanel(context: PanelExtensionContext): () =\u0026gt; void { ReactDOM.render(\u0026lt;RTSPPanel context={context} /\u0026gt;, context.panelElement); // Return a function to run when the panel is removed return () =\u0026gt; { ReactDOM.unmountComponentAtNode(context.panelElement); }; } 将index.ts修改如下，至此源码修改完成\nimport { ExtensionContext } from \u0026#34;@foxglove/studio\u0026#34;; import { initRTSPPanel } from \u0026#34;./RTSPPanel\u0026#34;; export function activate(extensionContext: ExtensionContext): void { extensionContext.registerPanel({ name: \u0026#34;RTSP流媒体播放\u0026#34;, initPanel: initRTSPPanel }); } 在项目根目录下打开命令行，执行下述指令，即可生成一个扩展名为foxe的插件\nnpm run package 默认情况下生成的插件名类似unknown.rtsp-player-extension-0.0.0.foxe，里面的unknown和0.0.0看着很刺眼，可将package.json中的publisher和version修改为类似如下\n{ \u0026#34;name\u0026#34;: \u0026#34;rtsp-player-extension\u0026#34;, \u0026#34;displayName\u0026#34;: \u0026#34;rtsp-player-extension\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;publisher\u0026#34;: \u0026#34;lucumt\u0026#34;, \u0026#34;homepage\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.0.1\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;UNLICENSED\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;./dist/extension.js\u0026#34;, \u0026#34;keywords\u0026#34;: [], \u0026#34;scripts\u0026#34;: { \u0026#34;build\u0026#34;: \u0026#34;foxglove-extension build\u0026#34;, \u0026#34;foxglove:prepublish\u0026#34;: \u0026#34;foxglove-extension build --mode production\u0026#34;, \u0026#34;lint:ci\u0026#34;: \u0026#34;eslint --report-unused-disable-directives .\u0026#34;, \u0026#34;lint\u0026#34;: \u0026#34;eslint --report-unused-disable-directives --fix .\u0026#34;, \u0026#34;local-install\u0026#34;: \u0026#34;foxglove-extension install\u0026#34;, \u0026#34;package\u0026#34;: \u0026#34;foxglove-extension package\u0026#34;, \u0026#34;pretest\u0026#34;: \u0026#34;foxglove-extension pretest\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { // xxx } } 之后重新执行npm run package即可生成一个名为lucumt.rtsp-player-extension-0.0.1.foxe的插件产物，至此整个插件开发与构建流程结束，接下来的就是安装与使用。\n安装\u0026amp;使用 在浏览器打开Foxglove播放界面，之后打开前述步骤中生成的插件，将其拖动到浏览器窗口中，类似下图所示\n若安装成功，会在浏览器顶部出现相关提示\n在新建面板时，可发现安装的插件位于列表底部，同时其名称中包含 [local] 后缀，可仿照正常面板的使用流程来使用该面板，使用效果参见RTSP视频播放，至此，Foxglove 自定义插件开发与使用的全部流程操作完毕！\nGitHub上有人讨论此问题AVC / H.264 video support #88，但截止到目前依旧没有整合进去\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n有关RTSP与HTML、JavaScript整合的说明可参考https://www.cnblogs.com/badaoliumangqizhi/p/17211019.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nnodejs的版本推荐为16.xx.xx，个人实际测试发现用12.xx.xx版本时会导致初始化过程出错\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-11-22T14:08:39+08:00","permalink":"https://lucumt.info/post/web/foxglove-custom-plugin-develop/","tags":["web","foxglove"],"title":"Foxglove自定义插件开发说明"},{"categories":["容器化","工具使用","消息队列"],"contents":"简要记录如何基于docker搭建Kafka服务器以及添加集成了LDAP的kafka-ui实现图形化界面的授权访问。\nkafka安装 基于docker-compose的方式安装，脚本如下\nversion: \u0026#34;3\u0026#34; services: zookeeper: restart: always image: docker.io/bitnami/zookeeper:3.8 #network_mode: \u0026#34;bridge\u0026#34; container_name: zookeeper_test ports: - \u0026#34;2181:2181\u0026#34; volumes: - $PWD/zk_data:/bitnami/zookeeper #持久化数据 environment: - TZ=Asia/Shanghai - ALLOW_ANONYMOUS_LOGIN=yes kafka: restart: always image: docker.io/bitnami/kafka:3.4.1 #network_mode: \u0026#34;bridge\u0026#34; container_name: kafka_test ports: - \u0026#34;9004:9004\u0026#34; volumes: - $PWD/kafka_data:/bitnami/kafka #持久化数据 environment: - TZ=Asia/Shanghai - KAFKA_BROKER_ID=1 - KAFKA_CFG_LISTENERS=PLAINTEXT://:9004 - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://10.10.2.98:9004 #替换成你自己的IP - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181 - ALLOW_PLAINTEXT_LISTENER=yes depends_on: - zookeeper kafka-ui的安装 参考kafka-ui的说明，基于docker-compose的方式安装，脚本如下\nversion: \u0026#34;3\u0026#34; services: kafka-ui: restart: always image: provectuslabs/kafka-ui:latest container_name: kafka-ui restart: always ports: - 9001:8080 environment: - KAFKA_CLUSTERS_0_NAME=kafka-test - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=10.10.2.98:9004 - KAFKA_CLUSTERS_0_ZOOKEEPER=10.10.2.98:2181 之后可通过http://SERVER_IP:9001访问，界面类似如下，\n此时同网络下的任何人都能访问，也能通过UI界面对其进行相关修改操作，缺乏权限控制。\n添加登录 普通登录 普通登录方式的配置脚本如下，此时其账户信息以硬编码的形式存在\nversion: \u0026#34;3\u0026#34; services: kafka-ui: restart: always image: provectuslabs/kafka-ui:latest container_name: kafka-ui restart: always ports: - 9001:8080 environment: - KAFKA_CLUSTERS_0_NAME=kafka-test - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=10.10.2.98:9004 - KAFKA_CLUSTERS_0_ZOOKEEPER=10.10.2.98:2181 - AUTH_TYPE=\u0026#34;LOGIN_FORM\u0026#34; - SPRING_SECURITY_USER_NAME=admin - SPRING_SECURITY_USER_sPASSWORD=123456 对应的登录界面如下:\nLDAP登录 LDAP登录方式的配置脚本如下，其登录界面与前述一样\nversion: \u0026#34;3\u0026#34; services: kafka-ui: restart: always image: provectuslabs/kafka-ui:latest container_name: kafka-ui restart: always ports: - 9001:8080 environment: - KAFKA_CLUSTERS_0_NAME=kafka-test - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=10.10.2.98:9004 - KAFKA_CLUSTERS_0_ZOOKEEPER=10.10.2.98:2181 - AUTH_TYPE=\u0026#34;LDAP\u0026#34; - SPRING_LDAP_URLS=\u0026#34;ldap://xxx.xxx.xxx.xxx:389\u0026#34; - SPRING_LDAP_BASE=\u0026#34;cn={0},ou=xxx,dc=xxx,dc=com\u0026#34; - SPRING_LDAP_ADMIN_USER=\u0026#34;cn=xxx,dc=xxx,dc=com\u0026#34; - SPRING_LDAP_ADMIN_PASSWORD=\u0026#34;xxx\u0026#34; - SPRING_LDAP_USER_FILTER_SEARCH_BASE=\u0026#34;dc=xxx,dc=com\u0026#34; - SPRING_LDAP_USER_FILTER_SEARCH_FILTER=\u0026#34;(\u0026amp;(uid={0})(objectClass=inetOrgPerson))\u0026#34; 问题 缺少退出登录功能 缺少中文汉化界面 参考文档：\nhttps://www.cnblogs.com/tonglin0325/p/5528560.html https://github.com/provectus/kafka-ui/issues/1466 ","date":"2023-11-20T15:37:31+08:00","permalink":"https://lucumt.info/post/kafka/integrate-ldap-into-kafka-ui/","tags":["docker","kafka","ldap"],"title":"在基于Docker搭建的Kafka UI中整合LDAP"},{"categories":["消息队列"],"contents":"近期项目中有一个数据展示功能，其数据来源于Kafka，项目要求Kafka每次都消费最新的数据，简要记录下其实现方案。\n固定组实现-不生效 将auto.offset.reset设置为latest同时采用固定group，此种方式只在第一次读取时有效，后续再次读取时仍然从上次读取的地方开始继续读，不满足使用要求。\nProperties props = new Properties(); props.put(\u0026#34;bootstrap.servers\u0026#34;, \u0026#34;10.10.2.98:9004\u0026#34;); // 每次将组名动态生成 props.put(\u0026#34;group.id\u0026#34;, \u0026#34;test-group-1\u0026#34;); props.put(\u0026#34;auto.commit.interval.ms\u0026#34;, \u0026#34;1000\u0026#34;); props.put(\u0026#34;session.timeout.ms\u0026#34;, \u0026#34;30000\u0026#34;); props.put(\u0026#34;auto.offset.reset\u0026#34;, \u0026#34;latest\u0026#34;); props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \u0026#34;true\u0026#34;); props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); KafkaConsumer\u0026lt;String, String\u0026gt; consumer = new KafkaConsumer\u0026lt;\u0026gt;(props); String topic = \u0026#34;raw_message\u0026#34;; consumer.subscribe(Arrays.asList(topic)); 动态组实现-生效 将auto.offset.reset设置为latest，同时每次消费时将group的名称动态生成，这样即可确保每次读取的都是最新的消息。\n其缺点是group的数量会不断增加，偏移量___consumer_offsets 多次保存，且没找到有效的删除group的方法，也没办法做到定期清理，会对性能产生影响，通常只作为测试与实现使用。\nProperties props = new Properties(); props.put(\u0026#34;bootstrap.servers\u0026#34;, \u0026#34;10.10.2.98:9004\u0026#34;); // 每次将组名动态生成 props.put(\u0026#34;group.id\u0026#34;, \u0026#34;test-group-\u0026#34; \u0026#43; RandomStringUtils.randomAlphabetic(6)); props.put(\u0026#34;auto.commit.interval.ms\u0026#34;, \u0026#34;1000\u0026#34;); props.put(\u0026#34;session.timeout.ms\u0026#34;, \u0026#34;30000\u0026#34;); props.put(\u0026#34;auto.offset.reset\u0026#34;, \u0026#34;latest\u0026#34;); props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \u0026#34;true\u0026#34;); props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); KafkaConsumer\u0026lt;String, String\u0026gt; consumer = new KafkaConsumer\u0026lt;\u0026gt;(props); String topic = \u0026#34;raw_message\u0026#34;; consumer.subscribe(Arrays.asList(topic)); 固定组实现-生效 将auto.offset.reset设置为latest的同时，group名称固定不变 ，给对应Consumer调用seekToEnd()方法，此种方式不需要动态切换组，推荐使用此方式。\nProperties props = new Properties(); props.put(\u0026#34;bootstrap.servers\u0026#34;, \u0026#34;10.10.2.98:9004\u0026#34;); props.put(\u0026#34;group.id\u0026#34;, \u0026#34;test-group-1\u0026#34;); props.put(\u0026#34;auto.commit.interval.ms\u0026#34;, \u0026#34;1000\u0026#34;); props.put(\u0026#34;session.timeout.ms\u0026#34;, \u0026#34;30000\u0026#34;); props.put(\u0026#34;auto.offset.reset\u0026#34;, \u0026#34;latest\u0026#34;); props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \u0026#34;true\u0026#34;); props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); KafkaConsumer\u0026lt;String, String\u0026gt; consumer = new KafkaConsumer\u0026lt;\u0026gt;(props); String topic = \u0026#34;raw_message\u0026#34;; TopicPartition topicPartition = new TopicPartition(topic, 0); List\u0026lt;TopicPartition\u0026gt; topics = Arrays.asList(topicPartition); consumer.assign(topics); consumer.seekToEnd(topics); ","date":"2023-11-16T15:42:25+08:00","permalink":"https://lucumt.info/post/kafka/consume-latest-message-each-time/","tags":["kafka"],"title":"Kafka每次都消费最新的数据"},{"categories":["Web编程"],"contents":"基于搭建基于Foxglove的时序数据播放环境一文，结合实际项目的使用情况对Foxglove的使用功能进行简要的介绍。\n面板操作 Foxglove中的数据展示是基于面板来实现的，可根据实际使用需求在浏览器窗口添加多个面板，每个面板需要配置对应的topic来展示不同的数据，它们各司其职互不干扰。\n自己项目中用到的面板主要有如下6种：\n面板 作用 关联topic1 备注 发布面板 与server端进行交互，如根据输入的底盘号动态切换数据 drive/chassis_code 该面板不做展示用 文本面板 以纯文字形式展示车辆数据 所有topic均可 建议使用drive/control_data 图表面板 以图表形式展示车辆数据 所有topic均可 地图面板 用于在地图中展示车辆的行驶轨迹 drive/map 3D面板 用于显示3D场景下的车道线、障碍物以及车辆本身 drive/3D 视频面板 视频展示 不需要 直接通过RTSP视频流的形式播放 可在Foxglove系统中进行面板的创建、修改、删除、调整、导入、导出等操作，实际使用时需要在server端根据Foxglove规范提前准备好相关的topic。\n创建面板 直接创建 在浏览器窗口的左上角点击创建按钮，在出现的菜单中选择对应的类型\n如下图所示直接创建的面板会占用左侧空间，挤占已有区域，当已有多个面板展示时不建议采用此种方式\n面板创建完毕后，根据不同的面板类型需要做相关配置操作(见下文)\n拆分创建 选中一个已有的面板，在其右上角点击如下图所示的按钮，根据需求选择拆分类型\n假设选择\u0026quot;向下拆分\u0026quot;，拆分后的结果如下所示，可看出会创建一个相同的面板且继承原有面板的各种配置\n如下图所示，在拆分后的新面板中继续点击右上角的按钮，在出现的菜单中选择更改面板，之后才出现的面板类型菜单中根据实际需要选择合适的类型\n选择完毕后，需根据实际情况对面板做出相应配置才能正常显示(具体请参见下文的面板配置说明)\n修改面板 对于已有的面板可修改其配置，如展示颜色、消息来源等，具体步骤如下：\n选择一个要修改的面板，点击右上角的设置按钮\n浏览器左侧会出现该面板对应的配置界面，如下图所示\n可根据实际请求修改配置，修改完毕后立即生效，下图显示的为修改按钮颜色后的效果\n删除面板 在要删除的面板右上角点击设置按钮，在出现的菜单中点击删除面板即可删除该面板\n面板删除完毕后Foxglove会自动调整浏览器中的界面布局，同时Foxglove会根据实际情况给server发送对应的通知，以决定是否要停止相关的线程。\n打开工具栏 除了通过修改面板打开工具栏这种方式外，也可点击浏览器窗口右上角的按钮来打开工具栏，之后再点击对应的面板也能出现设置界面，操作步骤如下：\n若展示界面没有显示工具栏，可点击页面右上角的按钮，如下图所示\n此时由于没有选择任何面板，工具栏区域为空\n单击任意一个面板后，工具栏部分会出现对应面板的设置界面，可根据实际情况进行相应的设置操作\n面板配置 文本 文本2在Foxglove中对应的类型为原始消息(英文环境下为Raw Message)，其配置较为简单：\n创建好面板后，在其上方可选择对应的topic，可选择所有的topic\n选择好之后Foxglove中会立即实时展示该topic中对应的数据\n若发现上述面板中现实的信息太多，可根据实际需求只展示某个参数(属性)，需要在选择topic后精确到具体的属性，如下图所示\n选择完毕后呈现的效果类似如下\n图表 表格在Foxglove中对应的类型为图表(英文环境下显示为Plot)，其配置过程如下：\n创建好图表面板之后，其展示效果类似如下，由于此时没有选择任何数据，所以面板上展示为空\n可在左侧配置界面的数据系列部分添加一个消息地址，类似文本种添加单个消息的操作，一次只能选择一个参数(属性)\n选择完参数后，执行效果类似下图\n可在上图的左侧设置区域点击增加按钮来添加多个统计参数，添加后的展示效果类似如下\n当有多个参数展示时，图表中默认悬浮显示的参数名称可能会影响观看，可点击其左侧的按钮将其折叠\n其它的配置包括设置线条颜色、X轴、Y轴、时间设置等也比较简单与直观，此处不再详述。\n地图 地图数据用于默认展示车辆在地图中的移动轨迹，其只能选择特定类型的topic，相关配置过程如下：\n创建完地图面板后展示效果如下，可以看出其结果空白，这是由于Foxglove中的地图默认采用的是OpenStreetMap而其在国内访问受限制，需要设置为国内的地图源\n打开其配置面板，按照下图所示依次设置，先将地图层改为Custom，然后在自定义的地图地址中输入高德地图的地址，目前可用的为https://webrd04.is.autonavi.com/appmaptile?lang=zh_cn\u0026amp;size=1\u0026amp;scale=1\u0026amp;style=7\u0026amp;x={x}\u0026amp;y={y}\u0026amp;z={z}，执行完这一步骤后地图面板中就能正常显示\n可以将Follow topic设置为具体的topic(本例中为/drive/map)，之后地图会随着车辆的移动轨迹动态更新变化。\n3D 3D面板同地图面板类似，只能使用特定的topic(本例中为/drive/3D)，其配置过程如下：\n创建完毕3D面板后其不会展示数据，同时打开配置界面会发现其在参考系部分报错，如下图所示，此时可在配置界面点击对应topic的眼睛按钮，将其设置为可见\n操作完毕后即可正常显示3D数据，同时报错消失，由于不同的车辆采集数据不同，可在对应展示区域中通过鼠标滚轮放大或缩小\n其余的场景、视图、变换等可根据实际情况进行配置操作。\n图片/视频 截止到本文写作时(2023年11月)，Foxglove的官方只支持图片播放，暂不支持视频直接播放，而个人在实际使用中发现按照特定的频率对视频进行抽帧时会有一定的耗时，导致播放时比较卡顿。\n考虑播放的连贯与性能，决定采用RTSP协议来播放视频替代图片播放，为此个人开发了一款插件rtsp-player-extension3，使用时需预先在浏览器上安装该插件，然后确保对应RTSP视频流有数据即可正常播放。\n布局操作 布局调整 如下图所示，当有多个面板时，可将鼠标放到面板边框来调整相邻面板的宽度或高度。\n导入/导出 当要在多个浏览器(电脑)上使用Foxglove进行显示时，若基于前述的步骤依次创建面板和导出面板的话，会显得不方便，此时可通过导入导出功能，将一个浏览器中已经配置的面板与布局导出为json配置文件，之后通过配置文件在另一个浏览器中快速导入。\n如下图所示，在配置好面板的浏览器中点击左上角的icon按钮，依次选择查看-\u0026gt;导出布局到文件，将当前配置好的面板和样式布局都导出到一个json文件中\n当在一个新的浏览器窗口(或电脑)上使用Foxglove时在配置后服务器后，其默认显示的界面如下，可以看出当前没有任何配置好的面板\n将前述导出的json文件拷贝到目标电脑上，然后在浏览器中点击左上角的icon按钮，依次选择查看-\u0026gt;通过文件导入布局来导入对应的json文件\n导入成功之后显示类似如下界面，需要在发布界面(若没有则手工添加)选择对应的底盘号发布，之后才能从Kafka中正常获取数据并显示。\n全屏展示 Foxglove支持单个面板的全屏展示与退出，同时不影响其它面板的正常使用。\n选择要全屏展示的组件，在其左上角点击设置按钮\n在出现菜单列表中点击全屏即可进入全屏模式\n如下图所示，在全屏模式下点击右上角的退出按钮，即可退出全屏模式\n动态交互 动态交互是指通过在FoxgloveUI端输入相应的参数给server端，server端根据相关参数对WebSocket中要返回的数据进行动态生成或动态过滤。\n本章节以切换车辆底盘号显示不同车辆数据的场景为例，进行说明：\n仿照前述步骤中的新建面板，将面板类型选择为发布(也可通过面板拆分创建的方式，将新面板的类型修改为发布)\n此时左侧的工具栏会报错，在Topic部分选择一个合适的topic本例中为drive/chassis_code后错误会消失\n在面板输入区域填入类似如下内容，其中chassis_code对应的值为车辆底盘号，之后点击Publish4即可更换车辆底盘号\n{ \u0026#34;chassis_code\u0026#34;: \u0026#34;ND000048\u0026#34; } 发布成功之后，各个面板中的数据都会切换为对应底盘号的数据，其呈现的结果都会变化，也可直接在原始消息中查看底盘号是否发生变化。\n数据正常切换后，可将发布面板删除，避免干扰正常使用。\n若需要关联特定topic则表示该类面板对返回的数据格式有特殊要求\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n此处主要指的是纯文字文本\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n具体请参见本人的另一篇博文Foxglove自定义插件开发说明\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n此时会给server端发送消息，具体参见foxglove-websocket-java\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-11-15T14:08:39+08:00","permalink":"https://lucumt.info/post/web/foxglove-function-instructions/","tags":["web","foxglove"],"title":"Foxglove基本功能使用说明"},{"categories":["持续集成"],"contents":"简要记录如何整合Jenkins与SSH免密登录，实现通过Jenkins流水线部署到不同的服务器环境下，提高开发与测试环境的灵活性。\n背景 在KubeSphere中通过Jenkins流水线部署时，可选择部署到KubeSphere原生支持的Kubernetes中或部署到Docker容器中，从流水线配置的角度而言，除了最后一个阶段部署环境的不同，其它阶段都是类似的。\n部署到Kubernetes:\nstart_build=\u003estart: 开始构建 clone_code=\u003eoperation: 下载代码 |request compile_code=\u003eoperation: 编译代码 |request build_image=\u003eoperation: 镜像编译 |request upload_image=\u003eoperation: 镜像上传 |request deploy_image_in_k8s=\u003eoperation: K8S中部署镜像 |invalid end_build=\u003eend: 构建完成 start_build(right)-\u003ecompile_code(right)-\u003ebuild_image(right)-\u003eupload_image(right)-\u003edeploy_image_in_k8s(right)-\u003eend_build 部署到Docker:\nstart_build=\u003estart: 开始构建 clone_code=\u003eoperation: 下载代码 |request compile_code=\u003eoperation: 编译代码 |request build_image=\u003eoperation: 镜像编译 |request upload_image=\u003eoperation: 镜像上传 |request deploy_image_in_docker=\u003eoperation: Docker中部署镜像 |rejected end_build=\u003eend: 构建完成 start_build(right)-\u003ecompile_code(right)-\u003ebuild_image(right)-\u003eupload_image(right)-\u003edeploy_image_in_docker(right)-\u003eend_build 两种部署方式对比如下：\n部署到Kubernetes 部署到Docker 备注 环境配置难易 复杂 简单 K8S集群配置和验证较为复杂\nDocker的安装较为简单 流水线配置 低 高 在Docker环境下需要为每个服务器配置ssh认证 使用便利性 高 中 K8S能与KubeSphere无缝整合，日志查看与操作更方便\nDocker环境下只是依赖KubeSphere做可视化部署 可迁移性 高 中 每新增一个Docker环境都需要重新配置对应的ssh认证 可扩展性 低 中 K8S需要添加集群节点\nDocker需要配置ssh认证 目前大部分项目都是直接部署到Kubernetes而部分项目由于环境以及运维等特殊考量采用的是直接部署到Docker，由于此种方式下配置流水线较为复杂，本文将相关操作过程简单记录下，供后续参考。\nSSH远程执行 理论基础 部署到Docker的理论基础是通过Jenkins所在的宿主机(目前部门内部的Jenkins与KubeSphere都在同一台宿主机上)通过SSH(Secure Shell)在要部署的服务器上执行Docker相关执行，将之前需要手工执行的操作步骤以自动化的方式替代。\n关于SSH远程执行的相关操作说明，详情请参见 SSH远程执行任务 ，常用的指令如下\n# 执行单条指令 ssh nick@xxx.xxx.xxx.xxx \u0026#34;df -h\u0026#34; # 执行多条指令 ssh nick@xxx.xxx.xxx.xxx \u0026#34;pwd; cat hello.txt\u0026#34; # 远程执行脚本，不带参数 ssh nick@xxx.xxx.xxx.xxx \u0026lt; test.sh # 远程执行脚本，带参数 ssh nick@xxx.xxx.xxx.xxx \u0026#39;bash -s\u0026#39; \u0026lt; test.sh helloworld # helloworld即为传入的参数 考虑到基于Docker部署时需要先检测同名的Docker容器是否存在，如存在要将其先该容器停止并删除，之后再创建新的同名容器，这一系列操作直接用指令写很复杂也不便于阅读，用shell脚本替代较为合适。\n同时考虑到要兼容多个不同的工程和版本，需要传递相关的参数进行区分，故最终采用的方案为以带参数的放方式执行远程脚本。\n初略的架构图如下：\n实际演示 假设现在有10.30.31.22和10.30.31.24这两台虚拟机，简单演示下在10.30.31.22中通过ssh远程访问10.30.31.24\n远程执行指令\n远程执行shell脚本\n免密登录 从上述运行效果图可看出每次执行ssh指令时都需要对应远程服务器的密码，这是一种交互式的操作，而如果我们通过Jenkins进行操作时，若要每次都输入对应远程服务器的密码，显然是不显示的，故需要进行免密登录的配置。\n如何给ssh设置免费登录，详情参见 SSH远程免密登录，由于我们实际使用过程中是基于Jenkins调用ssh进行远程登录的，故不需要执行此部操作，只需要在Jenkins中设置免密登录即可。\nJenkins相关配置 此部分操作需要使用Jenkins管理员的登录，其用户名通常为admin。\nJenkins插件安装 此过程只需操作一次，之前已经安装完毕，此处记录只作为参考。\nJenkins需要安装SSH Agent Plugin来执行ssh指令，相关操作如下：\n去Jenkins官网根据当前Jenkins的版本去下载对应版本的插件，插件的扩展名为hpi\n以管理员账户登录Jenkins，依次点击系统管理-\u0026gt;插件管理-\u0026gt;高级，在出现的界面中找到如下图所示的上传插件界面，选择对应的hpi文件并点击上传按钮上传对应插件，若对应文件的版本不兼容，会提示相应错徐消息\n若能正常上传，在系统管理-\u0026gt;插件管理-\u0026gt;已安装中列表中会出现刚才安装成功的插件信息，通过输入SSH Agent Plugin可缩小范围查询，至此整个插件安装完成。\nJenkins配置 每增加一个远程服务器时，都需要仿照下述说明在Jenkins中添加相关的配置。\n生成公钥与私钥 在要执行的服务器上执行下述指令，检测ssh目录是否存在\nls ~/.ssh/ # 如果该目录提示不存在，需要先ssh localhost用root用户登录一下ssh 以root账户或其它具有权限的账户在终端中执行下述指令来生成秘钥\n# 邮箱名称可根据实际情况填写 ssh-keygen -t rsa -b 4096 -C \u0026#34;xxx@xxx.com\u0026#34; 执行过程中一路按Enter键即可，执行结果类似如下 执行下述指令，将公钥写入到authorized_keys文件中(若缺少此步骤会导致Jenkins进行免密登录时一直认证不通过)\ncd ~/.ssh cat id_rsa.pub \u0026gt;\u0026gt; authorized_keys 执行结果输出类似如下，至此公钥与私钥配置完毕。\nJenkins配置凭据 此文参考于Jenkinsfile 中配置使用 ssh agent 连接远程主机，可在该文章中查看详细的说明。\n以admin等具有管理员权限的账号登录Jenkins，仿照下图所示，依次点击系统管理-\u0026gt;Manage Credentials会出现对应的凭据列表\n在出现的凭据列表中，点击任一个凭据的全局链接，进入全局凭据列表\n在出现的全局凭据列表中，点击左侧的添加凭据链接，进入添加凭据界面\n在出现的操作界面中，将类型设置为SSH Username with private key，之后会出现类似如下界面，按照下图中的说明进行添加即可。\n下图为基于10.30.31.24填写的相关配置，填写完毕后保存即可，至此Jenkins凭据配置完成。\n注意： 为了让步骤3中显示的凭据列表更直观，更具有可读性，建议将ID和描述填写的更具有可读性，如ID的格式为IP-key，具体到本例中为10-30-31-24-key\n添加相关信息后，点击确定按钮，会在凭据列表出现我们刚添加的凭据，需要记录ID的名称，后续在Jenkins流水线中会使用到，至此Jenkins凭据配置操作完成。\n流水线配置 在Jenkins中添加类似如下的代码并执行测试，若测试正常，则表示Jenkins中基于SSH的远程部署全部配置完成，操作过程全部结束！\nsshagent(credentials: [\u0026#39;10-30-31-24-key\u0026#39;]) { sh \u0026#39;\u0026#39;\u0026#39;if [ $TARGET_IP = \\\u0026#39;10.30.31.24\\\u0026#39; ];then ssh -o StrictHostKeyChecking=no root@10.30.31.24 \\\u0026#39;bash -s\\\u0026#39; \u0026lt; cicd/ssh_deploy.sh \u0026#34;${REGISTRY}/${DOCKERHUB_NAMESPACE}\u0026#34; ${NODE_PORT} ${PRODUCT_PHASE} \u0026#34;xxx-batch-storage:${BUILD_TAG}\u0026#34; fi\u0026#39;\u0026#39;\u0026#39; } 有如下几点需要注意：\nID值为前面在Jenkins中添加凭据时输入的值\nStrictHostKeyChecking用于当第一次连接到主机时，自动接受新的公钥\nif判断用于只有当KubeSphere的界面中选择的要执行的目标服务器IP是我们选中的值时才执行对应的shell脚本，KubeSphere对应的执行界面参考如下\n简单测试验证 基于前述的说明步骤，在KubeSphere中对10.30.31.24做个简单的测试：\n在10.30.31.24上执行docker ps的结果如下\n在KubeSphere中建立类似如下流水线\npipeline { agent { node { label \u0026#39;maven\u0026#39; } } stages { stage(\u0026#39;环境设置\u0026#39;) { agent none steps { container(\u0026#39;maven\u0026#39;) { sh \u0026#39;TZ=\u0026#34;Asia/Shanghai\u0026#34; date\u0026#39; } } } stage(\u0026#39;远程执行\u0026#39;) { agent none steps { sshagent(credentials: [\u0026#39;10-30-31-24-key\u0026#39;]) { sh \u0026#39;ssh -o StrictHostKeyChecking=no root@10.30.31.24 \u0026#34;pwd;echo $HOSTNAME;docker ps\u0026#34;\u0026#39; } } } } environment { DOCKER_CREDENTIAL_ID = \u0026#39;harbor-id\u0026#39; GITHUB_CREDENTIAL_ID = \u0026#39;gitlab-id\u0026#39; KUBECONFIG_CREDENTIAL_ID = \u0026#39;xxx-kubeconfig\u0026#39; REGISTRY = \u0026#39;xxx.xxx.local:30005\u0026#39; DOCKERHUB_NAMESPACE = \u0026#39;xxx-server-library\u0026#39; GITHUB_ACCOUNT = \u0026#39;kubesphere\u0026#39; } } 执行该流水线，在最后一个步骤的输出如下，可以看出docker ps的执行结果符合预期(至于pwd和echo $HOSTNAME输出结果有差异是由于Jenkins容器本身执行时使用的是特定的账户以及特定的路径导致的)\n参考示例 远程shell脚本 注意： shell脚本在我们要通过ssh远程执行的那台执行者的电脑上，而不是位于被执行者的电脑上。\n#!/bin/bash harbor_url=$1 node_port=$2 build_phase=$3 image_version=$4 clone_name=$5 module_name=${clone_name}-${build_phase} echo \u0026#34;===========harbor_url: ${harbor_url}\u0026#34; echo \u0026#34;===========node_port: ${node_port}\u0026#34; echo \u0026#34;===========build_phase: ${build_phase}\u0026#34; echo \u0026#34;===========image_version: ${image_version}\u0026#34; echo \u0026#34;===========module_name: ${module_name}\u0026#34; echo \u0026#34;开始检查并移除旧的容器\u0026#34; if [[ -n \u0026#34;$(docker ps -f \u0026#34;name=${module_name}$\u0026#34; -f \u0026#34;status=running\u0026#34; -q )\u0026#34; ]]; then printf \u0026#34;停止容器: \u0026#34; docker stop $module_name fi # 若容器存在，则删除 if [[ -n \u0026#34;$(docker ps -a -f \u0026#34;name=${module_name}$\u0026#34; -q )\u0026#34; ]]; then printf \u0026#34;删除容器: \u0026#34; docker rm $module_name fi docker_command=\u0026#34;docker run -d -p ${node_port}:${node_port}\u0026#34; docker_command=\u0026#34;${docker_command} -e TZ=Asia/Shanghai\u0026#34; docker_command=\u0026#34;${docker_command} --name ${module_name} ${harbor_url}/${image_version}\u0026#34; printf \u0026#34;要执行的命令为:\\n${docker_command}\\n\u0026#34; container_id=$(eval ${docker_command}) result=$(docker inspect -f {{.State.Running}} ${container_id}) if [[ \u0026#34;$result\u0026#34; = true ]]; then printf \u0026#34;\\033[32m$module_name对应的容器启动成功,容器id为${container_id:0:12}\\033[0m\\n\u0026#34; else printf \u0026#34;\\033[31m$module_name对应的容器启动失败,容器id为${container_id:0:12}!\\033[0m\\n\u0026#34; exit 1 fi Jenkins流水线 pipeline { agent { node { label \u0026#39;maven\u0026#39; } } stages { stage(\u0026#39;拉取代码\u0026#39;) { agent none steps { git(credentialsId: \u0026#39;gitlab-token\u0026#39;, url: \u0026#39;http://gitlab.xxx.com/xxx-backend/xxx-batch-storage.git\u0026#39;, branch: \u0026#39;$BRANCH_NAME\u0026#39;, changelog: true, poll: false) } } stage(\u0026#39;识别系统环境\u0026#39;) { agent none steps { container(\u0026#39;maven\u0026#39;) { script { def PROJECT_NAME=\u0026#39;xxx-batch-storage\u0026#39; def BUILD_TYPE=PRODUCT_PHASE def NACOS_NAMESPACE=\u0026#39;\u0026#39; env.PROJECT_NAME = PROJECT_NAME response = sh(script: \u0026#34;curl -X GET \u0026#39;http://xxx.xxx.local:8858/nacos/v1/console/namespaces\u0026#39;\u0026#34;, returnStdout: true) jsonData = readJSON text: response namespaces = jsonData.data for(nm in namespaces){ if(BUILD_TYPE==nm.namespaceShowName){ NACOS_NAMESPACE = nm.namespace } } response = sh(script: \u0026#34;curl -X GET \u0026#39;http://xxx.xxx.local:8858/nacos/v1/cs/configs?dataId=xxx-custom-server-config.json\u0026amp;group=xxx-custom-config\u0026amp;tenant=26e0c3df-a0c7-4fe0-9b59-d04c5ac48481\u0026#39;\u0026#34;, returnStdout: true) jsonData = readJSON text: response configs = jsonData.portConfig for(config in configs){ project = config.project if(project!=PROJECT_NAME){ continue } ports = config.ports for(port in ports){ if(port.env!=BUILD_TYPE){ continue } env.NODE_PORT = port.server } } yamlFile = \u0026#39;app/src/main/resources/bootstrap.yml\u0026#39; yamlData = readYaml file: yamlFile yamlData.server.port = env.NODE_PORT yamlData.spring.cloud.nacos.discovery.group = BUILD_TYPE yamlData.spring.cloud.nacos.discovery.namespace = NACOS_NAMESPACE yamlData.spring.cloud.nacos.config.namespace = NACOS_NAMESPACE yamlData.custom.nacos.ip = TARGET_IP // todo sh \u0026#34;rm $yamlFile\u0026#34; writeYaml file: yamlFile, data: yamlData } } } } stage(\u0026#39;项目编译\u0026#39;) { agent none steps { container(\u0026#39;maven\u0026#39;) { sh \u0026#39;ls\u0026#39; sh \u0026#39;mvn clean compile package -Dmaven.test.skip=true -U\u0026#39; } } } stage(\u0026#39;镜像构建\u0026#39;) { agent none steps { container(\u0026#39;maven\u0026#39;) { sh \u0026#39;\u0026#39;\u0026#39;docker build -f cicd/Dockerfile \\\\ -t xxx-batch-storage:$BUILD_TAG \\\\ --build-arg PROJECT_VERSION=$PROJECT_VERSION \\\\ --build-arg NODE_PORT=$NODE_PORT \\\\ --build-arg PROJECT_VERSION=$PROJECT_VERSION \\\\ .\u0026#39;\u0026#39;\u0026#39; } } } stage(\u0026#39;镜像推送\u0026#39;) { agent none steps { container(\u0026#39;maven\u0026#39;) { withCredentials([usernamePassword(credentialsId : \u0026#39;harbor-account\u0026#39; ,passwordVariable : \u0026#39;DOCKER_PWD_VAR\u0026#39; ,usernameVariable : \u0026#39;DOCKER_USER_VAR\u0026#39; ,)]) { sh \u0026#39;echo \u0026#34;$DOCKER_PWD_VAR\u0026#34; | docker login $REGISTRY -u \u0026#34;$DOCKER_USER_VAR\u0026#34; --password-stdin\u0026#39; sh \u0026#39;\u0026#39;\u0026#39;docker tag xxx-batch-storage:$BUILD_TAG $REGISTRY/$DOCKERHUB_NAMESPACE/xxx-batch-storage:$BUILD_TAG docker push $REGISTRY/$DOCKERHUB_NAMESPACE/xxx-batch-storage:$BUILD_TAG\u0026#39;\u0026#39;\u0026#39; } } } } stage(\u0026#39;ssh部署\u0026#39;) { agent none steps { sshagent(credentials: [\u0026#39;10-30-31-60-key\u0026#39;]) { sh \u0026#39;\u0026#39;\u0026#39;if [ $TARGET_IP = \\\u0026#39;10.30.31.60\\\u0026#39; ];then ssh -o StrictHostKeyChecking=no root@10.30.31.60 \\\u0026#39;bash -s\\\u0026#39; \u0026lt; cicd/ssh_deploy.sh \u0026#34;${REGISTRY}/${DOCKERHUB_NAMESPACE}\u0026#34; ${NODE_PORT} ${PRODUCT_PHASE} \u0026#34;xxx-batch-storage:${BUILD_TAG}\u0026#34; ${PROJECT_NAME} fi\u0026#39;\u0026#39;\u0026#39; } sshagent(credentials: [\u0026#39;10-30-31-61-key\u0026#39;]) { sh \u0026#39;\u0026#39;\u0026#39;if [ $TARGET_IP = \\\u0026#39;10.30.31.61\\\u0026#39; ];then ssh -o StrictHostKeyChecking=no root@10.30.31.61 \\\u0026#39;bash -s\\\u0026#39; \u0026lt; cicd/ssh_deploy.sh \u0026#34;${REGISTRY}/${DOCKERHUB_NAMESPACE}\u0026#34; ${NODE_PORT} ${PRODUCT_PHASE} \u0026#34;xxx-batch-storage:${BUILD_TAG}\u0026#34; ${PROJECT_NAME} fi\u0026#39;\u0026#39;\u0026#39; } } } } environment { DOCKER_CREDENTIAL_ID = \u0026#39;harbor-id\u0026#39; GITHUB_CREDENTIAL_ID = \u0026#39;gitlab-id\u0026#39; KUBECONFIG_CREDENTIAL_ID = \u0026#39;xxx-kubeconfig\u0026#39; REGISTRY = \u0026#39;xxx.xxx.local:30005\u0026#39; DOCKERHUB_NAMESPACE = \u0026#39;xxx-server-library\u0026#39; GITHUB_ACCOUNT = \u0026#39;kubesphere\u0026#39; } } ","date":"2023-11-15T10:14:18+08:00","permalink":"https://lucumt.info/post/devops/using-ssh-to-deploy-in-remote-server-in-jenkins/","tags":["docker","jenkins","kubesphere","ssh"],"title":"利用SSH实现在Jekins中给远程服务器部署项目"},{"categories":["Web编程"],"contents":"简要介绍如何配置Foxglove可视化工具的前后端环境以便实现在项目中以多种方式播放采集的时序数据。\n需求背景 在自动驾驶相关的项目中经常会对采集的时序数据进行可视化播放展示，常见展示方式包括纯文本、图片、表格、图表、地图、3D等展示形式，之前团队内部对于这种需求都是前后端配合自己开发相关的UI组件进行展示。但随着要展示数据的增多以及用户需求的多变，采用自行开发的方式已经力不从心，迫切的需要一款能同时支持多路数据以不同方式播放展示的工具来减轻研发压力，提升系统稳定性与可靠性。\n在切换为新的可视化工具之前，内部确定了如下几个指标：\n能同时支持多路数据播放，可方便的添加与配置 支持纯文本、表格、图表、地图、3D、ROS、图片、视频等形式播放 相关实现方案不是很小众，在有使用问题时能有相关途径寻找解决方案 软件License许可能允许商用，且软件代码开源以便能进行二次开发 软件概览 经过多方对比以及参考业界其它公司相关的方案后，最终决定采用基于Foxglove作为对应的可视化工具替代实现，其具有如下特性：\n核心是基于React实现的浏览器播放，server端只需根据规范返回对应格式的数据即可，不限制server端的编程语言和实现方式，前后端通信主要基于WebSocket实现 预先定义了几十种数据格式，基于这些数据格式和实际业务需求可组合成多种不同的数据播放源，每个数据播放源都对应为一个panel 支持多种类型的播放形式，除了前述的几种类型，其还支持滑块、服务，日志、状态图、主题图等十几种样式，且可根据实际需求自行开发第三方的插件并很容易的整合到系统中，在Foxglove实际播放时每种播放类型都对应为一个panel 支持多通道播放，可对同一类型的panel可基于多个不同的数据源创建多个不同的panel来同时播放，也可同时配置多个不同类型的panel进行同时播放 支持界面自定义布局与调整，可根据实际需求灵活调整不同的panel的展示位置以及宽高等信息，当关闭某个panel时整个播放界面会自动调整已达到最佳显示效果 在创建panel并关联server端相关的topic或关闭配置好的panel后都会给server端发送对应的通知，方便进行server端开启或关闭数据推送服务，减少不必要的压力。同时，重复配置的panel只会建立一个连接，减少页面端的负载 软件许可基于Mozilla Public License 2.0，可用于商业化的产品中1 支持在线版本和本地版本，在线版本需要付费，本地版本可通过Docker安装 Foxglove的使用流程如下图所示：\n首先要创建对应的topic,每个topic都代表某种类型的展示数据，除了纯文本和表格之外，对于地图、3D、图片的展示方式需要根据官方文档设置对应的schema topic创建完毕后要进行注册，只有注册完毕的topic才能被对应的panel使用 创建panel，panel是数据展示的基本单位，其中纯文本和表格类型可兼容所有的topic，而对于地图、3D、图片类型则需要与特定schema的topic关联 创建完panel后，需要将其关联到对应的topic，并根据实际情况进行针对性的设置，如3D场景下设置显示的物体，地图场景下设置使用的地图源 启动对应的server端，持续不停的给相关topic写入数据 若一切正常，在Foxglvoe前端界面上对应的panel中会实时2的展示server端发送来的数据 若不需要某个panel，直接关闭即可，此时Foxglove会自动关闭相关的WebSocket连接 start=\u003estart: 开始 end=\u003eend: 结束 create_topic=\u003eoperation: 创建topic | pink register_topic=\u003eoperation: 注册topic | pink create_panel=\u003eoperation: 创建panel | cyan config_panel=\u003eoperation: 配置panel | cyan send_data=\u003eoperation: server端发送数据 | peru display_data=\u003eoperation: foxglove展示 | peru close_panel=\u003eoperation: 关闭panel | cyan close_connection=\u003eoperation: 断开连接 | cyan start-\u003ecreate_topic(right)-\u003eregister_topic-\u003ecreate_panel(right)-\u003econfig_panel-\u003esend_data(right)-\u003edisplay_data display_data-\u003eclose_panel-\u003eclose_connection(right)-\u003eend 在个人项目使用中Server端的数据来源是基于Kafka实现的，相关的流程如下\nstart=\u003estart: 开始 set_server=\u003einputoutput: 配置服务端 | pink create_panel=\u003eoperation: 创建面板 | pink select_chassis=\u003einputoutput: 选择底盘号 | tomato fetch_data=\u003esubroutine: 拉取kafka数据 | cyan send_data=\u003esubroutine: 发送kafka数据 | cyan filter_data=\u003esubroutine: 过滤kafka数据 | darkcyan render_data=\u003eoperation: 展示数据 | peru close_browser=\u003eoperation: 关闭浏览器 | pink start-\u003eset_server(right)-\u003ecreate_panel-\u003eselect_chassis select_chassis-\u003efetch_data-\u003efilter_data filter_data(right)-\u003esend_data(right)-\u003erender_data render_data-\u003eselect_chassis 前后端配置 本章节以UI端本地私有化安装为例，说明如何配置Foxglove前后端通信的环境，server端采用Java实现。\n服务端安装 根据Foxglove官方网站的说明文档以及相关的Java Demo编写对应的server端项目，暴露WebSocket端口，此处假设其端口为8765 启动server端程序，则对应的WebSocket访问地址为http://127.0.0.1:8765 页面端安装 在Foxglove对应的GitHub地址上有其UI端的安装说明，主要采用Docker安装，相关的指令如下3\n# 官方原始的说明 docker run --rm -p \u0026#34;8080:8080\u0026#34; ghcr.io/foxglove/studio:latest # 个人新保存的镜像 docker run --rm -p \u0026#34;8080:8080\u0026#34; lucumt/foxglove_studio:1.74.1 上述指令安装完成之后，在浏览器中输入http://127.0.0.1:8080会打开类似如下界面，在打开数据源对话框中选择最下面的打开连接\n在弹出的对话框中添加前面使用的Websocket地址，之后点击open按钮关闭该对话框\n若连接配置正确，在左侧会出现相关的topic列表，类似如下图所示，至此Foxglove前后端通信的环境初步搭建完毕\n服务器端编写 由于Foxglove官方已经提供了相应的Docker镜像可直接运行，除非需要自定义开发插件，通常不涉及到对UI端的操作，我们使用Foxglove时更多的工作还是集中在server端。\n本文相关的完整代码参见foxglove-websocket-java。\ntopic创建 Foxglove前后端通信主要基于WebSocket实现，本文采用Netty提供的WebSocket工具类来简化使用，对应的Maven版本为\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.yeauty\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;netty-websocket-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.12.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 添加一个名为FoxgloveServer的类用于暴露WebSocket端口，此时在程序启动后前后端已具备初步的通信能力\n@Slf4j @ServerEndpoint(port = \u0026#34;8765\u0026#34;) public class FoxgloveServer { public static final String EMPTY_CHASSIS_CODE = \u0026#34;NaN\u0026#34;; @BeforeHandshake public void handshake(Session session) { log.info(\u0026#34;----------session信息\u0026#34; \u0026#43; session.toString()); session.setSubprotocols(\u0026#34;foxglove.websocket.v1\u0026#34;); } @OnOpen public void onOpen(Session session) { log.info(\u0026#34;这是一次新的链接 ---》 new connection\u0026#34; \u0026#43; session.hashCode()); } @OnClose public void onClose(Session session) throws IOException { // 从对象集合中删除该连接对象 log.info(\u0026#34;-------one connection closed\u0026#34;); session.close(); } @OnError public void onError(Session session, Throwable throwable) { throwable.printStackTrace(); } @OnMessage public void onMessage(Session session, String message) { JSONObject msg = JSON.parseObject(message); String op = msg.getString(\u0026#34;op\u0026#34;); log.info(\u0026#34;-------------on open msg:\\t\u0026#34; \u0026#43; message); } @OnBinary public void onBinary(Session session, byte[] bytes) { // 这里接收到用户指令 String data = new String(Arrays.copyOfRange(bytes, 5, bytes.length)); JSONObject message = JSON.parseObject(data); log.info(\u0026#34;--------binary message:\\t\u0026#34; \u0026#43; message); } } 建立一个名为ChannelInfo的topic类，代码如下所示，需要注意的是类名必须为ChannelInfo，否则最后生成的JSON格式错误会导致topic无法注册4\n@Data public class ChannelInfo { /** * topic id，在注册时指定其值 */ private Integer id; /** * topic名称 */ private String topic; /** * topic编码，如json,protobuf等 */ private String encoding; /** * topic描述 */ private String schemaName; /** * topic对应的数据结构，可以是自定义的，也可以是foxglove官方定义好的 */ private String schema; /** * 对用结构的表示形式，如json时为jsonschema */ private String schemaEncoding; } 添加一个名为ChannelUtil的类，用于创建对应的topic\npublic class ChannelUtil { public static List\u0026lt;ChannelInfo\u0026gt; createChannels() { String schema; ChannelInfo channelChassis = new ChannelInfo(); channelChassis.setId(0); channelChassis.setTopic(\u0026#34;/drive/chassis_code\u0026#34;); channelChassis.setEncoding(\u0026#34;json\u0026#34;); channelChassis.setSchemaName(\u0026#34;底盘编码(用于切换播放源)\u0026#34;); channelChassis.setSchema(\u0026#34;{\\\u0026#34;type\\\u0026#34;: \\\u0026#34;object\\\u0026#34;, \\\u0026#34;properties\\\u0026#34;: {\\\u0026#34;chassis_code\\\u0026#34;: {\\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;}}}\u0026#34;); channelChassis.setSchemaEncoding(\u0026#34;jsonschema\u0026#34;); ChannelInfo channelControl = createControlData(1); ChannelInfo channel3D = new ChannelInfo(); channel3D.setId(2); channel3D.setTopic(\u0026#34;/drive/3D\u0026#34;); channel3D.setEncoding(\u0026#34;json\u0026#34;); channel3D.setSchemaName(\u0026#34;foxglove.SceneUpdate\u0026#34;); schema = DataUtil.loadJsonSchema(\u0026#34;SceneUpdate.json\u0026#34;); channel3D.setSchema(schema); channel3D.setSchemaEncoding(\u0026#34;jsonschema\u0026#34;); ChannelInfo channelGPS = new ChannelInfo(); channelGPS.setId(3); channelGPS.setTopic(\u0026#34;/drive/map\u0026#34;); channelGPS.setEncoding(\u0026#34;json\u0026#34;); channelGPS.setSchemaName(\u0026#34;foxglove.LocationFix\u0026#34;); schema = DataUtil.loadJsonSchema(\u0026#34;LocationFix.json\u0026#34;); channelGPS.setSchema(schema); channelGPS.setSchemaEncoding(\u0026#34;jsonschema\u0026#34;); List\u0026lt;ChannelInfo\u0026gt; channelList = new ArrayList\u0026lt;\u0026gt;(); channelList.add(channelChassis); channelList.add(channelControl); channelList.add(channel3D); channelList.add(channelGPS); return channelList; } private static ChannelInfo createControlData(int index) { ChannelInfo channelControl = new ChannelInfo(); channelControl.setId(index); channelControl.setTopic(\u0026#34;/drive/control_data\u0026#34;); channelControl.setEncoding(\u0026#34;json\u0026#34;); channelControl.setSchemaName(\u0026#34;控制数据信号\u0026#34;); StringBuffer sb = new StringBuffer(); sb.append(\u0026#34;{\\\u0026#34;type\\\u0026#34;: \\\u0026#34;object\\\u0026#34;, \\\u0026#34;properties\\\u0026#34;:{\u0026#34;); sb.append(\u0026#34;\\\u0026#34;底盘号\\\u0026#34;: {\\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;},\u0026#34;); sb.append(\u0026#34;\\\u0026#34;终端id\\\u0026#34;: {\\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;},\u0026#34;); sb.append(\u0026#34;\\\u0026#34;时间\\\u0026#34;: {\\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;},\u0026#34;); sb.append(\u0026#34;\\\u0026#34;纬度\\\u0026#34;: {\\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;},\u0026#34;); sb.append(\u0026#34;\\\u0026#34;经度\\\u0026#34;: {\\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;},\u0026#34;); sb.append(\u0026#34;\\\u0026#34;海拔\\\u0026#34;: {\\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;},\u0026#34;); sb.append(\u0026#34;\\\u0026#34;变速箱输出轴转速\\\u0026#34;: {\\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;},\u0026#34;); sb.append(\u0026#34;\\\u0026#34;制动系统准备可以释放\\\u0026#34;: {\\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;},\u0026#34;); sb.append(\u0026#34;\\\u0026#34;角速度(rad/s)\\\u0026#34;: {\\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;},\u0026#34;); sb.append(\u0026#34;\\\u0026#34;AX(m/s^2)\\\u0026#34;: {\\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;},\u0026#34;); sb.append(\u0026#34;\\\u0026#34;AY(m/s^2)\\\u0026#34;: {\\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;},\u0026#34;); sb.append(\u0026#34;\\\u0026#34;总驱动力\\\u0026#34;: {\\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;}\u0026#34;); sb.append(\u0026#34;}}\u0026#34;); channelControl.setSchema(sb.toString()); channelControl.setSchemaEncoding(\u0026#34;jsonschema\u0026#34;); return channelControl; } } 对前述的FoxgloveServer类中的onOpen方法添加类似如下代码，用于真正的注册相关的topic，可注册的topic数目可根据实际需求添加任意多个\n@OnOpen public void onOpen(Session session) { log.info(\u0026#34;这是一次新的链接 ---》 new connection\u0026#34; \u0026#43; session.hashCode()); this.session = session; ServerInfo serverInfo = new ServerInfo(); serverInfo.setOp(\u0026#34;serverInfo\u0026#34;); serverInfo.setName(\u0026#34;foxglove data render\u0026#34;); serverInfo.setCapabilities(Arrays.asList(\u0026#34;clientPublish\u0026#34;, \u0026#34;services\u0026#34;)); serverInfo.setSupportedEncodings(Arrays.asList(\u0026#34;json\u0026#34;)); String severInfoString = JSON.toJSONString(serverInfo); session.sendText(severInfoString); Advertise advertise = new Advertise(); advertise.setOp(\u0026#34;advertise\u0026#34;); advertise.setChannels(ChannelUtil.createChannels()); session.sendText(JSON.toJSONString(advertise)); } 若连接配置正确，在UI界面的左侧会出现相关的topic列表，如前述步骤所示，至此topic的创建与注册完成\n数据发送 本章节以发送纯文本类型的消息为例说明如何在server端编写代码实现数据发送\ntopic注册完毕后，不能直接使用，需要创建panel并选中对应的topic，此时UI端会给server端通过WebSocket协议发送对应的事件消息，需修改FoxgloveServer中的onMessage方法\n@OnMessage public void onMessage(Session session, String message) { JSONObject msg = JSON.parseObject(message); String op = msg.getString(\u0026#34;op\u0026#34;); log.info(\u0026#34;-------------on open msg:\\t\u0026#34; \u0026#43; message); switch (op) { case \u0026#34;subscribe\u0026#34;: // 创建连接时会执行此处逻辑 this.createThread(msg); break; case \u0026#34;unsubscribe\u0026#34;: break; } } private void createThread(JSONObject msg) { List\u0026lt;Subscription\u0026gt; subscribeList = msg.getObject(\u0026#34;subscriptions\u0026#34;, new TypeReference\u0026lt;List\u0026lt;Subscription\u0026gt;\u0026gt;() { }); log.info(\u0026#34;============开始创建基于channel的数据发送线程==============\u0026#34; \u0026#43; subscribeList); for (Subscription sub : subscribeList) { Integer channelId = sub.getChannelId(); SendDataThread thread = getKafkaSendThread(sub.getId(), channelId, session); String threadName = \u0026#34;thread-\u0026#34; \u0026#43; getTopicName(channelId) \u0026#43; \u0026#34;-\u0026#34; \u0026#43; RandomStringUtils.randomAlphabetic(6).toLowerCase(); thread.setName(threadName); thread.setChassisCode(chassisCode == null ? EMPTY_CHASSIS_CODE : chassisCode); thread.start(); threadMap.put(channelId, thread); } } 其中SendDataThread类是一个继承自Thread类，用于封装Kafka的数据发送流程，具体的发送逻辑需要再次继承SendDataThread类来实现。\n在前述topic列表中纯文本对应的名称为/drive/chassis_code，对应的数据结构如下\n{ \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;chassis_code\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } } } 则可继承SendDataThread编写相应的实现类\n@Slf4j public class SendChassisThread extends SendDataThread { private DataConfig dataConfig; public SendChassisThread(int index, Session session) { super(index, session); this.dataConfig = AppCtxUtil.getBean(DataConfig.class); this.frequency = dataConfig.getChassis().getFrequency(); } @Override public void run() { while (running) { try { ChassisInfo chassis = new ChassisInfo(); chassis.setTimestamp(DateUtil.createTimestamp()); chassis.setChassisCode(RandomStringUtils.randomAlphanumeric(6).toUpperCase()); JSONObject jsonObject = (JSONObject) JSONObject.toJSON(chassis); byte[] bytes = jsonObject.toJSONString().getBytes(); this.session.sendBinary(bytes); log.info(\u0026#34;---------------chassis info:\\t\u0026#34; \u0026#43; chassis); sleep(frequency); } catch (InterruptedException e) { throw new RuntimeException(e); } } } } 对应的ChassisInfo类代码如下\n@Data public class ChassisInfo { @JsonProperty(\u0026#34;底盘号\u0026#34;) private String chassisCode; @JsonProperty(\u0026#34;时间戳\u0026#34;) private Timestamp timestamp; } 启动server端程序，在FoxgloveUI端按照下图所示点击创建按钮，在出现的panel列表中选择原始消息(英文环境下为Raw Message)，用于展示纯文本消息\n在出现的纯文本panel的顶部选择对应的topic，此处为/drive/chassis_code，执行到这一步后理论上就能正常播放数据，但在浏览器中查看结果时，会呈现出类似下图所示的效果，文本消息并没有正常展示。\n从上面报错的初步信息可知是UI端在解析二进制文件时出错，与官方Demo的WebSocket数据包进行对比，折腾一段时间后其原因是Foxglove有自己特定的编码算法，不能直接返回生成的原始消息，需要对其基于byte进行编码，之后UI端自行解码。相关的编码代码如下\npackage com.visualization.foxglove.util; import com.alibaba.fastjson.JSON; import com.fasterxml.jackson.databind.ObjectMapper; import org.apache.commons.io.IOUtils; import java.io.IOException; import java.io.InputStream; import java.util.Map; public class DataUtil { public static byte[] getFormattedBytes(byte[] data, int channel) { return getFormattedBytes(data, 0, channel); } public static byte[] getFormattedBytes(byte[] data, long ns, int channel) { byte constantInfo = 1; byte[] constantInfoByte = new byte[]{constantInfo}; byte[] dataType = getIntBytes(channel); byte[] nsTime = getLongBytes(ns); byte[] pack1 = byteConcat(constantInfoByte, dataType, nsTime); byte[] pack2 = byteConcat(pack1, data); return pack2; } public static byte[] loadGlbData(String glbFile) { try { ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); InputStream stream = classLoader.getResourceAsStream(\u0026#34;glb/\u0026#34; \u0026#43; glbFile); byte[] bytes = IOUtils.toByteArray(stream); return bytes; } catch (IOException e) { e.printStackTrace(); } return null; } public static String loadJsonSchema(String schemaFile) { ObjectMapper objectMapper = new ObjectMapper(); Map map = null; try { ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); InputStream stream = classLoader.getResourceAsStream(\u0026#34;schema/\u0026#34; \u0026#43; schemaFile); map = objectMapper.readValue(stream, Map.class); } catch (IOException e) { e.printStackTrace(); } return JSON.toJSONString(map); } public static final long fx = 0xffL; /** * int 转 byte[] * 小端 * * @param data * @return */ public static byte[] getIntBytes(int data) { int length = 4; byte[] bytes = new byte[length]; for (int i = 0; i \u0026lt; length; i\u0026#43;\u0026#43;) { bytes[i] = (byte) ((data \u0026gt;\u0026gt; (i * 8)) \u0026amp; fx); } return bytes; } /** * long 转 byte[] * 小端 * * @param data * @return */ public static byte[] getLongBytes(long data) { int length = 8; byte[] bytes = new byte[length]; for (int i = 0; i \u0026lt; length; i\u0026#43;\u0026#43;) { bytes[i] = (byte) ((data \u0026gt;\u0026gt; (i * 8)) \u0026amp; fx); } return bytes; } public static byte[] byteConcat(byte[] bt1, byte[] bt2) { byte[] bt4 = new byte[bt1.length \u0026#43; bt2.length]; int len = 0; System.arraycopy(bt1, 0, bt4, 0, bt1.length); len \u0026#43;= bt1.length; System.arraycopy(bt2, 0, bt4, len, bt2.length); return bt4; } public static byte[] byteConcat(byte[] bt1, byte[] bt2, byte[] bt3) { byte[] bt4 = new byte[bt1.length \u0026#43; bt2.length \u0026#43; bt3.length]; int len = 0; System.arraycopy(bt1, 0, bt4, 0, bt1.length); len \u0026#43;= bt1.length; System.arraycopy(bt2, 0, bt4, len, bt2.length); len \u0026#43;= bt2.length; System.arraycopy(bt3, 0, bt4, len, bt3.length); return bt4; } } 将数据发送的代码修改如下，并重新启动server端服务\n@Override public void run() { while (running) { try { ChassisInfo chassis = new ChassisInfo(); chassis.setTimestamp(DateUtil.createTimestamp()); chassis.setChassisCode(RandomStringUtils.randomAlphanumeric(6).toUpperCase()); JSONObject jsonObject = (JSONObject) JSONObject.toJSON(chassis); // 需要调用对应的编码函数 byte[] bytes = DataUtil.getFormattedBytes(jsonObject.toJSONString().getBytes(), index); this.session.sendBinary(bytes); log.info(\u0026#34;---------------chassis info:\\t\u0026#34; \u0026#43; chassis); sleep(frequency); } catch (InterruptedException e) { throw new RuntimeException(e); } } } 在UI端查看，可发现此时能正常播放消息，至此Foxglove前后端交互的配置基本搭建完毕，后续就是根据不同的面板类型进行针对性的编码。\n基于Mozilla Public License 2.0协议，若对其源码进行二次开发，也需要遵守同样的协议\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n此处的实时依赖于server端发送数据的频率\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n在2024年3月份原作者更新了REAME.md，在此次更新中将Docker安装的指令移除了，不过我们可通过历史记录去查找相关指令\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n感觉此处Foxglove的命名有些混乱，通道被命名为Topic，然而在JSON格式文件中却要求用Channel来替代\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-11-13T14:08:39+08:00","permalink":"https://lucumt.info/post/web/using-foxglove-to-render-time-sequence-data/","tags":["web","foxglove"],"title":"搭建基于Foxglove的时序数据播放环境"},{"categories":["工具使用"],"contents":"本文来源于个人在使用GitBook中遇到的问题，尽管自己通过 gitbook出现if (args[ii] == null) throw missingRequiredArg(ii 解决 这篇文章很快的找到了问题的解决方案，但该文章发布在CSDN，而CSDN的使用体验糟糕已是尽人皆知(此处不得不说一声 CSDN fuck you!)。\n为了给其他使用者提供一个简洁干净的参考，故写此文章。\n问题场景 通过gitbook install 进行相关插件的安装。\n问题描述 通过gitbook install 进行相关插件的安装，终端出现类似如下错误导致安装过程失败\nD:\\code\\gitbook-doc\u0026gt;gitbook install info: installing 24 plugins using npm@3.9.2 info: info: installing plugin \u0026#34;mermaid-fox\u0026#34; info: install plugin \u0026#34;mermaid-fox\u0026#34; (*) from NPM with version 0.0.3 fetchMetadata -\u0026gt; network \\ |##################-----------------------------------------------------------------------| C:\\Users\\yunqiang.lu\\.gitbook\\versions\\3.2.3\\node_modules\\npm\\node_modules\\aproba\\index.js:25 if (args[ii] == null) throw missingRequiredArg(ii) ^ Error: Missing required argument #1 at andLogAndFinish (C:\\Users\\yunqiang.lu\\.gitbook\\versions\\3.2.3\\node_modules\\npm\\lib\\fetch-package-metadata.js:31:3) at fetchPackageMetadata (C:\\Users\\yunqiang.lu\\.gitbook\\versions\\3.2.3\\node_modules\\npm\\lib\\fetch-package-metadata.js:51:22) at resolveWithNewModule (C:\\Users\\yunqiang.lu\\.gitbook\\versions\\3.2.3\\node_modules\\npm\\lib\\install\\deps.js:490:12) at C:\\Users\\yunqiang.lu\\.gitbook\\versions\\3.2.3\\node_modules\\npm\\lib\\install\\deps.js:491:7 at C:\\Users\\yunqiang.lu\\.gitbook\\versions\\3.2.3\\node_modules\\npm\\node_modules\\iferr\\index.js:13:50 at C:\\Users\\yunqiang.lu\\.gitbook\\versions\\3.2.3\\node_modules\\npm\\lib\\fetch-package-metadata.js:37:12 at addRequestedAndFinish (C:\\Users\\yunqiang.lu\\.gitbook\\versions\\3.2.3\\node_modules\\npm\\lib\\fetch-package-metadata.js:67:5) at returnAndAddMetadata (C:\\Users\\yunqiang.lu\\.gitbook\\versions\\3.2.3\\node_modules\\npm\\lib\\fetch-package-metadata.js:121:7) at pickVersionFromRegistryDocument (C:\\Users\\yunqiang.lu\\.gitbook\\versions\\3.2.3\\node_modules\\npm\\lib\\fetch-package-metadata.js:138:20) at C:\\Users\\yunqiang.lu\\.gitbook\\versions\\3.2.3\\node_modules\\npm\\node_modules\\iferr\\index.js:13:50 { code: \u0026#39;EMISSINGARG\u0026#39; } 原因分析 原作者不知道，本人也不知道，期待有大神能给出具体原因分析。\n解决方案 需要用npm先手工安装对应的插件，之后再执行gitbook install就不会出错。\n以本文为例，出错的插件为gitbook-plugin-mermaid-fox1，则按照下述方式执行即可\n# 必须先执行该指令 npm install gitbook-plugin-mermaid-fox gitbook install GitBook中的插件要求必须以gitbook-plugin-开头\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-10-13T19:10:56+08:00","permalink":"https://lucumt.info/post/gitbook/gitbook-install-missing-required-argement/","tags":["gitbook"],"title":"[非原创]解决Gitbook安装过程中出现的Error: Missing required argument #1错误"},{"categories":["工具使用","容器化"],"contents":"由于Docsify采用单页渲染的方式，在初次打开是特别慢，近期将团队内部的知识库工具从Docsify迁移到基于Docker搭建的GitBook并结合GitLab Runner实现自动更新，在这其中踩了一些坑，简单记录下。\n背景 技术选型 由于Docsify采用SPA模式开发，不会生成静态HTML页面，故随着内容与页面的增多，其初次加载时会花费较多时间进行全局渲染，导致显示很慢，浪费时间等于谋财害命，需要将其替换为其它框架！\n由于知识库的使用群体除了软件开发人员，还有产品设计师、测试工程师等不具备很强代码开发能力的群体，故在替换之前对要采用的新框架确定了如下目标：\n采用静态页面生成，避免每次浏览时都需要耗时渲染 采用纯Markdown语法，避免额外的学习与使用成本 界面美观，适合做文档展示，无须做过多配置 插件生态丰富，无须自己额外开发太多的插件 基于网络上的资料，初步选定Docsify、GitBook、Hexo和Hugo这4种框架，基于实际使用需求对它们进行对比如下：\n开发语言 构建速度 展示方式 格式要求 文档 / 社区 目录生成 优点 缺点 Docsify Vue 一般 单页面渲染 无 一般 可通过插件自动生成 环境安装简单 初次打开加载很慢 GitBook Node.js 一般 静态页面 无 一般 需自己在SUMMARY.md中生成 样式美观，专门用于做文档管理 官方专注于付费版，非付费版bug较多 Hexo Node.js 一般 静态页面 需添加日期、标题等信息 丰富 依赖于所选的主题 社区活跃，使用度很高 编译速度慢，主要适合做博客 Hugo Golang 快 静态页面 需添加日期、标题等信息 丰富 依赖于所选的主题 构建速度快，使用度很高 文档不完善，主要适合做博客 基于上述对比，可发现虽然Hugo的构建速度最快，但适合做博客，对于知识库这种文档系统不是特别合适，而GitBook虽然构建速度没有Hugo快，但GitBook更侧重于浏览，其构建只会在文档内容有更新时才发生，频率相对较小，同时GitBook从名字上即可看出是专门用于知识库文档管理的，综合考虑下决定采用GitBook来替换Docsify。\n同时为了降低GitBook的侵入性，指定如下规则：\nGitLab Runner和Nginx采用Docker进行容器化部署，避免对部署环境的强依赖 通过Docker在GitLab Runner中安装GitBook环境，使得实际的文档项目与GitBook解耦 使用流程 由于文档同代码一样都是采用GitLab管理的，为了实现在文档更新时能够自动化的部署，准备采用GitLab Runner+GitBook+Nginx的方案，整体流程图如下：\n在实际使用时，相关用户只需要在按照常规的流程在本地基于Markdown格式编写文档并提交到GitLab中，之后GitLab Runner会自动化的进行文档构建与文档生成，依赖于宿主物理机的配置和文档数量，整个过程通常不超过5秒钟，之后在浏览器中刷新即可查看生成的HTML静态文件。\n环境搭建 相关说明 出于简化使用流程与加快构建速度的考虑，将GitLab Runner与GitBook都放置到同一个容器中。在GitLab Runner的Docker容器中安装完毕GitBook环境后，还需将GitLab Runner注册到对应的GitLab仓库中，可通过Shell脚本将此过程固化下来，整个环境搭建流程如下：\n说明：由于GitBook是基于Nodejs开发的，而Nodejs和NPM对版本有强相关的依赖，版本过高或过低都会导致GitBook以及相关的插件无法安装，故本次采用了如下较旧的版本(采用Docker容器化部署不会造成额外的负面影响 )\n版本 备注 GitLab Runner gitlab/gitlab-runner:v15.5.2 GitBook Cli gitbook-cli@2.1.2 若版本不对，会导致依赖问题，请参见Gitbook-cli install error TypeError: cb.apply is not a function inside graceful-fs GitBook 3.2.3 Nodejs v12.22.12 NPM 7.5.2 操作流程 下述步骤展示了从头开始构建GitLab Runner与GitBook的过程\n在宿主机上执行如下指令安装jq指令，后续会用其来解析GitLab中返回的JSON数据\n# 在宿主机上安装jq，用于解析json文件 apt install -y jq 安装之前请仿照下图将本文最后的文件\u0026amp;脚本\n运行下述指令构建需要的镜像\ndocker build -t gitbook_custom:v1.0 Dockerfile在构建过程中会对它认为没有变化的文件和日志输出进行缓存，要想查看全部日志并取消缓存，可用如下指令\ndocker build -t gitbook_custom:v1.0 --progress string . --no-cache 执行下述指令启动Docker容器并执行相关的初始化操作\ndocker-compose down \u0026amp;\u0026amp; docker-compose up -d \u0026amp;\u0026amp; bash gitlab_runner_config_init.sh 安装过程中会有类似如下输出:\n若最后输出结果类似如下，则表示整个脚本安装过程顺利完成\n在对应GitLab项目中依次点击Settings-\u0026gt;CI/CD-\u0026gt;Runners，若出现类似如下界面则表示GitLab Runner正确安装与配置完毕，接下来即可验证GitBook是否能正常工作\n测试验证 自动构建 由于自动构建脚本中有如下配置，其中构建阶段的值被设置为build会导致每次代码发生变更时都执行自动构建\nstages: - build # build阶段执行的操作命令 build: stage: build 当我们通过git push将代码推送到GitLab后，在对应的GitLab工程中依次点击CI/CD-\u0026gt;Pipelines，会有类似如下输出，可以看到此时GitLab Runner正在执行构建\n点击对应的按钮可查看构建执行日志，类似如下：\n之后可通过Nginx对应端口访问相应的GitBook页面，可参考使用展示。\n手工构建 除了自动构建之外，也可点击对应的按钮进行手工提交，此种场景一般用于文档代码没有变更而对GitBook的样式或插件进行了修改，想提前验证结果，操作步骤如下：\n在对应的GitLab工程中依次点击CI/CD-\u0026gt;Pipelines，在出现的菜单中点击右上角的Run pipeline按钮\n在出现的界面中再次点击Run pipeline按钮进行确认，触发手工执行，之后的步骤与自动构建时相同。\n插件管理 GitBook在文档管理领域广受欢迎的一个很重要的原因是其丰富的插件生态，插件可快速集成，也可仿照别人的插件根据自己的需求快速开发新的插件，个人项目中用到的插件如下\n常用插件 插件 作用 备注 gitbook-plugin-prism-codetab-fox 对代码采用Prims.js进行高亮，同时可根据需求对代码进行分组 需要在book.js中通过 -highlight的方式屏蔽默认的高亮插件 gitbook-plugin-mermaid-fox 支持Mermaid图表功能 实际使用过程中发现部分图表无法展示 gitbook-plugin-flowchart-fox 用于支持flowchart图表 实际使用过程中发现该插件bug较多，在组件过多时会出现样式混乱 gitbook-plugin-advanced-emoji 用于展示Emoji表情 gitbook-plugin-chart 利用C3.js或Highcharts来展示图表 gitbook-plugin-popup 在新窗口中打开图片 gitbook-plugin-accordion 手风琴插件，用于展开或折叠相关内容 plugin-katex 支持基于KaTeX的数学公式展示 gitbook-plugin-search-pro 支持中文搜索的插件 需要在book.js中通过 -search的方式屏蔽默认的搜索插件1 gitbook-plugin-hide-element 隐藏特定元素 gitbook-plugin-chapter-fold 页面上方的导航目录折叠 gitbook-plugin-code 给代码块添加行号与复制按钮 gitbook-plugin-splitter 页面左侧的侧边栏可动态调节 该插件与xmind插件一并使用时会导致后者无法正常使用 gitbook-plugin-expandable-chapters-small 页面右侧的目录可展开或收缩 gitbook-plugin-tbfed-pagefooter 页面显示定制化的页脚信息 gitbook-plugin-ancre-navigation 页内导航回到顶部 gitbook-plugin-sharing 将特定页面分享到其它平台的按钮插件 需要在book.js中通过 -sharing的方式屏蔽默认的分享插件 gitbook-plugin-theme-comscore GitBook彩色主题 gitbook-plugin-favicon 添加favicon图标 gitbook-plugin-flexible-alerts 自定义的提示说明样式 自定义插件 已有的插件太老旧，自己fork代码后对它们进行了更新，项目位于gitbook-plugin-fox，目前包含如下插件：\ngitbook-plugin-mermaid-fox，GitBook中支持新版的flowchart.js图表，展示效果如下\ngitbook-plugin-mermaid-fox，GitBook中支持新版的Mermaid图表，展示效果如下\ngitbook-plugin-prism-codetab-fox，将gitbook-plugin-prism与gitbook-plugin-codetabs这两个插件整合为一个插件，在实现代码高亮的同时还能对代码进行分组，展示效果如下：\n其它设置 中文汉化 GitBook中的默认语言为英文，如下图所示，某些提示信息以英文展示，不方便使用\n可通过在book.js中添加language:'zh-hans'来将默认语言修改为中文，修改后的显示效果如下：\n自定义目录 如下所示GitBook中默认生成的菜单为Introduction，不太直观，可根据实际需求动态修改(对于菜单目录的生成可参考自动生成目录实现)\n将默认目录从\n* [Introduction](README.md) 修改为\n* [概览](README.md) 之后的展示效果类似如下\n自定义样式 若GitBook中的样式不满足我们的需求，可通过添加自定义CSS文件进行定制，实际使用中发现该文件必须叫做website.css且需位于生成的静态文件目录下才生效。\n\u0026#34;styles\u0026#34;: { \u0026#34;website\u0026#34;: \u0026#34;./styles/website.css\u0026#34;, } 使用展示 可通过Nginx对应端口访问相应的GitBook页面，个人项目中的界面类似如下，供参考\n文件\u0026amp;脚本 Dockerfile脚本 用于构建同时包含GitLab Runner与GitBook的容器\nFROM gitlab/gitlab-runner:v15.5.2 # 更改为公司内部的镜像源 RUN rm -rf /etc/apt/sources.list \u0026amp;\u0026amp; touch /etc/apt/sources.list RUN echo \u0026#39;deb [trusted=yes] https://mirrors.xxx.com/repository/Debian/ bullseye main non-free contrib\u0026#39; \u0026gt;\u0026gt; /etc/apt/sources.list RUN echo \u0026#39;deb-src [trusted=yes] https://mirrors.xxx.com/repository/Debian/ bullseye main non-free contrib\u0026#39; \u0026gt;\u0026gt; /etc/apt/sources.list RUN echo \u0026#39;deb [trusted=yes] https://mirrors.xxx.com/repository/Debian/ bullseye-updates main non-free contrib\u0026#39; \u0026gt;\u0026gt; /etc/apt/sources.list RUN echo \u0026#39;deb-src [trusted=yes] https://mirrors.xxx.com/repository/Debian/ bullseye-updates main non-free contrib\u0026#39; \u0026gt;\u0026gt; /etc/apt/sources.list RUN echo \u0026#39;deb [trusted=yes] https://mirrors.xxx.com/repository/Debian/ bullseye-backports main non-free contrib\u0026#39; \u0026gt;\u0026gt; /etc/apt/sources.list RUN echo \u0026#39;deb-src [trusted=yes] https://mirrors.xxx.com/repository/Debian/ bullseye-backports main non-free contrib\u0026#39; \u0026gt;\u0026gt; /etc/apt/sources.list # 安装nodejs RUN apt-get update -y RUN apt-get install nodejs npm -y RUN npm cache clean --force RUN npm config set registry https://mirrors.xxx.com/repository/NPM/ RUN npm install -g gitbook-cli@2.1.2 RUN mkdir -p /usr/local/gitbook/data RUN mkdir -p /usr/local/gitbook/tmp/docs RUN chown -R gitlab-runner:gitlab-runner /usr/local/gitbook/tmp COPY book.js /usr/local/gitbook/tmp/book.js COPY custom.css /usr/local/gitbook/tmp/custom.css COPY favicon.ico /usr/local/gitbook/tmp/favicon.ico COPY auto_generate_summary.sh /usr/local/gitbook/auto_generate_summary.sh docker启停脚本 docker-compose.yml用于启动GitLab Runner与Nginx容器\nversion: \u0026#34;3\u0026#34; services: gitbook: privileged: true image: gitbook_custom:v1.0 volumes: - $PWD/data:/usr/local/gitbook/data:rw restart: always container_name: gitbook-custom nginx: privileged: true image: nginx:1.22 ports: - \u0026#34;3000:80\u0026#34; volumes: - $PWD/data:/usr/share/nginx/html restart: always container_name: gitbook-nginx 自动构建脚本 .gitlab-ci.yml是GitLab Runner构建时使用的文件，此文件规定了构建过程中要具体执行的步骤，只有此文件必须存在于目标文档对应的GitLab仓库，用于每次修改文档时触发自动构建\nvariables: # 是否自动生成目录 AUTO_SUMMARY: \u0026#34;true\u0026#34; # 定义ci/cd 执行build流程 stages: - build # build阶段执行的操作命令 build: stage: build tags: - xxx-doc script: - echo \u0026#34;======== start build ========\u0026#34; - rm -rf /usr/local/gitbook/tmp/docs/* - cp -r * /usr/local/gitbook/tmp/docs/ - mkdir -p /usr/local/gitbook/tmp/docs/styles - cd /usr/local/gitbook/tmp - cp custom.css /usr/local/gitbook/tmp/docs/styles/website.css - bash /usr/local/gitbook/auto_generate_summary.sh $PWD - gitbook build - rm -rf /usr/local/gitbook/data/* - cp -r /usr/local/gitbook/tmp/_book/* /usr/local/gitbook/data/ - cp -rf /usr/local/gitbook/tmp/favicon.ico /usr/local/gitbook/data/gitbook/images/favicon.ico 自动注册脚本 gitlab_runner_config_init.sh用于注册GitLab Runner同时检测GitBook是否存在\n#/bin/bash #更新文件权限 FOLDER=\u0026#34;/usr/local/gitbook/data\u0026#34; docker exec -it gitbook-custom bash -c \u0026#34;chown -R gitlab-runner:gitlab-runner $FOLDER\u0026#34; echo \u0026#34;===================完成$FOLDER数据目录权限修改=====================\u0026#34; # 删除gitlab runner GITLAB_URL=\u0026#39;http://aeectss.xxx.local:1800/\u0026#39; echo \u0026#39;===================开始删除旧的gitlab runner=====================\u0026#39; PRIVATE_TOKEN=\u0026#39;5JZxxYzapBB_zfze5c2_\u0026#39; PROJECT_ID=57 ids=$(curl --header \u0026#34;PRIVATE-TOKEN:${PRIVATE_TOKEN}\u0026#34; \u0026#34;${GITLAB_URL}/api/v4/runners\u0026#34; |jq -r \u0026#39;.[]|\u0026#34;\\(.id)\u0026#34;\u0026#39;) for id in $ids; do eval \u0026#34;curl --request DELETE --header \u0026#39;PRIVATE-TOKEN:${PRIVATE_TOKEN}\u0026#39; \u0026#39;${GITLAB_URL}/api/v4/runners/${id}\u0026#39;\u0026#34; printf \u0026#34;\\033[32m=====================删除id为${id}的runner======================\\033[0m\\n\u0026#34; done # 注册gitlab runner CUR_DATE=$(date \u0026#34;\u0026#43;%Y-%m-%d %H:%M:%S\u0026#34;) TOKEN=\u0026#39;M9VwuFfu9E42mb5QRx7M\u0026#39; TAG_LIST=\u0026#39;xxxxx-doc\u0026#39; DESC=\u0026#39;xxxxx文档撰写\u0026#39; echo \u0026#39;===================开始注册gitlab runner=====================\u0026#39; sudo docker exec -it gitbook-custom \\ gitlab-runner register --non-interactive \\ --url \u0026#34;${GITLAB_URL}\u0026#34; \\ --registration-token \u0026#34;${TOKEN}\u0026#34; \\ --executor \u0026#34;shell\u0026#34; \\ --tag-list \u0026#34;${TAG_LIST}\u0026#34; \\ --description \u0026#34;${DESC} -- 添加时间:${CUR_DATE}\u0026#34; # 安装gitbook echo \u0026#39;===================开始检查gitbook=====================\u0026#39; check=$(docker exec -it --user gitlab-runner gitbook-custom gitbook ls) if [[ $check == *\u0026#34;no versions installed\u0026#34;* ]]; then echo \u0026#34;gitbook在gitlab-runner用户下没有安装\u0026#34; command=\u0026#34;npm config set registry https://mirrors.xxx.com/repository/NPM/\u0026#34; command=\u0026#34;${command};gitbook fetch\u0026#34; command=\u0026#34;${command};cd /usr/local/gitbook/tmp\u0026#34; command=\u0026#34;${command};npm install gitbook-plugin-mermaid-fox\u0026#34; command=\u0026#34;${command};gitbook install\u0026#34; #command=\u0026#34;${command};cp /usr/local/gitbook/tmp/node_modules/prismjs/components/prism-docker.js /usr/local/gitbook/tmp/node_modules/prismjs/components/prism-dockerfile.js\u0026#34; command=\u0026#34;docker exec -it --user gitlab-runner gitbook-custom bash -c \u0026#39;$command\u0026#39;\u0026#34; echo \u0026#34;=========================要执行的命令=======================\u0026#34; printf \u0026#34;\\033[32m${command}\\033[0m\\n\u0026#34; echo \u0026#34;============================================================\u0026#34; eval $command else printf \u0026#34;\\033[32mGitbook已经安装，相关检查结果如下:\\033[0m\\n\u0026#34; echo \u0026#34;$check\u0026#34; fi printf \u0026#34;\\033[32m===================gitlab runner初始化完毕!=====================\\033[0m\\n\u0026#34; 自动生成目录 auto_generate_summary.sh用于自动生成目录，GitBook左侧的目录树依赖于此脚本的生成结果，此文件会在GitLab Runner构建阶段执行\n#!/bin/bash # 先清空文件 echo \u0026#34;\u0026#34; \u0026gt; docs/SUMMARY.md # 子文件夹读取的递归函数 dirReader(){ # $1 文件绝对路径 # $2 章节名称 # $3 缩进 # 循环处理该文件夹下的文件 for item in \u0026#34;${1}\u0026#34;/* do # 判断是否是文件夹且不是图片文件夹 if [ -d \u0026#34;$item\u0026#34; ] \u0026amp;\u0026amp; ! [[ \u0026#34;${item}\u0026#34; =~ assets$ ]] then # 判断该文件夹是否存在README.md文件 if [ ! -f \u0026#34;$item/README.md\u0026#34; ] then # 如果没有就创建README.md echo \u0026#34;\u0026#34; \u0026gt; \u0026#34;$item/README.md\u0026#34; fi # 获取文件名称 beginPos=`expr ${#1} \u0026#43; 1` endPos=`expr ${#item} - ${#1}` dirName=${item:$beginPos:$endPos} echo ${item} # 写入目录文件 echo \u0026#34;$3\u0026#43; [$dirName]($2/$dirName/README.md)\u0026#34; \u0026gt;\u0026gt; docs/SUMMARY.md # 递归处理该文件夹 dirReader \u0026#34;$item\u0026#34; \u0026#34;$2/$dirName\u0026#34; \u0026#34;$3 \u0026#34; # 判断该文件是否是.md结尾 并且不是README.md elif [ -f \u0026#34;$item\u0026#34; ] \u0026amp;\u0026amp; [ \u0026#34;${item##*.}\u0026#34; == \u0026#39;md\u0026#39; ] then beginPos=`expr ${#1} \u0026#43; 1` endPos=`expr ${#item} - ${#1} - 4` dirName=${item:$beginPos:$endPos} # 写入目录文件 if[ \u0026#34;$dirName\u0026#34; != \u0026#39;README\u0026#39; ] then echo ${item} echo \u0026#34;$3\u0026#43; [$dirName]($2/$dirName.md)\u0026#34; \u0026gt;\u0026gt; docs/SUMMARY.md fi fi done } # 读取当前路径 dirs=\u0026#34;${PWD}/docs/\u0026#34; echo \u0026#34;- [主页](README.md)\u0026#34; \u0026gt; docs/SUMMARY.md # 循环处理该文件夹下的文件dir for dir in docs/* do # 截取掉dir路径名称里的 docs/ startPos=\u0026#39;5\u0026#39; length=`expr ${#dir} - 5` dir=${dir:$startPos:$length} # 判断是否是文件夹且不是图片文件夹 if [ -d \u0026#34;${dirs}/${dir}\u0026#34; ] \u0026amp;\u0026amp; ! [[ \u0026#34;${dir}\u0026#34; =~ assets$ ]] \u0026amp;\u0026amp; ! [[ \u0026#34;${dir}\u0026#34; =~ styles$ ]] then # 判断该文件夹是否存在README.md文件 if [ ! -f \u0026#34;$dirs/$dir/README.md\u0026#34; ] then echo \u0026#34;\u0026#34; \u0026gt; \u0026#34;$dirs/$dir/README.md\u0026#34; fi # 写入目录文件 echo \u0026#34;\u0026#43; [$dir]($dir/README.md)\u0026#34; \u0026gt;\u0026gt; docs/SUMMARY.md # 处理文件夹内部的文件 dirReader \u0026#34;$dirs$dir\u0026#34; \u0026#34;$dir\u0026#34; \u0026#34; \u0026#34; # 判断该文件是否是.md结尾 并且不是SUMMARY.md 和 README.md elif [ \u0026#34;${dir##*.}\u0026#34; == \u0026#39;md\u0026#39; ] \u0026amp;\u0026amp; [ \u0026#34;${dir}\u0026#34; != \u0026#34;SUMMARY.md\u0026#34; ] \u0026amp;\u0026amp; [ \u0026#34;${dir}\u0026#34; != \u0026#39;README.md\u0026#39; ] then # 写入目录文件 echo \u0026#34;\u0026#43; [$dir]($dir)\u0026#34; \u0026gt;\u0026gt; docs/SUMMARY.md fi done 目录分类显示 若需要在生成目录时能自动进行如上图所示的分类展示，则可将上述脚本修改为类似如下\n#!/bin/bash : \u0026#39; 此脚本用于生成目录时可根据目录类别分成多个子类，要分类的顶层文件夹记录在special_tags数组变量中 \u0026#39; # 先清空文件 echo \u0026#34;\u0026#34; \u0026gt; docs/SUMMARY.md # 子文件夹读取的递归函数 dirReader(){ # $1 文件绝对路径 # $2 章节名称 # $3 缩进 # 循环处理该文件夹下的文件 for item in \u0026#34;${1}\u0026#34;/* do\t# 判断是否是文件夹且不是图片文件夹 if [ -d \u0026#34;$item\u0026#34; ] \u0026amp;\u0026amp; ! [[ \u0026#34;${item}\u0026#34; =~ assets$ ]] then # 判断该文件夹是否存在README.md文件 if [ ! -f \u0026#34;$item/README.md\u0026#34; ] then # 如果没有就创建README.md echo \u0026#34;\u0026#34; \u0026gt; \u0026#34;$item/README.md\u0026#34; fi # 获取文件名称 beginPos=`expr ${#1} \u0026#43; 1` endPos=`expr ${#item} - ${#1}` dirName=${item:$beginPos:$endPos} echo ${item} # 写入目录文件 echo \u0026#34;$3\u0026#43; [$dirName]($2/$dirName/README.md)\u0026#34; \u0026gt;\u0026gt; docs/SUMMARY.md # 递归处理该文件夹 dirReader \u0026#34;$item\u0026#34; \u0026#34;$2/$dirName\u0026#34; \u0026#34;$3 \u0026#34; # 判断该文件是否是.md结尾 并且不是README.md elif [ -f \u0026#34;$item\u0026#34; ] \u0026amp;\u0026amp; [ \u0026#34;${item##*.}\u0026#34; == \u0026#39;md\u0026#39; ] then beginPos=`expr ${#1} \u0026#43; 1` endPos=`expr ${#item} - ${#1} - 4` dirName=${item:$beginPos:$endPos} # 写入目录文件 if\t[ \u0026#34;$dirName\u0026#34; != \u0026#39;README\u0026#39; ] then echo ${item} echo \u0026#34;$3\u0026#43; [$dirName]($2/$dirName.md)\u0026#34; \u0026gt;\u0026gt; docs/SUMMARY.md fi fi done } baseReader(){ # 需要另外新开一个分类 special_tags=(\u0026#34;VDE相关\u0026#34; \u0026#34;云授权平台\u0026#34;) regex=$(IFS=\u0026#39;|\u0026#39;; echo \u0026#34;${special_tags[*]}\u0026#34;) special_dirs=() # 读取当前路径 dirs=\u0026#34;${PWD}/docs/\u0026#34; echo \u0026#34;- [主页](README.md)\u0026#34; \u0026gt; docs/SUMMARY.md # 循环处理该文件夹下的文件dir for dir in docs/* do # 截取掉dir路径名称里的 docs/ startPos=\u0026#39;5\u0026#39; length=`expr ${#dir} - 5` dir=${dir:$startPos:$length} if echo \u0026#34;$dir\u0026#34; | egrep -iq \u0026#34;$regex\u0026#34; ; then special_dirs\u0026#43;=(\u0026#34;$dir\u0026#34;) else baseWrite \u0026#34;$dirs\u0026#34; \u0026#34;$dir\u0026#34; fi done # 处理特殊类别的文件 if [[ -n \u0026#34;$special_dirs\u0026#34; ]]; then echo $\u0026#39;\\n#\\n\u0026#39; \u0026gt;\u0026gt; docs/SUMMARY.md fi for dir in \u0026#34;${special_dirs[@]}\u0026#34;; do baseWrite \u0026#34;$dirs\u0026#34; \u0026#34;$dir\u0026#34; done } baseWrite(){ dirs=$1 dir=$2 # 判断是否是文件夹且不是图片文件夹 if [ -d \u0026#34;${dirs}/${dir}\u0026#34; ] \u0026amp;\u0026amp; ! [[ \u0026#34;${dir}\u0026#34; =~ assets$ ]] \u0026amp;\u0026amp; ! [[ \u0026#34;${dir}\u0026#34; =~ styles$ ]] then # 判断该文件夹是否存在README.md文件 if [ ! -f \u0026#34;$dirs/$dir/README.md\u0026#34; ] then echo \u0026#34;\u0026#34; \u0026gt; \u0026#34;$dirs/$dir/README.md\u0026#34; fi # 写入目录文件 echo \u0026#34;\u0026#43; [$dir]($dir/README.md)\u0026#34; \u0026gt;\u0026gt; docs/SUMMARY.md # 处理文件夹内部的文件 dirReader \u0026#34;$dirs$dir\u0026#34; \u0026#34;$dir\u0026#34; \u0026#34; \u0026#34; # 判断该文件是否是.md结尾 并且不是SUMMARY.md 和 README.md elif [ \u0026#34;${dir##*.}\u0026#34; == \u0026#39;md\u0026#39; ] \u0026amp;\u0026amp; [ \u0026#34;${dir}\u0026#34; != \u0026#34;SUMMARY.md\u0026#34; ] \u0026amp;\u0026amp; [ \u0026#34;${dir}\u0026#34; != \u0026#39;README.md\u0026#39; ] then # 写入目录文件 echo \u0026#34;\u0026#43; [$dir]($dir)\u0026#34; \u0026gt;\u0026gt; docs/SUMMARY.md fi } baseReader 自定义样式 custom.css是自定义样式文件，当对GitBook的某些样式不满意时，可用自定义CSS文件来覆盖\n.book .book-body .page-wrapper .page-inner { max-width: 1200px !important; } .markdown-section img:not(.emoji) { max-width: 100%; border: 1px dashed #a9a4a4; } table \u0026gt; thead \u0026gt; tr \u0026gt; th { text-align:center !important; } .markdown-section code:not([class^=\u0026#34;lang-\u0026#34;]) { padding: 3px 5px; margin: 0; font-size: .85em; color: #c7254e; border-radius: 4px; } small { font-size: 80% !important; } section { width:100%; } h1 { color: #2674BA; } h2 { color: #0099CC; } h3 { color: #F77A0B; } h4 { color: #662D91; } h5 { color: #444444; } th { background-color: #2674BA; color: white; } GitBook配置文件 book.js是GitBook的配置文件，包含全局配置与各种插件\nmodule.exports = { // markdown文档所在路径 root: \u0026#39;./docs\u0026#39;, // 项目标题 title: \u0026#39;xxxxx平台文档\u0026#39;, // 版本 gitbook: \u0026#39;3.2.3\u0026#39;, language: \u0026#39;zh-hans\u0026#39;, // 插件 plugins: [ \u0026#39;-highlight\u0026#39;, \u0026#39;prism-codetab-fox\u0026#39;, \u0026#39;advanced-emoji\u0026#39;, \u0026#39;mermaid-fox\u0026#39;, // 图表 \u0026#39;graph\u0026#39;, \u0026#39;flowchart-fox\u0026#39;, \u0026#39;chart\u0026#39;, \u0026#39;popup\u0026#39;, \u0026#39;accordion\u0026#39;, \u0026#39;katex\u0026#39;, \u0026#39;-search\u0026#39;, //搜索 \u0026#39;search-pro\u0026#39;, //中文搜索 \u0026#39;hide-element\u0026#39;, //元素隐藏 \u0026#39;-lunr\u0026#39;, //索引 \u0026#39;chapter-fold\u0026#39;, //导航目录折叠 \u0026#39;code\u0026#39;, //代码复制按钮 \u0026#39;splitter\u0026#39;, //侧边栏宽度可调节 \u0026#39;expandable-chapters-small\u0026#39;, //目录收起 \u0026#39;tbfed-pagefooter\u0026#39;, //页面添加页脚 \u0026#39;ancre-navigation\u0026#39;, //页内导航回到顶部 \u0026#39;-sharing\u0026#39;, \u0026#39;sharing-plus\u0026#39;, //分享链接 \u0026#39;theme-comscore\u0026#39;, //主题 \u0026#39;favicon\u0026#39;, //图标 \u0026#39;flexible-alerts\u0026#39; // 警告 ], // 插件配置 pluginsConfig: { \u0026#39;prism\u0026#39;: { \u0026#39;css\u0026#39;: [ \u0026#39;prismjs/themes/prism-solarizedlight.css\u0026#39; ], \u0026#34;lang\u0026#34;: { \u0026#34;dockerfile\u0026#34;: \u0026#34;docker\u0026#34; }, \u0026#34;ignore\u0026#34;: [ \u0026#34;mermaid\u0026#34;, \u0026#34;eval-js\u0026#34; ] }, \u0026#39;hide-element\u0026#39;: { \u0026#39;elements\u0026#39;: [\u0026#39;.gitbook-link\u0026#39;] //需要隐藏的元素，可以通过浏览网页找到该class }, \u0026#39;tbfed-pagefooter\u0026#39;: { \u0026#39;copyright\u0026#39;: \u0026#39;Copyright \u0026amp;copy xxx.com 2023-2033\u0026#39;, \u0026#39;modify_label\u0026#39;: \u0026#39;修订时间：\u0026#39;, \u0026#39;modify_format\u0026#39;: \u0026#39;YYYY-MM-DD HH:mm:ss\u0026#39; }, \u0026#39;sharing\u0026#39;: { \u0026#39;all\u0026#39;: [] }, \u0026#34;chart\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;c3\u0026#34; }, \u0026#34;chapter-fold\u0026#34;: {}, \u0026#34;favicon\u0026#34;: { \u0026#34;shortcut\u0026#34;: \u0026#34;/favicon.ico\u0026#34;, \u0026#34;bookmark\u0026#34;: \u0026#34;/favicon.ico\u0026#34; }, \u0026#39;flowchart\u0026#39;: { \u0026#34;arrow-end\u0026#34;: \u0026#34;block\u0026#34;, \u0026#34;element-color\u0026#34;: \u0026#34;black\u0026#34;, \u0026#34;fill\u0026#34;: \u0026#34;white\u0026#34;, \u0026#34;flowstate\u0026#34;: { \u0026#34;approved\u0026#34;: { \u0026#34;fill\u0026#34;: \u0026#34;#58C4A3\u0026#34;, \u0026#34;font-size\u0026#34;: 12 }, \u0026#34;current\u0026#34;: { \u0026#34;fill\u0026#34;: \u0026#34;#008080\u0026#34;, \u0026#34;font-color\u0026#34;: \u0026#34;white\u0026#34;, \u0026#34;font-weight\u0026#34;: \u0026#34;bold\u0026#34; }, \u0026#34;future\u0026#34;: { \u0026#34;fill\u0026#34;: \u0026#34;#8A624A\u0026#34; }, \u0026#34;success\u0026#34;: { \u0026#34;fill\u0026#34;: \u0026#34;#0B6623\u0026#34; }, \u0026#34;invalid\u0026#34;: { \u0026#34;fill\u0026#34;: \u0026#34;#6c5696\u0026#34; }, \u0026#34;past\u0026#34;: { \u0026#34;fill\u0026#34;: \u0026#34;#CCCCCC\u0026#34;, \u0026#34;font-size\u0026#34;: 12 }, \u0026#34;select\u0026#34;: { \u0026#34;fill\u0026#34;: \u0026#34;#E1AD01\u0026#34;, \u0026#34;font-size\u0026#34;: 12 }, \u0026#34;rejected\u0026#34;: { \u0026#34;fill\u0026#34;: \u0026#34;#C45879\u0026#34;, \u0026#34;font-size\u0026#34;: 12 }, \u0026#34;request\u0026#34;: { \u0026#34;fill\u0026#34;: \u0026#34;#569656\u0026#34; }, \u0026#39;yellowgreen\u0026#39;: { \u0026#34;fill\u0026#34;: \u0026#34;yellowgreen\u0026#34; }, \u0026#39;failed\u0026#39;: { \u0026#34;fill\u0026#34;: \u0026#34;#800020\u0026#34; } }, \u0026#34;font-color\u0026#34;: \u0026#34;black\u0026#34;, \u0026#34;font-size\u0026#34;: 14, \u0026#34;line-color\u0026#34;: \u0026#34;black\u0026#34;, \u0026#34;line-length\u0026#34;: 50, \u0026#34;line-width\u0026#34;: 1.3, \u0026#34;scale\u0026#34;: 1, \u0026#34;symbols\u0026#34;: { \u0026#34;end\u0026#34;: { \u0026#34;class\u0026#34;: \u0026#34;end-element\u0026#34;, \u0026#34;font-color\u0026#34;: \u0026#34;white\u0026#34;, \u0026#34;font-weight\u0026#34;: \u0026#34;bold\u0026#34; }, \u0026#34;start\u0026#34;: { \u0026#34;fill\u0026#34;: \u0026#34;#8c2106\u0026#34;, \u0026#34;font-color\u0026#34;: \u0026#34;white\u0026#34;, \u0026#34;font-weight\u0026#34;: \u0026#34;bold\u0026#34; } }, \u0026#34;text-margin\u0026#34;: 10, \u0026#34;width\u0026#34;: 1, \u0026#34;x\u0026#34;: 0, \u0026#34;y\u0026#34;: 0, \u0026#34;yes-text\u0026#34;: \u0026#34;是\u0026#34;, \u0026#34;no-text\u0026#34;: \u0026#34;否\u0026#34; } }, variables: { \u0026#34;styles\u0026#34;: { \u0026#34;website\u0026#34;: \u0026#34;./styles/website.css\u0026#34;, } } }; 可根据实际要求通过-lunr来屏蔽对应的索引插件\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-10-07T10:14:02+08:00","permalink":"https://lucumt.info/post/gitbook/using-docker-to-build-gitbook-with-gitlab-runner/","tags":["gitbook","docker","gitlab-runner"],"title":"在Docker中构建GitBook并整合GitLab Runner的使用经验分享"},{"categories":["工具使用"],"contents":"记录下如何给docsify添加多语言的代码高亮支持，以及在代码高亮的同时能显示行号，便利使用。\n环境准备 需要预先安装nodejs，之后在终端执行下述命令\nnpm i docsify-cli -g docsify init ./docs docsify serve ./docs 之后可通过http://localhost:3000来访问默认的模板，给默认生成的README.md文件分别添加javascript、java、golang代码块后显示结果类似如下\n从上图中可发现如下几个问题：\njavascript代码有高亮显示，而java和golang代码没有高亮显示 javascript代码虽然支持高亮显示，但是没有显示行号 代码块与真正的代码内容之间的间距过大，占用过多空间也不便于阅读 代码高亮 在Language highlighting中有如下说明\n可知其默认支持的代码高亮语言有限，其它的需要手工添加，在prismjs CDN files可查看全部支持的语言列表，在其生成的index.html文件中添加相关的高亮文件\n\u0026lt;script src=\u0026#34;//cdn.jsdelivr.net/npm/prismjs@1/components/prism-go.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;//cdn.jsdelivr.net/npm/prismjs@1/components/prism-java.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 保存配置后，可发现浏览器中的页面已经修改，java和golang已经添加了高亮支持\n前述第1个问题解决，余下的2个仍未解决。\n样式改进 在index.html中添加如下css代码\n.markdown-section pre \u0026gt; code { padding: 5px; } 此时可发现代码块的间距已经显著减少，问题2解决。\n显示行号 显示行号是代码高亮的一个刚需功能，不太明白为啥docsify的开发者一直没有整合这个功能。\n简单搜素下就发现有人已经提过此类问题 Prismjs supports line numbers and sepcific line highlight 根据该链接的回复对index.js做一些修改。\n将默认的渲染行为修改如下：\nwindow.$docsify = { name: \u0026#39;\u0026#39;, repo: \u0026#39;\u0026#39;, markdown: { renderer:{ code: function(code, lang) { if(lang ==\u0026#39;html\u0026#39;){ code = code.replace(/\u0026amp;/g, \u0026#34;\u0026amp;amp;\u0026#34;).replace(/\u0026lt;/g, \u0026#34;\u0026amp;lt;\u0026#34;).replace(/\u0026gt;/g, \u0026#34;\u0026amp;gt;\u0026#34;).replace(/\u0026#34;/g, \u0026#34;\u0026amp;quot;\u0026#34;).replace(/\u0026#39;/g, \u0026#34;\u0026amp;#039;\u0026#34;); } return (\u0026#39;\u0026lt;pre data-lang=\u0026#34;\u0026#39;\u0026#43;lang\u0026#43;\u0026#39;\u0026#34;\u0026gt;\u0026lt;code class=\u0026#34;line-numbers language-\u0026#39;\u0026#43;lang\u0026#43;\u0026#39;\u0026#34;\u0026gt;\u0026#39;\u0026#43;code\u0026#43;\u0026#39;\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\u0026#39;) } }\t}, plugins: [ function (hook, vm) { hook.doneEach(function (html) { Prism.highlightAll(); }) } ] } 添加如下css样式\n.markdown-section pre[data-lang] { overflow: auto !important; } .markdown-section pre[data-lang] code { overflow: visible; } .line-numbers .line-numbers-rows { border-right : 0px solid white; /* Fix paddings to align with code.*/ padding: 5px; /* Same as code block */ } 分别引入相关的css和js文件\n\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;//cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/line-numbers/prism-line-numbers.min.css\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;//cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/line-numbers/prism-line-numbers.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 之后查看docsify页面，效果如下，至此问题3也解决，顺利达成目的！\n后记 框架切换 由于docsify是将所有的markdown文件全部加载并渲染成单个html文件，导致其在初次打开时很卡顿，渲染完成后就很流畅。但每次打开浏览器访问docsify时都需要花时间进行初次渲染，尤其是随着markdown文件越来越多，渲染耗时也越来越多，严重影响体验。\n后续处于便于使用以及便于扩展、维护的角度考虑，最终将docsify替换为了GitBook，详情参见GitBook插件中实现从多个不同的文件夹下加载css和js文件。\n参考代码 完整的index.html代码如下\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Document\u0026lt;/title\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge,chrome=1\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;description\u0026#34; content=\u0026#34;Description\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0, minimum-scale=1.0\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;//cdn.jsdelivr.net/npm/docsify@4/lib/themes/vue.css\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;//cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/line-numbers/prism-line-numbers.min.css\u0026#34;\u0026gt; \u0026lt;style type=\u0026#34;text/css\u0026#34;\u0026gt;\t.markdown-section pre[data-lang] { overflow: auto !important; } .markdown-section pre[data-lang] code { overflow: visible; } .line-numbers .line-numbers-rows { border-right : 0px solid white; /* Fix paddings to align with code.*/ padding: 5px; /* Same as code block */ } .markdown-section pre \u0026gt; code { padding: 5px; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; window.$docsify = { name: \u0026#39;\u0026#39;, repo: \u0026#39;\u0026#39;, markdown: { renderer:{ code: function(code, lang) { if(lang ==\u0026#39;html\u0026#39;){ code = code.replace(/\u0026amp;/g, \u0026#34;\u0026amp;amp;\u0026#34;).replace(/\u0026lt;/g, \u0026#34;\u0026amp;lt;\u0026#34;).replace(/\u0026gt;/g, \u0026#34;\u0026amp;gt;\u0026#34;).replace(/\u0026#34;/g, \u0026#34;\u0026amp;quot;\u0026#34;).replace(/\u0026#39;/g, \u0026#34;\u0026amp;#039;\u0026#34;); } return (\u0026#39;\u0026lt;pre data-lang=\u0026#34;\u0026#39;\u0026#43;lang\u0026#43;\u0026#39;\u0026#34;\u0026gt;\u0026lt;code class=\u0026#34;line-numbers language-\u0026#39;\u0026#43;lang\u0026#43;\u0026#39;\u0026#34;\u0026gt;\u0026#39;\u0026#43;code\u0026#43;\u0026#39;\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\u0026#39;) } }\t}, plugins: [ function (hook, vm) { hook.doneEach(function (html) { Prism.highlightAll(); }) } ] } \u0026lt;/script\u0026gt; \u0026lt;!-- Docsify v4 --\u0026gt; \u0026lt;script src=\u0026#34;//cdn.jsdelivr.net/npm/docsify@4\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;//cdn.jsdelivr.net/npm/prismjs@1/components/prism-go.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;//cdn.jsdelivr.net/npm/prismjs@1/components/prism-java.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;//cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/line-numbers/prism-line-numbers.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ","date":"2023-09-22T10:13:56+08:00","permalink":"https://lucumt.info/post/docsify/enchane-code-highlight-in-docsify/","tags":["docsify"],"title":"对Docsify中的代码高亮显示进行增强"},{"categories":["java编程"],"contents":"简单记录由于Nacos导致的Spring Boot与Spring Cloud版本不兼容的原因分析过程。\n在在Python程序中使用Nacos这篇文章中我吐槽了Nacos，今天我还要继续吐槽Nacos！\nWhy? 因为Nacos中的一个jar包引入了错误的spring-cloud-commons依赖，导致Spring Boot程序启动时出现版本不兼容问题，启动失败，浪费了我好几个小时的时间(虽然这样显得我很不专业)！\n问题 自己准备将网关项目加入Nacos的服务管理和配置管理功能，依照官方文档的说明添加了com.alibaba.cloud相关的依赖，pom.xml文件中的完整配置如下\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.lucumt\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-gateway-test\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;spring-gateway-demo\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://lucumt.info\u0026lt;/url\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;maven.compiler.source\u0026gt;1.8\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;1.8\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;spring.boot.version\u0026gt;2.7.3\u0026lt;/spring.boot.version\u0026gt; \u0026lt;spring.cloud.version\u0026gt;3.1.3\u0026lt;/spring.cloud.version\u0026gt; \u0026lt;spring.cloud.alibaba.version\u0026gt;2021.1\u0026lt;/spring.cloud.alibaba.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2021.0.8\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-alibaba-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.cloud.alibaba.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-config\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.cloud.alibaba.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.cloud.alibaba.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-bootstrap\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.cloud.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.boot.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.boot.version}\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.boot.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.18.24\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.boot.version}\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;repackage\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; 启动该程序后控制台提示如下错误，程序启动失败！\nError starting ApplicationContext. To display the conditions report re-run your application with \u0026#39;debug\u0026#39; enabled. 2023-09-01 21:02:30.144 ERROR 20760 --- [ main] o.s.b.d.LoggingFailureAnalysisReporter : *************************** APPLICATION FAILED TO START *************************** Description: Your project setup is incompatible with our requirements due to following reasons: - Spring Boot [2.7.3] is not compatible with this Spring Cloud release train Action: Consider applying the following actions: - Change Spring Boot version to one of the following versions [2.3.x, 2.4.x] . You can find the latest Spring Boot versions here [https://spring.io/projects/spring-boot#learn]. If you want to learn more about the Spring Cloud Release train compatibility, you can visit this page [https://spring.io/projects/spring-cloud#overview] and check the [Release Trains] section. If you want to disable this check, just set the property [spring.cloud.compatibility-verifier.enabled=false] 分析 根据上述报错提示信息去https://spring.io/projects/spring-cloud#overview中去查看Release Train:\n进一步的查看上图中标红的版本结果如下，可发现Spring Cloud中主要的模块版本都为3.1.x系列。\n而我自己项目中Spring Boot和Spring Cloud的版本定义如下，明明符合上图中的版本对应关系，为啥还是报错呢？\n\u0026lt;spring.boot.version\u0026gt;2.7.3\u0026lt;/spring.boot.version\u0026gt; \u0026lt;spring.cloud.version\u0026gt;3.1.3\u0026lt;/spring.cloud.version\u0026gt; 虽然可通过提示说明spring.cloud.compatibility-verifier.enabled=false来暂时规避掉此问题，但我还是很好奇为啥明明版本对应上了，实际上却依然报错？\n遇到这种问题自己的第一反应是通过Google与Stackoverflow去查找，但并没有找到有用信息。\n之后根据提示尝试将SpringBoot版本降低到2.3.x或2.4.x，依然未能解决问题。\n没办法我只能采用终极大招通过二分法查找定位！将Nacos相关的依赖都去掉，然后逐步添加回去，最终发现是spring-cloud-starter-alibaba-nacos-config导致的，之后再次去Google一番，依旧没能找到原因。\n怎么办？\n突然间想到将日志级别设置为DEBUG是否能找到一些有用的信息呢？说干就干，bootstrap.yaml文件中添加如下配置\nlogging: level: root: DEBUG 重新启动后控制台虽然依旧报错，但提示信息更详细，从中我们可找到如下信息:\norg.springframework.cloud.configuration.CompatibilityNotMetException: null at org.springframework.cloud.configuration.CompositeCompatibilityVerifier.verifyDependencies(CompositeCompatibilityVerifier.java:47) ~[spring-cloud-commons-3.0.1.jar:3.0.1] at org.springframework.cloud.configuration.CompatibilityVerifierAutoConfiguration.compositeCompatibilityVerifier(CompatibilityVerifierAutoConfiguration.java:44) ~[spring-cloud-commons-3.0.1.jar:3.0.1] 很明显版本不兼容是由spring-cloud-common导致的，在命令行执行mvn dependency:tree -Dincludes=\u0026quot;org.springframework.cloud:spring-cloud-commons\u0026quot;输出结果如下\n[INFO] com.lucumt:spring-gateway-test:jar:1.0-SNAPSHOT [INFO] \\- com.alibaba.cloud:spring-cloud-starter-alibaba-nacos-config:jar:2021.1:compile [INFO] \\- org.springframework.cloud:spring-cloud-commons:jar:3.0.1:compile 可以看出确实是由于spring-cloud-starter-alibaba-nacos-config包引入后导致的。\n在Maven中央仓库中查看该版本对应的jar包依赖结果如下，spring-cloud-commons的依赖版本确实是3.0.1，与前述分析结果一致。\n解决 找到问题原因后，解决起来很简单，在pom.xml文件中手工指定spring-cloud-commons的依赖并下载即可：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-commons\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.cloud.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 反思 虽然此问题的原因和解决方案都不复杂，但我在此问题上浪费了好几个小时感觉很不划算，本着严于律己，宽以待人的原则主要问题还是出在自己身上：没有早点开启DEBUG日志模块，早点打开就能早发现，自己没有形成相关的问题排查方法论。\n","date":"2023-09-01T10:19:48+08:00","permalink":"https://lucumt.info/post/nacos/spring-boot-cloud-version-not-compatible-due-to-nacos/","tags":["nacos","spring-boot","spring-cloud"],"title":"由于Nacos导致的Spring Boot与Spring Cloud版本不兼容原因分析"},{"categories":["翻译"],"contents":" 说明\n在阅读阮一峰老师的科技爱好者周刊（第 266 期）时，发现其中一篇关于Docker Compose的文章4'000 Stars and counting, a trip down memory lane很有意思，基于自己粗浅的英文翻译一下。\n正文：\n回忆之旅，Docker Compose以及使用Docker和Prometheus进行监控的历史，在这个过程中，我发现了一个很棒的社区。\n由Clarisse Meyer/ Unsplash拍摄\n在2014年我很幸运成为第一批踏上Docker之旅并尝试将监控堆栈容器化的人之一，从年初开始了解Docker，我花了几个月时间弄清楚它是如何工作的，同时在工程师间的DM\u0026rsquo;s1中修复问题并提出了大量问题，当时只有少数人在聊天，社区很小以至于大家互相之间都认识。\n作为一名监控和数据极客，在2014年我负责为我们新的云创业(Cloud venture)构建适应性更强的监控解决方案。最开始，我试图在Docker中构建当前的监控解决方案。就像容器友好之前的Nagios、Centreon、Piwik 分析以及许多其它工具一样，这些工具并没有真正解决我的问题。我通过Grafana偶然发现了InfluxD，但很快意识到它不符合我们的使用场景。\n经过对不同工具的多次尝试和错误后，我偶然间发现Soundcloud基础设施博客以及他们如何基于微服务架构构建用Go编写的时间序列监控工具，在当时，这似乎太过超前和牵强，甚至看起来不真实。如果我没记错的话，就是这篇博客文章，它将Prometheus推向了公众：Prometheus: Monitoring at SoundCloud。\n首先，我们要容器化一切。\n回到2014年，相信与否，这是一个没有编排器的时代，大多数人将一堆单个Docker运行命令与bash脚本串在一起，并尝试使用bash脚本“编排”容器。\n幸运的是，在2015 年，一家名为Orchard的公司正忙于构建名为Fig的第一个Docker容器编排器。Fig是一个绝对令人惊奇的工具，你可以用YAML来编写一些奇怪的代码，这是我之前从未见过的。基本上，将所有 Docker运行命令组合到一个文件中，从而允许我们将微服务构建到一个文件中。\n用单个文件运行Docker命令==令人震惊 在我开始使用Fig并加快步伐后不久，Docker宣布收购Fig的母公司：Orchad，我们还可以在Docker Compose版本历史记录中看到Fig于2014年10月加入Docker时的精彩历史快照。\n几个月之后，Docker在2015年2月宣布将Fig更名为Docker Compose，它是容器发展史上我永远不会忘掉的一个里程碑。从那之后，我开始研究如何将我所有我喜欢的监控工具整合到一个文件中，我开始使用Prometheus、Grafana、Node Exporters和Google cAdvisor。我花了几周的时间才弄清楚Docker Compose内部的网络，因为还处于早期阶段，我们今天认为理所当然的很多东西在当时还不可用。让容器通过多个服务相互通信、配置、安装存储等是一项艰巨的任务，但最后确实生效了。\n下图展示了我使用Prometheus和Grafana创建的第一个仪表板，它并不美观，但是嘿，它们是基于Docker Compose编排与协同工作的，同时还能监视容器和基础设施。\n基于Prometheus和Grafana的监控面板初始版本 在它启动并成功运行之后，我在博客上写了几篇关于它的文章，与此同时获得了来自Google、Docker和整个社区的广泛关注，Google还主动联系并要求我在他们位于瑞士苏黎世的总部展示我正在构建的东西。\n我不确定我是否为第一个使用Docker Compose创建完整监控堆栈的人，但我绝对是第一个创建详细手册、简单的一键部署指南，参加Docker监控研讨会培训并100人如何开始使用Docker和监控的人。很快我成为第一批Docker Captains之一，写书、参加采访，并很早就成为Docker社区不可或缺的一部分。\n对我来说始终很重要的一点是：Docker Prometheus项目的目标是帮助他人并回馈社区，开源不仅对于代码编写非常重要，而且对于支持、教导和指导他人也非常重要，我相信这个项目帮助启动了其它的一些项目和组织，以继续构建令人惊叹的作品。\n我知道的第2件事情：Docker Prometheus GitHub项目有1k点赞，然后是2k，现在是4k，GitHub项目的点赞数在早期有特殊的含义，一些公司使用它们作为向投资机构推销的指标，而现在它只是一个虚荣指标，但我仍然喜欢不时的对自己的项目进行检查和反思。\n这是一段尚未完成的奇妙旅程，我鼓励每个人尽其所能帮助并回馈开源项目，从编写代码到修复文档，每一个贡献都是有益的。\n感谢Solomon Hykes、Scott Johnston、Bret Fisher、Laura Tacho、Julien Bisconti，所有Docker Captains以及Docker和整个Docker社区的每个人。\n\u0026lt;–翻译结束!–\u0026gt;\n注：全称为Direct Message，即私有消息，一对一聊天，Twitter中的常用语法\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-08-13T17:49:14+08:00","permalink":"https://lucumt.info/post/translate/docker/4000-stars-and-counting-a-trip-down-memory-lane/","tags":["docker"],"title":"[译]4000个点赞并且在不断增加，回忆之旅"},{"categories":["持续集成","工具使用"],"contents":"近期在给公司内部安装KubeSphere新环境和维护原有KubeSphere环境的过程中，频繁遇到x509: certificate relies on legacy Common Name field, use SANs instead，此问题会影响正常功能的使用，简要介绍其解决方案。\n问题描述 本操作过程基于KubeSphere离线安装一文来操作的。\n执行下述命令生成自己的证书\nmkdir -p certs openssl req -newkey rsa:4096 -nodes -sha256 -keyout certs/domain.key -x509 -days 36500 -out certs/domain.crt 在生成证书的过程中按照文档要求将Common Name的值设置为dockerhub.kubekey.local\n在/etc/hosts中将dockerhub.kubekey.local映射到当前服务器IP地址\n192.168.0.2 dockerhub.kubekey.local 让Docker信任刚生成的证书\nmkdir -p /etc/docker/certs.d/dockerhub.kubekey.local cp certs/domain.crt /etc/docker/certs.d/dockerhub.kubekey.local/ca.crt 执行下述命令启动Docker仓库\ndocker run -d \\ --restart=always \\ --name registry \\ -v \u0026#34;$(pwd)\u0026#34;/certs:/certs \\ -v /mnt/registry:/var/lib/registry \\ -e REGISTRY_HTTP_ADDR=0.0.0.0:443 \\ -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt \\ -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key \\ -p 443:443 \\ registry:2 在终端执行docker pull dockerhub.kubekey.local/nginx，运行结果如下，提示原证书的配置方式过期，不能正常使用，问题出现!\n分析与解决 在https://go.dev/doc/go1.15#commonname中找到如下一段说明\nThe deprecated, legacy behavior of treating the CommonName field on X.509 certificates as a host name when no Subject Alternative Names are present is now disabled by default. It can be temporarily re-enabled by adding the value x509ignoreCN=0 to the GODEBUG environment variable.\nNote that if the CommonName is an invalid host name, it\u0026rsquo;s always ignored, regardless of GODEBUG settings. Invalid names include those with any characters other than letters, digits, hyphens and underscores, and those with empty labels or trailing dots\n从中可知在Go10.15之后Common Name这个字段已经废弃，可在GODEBUG中通过配置x509ignoreCN=0来重新启用此字段，不过我们是基于Go的Docker应用环境，而非Go开发环境，显然此种方式不大可行。\n继续搜索，找到这篇文章how-do-i-use-sans-with-openssl-instead-of-common-name，其中提供了一个解决思路\n对原有生成证书的步骤改进如下，然后重新执行生成证书\nopenssl req -addext \u0026#34;subjectAltName = DNS:dockerhub.kubekey.local\u0026#34; -newkey rsa:4096 -nodes -sha256 -keyout certs/domain.key -x509 -days 36500 -out certs/domain.crt 重新执行docker pull dockerhub.kubekey.local/nginx可发现证书问题已经解决\n前述执行结果任然报错的原因为镜像不存在，切换为一个已经存在的镜像重新执行即可\n","date":"2023-07-06T09:54:01+08:00","permalink":"https://lucumt.info/post/docker/x509-certificate-relies-on-legacy-common-name-field-use-sans-instead/","tags":["docker","kubernetes","kubesphere"],"title":"在Docker中遇到x509: certificate relies on legacy Common Name field, use SANs instead问题的解决"},{"categories":["翻译","JUnit5翻译"],"contents":"本文翻译自How Do I Test Private Methods?\n测试私有方法的最佳方式是什么，使用一些库还是使用反射？\n不要直接测试私有方法，测试私有方法的最佳方法是通过另一个公共方法，私有方法是公共方法的实现细节。\n但是，但是……通过公共方法来测试私有方法可能会很困难。\n如果是这种情况，那么意味着测试的类设计不太好，如果测试设置太复杂，该类可能会尝试做太多事情，此时应该看看是否可以在新类中提取出一些功能。\n但是，但是……如果添加更多的类，不是会增加复杂性吗？\n在大多数情况下，添加新类会降低而不是增加复杂性，当一个类有一个明确的、小的职责时，它就很容易理解和测试。\n但是，但是……所以仅仅只是为了测试我们需要编写10个小类来替代私有方法？\n我并不是建议你应该创建一个新类只是为了测试方法，我建议如果你关注输出则可以改进你的设计，诸如复杂的测试设置之类的事情是关于实现复杂性的提示线索。\n但是，但是……能否把这个方法公开？\n仅仅为了测试而暴露方法并不是一个好主意，它会破坏封装并泄漏内部结构且每个人都能访问，这可能会产生有害的副作用，测试私有方法的设计可能意味着它是属于另一个类的单独职责的一部分。\n但是，但是……如果不能将方法公开，那么提取到一个单独的类不也是做同样的事情吗？\n如果将某些内容移动到另一个类让你感到困惑，那么除了public和private之外还有更多的可见性修饰符，如package-private和protected，可利用这些优势来发挥，如果测试类与目标类位于同一个包中，则没有问题。\n但是，但是……我想单独测试代码，单元测试不是应该被隔离吗？\n隔离通常意味着与服务、数据库或文件系统等外部依赖项的隔离。\n如果直接测试私有方法，则每次重构类时测试都会中断，另一方面如果只测试公共方法，则可以在不破坏测试的情况下重构类内部。\n但是，但是……测试和代码不是应该齐头并进吗？\n是的，但仅限于公共协作层面，如果直接测试实现逻辑而有人想对其进行小更改，那么他也必须更改测试。\n如果重复这样做，单元测试就会开始阻碍开发并成为开发团队的烦恼，如果不能在不改变测试的情况下改变你的实现，那么测试策略就不合适。\n但是，但是……如果我喜欢采用自下而上的方法，并且在编写私有方法时没有公共方法怎么办？\n也许你应该尝试自上而下的方法，如果先编写私有方法，你就会猜测你需要什么，如果最后对解决方案不满意则必须重写所有测试，从公共方法开始编写会让你思考它将如何使用。\n但是，但是……如果我开发出解决方案，但测试没有通过，那不是很难知道问题出在哪里吗？\n不完全这样，你不会一次性实施所有事情，你将从一个简单的测试和一个简单的解决方案开始，之后可以逐步添加测试和功能，可以获得相同的覆盖范围，并且可以在不破坏测试的情况下重构实现。\n嗯\u0026hellip; 好吧，我还没有100%相信，但你已经提出了一些很好的观点，让我考虑一下。\n好极了，稍后告诉我你的想法。\n","date":"2023-07-03T22:42:07+08:00","permalink":"https://lucumt.info/post/translate/junit5/testing-private-methods/","tags":["java","junit"],"title":"[译]如何测试私有方法"},{"categories":["翻译","JUnit5翻译"],"contents":"本文翻译自JUnit 5 Expected Exception: How to assert an exception is thrown?\n在本文中，我们将学习如何使用JUnit 5断言抛出异常以及如何检查抛出异常的错误消息。\n本文是JUnit 5 教程的一部分。\n概览 为了确保我们的错误处理逻辑正常工作，验证一段代码在某些条件下是否出发特定异常是有必要的。\n断言抛出异常 断言一段代码抛出特定的异常可通过使用JUnit 5中的assertThrows()方法来完成：\n@Test void notEnoughFunds() { BankAccount account = new BankAccount(9); assertThrows(NotEnoughFundsException.class, () -\u0026gt; account.withdraw(10), \u0026#34;Balance must be greater than amount of withdrawal\u0026#34;); } 在此示例中，如果我们尝试从帐户余额允许的银行帐户中提取更多资金，则相关代码实现会抛出NotEnoughFundsException异常。\n失败的断言 现在，假设在我们的示例中忘记在提款前检查余额，如果不抛出异常，测试将失败并显示错误消息：\nBalance must be greater than amount of withdrawal ==\u0026gt; Expected com.arhohuttunen.junit5.exception.NotEnoughFundsException to be thrown, but nothing was thrown. org.opentest4j.AssertionFailedError: Balance must be greater than amount of withdrawal ==\u0026gt; Expected com.arhohuttunen.junit5.exception.NotEnoughFundsException to be thrown, but nothing was thrown. 此外，假设在我们的示例中我们忘记初始化余额，代码将抛出NullPointerException异常，如果抛出非预期异常，测试将失败并显示不同的错误消息：\nBalance must be greater than amount of withdrawal ==\u0026gt; Unexpected exception type thrown ==\u0026gt; expected: \u0026lt;com.arhohuttunen.junit5.exception.NotEnoughFundsException\u0026gt; but was: \u0026lt;java.lang.NullPointerException\u0026gt; org.opentest4j.AssertionFailedError: Balance must be greater than amount of withdrawal ==\u0026gt; Unexpected exception type thrown ==\u0026gt; expected: \u0026lt;com.arhohuttunen.junit5.exception.NotEnoughFundsException\u0026gt; but was: \u0026lt;java.lang.NullPointerException\u0026gt; 断言异常消息 此外，有时我们想要验证异常的一些信息，例如错误消息或原因，在这种情况下可以捕获抛出的异常：\n@Test void notEnoughFundsWithMessage() { BankAccount account = new BankAccount(0); Throwable thrown = assertThrows(NotEnoughFundsException.class, () -\u0026gt; account.withdraw(100)); assertEquals(\u0026#34;Attempted to withdraw 100 with a balance of 0\u0026#34;, thrown.getMessage()); } 总结 JUnit 5可以轻松断言使用assertThrows()方法引出发预期的异常，此外也可以捕获抛出的异常以检查错误消息等更多信息。\n本文的示例代码能在GitHub中找到。\n","date":"2023-07-02T14:21:43+08:00","permalink":"https://lucumt.info/post/translate/junit5/junit-5-expected-exception/","tags":["java","junit","junit5"],"title":"[译]Junit 5 预期异常 - 如何检测异常是否抛出"},{"categories":["翻译","JUnit5翻译"],"contents":"本文翻译自JUnit 5 Gradle Example。\n在本教程中，我们将学习在基于Gradle编写JUnit 5测试时如何获取相关的依赖，以及如何配置 JUnit Gradle插件来运行相关测试。\n本文是JUnit 5 教程的一部分。\n相关依赖 若要能够编写JUnit 5测试需要在build.gradle中添加junit-jupiter作为依赖项：\ndependencies { testImplementation(\u0026#34;org.junit.jupiter:junit-jupiter:5.8.0\u0026#34;) } 之后配置让相关测试使用JUnit平台：\ntest { useJUnitPlatform() } 至此我们已经有了使用Gradle编写和运行JUnit 5测试的最基本配置。\n旧版本配置 从JUnit Jupiter 5.4.0开始有一个聚合器组件junit-jupiter它可以传递对junit-jupiter-api、junit-jupiter-params和junit-jupiter-engine的依赖以简化依赖关系管理,这意味着我们不需要额外的依赖项就能够编写参数化测试。\n为了能够使用旧版本编写JUnit 5测试，需要junit-jupiter-api组件作为依赖项，同时需要在运行时类路径下添加JUnit Jupiter测试引擎：\ndependencies { testImplementation(\u0026#34;org.junit.jupiter:junit-jupiter-api:5.3.2\u0026#34;) testRuntimeOnly(\u0026#34;org.junit.jupiter:junit-jupiter-engine:5.3.2\u0026#34;) } 从Gradle 4.6开始，提供了对JUnit Jupiter的原生支持，而在使用Gradle 4.5或更早版本时，为了能够运行JUnit 5测试则必须配置JUnit Gradle插件：\nbuildscript { repositories { mavenCentral() } dependencies { classpath \u0026#39;org.junit.platform:junit-platform-gradle-plugin:1.3.2\u0026#39; } } apply plugin: \u0026#39;org.junit.platform.gradle.plugin\u0026#39; 至此我们已经有了使用旧版本的Gradle运行JUnit 5测试的基本配置。\n运行测试 JUnit Gradle插件默认情况下在src/test/java目录下查找测试用例。\n可通过添加一个空测试来检查我们的配置是否生效。\nclass GradleExampleTest { @Test void shouldRun() { } } 在命令行中运行相关测试：\ngradle test 我们应该能看到类似如下输出：\n:test BUILD SUCCESSFUL in 2s 好了， JUnit Gradle插件现在可正常运行我们的测试。\n总结 在这个JUnit 5 Gradle教程中，我们学习了如何添加编写JUnit 5测试所需的依赖项以及如何配置JUnit Gradle插件以便能够运行测试。\n本文的示例代码能在GitHub中找到。\n","date":"2023-06-27T14:21:43+08:00","permalink":"https://lucumt.info/post/translate/junit5/junit-5-gradle-example/","tags":["junit5","junit","java","gradle"],"title":"[译]JUnit5 Gradle示例 - 基于Gradle运行测试"},{"categories":["翻译","JUnit5翻译"],"contents":"本文翻译自JUnit 5 Maven Example: Running Tests with Surefire。\n在本教程中，我们将学习在基于Maven编写JUnit 5测试时如何获取相关的依赖，以及如何配置maven-surefire-plugin来运行相关测试。\n本文是JUnit 5 教程的一部分。\n相关依赖 若要能够编写JUnit 5测试需要在pom.xml中添加junit-jupiter作为依赖项：\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.junit.jupiter\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-jupiter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.8.0\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 此外还需添加maven-surefire-plugin以便能运行JUnit 5测试:\n\u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.22.2\u0026lt;/version\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 至此我们已经有了使用Maven编写和运行JUnit 5测试的最基本配置。\n旧版本配置 从JUnit Jupiter 5.4.0开始，有一个聚合器组件junit-jupiter，它可以传递对junit-jupiter-api、junit-jupiter-params和junit-jupiter-engine的依赖关系，从而简化依赖关系管理。\n为了能够使用旧版本编写JUnit 5测试，需要junit-jupiter-api组件作为依赖项：\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.junit.jupiter\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-jupiter-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.2\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 从Maven Surefire2.22.0 开始，对JUnit Jupiter提供了原生支持，当使用Maven Surefire2.21.0或更早版本时，则必须使用Maven Surefire插件来运行测试：\n\u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.21.0\u0026lt;/version\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.junit.platform\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-platform-surefire-provider\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.3.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 同样需要在运行时类路径下添加JUnit Jupiter测试引擎，可在 maven-surefire-plugin插件中添加相关依赖：\n\u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.21.0\u0026lt;/version\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.junit.platform\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-platform-surefire-provider\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.3.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.junit.jupiter\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-jupiter-engine\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 至此我们已经有了使用旧版本的Maven Surefire运行JUnit 5测试的基本配置。\n运行测试 maven-surefire-plugin插件默认情况下在src/test/java目录下查找测试用例。\n可通过添加一个空测试来检查我们的配置是否生效。\nclass MavenExampleTest { @Test void shouldRun() { } } 在命令行中运行相关测试：\nmvn test 我们应该能看到类似如下输出：\n[INFO] --- maven-surefire-plugin:2.22.0:test (default-test) @ junit5-maven --- [INFO] [INFO] ------------------------------------------------------- [INFO] T E S T S [INFO] ------------------------------------------------------- [INFO] Running MavenExampleTest [INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.003 s - in MavenExampleTest [INFO] [INFO] Results: [INFO] [INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0 [INFO] [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ 好了，Maven Surefire现在可正常运行测试。\n总结 在这篇JUnit 5 Maven 示例中，我们学习了如何添加编写JUnit 5测试所需的依赖项以及如何配置Maven Surefire插件以便能够运行测试。\n本文的示例代码能在GitHub中找到。\n","date":"2023-06-23T12:21:43+08:00","permalink":"https://lucumt.info/post/translate/junit5/junit-5-maven-example/","tags":["junit5","junit","java","maven"],"title":"[译]JUnit5 Maven示例-基于Surefire运行测试"},{"categories":["翻译","JUnit5翻译"],"contents":"本文翻译自Migrating From JUnit 4 to JUnit 5: A Definitive Guide。\n在教程中，我们将了解从JUnit 4迁移到JUnit 5所需的步骤，我们将了解如何将现有测试与新版本一起运行，以及必须进行哪些更改才能迁移代码。\n本文是JUnit 5 教程的一部分。\n概览 JUnit 5不同于之前的版本，它采用模块化设计，这种新架构的关键点是将编写测试、扩展和工具之间的关注点分开。\nJUnit被拆分为3个不同的子工程：\nJUnit Platform是基础，提供构建插件和用于编写测试引擎的API JUnit Jupiter是在JUnit 5中用于编写测试和扩展的新式API JUnit Vintage允许我们在JUnit 5中运行JUnit 4编写的测试 以下是JUnit 5相对于JUnit 4的一些优点：\nJUnit 4最大的一个缺陷是不支持运行多个Runners(例如不能同时使用SpringJUnit4ClassRunner和Parameterized)，而在JUnit 5中可通过注册多个扩展实现。\n此外，JUnit 5利用了Java 8中的一些特性如lambda用于惰性评估，JUnit 4从没使用超过Java 7的版本因而错失了Java 8的特性。\n同样，JUnit 4在参数化测试方面有缺陷并且缺乏嵌套测试，由此激发了第三方开发者为这些场景开发专门的Runner。\nJUnit 5给参数化测试提供了更好的支持，在对嵌套测试提供原生支持的同时也增加了一些新功能。\n关键迁移步骤 JUnit在JUnit Vintage测试引擎的帮助下提供了渐进的迁移路径，我们可使用JUnit Vintage测试引擎在JUnit 5中运行JUnit 4相关的测试。\n所有JUnit 4相关的类都位于org.junit包下，所有JUnit 5相关的类都位于org.junit.jupiter包下，如果JUnit 4和JUnit 5在当前类路径下同时存在，也不会产生冲突。\n因此，我们可以将之前实现的JUnit 4测试与JUnit 5测试保留在一起，直到完成迁移，同时可逐步规划迁移。\n下属表格总结了从JUnit 4迁移到JUnit 5中的一些关键步骤：\n步骤 解释 替换依赖 JUnit 4使用单个依赖,JUnit 5对迁移支持和JUnit Vintage引擎有额外的依赖项 替换注解 JUnit 5中的一些注解与JUnit 4中的相同，一些新注解替换了旧的，并且功能略有不同。 替换测试类和方法 断言和假设已被移动到新的类中，方法参数的顺序在某些场景下所有不同。 替换runners、规则、扩展 JUnit 5用一个扩展模型替换了runners和规则，此步骤相较于其它步骤更耗时。 接下来我们将更深入地研究每个步骤。\n依赖 先看看需要做什么才能在新平台上运行现有测试，为了同时运行JUnit 4和JUnit 5测试，需要如下操作：\nJUnit Jupiter用于编写和运行JUnit 5测试 JUnit Vintage测试引擎用于运行JUnit 4测试 除此之外，要使用Maven运行测试，我们还需要Surefire插件，需要在pom.xml中添加所需的全部依赖：\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.22.2\u0026lt;/version\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.junit.jupiter\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-jupiter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.8.0\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.junit.vintage\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-vintage-engine\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.8.0\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 相似的，要使用Gradle运行测试的话，同样需要在测试中开启JUnit Platform支持，同时在build.gradle中添加所需的全部依赖：\ntest { useJUnitPlatform() } dependencies { testImplementation(\u0026#39;org.junit.jupiter:junit-jupiter:5.8.0\u0026#39;) testRuntime(\u0026#39;org.junit.vintage:junit-vintage-engine:5.8.0\u0026#39;) } 注解 注解位于org.junit.jupiter.api包中而不是org.junit。\n大部分的注解名称也不相同：\nJUnit 4 JUnit 5 @Test @Test @Before @BeforeEach @After @AfterEach @BeforeClass @BeforeAll @AfterClass @AfterAll @Ignore @Disable @Category @Tag 在大多数情况下，我们可以查找并替换相关的包名与类名。\n但是，@Test注解不再具有expected和timeout属性。\n异常 我们无法在@Test注解中使用expected属性。\n可用JUnit 5中的assertThrows()方法来替换JUnit 4中的expected属性：\npublic class JUnit4ExceptionTest { @Test(expected = IllegalArgumentException.class) public void shouldThrowAnException() { throw new IllegalArgumentException(); } } class JUnit5ExceptionTest { @Test void shouldThrowAnException() { Assertions.assertThrows(IllegalArgumentException.class, () -\u0026gt; { throw new IllegalArgumentException(); }); } } 超时 同样也无法在@Test注解中使用timeout属性。\n可在JUnit 5中使用assertTimeout()方法来替换JUnit 4中的timeout属性。\npublic class JUnit4TimeoutTest { @Test(timeout = 1) public void shouldTimeout() throws InterruptedException { Thread.sleep(5); } } class JUnit5TimeoutTest { @Test void shouldTimeout() { Assertions.assertTimeout(Duration.ofMillis(1), () -\u0026gt; Thread.sleep(5)); } } 测试类和方法 如前所述，断言和假设被移动到新的类中，同样的，方法参数的顺序在某些场景下所有不同。\n下述表格总结了JUnit 4和JUnit 5中测试类和测试方法的一些主要的不同点：\nJUnit 4 JUnit 5 测试包 org.junit org.junit.jupiter.api 断言类 Assert Assertions assertThat() MatcherAssert.assertThat() 可选的断言消息 第一个方法参数 最后一个方法参数 假设类 Assume Assumptions assumeNotNull() 移除 assumeNoException() 移除 值得注意的是，我们在JUnit 4中自己编写的测试类和方法必须是public修饰的。\nJUnit 5移除了上述限制，测试方法和测试类可以在包中私有，我们可在提供的示例中看到这种差异。\n接下来我们详细看看测试类和测试方法中的变化。\n断言 断言方法位于org.junit.jupiter.api.Assertions类中，而不是org.junit.Assert类中。\n在大多数场景下，我们可直接查找并替换包名。\n然而，如果我们给断言提供了自定义消息，在编译时会报错，可选的断言消息现在是最后一个参数，这种参数顺序看起来更自然：\npublic class JUnit4AssertionTest { @Test public void shouldFailWithMessage() { Assert.assertEquals(\u0026#34;numbers \u0026#34; \u0026#43; 1 \u0026#43; \u0026#34; and \u0026#34; \u0026#43; 2 \u0026#43; \u0026#34; are not equal\u0026#34;, 1, 2); } } class JUnit5AssertionTest { @Test void shouldFailWithMessage() { Assertions.assertEquals(1, 2, () -\u0026gt; \u0026#34;numbers \u0026#34; \u0026#43; 1 \u0026#43; \u0026#34; and \u0026#34; \u0026#43; 2 \u0026#43; \u0026#34; are not equal\u0026#34;); } } 也可以像示例中那样惰性评估断言消息，从而避免构造不必要的复杂消息。\n注意\n当断言一个String对象并有自定义消息时，由于所有的参数类型都是String我们不会看见编译错误，然而我们可以很容易地发现这些情况，因为当运行它们时测试将会失败。\n此外，有些遗留的测试代码会基于JUnit 4中的Assert.assertThat()来使用Hamcrest断言，JUnit 5没有像JUnit 4那样提供Assert.assertThat()，相反，我们必须从Hamcrest的MatcherAssert中导入相关方法：\npublic class JUnit4HamcrestTest { @Test public void numbersNotEqual() { Assert.assertThat(\u0026#34;numbers 1 and 2 are not equal\u0026#34;, 1, is(not(equalTo(2)))); } } class JUnit5HamcrestTest { @Test void numbersNotEqual() { MatcherAssert.assertThat(\u0026#34;numbers 1 and 2 are not equal\u0026#34;, 1, is(not(equalTo(2)))); } } 假设 假设方法位于org.junit.jupiter.Assumptions类中，而不是org.junit.Assume类中。\n这些方法有类似的改动，假设消息现在是最后一个参数。\n@Test public class JUnit4AssumptionTest { public void shouldOnlyRunInDevelopmentEnvironment() { Assume.assumeTrue(\u0026#34;Aborting: not on developer workstation\u0026#34;, \u0026#34;DEV\u0026#34;.equals(System.getenv(\u0026#34;ENV\u0026#34;))); } } class JUnit5AssumptionTest { @Test void shouldOnlyRunInDevelopmentEnvironment() { Assumptions.assumeTrue(\u0026#34;DEV\u0026#34;.equals(System.getenv(\u0026#34;ENV\u0026#34;)), () -\u0026gt; \u0026#34;Aborting: not on developer workstation\u0026#34;); } } 同样需要注意的是，现在不再有Assume.assumeNotNUll()和Assume.assumeNoException() 。\n分类 JUnit 4中的@Category注解在JUnit 5中被@Tag注解替换，此外我们不再使用标记接口，而是向注解传递字符串参数。\n在JUnit 4可通过标记接口来使用分类：\npublic interface IntegrationTest {} @Category(IntegrationTest.class) public class JUnit4CategoryTest {} 之后可通过在pom.xml中配置基于标签过滤测试。\n\u0026lt;plugin\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.22.2\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;groups\u0026gt;com.example.AcceptanceTest\u0026lt;/groups\u0026gt; \u0026lt;excludedGroups\u0026gt;com.example.IntegrationTest\u0026lt;/excludedGroups\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 或者，在使用Gradle时在build.gradle中进行配置：\ntest { useJUnit { includeCategories \u0026#39;com.example.AcceptanceTest\u0026#39; excludeCategories \u0026#39;com.example.IntegrationTest\u0026#39; } } 但是在JUnit 5中可直接使用标签来实现：\n@Tag(\u0026#34;integration\u0026#34;) class JUnit5TagTest {} Maven中的pom.xml配置也更简单：\n\u0026lt;plugin\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.22.2\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;groups\u0026gt;acceptance\u0026lt;/groups\u0026gt; \u0026lt;excludedGroups\u0026gt;integration\u0026lt;/excludedGroups\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 相似的，build.gradle中的配置也更简洁：\ntest { useJUnitPlatform { includeTags \u0026#39;acceptance\u0026#39; excludeTags \u0026#39;integration\u0026#39; } } Runners JUnit 4中的@RunWith注解在JUnit 5中不存在，可通过使用org.junit.jupiter.api.extension包和@ExtendWith注解中的新扩展模型实现相似的功能。\nSpring Runner JUnit 4中使用的一个流行的runner是Spring test runner，在JUnit 5中需要将其替换为一个Spring扩展。\n如果我们使用Spring 5，该扩展会与Spring Test绑定在一起。\n@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(classes = SpringTestConfiguration.class) public class JUnit4SpringTest { } @ExtendWith(SpringExtension.class) @ContextConfiguration(classes = SpringTestConfiguration.class) class JUnit5SpringTest { } 然而在使用Spring 4时该扩展没有与SpringExtension绑定，我们仍然可以使用它，但需要JitPack仓库中的额外依赖。\n要在JUnit 4中使用SpringExtension注解我们需要在pom.xml中添加如下依赖：\n\u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;jitpack.io\u0026lt;/id\u0026gt; \u0026lt;url\u0026gt;https://jitpack.io\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.sbrannen\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-test-junit5\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.5.0\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 类似的，在使用Gradle时也需要在build.gradle中添加相应依赖：\nrepositories { mavenCentral() maven { url \u0026#39;https://jitpack.io\u0026#39; } } dependencies { testImplementation(\u0026#39;com.github.sbrannen:spring-test-junit5:1.5.0\u0026#39;) } Mockito Runner JUnit 4中另一个流行的runner是Mockito runner，在使用JUnit 5时需要将其替换为JUnit 5中的Mockito扩展。\n要使用Mockito扩展，需要在pom.xml中添加相关的依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mockito\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mockito-junit-jupiter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.6.28\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 类似的，使用Gradle时需要在build.gradle中添加依赖：\ndependencies { testImplementation(\u0026#39;org.mockito:mockito-junit-jupiter:3.12.4\u0026#39;) } 现在，可将MockitoJUnitRunner简单的替换为MockitoExtension：\n@RunWith(MockitoJUnitRunner.class) public class JUnit4MockitoTest { @InjectMocks private Example example; @Mock private Dependency dependency; @Test public void shouldInjectMocks() { example.doSomething(); verify(dependency).doSomethingElse(); } } @ExtendWith(MockitoExtension.class) class JUnit5MockitoTest { @InjectMocks private Example example; @Mock private Dependency dependency; @Test void shouldInjectMocks() { example.doSomething(); verify(dependency).doSomethingElse(); } } 规则 JUnit 4中的@Rule和@ClassRule注解在JUnit 5中不存在，可通过使用org.junit.jupiter.api.extension包和@ExtendWith注解中的新扩展模型实现相似的功能。\n然而，要实现一个平滑的迁移，junit-jupiter-migrationsupport模块提供了JUnit 4中的规则子集和子类的支持:\nExternalResource(例如TemporaryFolder) Verifier(例如ErrorCollector) ExpectedException 通过使用org.junit.jupiter.migrationsupport.rules包中的类级别注释@EnableRuleMigrationSupport，可让使用这些规则的已有代码保持不变。\n要在Maven中开启该支持需要添加相关依赖：\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.junit.jupiter\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-jupiter-migrationsupport\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.8.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 同样的，若使用Gradle需要在build.gradle中添加相关依赖：\ndependencies { testImplementation(\u0026#39;org.junit.jupiter:junit-jupiter-migrationsupport:5.8.0\u0026#39;) } 预期异常 在JUnit 4中使用@Test(expected = SomeException.class)注解不允许我们检查异常的详细信息，若需要检查，则要使用ExpectedException规则。\nJUnit 5迁移支持允许我们通过在测试中添加@EnableRuleMigrationSupport来仍然使用该规则。\n@EnableRuleMigrationSupport class JUnit5ExpectedExceptionTest { @Rule public ExpectedException thrown = ExpectedException.none(); @Test void catchThrownExceptionAndMessage() { thrown.expect(IllegalArgumentException.class); thrown.expectMessage(\u0026#34;Wrong argument\u0026#34;); throw new IllegalArgumentException(\u0026#34;Wrong argument!\u0026#34;); } } 由于我们将所有内容都集中在一起，结果更具有可读性。\n临时目录 在JUnit 4中可通过使用TemporaryFolder规则来创建和清除一个临时目录，同样的，JUnit 5迁移支持允许我们添加@EnableRuleMigrationSupport来继续使用该功能。\n@EnableRuleMigrationSupport class JUnit5TemporaryFolderTest { @Rule public TemporaryFolder temporaryFolder = new TemporaryFolder(); @Test void shouldCreateNewFile() throws IOException { File textFile = temporaryFolder.newFile(\u0026#34;test.txt\u0026#34;); Assertions.assertNotNull(textFile); } } 要完全摆脱JUnit 4中的规则，我们需要将其替换为TempDirectory扩展，可通过给一个Path或File属性添加@TempDir注解来使用此扩展：\nclass JUnit5TemporaryFolderTest { @TempDir Path temporaryDirectory; @Test public void shouldCreateNewFile() { Path textFile = temporaryDirectory.resolve(\u0026#34;test.txt\u0026#34;); Assertions.assertNotNull(textFile); } } 此扩展与前面的规则类似，一个不同点是我们也可以将其添加到方法参数中：\n@Test public void shouldCreateNewFile(@TempDir Path anotherDirectory) { Path textFile = anotherDirectory.resolve(\u0026#34;test.txt\u0026#34;); Assertions.assertNotNull(textFile); } 自定义规则 迁移JUnit 4中的规则时需要将其重写为JUnit 5中的扩展。\n可通过实现BeforeEachCallback和AfterEachCallback接口来重现引用了@Rule注解的业务逻辑。\n例如，我们有一个实现性能日志的JUnit 4规则：\npublic class JUnit4PerformanceLoggerTest { @Rule public PerformanceLoggerRule logger = new PerformanceLoggerRule(); } public class PerformanceLoggerRule implements TestRule { @Override public Statement apply(Statement base, Description description) { return new Statement() { @Override public void evaluate() throws Throwable { // Store launch time base.evaluate(); // Store elapsed time } }; } } 反过来，我们可以编写与JUnit 5扩展相同的规则：\n@ExtendWith(PerformanceLoggerExtension.class) public class JUnit5PerformanceLoggerTest { } public class PerformanceLoggerExtension implements BeforeEachCallback, AfterEachCallback { @Override public void beforeEach(ExtensionContext context) throws Exception { // Store launch time } @Override public void afterEach(ExtensionContext context) throws Exception { // Store elapsed time } } 自定义类规则 类似的，可通过实现BeforeEachCallback和AfterEachCallback接口来重现引用了@ClassRule注解的业务逻辑。\n在某些场景中，我们可能在JUnit 4中将类规则编写为匿名内部类，如下述例子，有一个服务器资源我们希望可以很轻松的在不同的测试中使用设置。\npublic class JUnit4ServerBaseTest { static Server server = new Server(9000); @ClassRule public static ExternalResource resource = new ExternalResource() { @Override protected void before() throws Throwable { server.start(); } @Override protected void after() { server.stop(); } }; } public class JUnit4ServerInheritedTest extends JUnit4ServerBaseTest { @Test public void serverIsRunning() { Assert.assertTrue(server.isRunning()); } } 可将该规则编写为JUnit 5扩展，不幸的是，如果在该扩展中使用@ExtendWith注解，我们无法访问该扩展提供的资源，但可通过使用@RegisterExtension来替换：\npublic class ServerExtension implements BeforeAllCallback, AfterAllCallback { private Server server = new Server(9000); public Server getServer() { return server; } @Override public void beforeAll(ExtensionContext context) throws Exception { server.start(); } @Override public void afterAll(ExtensionContext context) throws Exception { server.stop(); } } class JUnit5ServerTest { @RegisterExtension static ServerExtension extension = new ServerExtension(); @Test void serverIsRunning() { Assertions.assertTrue(extension.getServer().isRunning()); } } 参数化测试 在JUnit 4中编写参数化测试时需要使用Parameterized runner，此外，我们需要通过一个添加了@Parameterized.Parameters注解的方法来传递参数化数据：\n@RunWith(Parameterized.class) public class JUnit4ParameterizedTest { @Parameterized.Parameters public static Collection\u0026lt;Object[]\u0026gt; data() { return Arrays.asList(new Object[][] { { 1, 1 }, { 2, 1 }, { 3, 2 }, { 4, 3 }, { 5, 5 }, { 6, 8 } }); } private int input; private int expected; public JUnit4ParameterizedTest(int input, int expected) { this.input = input; this.expected = expected; } @Test public void fibonacciSequence() { assertEquals(expected, Fibonacci.compute(input)); } } 编写JUnit 4参数化测试有很多缺点，并且像JUnitParams这样的社区runner将自己描述为并不糟糕的参数化测试。\n不幸的是没有JUnit 4参数化runner的直接替代品，相反的，JUnit 5中提供了一个@ParameterizedTest注解，可以为数据提供各种数据源注解，其中最接近JUnit 4的是@MethodSource注释：\nclass JUnit5ParameterizedTest { private static Stream\u0026lt;Arguments\u0026gt; data() { return Stream.of( Arguments.of(1, 1), Arguments.of(2, 1), Arguments.of(3, 2), Arguments.of(4, 3), Arguments.of(5, 5), Arguments.of(6, 8) ); } @ParameterizedTest @MethodSource(\u0026#34;data\u0026#34;) void fibonacciSequence(int input, int expected) { assertEquals(expected, Fibonacci.compute(input)); } } 注意\n在JUnit 5中与JUnit 4参数化测试最接近的是使用@ParameterizedTest和@MethodSource数据源，但JUnit 5中的参数化测试有多项改进，可在JUnit 5参数化测试中阅读有关改进的更多信息。\n总结 从JUnit 4迁移到JUnit 5需要一些工作，具体取决于现有测试的编写方式。\n我们可以将JUnit 4测试与JUnit 5测试一起运行，以允许逐步迁移。 在很多情况下，我们只需查找并替换包名和类名。 我们可能必须将自定义运行程序和规则转换为扩展。 要转换参数化测试，我们可能需要做一些返工。 本文的示例代码能在GitHub中找到。\n","date":"2023-06-21T22:21:43+08:00","permalink":"https://lucumt.info/post/translate/junit5/junit-5-migration/","tags":["junit5","java","mockito","junit"],"title":"[译]从JUnit 4 迁移到JUnit 5 - 权威指南"},{"categories":["翻译","JUnit5翻译"],"contents":"本文翻译自JUnit 5 With Kotlin for Java Developers。\n在本教程中将学习在Java和Kotlin中编写JUnit 5测试的差异，同时也将学习如何在Gradle Kotlin DSL1在构建脚本中配置JUnit 5环境。\n本文是JUnit 5 教程的一部分。\n相关视频 如果你喜欢通过视频学习，可以查看Youtube中相关的学习视频。\n配置 我们使用Groovy DSL将传统的Gradle构建脚本编写为build.gradle文件。Gradle Kotlin DSL对多项改进提供了替代语法，如内容辅助和重构，通过Kotlin DSL编写的构建脚本被命名为build.gradle.kts。要在Kotlin中编写JUnit 5测试，首先需要在build.gradle.kts中添加junit-jupiter坐标并且告知其在测试中使用JUnit平台。\ndependencies { testImplementation(\u0026#34;org.junit.jupiter:junit-jupiter:5.8.0\u0026#34;) } tasks.withType\u0026lt;Test\u0026gt; { useJUnitPlatform() } 基本功能 JUnit 5中的大部分功能在Kotlin中都能像在Java中一样正常工作，一切都是开箱即用的。\n一个显著的不同是如何在测试报告或IDE中自定义展示测试方法的名称。\n在Java中，我们可使用@DisplayName注解来让方法名可读，但在Kotlin中我们给变量和方法添加反引号来表示。\n@Test fun `1 \u0026#43; 2 = 3`() { assertEquals(3, calculator.add(1, 2)) } 利用反引号让代码和测试结果更具有可读性，通常我们不应该使用这样的方法名称吗，但它对此需求实现很方便。\n惰性评估 JUnit 5通过lambda对错误消息提供了惰性评估，利用lambda可避免构建不必要的昂贵错误消息。\n在Kotlin中，如果一个函数的最后一个参数接收一个函数，就能重写为括号外的lambda表达式。\n@Test fun `1 \u0026#43; 2 = 3`() { assertEquals(3, calculator.add(1, 2)) { \u0026#34;1 \u0026#43; 2 should equal 3\u0026#34; } } 相对于Java，此种实现方式让在Kotlin中编写断言时的语法更简洁。\n断言 JUnit 5中的任何断言都能在Kotlin中正常工作，然而有几种Kotlin特定的断言方法更适合该语言，这些断言方法是org.junit.jupiter.api包中的顶级函数。\n下面是一个代码抛出异常的断言示例，在Java中，我们可通过在assertThrows()调用中传入一个lambda表达式，在Kotlin中，同样可通过在断言调用后添加一个lambda表达式让其更具有可读性。\n@Test fun `Divide by zero should throw ArithmeticException`() { assertThrows\u0026lt;ArithmeticException\u0026gt; { calculator.divide(1, 0) } } 这个简单的lambda语法同样适用于分组断言，通过分组断言可实现同一时刻执行多个断言并且一并反馈失败。\n就像在Java中，我们可在Kotlin的assertAll()调用中编写lambda表达式，但该语法不太冗长。\n@Test fun `Square of a number should equal the number multiplied by itself`() { assertAll( { assertEquals(1, calculator.square(1)) }, { assertEquals(4, calculator.square(2)) }, { assertEquals(9, calculator.square(3)) } ) } 相比较Java，此种方式不太冗长同时更具有可读性。\n参数化测试 在JUnit 5中有多种方式编写参数化测试，它们中的大部分可在Kotlin中无需修改直接运行。\n需要考虑的一点是在使用@MethodSource注解时有一些不同，此注解在类中接收一个静态方法作为参数来源。\n要在Kotlin中实现同样功能，我们需要创建一个伴生对象并给相关方法添加@JvmStatic注解，此注解将使该方法以Java静态方法的形式存在。\ncompanion object { @JvmStatic fun squares() = listOf( Arguments.of(1, 1), Arguments.of(2, 4), Arguments.of(3, 9) ) } @ParameterizedTest(name = \u0026#34;Square of {0} should equal {1}\u0026#34;) @MethodSource(\u0026#34;squares\u0026#34;) fun `Square of a number`(input: Int, expected: Int) { assertEquals(expected, calculator.square(input)) } 若没有添加@JvmStatic注解将会出现如下错误：\norg.junit.platform.commons.JUnitException: Could not find method [squares] in class [com.arhohuttunen.junit5.kotlin.CalculatorParameterizedTest] 利用此种方式实现参数化测试虽然能正常工作但却没有Java中的方便，另一个需要注意的是每个类中只能有一个伴生对象，因此所有需要提供参数的方法需要组织在一起。\n补充阅读\nJUnit 5 参数化测试\n动态测试 JUnit 5引入了一种新的编程模型，允许我们通过@TestFactory注解注释的工厂方法在运行时生成动态测试。\n通常我们会提供一个DynamicTest示例的集合，以前述的计算器为例：\n@TestFactory fun `Square of a number`() = listOf( DynamicTest.dynamicTest(\u0026#34;Square of 1 should equal 1\u0026#34;) { assertEquals(1, calculator.square(1)) }, DynamicTest.dynamicTest(\u0026#34;Square of 2 should equal 4\u0026#34;) { assertEquals(4, calculator.square(2)) }, DynamicTest.dynamicTest(\u0026#34;Square of 3 should equal 9\u0026#34;) { assertEquals(9, calculator.square(3)) } ) 每个动态测试都会显示为自己的测试，但这看起来不干净且有一些重复。\n再次，此处有一种方式让其更具有可读性，我们可用一些应映射函数来消除这些重复。··\n@TestFactory fun `Square of a number`() = listOf( 1 to 1, 2 to 4, 3 to 9 ).map { (input, expected) -\u0026gt; DynamicTest.dynamicTest(\u0026#34;Square of $input should equal $expected\u0026#34;) { assertEquals(expected, calculator.square(input)) } } 此种方式除了语法略有不同，与我们在参数化测试种的实现很相似。\n嵌套测试 JUnit 5中的嵌套测试允许我们给测试定义层级结构，同Java中类似，我们或许希望下述代码能正常运行：\nclass NestedTest { @Nested class GetRequest { @Test fun `return existing entity`() {} } @Nested class PostRequest { @Test fun `create new entity`() {} } } 上述例子会给我们一个警告:只有非静态的嵌套类才能作为@Nested测试类，JUnit 5找不到任何可执行的测试方法。\n默认情况下，Kotlin中的嵌套类与Java中的静态类很像，只有非静态嵌套类(如内部类)才能添加@Nested 注解作为测试类。\n解决方案为将对应类在Kotlin中标记为inner class:\nclass NestedTest { @Nested inner class GetRequest { @Test fun `return existing entity`() {} } @Nested inner class PostRequest { @Test fun `create new entity`() {} } } 现在JUnit 5能够发现内部嵌套的测试类以及对应的测试方法。\n补充阅读\nJUnit 5 嵌套测试\n静态方法和属性 我们已经简要介绍了静态方法和Kotlin，要让Kotlin中的方法看起来像一个Java静态方法，我们需要创建一个伴生对象并给对应方法上添加@JvmStatic注解。\ncompanion object { @JvmStatic fun squares() = listOf( Arguments.of(1, 1), Arguments.of(2, 4), Arguments.of(3, 9) ) } 另一个可能的陷阱是在使用静态属性时，在Java中可通过添加static属性来实现，因此如果你刚接触Kotlin，或许会期望类似下述代码能够执行：\nclass RegisterStaticExtensionTest { companion object { @RegisterExtension val jettyExtension: JettyExtension = JettyExtension() } } 但是，如果我们编写类似的代码并执行，将会看见一个关于属性为私有的错误消息:\norg.junit.platform.commons.PreconditionViolationException: Failed to register extension via @RegisterExtension field [private static final com.arhohuttunen.junit5.kotlin.JettyExtension com.arhohuttunen.junit5.kotlin.RegisterStaticExtensionTest.jettyExtension]: field must not be private. 解决方案为给该属性添加@JvmField注解：\nclass RegisterStaticExtensionTest { companion object { @JvmField @RegisterExtension val jettyExtension: JettyExtension = JettyExtension() } 添加上该注解后会暴露该Kotlin属性作为一个Java属性并且JUnit 5能够发现它。\n生命周期方法 JUnit 5中的生命周期方法同样能在Kotlin中运行。\n然而，添加了@BeforeAll和@AfterAll注解的方法在默认情况下需要为静态方法，原因是JUnit 5为每个测试方法创建一个测试实例，并且没有其他方法可以在所有测试之间共享状态。\n幸运的是，在JUnit 5中可通过添加@TestInstance(Lifecycle.PER_CLASS)注解让每个测试类只创建一个测试实例，通过对生命周期更改消除了对静态方法的要求。\n@TestInstance(TestInstance.Lifecycle.PER_CLASS) class LifecycleTest { @BeforeAll fun beforeAll() { println(\u0026#34;Before all\u0026#34;) } @AfterAll fun afterAll() { println(\u0026#34;After all\u0026#34;) } @Test fun firstTest() { println(\u0026#34;First test\u0026#34;) } @Test fun secondTest() { println(\u0026#34;Second test\u0026#34;) } } 由于现在测试方法见共享实例状态，如果测试方法依赖于存储在实例间的状态，或许需要在@BeforeEach或@AfterEach注解方法中重置状态，一般来说，尽量避免编写依赖于这种状态的测试。\n补充阅读\nJUnit 5 生命周期\n可重复注解 当前Kotlin并不支持重复注解，因此使用多个扩展或标签进行测试比 Java 稍微复杂一些。\n譬如，在Java中我们可重复添加@Tag注解来给某个测试添加多个标签：\n@Tag(\u0026#34;first\u0026#34;) @Tag(\u0026#34;second\u0026#34;) class RepeatableAnnotationTest {} 然而在Kotlin中我们不能同时有多个@Tag注解，相反必须使用@Tags注解来包装重复的标签。\n@Tags( Tag(\u0026#34;first\u0026#34;), Tag(\u0026#34;second\u0026#34;) ) class RepeatableAnnotationTest 当有多个扩展时也是类似，因此我们不能直接使用多个@ExtendWith，相反必须使用@Extensions注解来包装重复的扩展。\n@Extensions( ExtendWith(CoolestEverExtension::class), ExtendWith(SecondBestExtension::class) ) class RepeatableAnnotationTest 总结 尽管在某些场景下有些语法与Java中的不同，大部分JUnit 5的功能特性能在Kotlin中完美运行，然而，由于Kotlin语言的工作方式，我们通常可以使代码更具可读性。\n本文的示例代码能在GitHub中找到。\nDSL即Domain Specific Language，中文译领域特定语言，专门用于解决特定领域问题而设计开发的。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-06-21T19:21:43+08:00","permalink":"https://lucumt.info/post/translate/junit5/junit-5-kotlin/","tags":["junit5","java","junit"],"title":"[译]JUnit5 整合Kotlin"},{"categories":["翻译","JUnit5翻译"],"contents":"本文翻译自Using Mockito With JUnit 5。\n在本教程中将学习在JUnit 5中如何使用Mockito框架，我们将以独立的方式学习测试框架，之后学习如何在JUnit 5中使用Mockito扩展。\n本文是JUnit 5 教程的一部分。\n相关视频 如果你喜欢通过视频学习，可以查看Youtube中相关的学习视频。\n手工初始化 在做其它事情之前，需要添加Mockito相关的依赖：\ndependencies { testImplementation(\u0026#39;org.mockito:mockito-core:3.12.4\u0026#39;) } 如果我们只是想创建一个要注入其它对象的mock，最简单的方式是调用Mockito.mock()方法，该方法将要实例化的对象的类作为参数。\nclass MockitoManualTest { private OrderRepository orderRepository; private OrderService orderService; @BeforeEach void initService() { orderRepository = mock(OrderRepository.class); orderService = new OrderService(orderRepository); } @Test void createOrderSetsTheCreationDate() { Order order = new Order(); when(orderRepository.save(any(Order.class))).then(returnsFirstArg()); Order savedOrder = orderService.create(order); assertNotNull(savedOrder.getCreationDate()); } } 手工初始化在我们没有太多要mock的对象时是一个合法的解决方案。\n优点:\n对要mock的对象有最大程度的控制 缺点:\n代码会变得很冗长 无法检测框架的使用情况以及检测不正常的打桩 基于注解初始化 Mockito.mock()的一种声明式替代方案为给要mock的对象上添加@Mock注解，同时需要调用一个特殊方法来初始化被注解的对象。\n在Mockito 2中有一个MockitoAnnotations.initMocks()方法，该方法已经被废弃并在Mockito 3中被MockitoAnnotations.openMocks()替代，该方法返回一个AutoCloseable对象可用于在测试之后关闭资源。\npublic class MockitoAnnotationTest { @Mock private OrderRepository orderRepository; private AutoCloseable closeable; private OrderService orderService; @BeforeEach void initService() { closeable = MockitoAnnotations.openMocks(this); orderService = new OrderService(orderRepository); } @AfterEach void closeService() throws Exception { closeable.close(); } @Test void createOrderSetsTheCreationDate() { Order order = new Order(); when(orderRepository.save(any(Order.class))).then(returnsFirstArg()); Order savedOrder = orderService.create(order); assertNotNull(savedOrder.getCreationDate()); } } MockitoAnnotations.openMocks(this)方法的调用可告知Mockito扫描测试类中任何包含有@Mock注解的属性并将这些属性初始化为mock对象。\n优点:\n容易创建mock对象 可读性更高 缺点：\n无法检测框架的使用情况以及检测不正常的打桩 Mock自动注入 同样可以通过给对应属性添加@InjectMocks注解来自动注入mock对象。\n当调用MockitoAnnotations.openMocks()时,Mockito会执行如下操作：\n对有@Mock注解的属性创建mock对象 对有@InjectMocks的属性创建实例并尝试将前一个步骤中创建的mock对象注入其中 使用@InjectMocks与我们手工创建实例所做的相同，但现在是自动化的。\npublic class MockitoInjectMocksTests { @Mock private OrderRepository orderRepository; private AutoCloseable closeable; @InjectMocks private OrderService orderService; @BeforeEach void initService() { closeable = MockitoAnnotations.openMocks(this); } @AfterEach void closeService() throws Exception { closeable.close(); } @Test void createOrderSetsTheCreationDate() { Order order = new Order(); when(orderRepository.save(any(Order.class))).then(returnsFirstArg()); Order savedOrder = orderService.create(order); assertNotNull(savedOrder.getCreationDate()); } } Mockito将首先尝试通过构造器注入的方式注入mock对象，之后为setter注入、属性注入。\n优点：\n容易注入mock对象 缺点:\n无法强制使用构造器注入 注意\n不推荐使用属性注入或setter注入，使用构造器注入时，我们可以百分百确定没有注入相关依赖之前无法实例化该类。\nJUnit5 Mockito扩展 JUnit 5中同样有一个Mockito扩展让实例化更简单。\n要使用该扩展，首先需要添加对应的依赖。\ndependencies { testImplementation(\u0026#39;org.mockito:mockito-junit-jupiter:3.12.4\u0026#39;) } 现在可使用该扩展并避免对MockitoAnnotations.openMocks()的方法调用：\n@ExtendWith(MockitoExtension.class) public class MockitoExtensionTest { @Mock private OrderRepository orderRepository; private OrderService orderService; @BeforeEach void initService() { orderService = new OrderService(orderRepository); } @Test void createOrderSetsTheCreationDate() { Order order = new Order(); when(orderRepository.save(any(Order.class))).then(returnsFirstArg()); Order savedOrder = orderService.create(order); assertNotNull(savedOrder.getCreationDate()); } } 同样可以在MockitoExtension中使用@InjectMocks注解来进一步的简化配置。\n@ExtendWith(MockitoExtension.class) public class MockitoExtensionInjectMocksTest { @Mock private OrderRepository orderRepository; @InjectMocks private OrderService orderService; @Test void createOrderSetsTheCreationDate() { when(orderRepository.save(any(Order.class))).then(returnsFirstArg()); Order order = new Order(); Order savedOrder = orderService.create(order); assertNotNull(savedOrder.getCreationDate()); } } 如果我们不像在测试用例间共享mock变量，可将mock对象注入到方法参数中。\n@Test void createOrderSetsTheCreationDate(@Mock OrderRepository orderRepository) { OrderService orderService = new OrderService(orderRepository); when(orderRepository.save(any(Order.class))).then(returnsFirstArg()); Order order = new Order(); Order savedOrder = orderService.create(order); assertNotNull(savedOrder.getCreationDate()); } 将mock对象注入方法参数中既适用于生命周期方法也适用于测试方法本身。\n优点：\n不需要调用MockitoAnnotations.openMocks()方法 能检测框架使用情况以及不正确的打桩 容易创建mock对象 容易阅读 缺点：\n需要一个额外的依赖org.mockito:mockito-junit-jupiter 总结 在JUnit 5中有3种不同的方式使用Mockito，前2种方式可独立于框架单独使用，而第3种方式需使用JUnit 5中的Mockito扩展。\nMock对象可通过一下方式创建和初始化:\n通过调用Mockito.mock()手工创建 添加@Mock注解并通过调用MockitoAnnotations.openMocks()方法来初始化 添加@Mock注解并在测试中使用MockitoExtension扩展 本文的示例代码能在GitHub中找到。\n","date":"2023-06-19T19:21:43+08:00","permalink":"https://lucumt.info/post/translate/junit5/using-mockito-in-junit5/","tags":["junit5","java","mockito","junit"],"title":"[译]在JUnit 5中使用Mockito"},{"categories":["工具使用","持续集成"],"contents":"在使用KubeSphere对公司项目进行持续集成时，有一个项目在Gitlab中采用了Submodules结构，导致原有的流水线不能直接使用，一番折腾后找到两种方案，其中一种比较优雅，简单记录下。\n没有子模块 在没有子模块时，自己是直接通过KubeSphere的图形界面操作，类似下图，只需根据实际情况填入必要的参数保存即可。\n之后KubeSphere会自动生成对应的Jenkins代码：\nstage(\u0026#39;拉取代码\u0026#39;) { agent none steps { git(credentialsId: \u0026#39;gitlab-account\u0026#39;, url: \u0026#39;http://gitlab.xxx.com/lucumt-group/system.git\u0026#39;, branch: \u0026#39;$BRANCH_NAME\u0026#39;, changelog: true, poll: false) } } 可以看到生成的代码是通过调用Jekins中的git方法封装实现的，而不是原始的git clone xxx。\n有子模块时 前述pipeline代码在没有submodules时能正常工作，但遇到有submodules的工程时，无法将其对应的子模块下载下来导致在后续的代码编译阶段出错。\n最开始自己参考的是How do I git clone a repo, including its submodules中--recurse-submodules标识，想直接通过git命令直接下载，类似代码如下：\nstage(\u0026#39;拉取代码\u0026#39;) { agent none steps { sh \u0026#39;\u0026#39;\u0026#39;git clone --recurse-submodules -j8 http://gitlab.xxx.com/lucumt-group/system.git\t\u0026#39;\u0026#39;\u0026#39; } } 实际运行后很快发现问题：由于Gitlab需要授权访问导致请求被拒绝！可之前的为啥好使？因为之前的是通过git函数基于token的方式访问的，但直接在命令行中通过git命令访问的话，又没法使用token，而每次git clone时手工输入用户密码又很不方便，怎么办？\n对KubeSphere和Jenkins进行深入研究，并结合实际使用流程后，确定了如下考量点：\n出于简化的考虑，Gitlab的用户名和密码不能每次都输入，故只能用原来的token方式 单次git clone无法下载所有工程的话，可考虑分批多次下载，每次下载对应一个Gitlab工程地址 去Jenkins官网查看是否有支持下载子模块的插件或函数 接下来基于2和3分别说明对应的实现。\n分批下载 既然没有submodules时直接下载没问题，那将子模块也当成一个独立的Gitlab工程(事实就是这样)再次复用之前的代码去下载，之后将其移动到对应的位置不就行了吗？有问题没，完全没有问题！相关代码实现如下：\nstage(\u0026#39;拉取代码\u0026#39;) { agent none steps { dir(\u0026#39;system\u0026#39;) { git(credentialsId: \u0026#39;gitlab-token\u0026#39;, url: \u0026#39;http://gitlab.xxx.com/lucumt-group/system.git\u0026#39;, branch: \u0026#39;$BRANCH_NAME\u0026#39;, changelog: true, poll: false) } dir(\u0026#39;module1\u0026#39;) { git(credentialsId: \u0026#39;gitlab-token\u0026#39;, url: \u0026#39;http://gitlab.xxx.com/lucumt-group/module_1.git\u0026#39;, branch: \u0026#39;$MODULE_BRANCH_1\u0026#39;, changelog: true, poll: false) } dir(\u0026#39;module2\u0026#39;) { git(credentialsId: \u0026#39;gitlab-token\u0026#39;, url: \u0026#39;http://gitlab.xxx.com/lucumt-group/module_2.git\u0026#39;, branch: \u0026#39;$MODULE_BRANCH_2\u0026#39;, changelog: true, poll: false) } sh \u0026#39;\u0026#39;\u0026#39;rm -rf system/module_1 system/module_2 mv module1 system/ mv module2 system/ \u0026#39;\u0026#39;\u0026#39; } } 此种方式实现起来很简单，但存在以下缺陷：\n每个子工程都需要单独的配置与单独下载，工作量增加 每个子工程的分支需要手工指定，无法进行原生关联，增加了复杂度 子工程下载完毕后需要通过shell脚本将其移动到对应目录下，才能形成完整的项目结构 递归下载 基于Jenkins中的GitSCM，通过此种方式可以在下载主工程时将其附带的子模块功能一并下载下来，同时还能确保子模块的分支也是正确的，不需要显示指定，相对于前一种方式更简洁，最终代码如下：\nstage(\u0026#39;拉取代码\u0026#39;) { agent none steps { checkout([$class: \u0026#39;GitSCM\u0026#39;, branches: [[name: \u0026#39;$BRANCH_NAME\u0026#39;]], doGenerateSubmoduleConfigurations: false, extensions: [[$class: \u0026#39;SubmoduleOption\u0026#39;, disableSubmodules: false, parentCredentials: true, recursiveSubmodules: true, reference: \u0026#39;\u0026#39;, trackingSubmodules: false]], userRemoteConfigs: [[url: \u0026#39;http://gitlab.xxx.com/lucumt-group/system.git\u0026#39;,credentialsId:\u0026#39;gitlab-token\u0026#39;]]]) } } 在上述代码中重点是通过recursiveSubmodules来递归下载子模块，通过parentCredentials来使用父模块下载时使用的token。\n需要注意的是截止本文写作时KubeSphere v3.3.1不支持此种方式的图形化编辑，当采用图形化编辑时会出现雷系如下界面，没有正确的展示出实际配置的代码，此时若再次保存，会导致之前的配置丢失，故在此种方式下不能使用图形化方式对其进行二次修改。\n","date":"2023-06-17T14:27:13+08:00","permalink":"https://lucumt.info/post/devops/checkout-project-with-submodule-in-kubesphere/","tags":["devops","jenkins","git","kubesphere"],"title":"在KubeSphere的流水线中下载构建具有子模块的项目"},{"categories":["翻译","JUnit5翻译"],"contents":"本文翻译自A More Practical Guide to JUnit 5 Parameterized Tests。\n在本教程中我们将学习如何编写JUnit5参数化测试，本教程以结构化方式展现以便能够同时解答关于参数化测试的常见问题。\n本文是JUnit 5 教程的一部分。\n相关视频 如果你喜欢通过视频学习，可以查看Youtube中相关的学习视频。\n概览 参数化测试使得可以使用不同的参数多次运行同一个测试方法，通过这种方式我们可以快速的验证不同的场景而无需为它们分别编写测试代码。\n可以像编写常规JUnit 5测试一样编写JUnit 5参数化测试代码，但必须使用@ParameterizedTest注释，同时必须为相关测试声明参数源，可通过不同类型的参数来源注解来声明参数源。\n单参数与@ValueSource 最简单的参数源为@ValueSource，它使得我们可创建一个包含原始类型(如何short、byte、int、long、float、double、char、boolean、String或Class)的数组来使用。\n下述代码使用不同字符串作为测试参数：\n@ParameterizedTest @ValueSource(strings = { \u0026#34;level\u0026#34;, \u0026#34;madam\u0026#34;, \u0026#34;saippuakivikauppias\u0026#34; }) void palindromeReadsSameBackward(String string) { assertTrue(StringUtils.isPalindrome(string)); } 顺便说下saippuakivikauppias在芬兰语中表示皂石供应商。\n执行上述测试代码后，我们可从输出结果中看出测试方法使用不同的字符串值执行了三次。\npalindromeReadsSameBackward(String) ├─ [1] level ├─ [2] madam └─ [3] saippuakivikauppias 下述代码为另一个使用int类型进行参数化测试的示例：\n@ParameterizedTest @ValueSource(ints = { 3, 6, 15}) void divisibleByThree(int number) { assertEquals(0, number % 3); } 另一种单参数源注解是@EnumSource，它使用枚举类作为参数并使用枚举值进行测试：\nenum Protocol { HTTP_1_0, HTTP_1_1, HTTP_2 } @ParameterizedTest @EnumSource(Protocol.class) void postRequestWithDifferentProtocols(Protocol protocol) { webServer.postRequest(protocol); } 执行上述测试后，可发现测试方法基于Protocol中的每个枚举值分别执行了一次。\n空值与@NullSource @ValueSource注解不接收null值。\n有一个名为@NullSource的特殊注解，可用来在测试中提供null参数，另一个特殊的注解是@EmptySource，它为String、List、Set、Map或数组提供empty值。\n在下述例子中，我们将null值、空字符串和空白字符串传递给测试方法：\n@ParameterizedTest @NullSource @EmptySource @ValueSource(strings = { \u0026#34; \u0026#34; }) void nullEmptyAndBlankStrings(String text) { assertTrue(text == null || text.trim().isEmpty()); } 也可以使用@NullAndEmptySource将两者结合起来。\n多参数与@MethodSource @ValueSource和@EnumSource注解只有在测试方法只有一个参数时生效，不过我们经常需要使用多个参数。\n@MethodSource注解允许我们引用一个返回多参数的工厂方法，此类方法需返回Stream、Iterable、Iterator或参数数组。\n假设我们有一个DateUtils类基于数字获取对应月份的名称，我们需要在参数化测试中传递多个参数，因此我们可以在工厂方法中使用Stream参数实现。\n@ParameterizedTest @MethodSource(\u0026#34;numberToMonth\u0026#34;) void monthNames(int month, String name) { assertEquals(name, DateUtils.getMonthName(month)); } private static Stream\u0026lt;Arguments\u0026gt; numberToMonth() { return Stream.of( arguments(1, \u0026#34;January\u0026#34;), arguments(2, \u0026#34;February\u0026#34;), arguments(12, \u0026#34;December\u0026#34;) ); } 当在@MethodSource注解中引用工厂方法时，它将给测试方法提供不同的month和name参数。\n若在@MethodSource注解中没有提供方法名称，JUnit 5将会尝试寻找具有相同名称的方法。\n@ParameterizedTest @MethodSource void monthNames(int month, String name) { assertEquals(name, DateUtils.getMonthName(month)); } private static Stream\u0026lt;Arguments\u0026gt; monthNames() { return Stream.of( arguments(1, \u0026#34;January\u0026#34;), arguments(2, \u0026#34;February\u0026#34;), arguments(12, \u0026#34;December\u0026#34;) ); } 共享参数与@ArgumentSource 也可通过@MethodSource注解来引用其它类中的方法，需要使用方法的全限定名来实现。\npackage com.arhohuttunen; import java.util.stream.Stream; public class StringsProvider { private static Stream\u0026lt;String\u0026gt; palindromes() { return Stream.of(\u0026#34;level\u0026#34;, \u0026#34;madam\u0026#34;, \u0026#34;saippuakivikauppias\u0026#34;); } } 全限定名是包名称、类名称和方法名称的组合：\n@ParameterizedTest @MethodSource(\u0026#34;com.arhohuttunen.StringsProvider#palindromes\u0026#34;) void externalPalindromeMethodSource(String string) { assertTrue(StringUtils.isPalindrome(string)); } 另一种方式是使用实现了ArgumentsProvider接口的自定义类：\npublic class PalindromesProvider implements ArgumentsProvider { @Override public Stream\u0026lt;? extends Arguments\u0026gt; provideArguments(ExtensionContext context) { return Stream.of(\u0026#34;level\u0026#34;, \u0026#34;madam\u0026#34;, \u0026#34;saippuakivikauppias\u0026#34;).map(Arguments::of); } } 之后再测试方法中通过@ArgumentsSource指定该类：\n@ParameterizedTest @ArgumentsSource(PalindromesProvider.class) void externalPalindromeMethodSource(String string) { assertTrue(StringUtils.isPalindrome(string)); } 多参数与@CsvSource @CsvSource注解允许我们使用以逗号分隔的字符串参数，基于该注解能够以相当紧凑的方式给测试方法提供多个参数。\n@CsvSource({ \u0026#34;Write a blog post, IN_PROGRESS, 2020-12-20\u0026#34;, \u0026#34;Wash the car, OPENED, 2020-12-15\u0026#34; }) void readTasks(String title, Status status, LocalDate date) { System.out.printf(\u0026#34;%s, %s, %s\u0026#34;, title, status, date); } 如果在测试代码中写入了大量的测试数据，测试代码很快将会变得不可读，一种解决方案是通过@CsvFileSource注解在外部CSV文件中提供数据。\n基于前面的示例，首先在tasks.csv中创建一个以逗号分隔的参数列表，将其放在src/test/resources目录下，文件中的每一行都是一个参数列表。\nWrite a blog post, IN_PROGRESS, 2020-12-20 Wash the car, OPENED, 2020-12-15 接下来，使用@CsvFileSource注解给测试方法提供测试参数。\n@ParameterizedTest @CsvFileSource(resources = \u0026#34;/tasks.csv\u0026#34;) void readTasks(String title, Status status, LocalDate date) { System.out.printf(\u0026#34;%s, %s, %s\u0026#34;, title, status, date); } 空CSV参数 如果@CsvSource中有empty值，JUnit 5会将其作为null值。\n@ParameterizedTest @CsvSource(\u0026#34;, IN_PROGRESS, 2020-12-20\u0026#34;) void nullArgument(String title, Status status, LocalDate date) { assertNull(title); } 空字符串可使用单引号包含起来：\n@ParameterizedTest @CsvSource(value = \u0026#34;NULL, IN_PROGRESS, 2020-12-20\u0026#34;, nullValues = \u0026#34;NULL\u0026#34;) void customNullArgument(String title, Status status, LocalDate date) { assertNull(title); } 如果想将null值替换为特殊的字符串，可在@CsvSource注解中使用nullValues参数：\n@ParameterizedTest @CsvSource(value = \u0026#34;NULL, IN_PROGRESS, 2020-12-20\u0026#34;, nullValues = \u0026#34;NULL\u0026#34;) void customNullArgument(String title, Status status, LocalDate date) { assertNull(title); } 将字符串转换为其它类型 为了更好的支持类似@CsvSource等注解，JUnit 5对原始参数类型、枚举，java.time包中的日期和时间类型进行自动转换。\n例如，这意味着它会自动将以下日期字符串转换为LocalDate实例:\n@ParameterizedTest @ValueSource(strings = { \u0026#34;2018-01-01\u0026#34;, \u0026#34;2018-01-31\u0026#34; }) void convertStringToLocalDate(LocalDate localDate) { assertEquals(Month.JANUARY, localDate.getMonth()); } JUnit 5参数化测试默认支持更多类型转化，我们可查看JUnit5 implicit conversion获取转换类型列表，而不是在此处讲解全部内容。\n如果JUnit 5无法转化参数，它将对目标类型调用下述两种方法：\n只有一个String参数的构造方法 接收一个String参数并返回目标类型实例的静态方法 在下面的例子中，JUnit 5将调用Person类的构造来进行String类型转换：\npublic class Person { private String name; public Person(String name) { this.name = name; } } 类似的，下述例子中的Person类也能正常工作：\npublic class Person { private final String name; public static Person fromName(String name) { return new Person(name); } } 自定义类型转换 若要编写自定义参数转换器，则需要实现ArgumentConverter接口，之后则可在任何需要自定义转换的参数上使用@ConvertWith注解。\n举例来说，我们要写一个转换器将十六进制转化为十进制，除了实现ArgumentConverter，在只需要处理一种类型时我们也可以继承TypedArgumentConverter类：\nclass HexConverter extends TypedArgumentConverter\u0026lt;String, Integer\u0026gt; { protected HexConverter() { super(String.class, Integer.class); } @Override public Integer convert(String source) throws ArgumentConversionException { try { return Integer.parseInt(source, 16); } catch (NumberFormatException e) { throw new ArgumentConversionException(\u0026#34;Cannot convert hex value\u0026#34;, e); } } } 接下来，我们需要将测试中需要自定义转换的参数添加@ConvertWith注解：\n@ParameterizedTest @CsvSource({ \u0026#34;15, F\u0026#34;, \u0026#34;16, 10\u0026#34;, \u0026#34;233, E9\u0026#34; }) void convertWithCustomHexConverter(int decimal, @ConvertWith(HexConverter.class) int hex){ assertEquals(decimal, hex); } 为了让测试本身技术性降低一些同时更具有可读性，我们可以进一步的创建一个元注解来封装转换：\n@Target({ ElementType.ANNOTATION_TYPE, ElementType.PARAMETER }) @Retention(RetentionPolicy.RUNTIME) @ConvertWith(HexConverter.class) public @interface HexValue { } 现在，可以使用新组合的注解让测试代码更具有可读性：\n@ParameterizedTest @CsvSource({ \u0026#34;15, F\u0026#34;, \u0026#34;16, 10\u0026#34;, \u0026#34;233, E9\u0026#34; }) void convertWithCustomHexConverter(int decimal, @HexValue int hex) { assertEquals(decimal, hex); } 将多参数转化为对象 默认情况下，提供参数化测试的参数对应于单个方法参数，可以使用ArgumentsAccessor将这些参数聚合到单个测试方法参数中。\n为了创建一个更具可读性和可重用性的参数聚合器，我们可编码自己实现：\npublic class TaskAggregator implements ArgumentsAggregator { @Override public Object aggregateArguments( ArgumentsAccessor accessor, ParameterContext context ) throws ArgumentsAggregationException { return new Task( accessor.getString(0), accessor.get(1, Status.class), accessor.get(2, LocalDate.class) ); } } @ParameterizedTest @CsvSource({ \u0026#34;Write a blog post, IN_PROGRESS, 2020-12-20\u0026#34;, \u0026#34;Wash the car, OPENED, 2020-12-15\u0026#34; }) void aggregateArgumentsWithAggregator(@AggregateWith(TaskAggregator.class) Task task) { System.out.println(task); } 如同自定义参数转换器，我们也可以给聚合器创建一个速记注解：\n@ParameterizedTest @CsvSource({ \u0026#34;Write a blog post, IN_PROGRESS, 2020-12-20\u0026#34;, \u0026#34;Wash the car, OPENED, 2020-12-15\u0026#34; }) void aggregateArgumentsWithAnnotation(@CsvToTask Task task) { System.out.println(task); } 现在可以在任何需要的地方使用该聚合器注解。\n自定义测试参数名称 默认情况下，JUnit 5参数化测试的显示名称包括所有参数的调用索引和字符串表示形式，然而，我们可以通过@ParameterizedTest注解中的name属性来展示自定义的名称。\n再次基于前面的月份名称示例：\n@ParameterizedTest(name = \u0026#34;{index} =\u0026gt; number={0}, month={1}\u0026#34;) @MethodSource void monthNames(int month, String name) { assertEquals(name, DateUtils.getMonthName(month)); } private static Stream\u0026lt;Arguments\u0026gt; monthNames() { return Stream.of( arguments(1, \u0026#34;January\u0026#34;), arguments(2, \u0026#34;February\u0026#34;), arguments(12, \u0026#34;December\u0026#34;) ); } 名称属性中的{index}占位符表示当前的调用序号，{0},{1}则表示实际的参数值。\n执行上述测试会得到类似如下输出：\nmonthNames(int, String) ├─ 1 =\u0026gt; number=1, month=January ├─ 2 =\u0026gt; number=2, month=February └─ 3 =\u0026gt; number=12, month=December 总结 JUnit 5参数化测试允许我们消除重复的测试代码，它使得通过使用不同的参数来多次执行同一个测试方法成为可能。\n如果我们只有一个参数在大多数情况下使用@ValueSource即可满足要求，我们也可以使用@EnumSource、@NullSource和@EmptySource 如果有多个参数，在大多数情况下@MethodSource注解是合适选择，也可以使用@ArgumentsSource实现重复使用 对于数据驱动的测试，可使用@CsvFileSource注解 可基于ArgumentConverter接口实现自定义参数转化规则 可使用ArgumentsAggregator接口实现参数聚合 本文的示例代码能在GitHub中找到。\n","date":"2023-06-17T09:21:43+08:00","permalink":"https://lucumt.info/post/translate/junit5/junit-5-parameterized-tests/","tags":["junit5","java","junit"],"title":"[译]JUnit 5 参数化测试实用指南"},{"categories":["翻译","JUnit5翻译"],"contents":"本文翻译自JUnit 5 Test Lifecycle: Before and After Annotations。\n在本教程中我们将学习如何在测试类的每个测试方法或测试类中所有方法之前和之后运行代码，同时将了解嵌套测试和扩展测试时的执行顺序。\n本文是JUnit 5 教程的一部分。\n生命周期相关方法 一个生命周期方法是指任何添加了@BeforeAll、@AfterAll、@BeforeEach或@AfterEach注解的方法，生命周期方法在实际测试方法之前或之后执行。\n@BeforeAll和@AfterAll注解表示在测试类中使用使用该注解的方法应该在全部的测试方法之前或之后执行。\n与之相似，@BeforeEach和@AfterEach分别表示使用该注解的方法应该在测试类中的每个测试方法之前或之后执行。\n如果测试类中有10个测试方法，@BeforeEach 和@AfterEach会执行10次，而@BeforeAll和@AfterAll只执行一次。\n测试生命周期 默认情况下，JUnit在执行测试中的每个测试方法之前都会创建一个新的实例，这有助于我们单独运行各个测试方法并避免意外的副作用。\n要了解该机制是如何工作的，可以看一下下面的示例:\nclass PerMethodLifecycleTest { public PerMethodLifecycleTest() { System.out.println(\u0026#34;Constructor\u0026#34;); } @BeforeAll static void beforeTheEntireTestFixture() { System.out.println(\u0026#34;Before the entire test fixture\u0026#34;); } @AfterAll static void afterTheEntireTestFixture() { System.out.println(\u0026#34;After the entire test fixture\u0026#34;); } @BeforeEach void beforeEachTest() { System.out.println(\u0026#34;Before each test\u0026#34;); } @AfterEach void afterEachTest() { System.out.println(\u0026#34;After each test\u0026#34;); } @Test void firstTest() { System.out.println(\u0026#34;First test\u0026#34;); } @Test void secondTest() { System.out.println(\u0026#34;Second test\u0026#34;); } } 需要注意的是使用@BeforeAll和@AfterAll注解的方法是静态方法，这是因为每个测试方法在创建新的实例时，它们之间没有共享状态。\n通过下图可更直观的理解：\n执行上述测试类中的测试方法会得到如下输出(输出结果进行了格式化以便其看起来更直观)\nBefore the entire test fixture Constructor Before each test First test After each test Constructor Before each test Second test After each test After the entire test fixture 观察上述输出，可发现JUnit会为每个测试方法构造一个测试类，生命周期相关的fixture方法只执行一次，测试相关的生命周期方法会被执行多次。\n按类实例测试 也可以让JUnit在同一个测试实例中执行所有的测试方法，如果将测试类使用@TestInstance(Lifecycle.PER_CLASS)注解，JUnit将为每个测试类创建一个测试实例。\n由于实例共享，此时没有必要使用静态方法：\n@TestInstance(TestInstance.Lifecycle.PER_CLASS) public class PerClassLifecycleTest { @BeforeAll void beforeTheEntireTestFixture() { System.out.println(\u0026#34;Before the entire test fixture\u0026#34;); } @AfterAll void afterTheEntireTestFixture() { System.out.println(\u0026#34;After the entire test fixture\u0026#34;); } // ... } 同样的，可以用下图理解其执行过程:\n此时的执行结果略有不同：\nConstructor Before the entire test fixture Before each test First test After each test Before each test Second test After each test After the entire test fixture 从输出结果中可看出，生命周期相关方法的执行顺序没有发生改变，但不同之处在于JUnit只会构建一次测试类。\n根本区别在于，在构造新测试类实例的默认生命周期方法中会重置实例变量中存储的状态，而当每个类的生命周期方法仅构造一次实例时，存储在实例变量中的状态则会在测试方法之间共享。\n注意\n​ 如果测试方法依赖于存储在实例变量中的状态，则需要在使用@BeforeEach 或@AfterEach注解的生命周期方法中重置其状态，要尽可能的避免编写依赖与存储实例状态的测试方法。\n更具体的例子 现在我们知道了生命周期方法如何工作的，进一步探索如何在实践中使用它们是有益的。通常如果有一些计算成本较高的东西，可以在多个测试方法中进行共享。\n此类示例包括打开数据库连接、从依赖注入框架获取上下文或读取文件。\n@TestInstance(TestInstance.Lifecycle.PER_CLASS) public class ExpensiveResourceTest { private JettyServer jettyServer; @BeforeAll void startServer() throws Exception { jettyServer = new JettyServer(); jettyServer.start(); } @AfterAll void stopServer() throws Exception { jettyServer.stop(); } @Test void checkServerStatus() throws IOException { URL url = new URL(\u0026#34;http://localhost:8080/status\u0026#34;); HttpURLConnection connection = (HttpURLConnection) url.openConnection(); int response = connection.getResponseCode(); assertEquals(200, response); } @Test void checkInvalidEndpoint() throws IOException { URL url = new URL(\u0026#34;http://localhost:8080/invalid\u0026#34;); HttpURLConnection connection = (HttpURLConnection) url.openConnection(); int response = connection.getResponseCode(); assertEquals(404, response); } } 嵌套测试生命周期 生命周期方法同样可以用于嵌套测试，但在默认情况下@BeforeAll 和@AfterAll注解不会工作，这是由于嵌套类是内部类，而Java内部类中不支持静态方法。\n可将嵌套类添加@TestInstance(Lifecycle.PER_CLASS)注解来实现类似效果：\npublic class NestedLifecycleTest { @Nested class HappyPath { @BeforeEach void beforeEachHappyPath() { System.out.println(\u0026#34;Before each happy path\u0026#34;); } @AfterEach void afterEachHappyPath() { System.out.println(\u0026#34;After each happy path\u0026#34;); } @Test void happyPathOne() { System.out.println(\u0026#34;Happy path one\u0026#34;); } @Test void happyPathTwo() { System.out.println(\u0026#34;Happy path two\u0026#34;); } } @Nested @TestInstance(TestInstance.Lifecycle.PER_CLASS) class ExceptionalPath { @BeforeAll void beforeEntireExceptionalPath() { System.out.println(\u0026#34;Before entire exceptional path\u0026#34;); } @AfterAll void afterEntireExceptionalPath() { System.out.println(\u0026#34;After entire exceptional path\u0026#34;); } @Test void exceptionalPathOne() { System.out.println(\u0026#34;Exceptional path one\u0026#34;); } @Test void exceptionalPathTwo() { System.out.println(\u0026#34;Exceptional path two\u0026#34;); } } } 如我们所见，生命周期方法分别应用在每个嵌套测试中：\nBefore entire exceptional path Exceptional path one Exceptional path two After entire exceptional path Before each happy path Happy path one After each happy path Before each happy path Happy path two After each happy path 补充阅读\nJUnit5 嵌套测试\n扩展生命周期 在使用扩展时，JUnit除了调用测试类的生命周期方法之外，还调用对应扩展的生命周期回调方法。\nJUnit会确保多个注册扩展的封装行为，假设有扩展ExtensionOne和ExtensionTwo，它会确保ExtensionOne中所有before相关的方法都在ExtensionTwo之前执行，类似的，ExtensionOne中所有after相关的方法都在ExtensionTwo之侯执行。\n看看如下的例子：\npublic class ExtensionOne implements BeforeEachCallback, AfterEachCallback { @Override public void beforeEach(ExtensionContext context) { System.out.println(\u0026#34;Before each from ExtensionOne\u0026#34;); } @Override public void afterEach(ExtensionContext context) { System.out.println(\u0026#34;After each from ExtensionOne\u0026#34;); } } @ExtendWith(ExtensionOne.class) @ExtendWith(ExtensionTwo.class) public class ExtensionLifecycleTest { @BeforeEach void beforeEachTest() { System.out.println(\u0026#34;Before each test\u0026#34;); } @AfterEach void afterEachTest() { System.out.println(\u0026#34;After each test\u0026#34;); } @Test void firstTest() { System.out.println(\u0026#34;First test\u0026#34;); } @Test void secondTest() { System.out.println(\u0026#34;Second test\u0026#34;); } } 执行上述代码后，可在结果中看见相关扩展的封装行为：\nBefore each from ExtensionOne Before each from ExtensionTwo Before each test First test After each test After each from ExtensionTwo After each from ExtensionOne Before each from ExtensionOne Before each from ExtensionTwo Before each test Second test After each test After each from ExtensionTwo After each from ExtensionOne 补充阅读\nJUnit5官方文档中有关于执行顺序和扩展的更详细说明\nJUnit5 User Guide\n总结 要在每次测试之前和之后执行一段代码，可使用JUnit5中的@BeforeEach和@AfterEach注解，类似的，若要对测试实例中的所有测试执行一次代码，可使用@BeforeAll和@AfterAll注解。\n此外，可通过给测试类添加@TestInstance(Lifecycle.PER_CLASS)注解让其执行测试时只创建一个实例，它同时为嵌套测试中开启了\u0026quot;before all\u0026quot;和\u0026quot;after all\u0026quot;相关的生命周期方法。\n最后，当注册多个扩展时，JUnit5会确保它们生命周期方法的封装行为。\n本文的示例代码能在GitHub中找到。\n","date":"2023-06-16T19:21:43+08:00","permalink":"https://lucumt.info/post/translate/junit5/junit-5-test-lifecycle/","tags":["junit5","java","junit"],"title":"[译]JUnit 5 生命周期 - 注释之前和之后"},{"categories":["持续集成","工具使用"],"contents":"简要记录下在安装完成KubeSphere后由于缺少OpenEBS而导致名为prometheus-k8s-0的pod节点一直处于Pending状态，进而导致在KubeSphere集群管理中资源统计部分出现NaN的问题。\nKubeSphere初步安装完成之后，以admin账户登录该系统，依次点击平台管理-\u0026gt;集群管理，可发现界面正中的资源统计部分很多数据都为NaN，影响使用\n执行kubectl get po -A结果如下，可发现名为prometheus-k8s-0-pod-pending的pod节点处于Pending状态，问题原因初步找到!\n执行kubectl describe pod prometheus-k8s-0 -n kubesphere-monitoring-system查看该节点信息如下，没有找出特别有用的信息，问题分析暂时陷入僵局\n在KubeSphere的官方论坛找到这篇文章，在其中看到了如下回复，初步判定和OpenEBS有关\n在GitHub上找到OpenEBS对应的项目，将openebs-operator.yaml下载到对应的服务器，之后执行kubectl apply -f openebs-operator.yaml 接着执行kubectl get po -A查看对应pod节点，结果如下，可以看出prometheus-k8s-0已正常运行\n在KubeSphere中刷新页面，显示结果如下，数据可正常显示，至此问题解决!\n","date":"2023-06-06T16:17:41+08:00","permalink":"https://lucumt.info/post/devops/prometheus-k8s-0-pending-in-kubesphere/","tags":["docker","kubernetes","kubesphere"],"title":"KubeSphere中名为prometheus-k8s-0的pod一直处理Pending状态解决"},{"categories":["数据计算"],"contents":"记录下如何基于NumPy将npz文件解析成多个csv文件，以自己项目中使用的npz文件结构为例，其它地方使用时可能会有差异\n执行下述代码分析其key结构\nif __name__ == \u0026#39;__main__\u0026#39;: src_file = r\u0026#39;D:\\test-001.npz\u0026#39; results = np.load(src_file) for key, value in results.items(): print(key) 输出结果类似如下\nCAN/2/localmap1__message394/left_line_id_11 CAN/2/localmap1__message394/left_line_id_12 CAN/2/localmap1__message394/left_line_id_13 CAN/2/localmap1__message396/_timestamp CAN/2/localmap1__message396/timeStamp CAN/2/localmap1__message396/right_line_id_15 基于此可发现其组织结构为协议/通道/序号/信号/报文，我们要做的时基于以信号为单位生成csv文件\n改进测试代码\nif __name__ == \u0026#39;__main__\u0026#39;: src_file = r\u0026#39;D:\\test-001.npz\u0026#39; results = np.load(src_file) for key, value in results.items(): print(key \u0026#43; \u0026#34;\\t\u0026#34; \u0026#43; str(len(value))) 执行后输出结果类似如下\nCAN/2/localmap1__message394/left_line_id_11\t322 CAN/2/localmap1__message394/left_line_id_12\t322 CAN/2/localmap1__message394/left_line_id_13\t322 CAN/2/localmap1__message396/_timestamp\t350 CAN/2/localmap1__message396/timeStamp\t350 CAN/2/localmap1__message396/right_line_id_15\t350 可发现一个报文对应多行记录，且每个信号下的报文记录数基本上相同。\n同时也能发现在npz中的数据是一行一行的，逐行拼接在一起，若要转化为csv文件，则涉及到行专列操作，同样可基于NumPy进行操作，完整的代码如下\nimport os import shutil import numpy as np import time import sys def parse_npz(data_folder, src_file): if os.path.exists(data_folder): shutil.rmtree(data_folder) os.makedirs(data_folder) results = np.load(src_file) dict = {} message_name = None for key, value in results.items(): data = key.split(\u0026#34;/\u0026#34;) # 长度不符合要求，直接跳过 if (len(data)) != 4: continue new_message = data[-2] # 新的信号开始，要处理之前的信号 if new_message != message_name: process_message(data_folder, message_name, dict) message_name = new_message dict[message_name] = [] signal = str(data[-1]) is_timestamp = signal == \u0026#39;_timestamp\u0026#39; if is_timestamp: value = np.multiply(value, 100_0000).astype(np.int64) value = value - value[0] signal = \u0026#39;Timestamp\u0026#39; dict[message_name].append([signal, *value]) # 处理最后一个信号 process_message(data_folder, message_name, dict) def process_message(folder, message, dict): if message is None: return signals = dict[message] length = min(len(v) for v in signals) signals = [v[0:length] for v in signals] # 将行转化为列，以符合业务需求 csv_data = np.array(signals).swapaxes(0, 1) # 保存到磁盘 file_name = folder \u0026#43; os.sep \u0026#43; message \u0026#43; \u0026#34;.csv\u0026#34; np.savetxt(file_name, csv_data, delimiter=\u0026#34;,\u0026#34;, fmt=\u0026#34;%s\u0026#34;) # print(\u0026#39;-------------save file to \u0026#39; \u0026#43; file_name \u0026#43; \u0026#39;---------------\u0026#39;) del dict[message] if __name__ == \u0026#39;__main__\u0026#39;: #data_folder = sys.argv[1] #src_file = sys.argv[2] data_folder = r\u0026#39;D:\\npz_csv\u0026#39; src_file = r\u0026#39;D:\\test-001.npz\u0026#39; start = time.time() parse_npz(data_folder, src_file) end = time.time() print(f\u0026#39;=============== Parse npz file time cost:{end - start:.4f}s =============\u0026#39;) ","date":"2023-05-16T10:09:16+08:00","permalink":"https://lucumt.info/post/python/using-numpy-to-parse-npzp-into-csv/","tags":["python"],"title":"利用Numpy将npz文件解析为csv文件"},{"categories":["翻译","JUnit5翻译"],"contents":"本文翻译自JUnit 5 Nested Tests: Grouping Related Tests Together。\n在本教程中我们讲学习如何利用JUnit 5编写嵌套测试，学习如何提供一个层级结构用于描述测试方法间的依赖关系。\n本文是JUnit 5 教程的一部分。\n如果你喜欢通过视频学习，可以查看Youtube中相关的学习视频\n无嵌套测试 为了给嵌套测试奠定基础，首先看一个没有嵌套的例子，为了简洁起见省略了测试内容，完整的内容在GitHub中。\npublic class MoneyTest { @Test @DisplayName(\u0026#34;monies with same amounts and currency are equal\u0026#34;) void moniesWithSameAmountsAndCurrencyAreEqual() { CurrencyUnit eur = CurrencyUnit.of(\u0026#34;EUR\u0026#34;); Money first = Money.of(eur, 3.99); Money second = Money.of(eur, 3.99); assertEquals(second, first); } @Test @DisplayName(\u0026#34;monies with different amounts are not equal\u0026#34;) void moniesWithDifferentAmountsAreNotEqual() { } @Test @DisplayName(\u0026#34;monies with different currencies are not equal\u0026#34;) void moniesWithDifferentCurrenciesAreNotEqual() { } @Test @DisplayName(\u0026#34;can add monies of same currency\u0026#34;) void addMoneyWithSameCurrency() { } @Test @DisplayName(\u0026#34;cannot add monies of different currency\u0026#34;) void addMoneyWithDifferentCurrency() { } } 此处我们有一个包含多个用于测试Money类的测试方法，Money中包含货币与金额，可检测Money实例是否相等，也可以对其相加。\n当在命令行运行上述代码时，下面展示了大致的输出结果：\nMoneyTest \u0026gt; monies with same amounts and currency are equal PASSED MoneyTest \u0026gt; can add monies of same currency PASSED MoneyTest \u0026gt; cannot add monies of different currency PASSED MoneyTest \u0026gt; monies with different amounts are not equal PASSED MoneyTest \u0026gt; monies with different currencies are not equal PASSED 此处没有太多的测试方法，所以仍然具有较好的可读性，然而，我们已经能够看出关联的测试方法在输出结果中没有分组在一起。\n添加嵌套类 JUnit 5中的嵌套测试为我们提供了一种构建层级结构的实现，可基于逻辑结构组织测试，组织起来的嵌套结构能让我们更好的表述测试方法间的关系。\n通过在测试类中创建内部类并添加@Nested注解，我们可在JUnit 5中创建嵌套测试，同样可通过添加@DisplayName注解给嵌套类赋予一个更容易阅读的名称。\npublic class MoneyTest { @Nested @DisplayName(\u0026#34;equality is based on values\u0026#34;) class Equality { @Test @DisplayName(\u0026#34;monies with same amounts are equal\u0026#34;) void moniesWithSameAmountsAreEqual() { } @Test @DisplayName(\u0026#34;monies with different amounts are not equal\u0026#34;) void moniesWithDifferentAmountsAreNotEqual() { } @Test @DisplayName(\u0026#34;monies with different currencies are not equal\u0026#34;) void moniesWithDifferentCurrenciesAreNotEqual() { } } @Nested @DisplayName(\u0026#34;adding monetary amounts\u0026#34;) class Addition { @Test @DisplayName(\u0026#34;can add monies of same currency\u0026#34;) void addMoneyWithSameCurrency() { } @Test @DisplayName(\u0026#34;cannot add monies of different currency\u0026#34;) void addMoneyWithDifferentCurrency() { } } } 这个例子没有特别之处，但我们已经将检查金额相等和金额累加的测试关注点分离开来了，该测试代码有更多层级结构，同时相关联的测试方法被更好的分组在一起。\n在命令行中重置执行后，可以看见与之前的一些差异：\nMoneyTest \u0026gt; adding monetary amounts \u0026gt; can add monies of same currency PASSED MoneyTest \u0026gt; adding monetary amounts \u0026gt; cannot add monies of different currency PASSED MoneyTest \u0026gt; equality is based on values \u0026gt; monies with different amounts are not equal PASSED MoneyTest \u0026gt; equality is based on values \u0026gt; monies with different currencies are not equal PASSED MoneyTest \u0026gt; equality is based on values \u0026gt; monies with same amounts are equal PASSED 与没有嵌套的测试相比，由于相关的测试被分组在一起，所以组织的更好一些，同代码类似，输出结果有更多的结构。\n从IDE工具中运行后能看见添加嵌套结构后带来的额外好处，下图展示了在Intellij IDEA中运行后的结果：\n在Intellij IDEA中运行嵌套测试 该报告看起来已经要好一些，每个嵌套类都可被展开或折叠，可只关注于想要的结果。\n添加二级嵌套 来看一个更复杂的示例，我们正在测试一个REST controller，我们正在测试用于创建、读取和删除产品的HTTP POST、GET和DELETE方法，我们会检查验证各种内容，如请求正文字段和HTTP响应状态码。\nclass ProductControllerTest { @Test @DisplayName(\u0026#34;POST returns HTTP status Bad Request when fields are missing\u0026#34;) void postReturnsHttpStatusBadRequestWhenFieldsAreMissing() throws Exception { Product product = new Product(null, null, null); mockMvc.perform(post(\u0026#34;/product\u0026#34;) .contentType(MediaType.APPLICATION_JSON) .content(objectMapper.writeValueAsString(product))) .andExpect(status().isBadRequest()); } @Test @DisplayName(\u0026#34;POST does not create a product when fields are missing\u0026#34;) void postDoesNotCreateProductWhenFieldsAreMissing() throws Exception { } @Test @DisplayName(\u0026#34;POST returns HTTP status Created when fields are valid\u0026#34;) void postReturnsHttpStatusCreatedWhenFieldsAreValid() throws Exception { } @Test @DisplayName(\u0026#34;GET returns HTTP status Not Found when product is not found\u0026#34;) void getReturnsHttpStatusNotFoundWhenProductIsNotFound() throws Exception { } @Test @DisplayName(\u0026#34;GET returns HTTP status OK when product is found\u0026#34;) void getReturnsHttpStatusOkWhenProductIsFound() throws Exception { } @Test @DisplayName(\u0026#34;GET returns found product as JSON when product is found\u0026#34;) void getReturnsFoundProductAsJsonWhenProductIsFound() throws Exception { } @Test @DisplayName(\u0026#34;DELETE returns HTTP status Not Found when product is not found\u0026#34;) void deleteReturnsHttpStatusNotFoundWhenProductIsNotFound() throws Exception { } @Test @DisplayName(\u0026#34;DELETE returns HTTP status No Content when product is found\u0026#34;) void deleteReturnsHttpStatusNoContentWhenProductIsFound() throws Exception { } } 这些测试方法都有自定义名称，但描述信息和方法名称变的很长，我们甚至可以说已经变的很冗长。\n在命令行中执行后会出现同样的问题：\nProductControllerTest \u0026gt; POST returns HTTP status Created when fields are valid PASSED ProductControllerTest \u0026gt; DELETE returns HTTP status No Content when product is found PASSED ProductControllerTest \u0026gt; GET returns HTTP status OK when product is found PASSED ProductControllerTest \u0026gt; POST does not create a product when fields are missing PASSED ProductControllerTest \u0026gt; GET returns HTTP status Not Found when product is not found PASSED ProductControllerTest \u0026gt; DELETE returns HTTP status Not Found when product is not found PASSED ProductControllerTest \u0026gt; GET returns found product as JSON when product is found PASSED ProductControllerTest \u0026gt; POST returns HTTP status Bad Request when fields are missing PASSED 我们可看出，随着测试数量增加，输出内容开始变得有点难以阅读，虽然语言本身很容易阅读，但输出结果变得冗长，同时难以阅读。\n现在我们可以看下如果在HTTP方法中添加嵌套、并为假设的场景添加另外一层嵌套(如产品存在/不存在)时会发生什么。\nclass ProductControllerTest { @Nested @DisplayName(\u0026#34;Creating a product\u0026#34;) class Post { @Nested @DisplayName(\u0026#34;when fields are missing\u0026#34;) class WhenFieldsAreMissing { @Test @DisplayName(\u0026#34;return HTTP status Bad Request\u0026#34;) void returnHttpStatusBadRequest() throws Exception { } @Test @DisplayName(\u0026#34;do not create a product\u0026#34;) void doNotCreateProduct() throws Exception { } } @Nested @DisplayName(\u0026#34;when fields are valid\u0026#34;) class WhenFieldsAreValid { @Test @DisplayName(\u0026#34;return HTTP status Created\u0026#34;) void returnHttpStatusCreated() throws Exception { } } } @Nested @DisplayName(\u0026#34;Finding a product\u0026#34;) class GetById { @Nested @DisplayName(\u0026#34;when product is not found\u0026#34;) class WhenProductIsNotFound { @Test @DisplayName(\u0026#34;return HTTP status Not Found\u0026#34;) void returnHttpStatusNotFound() throws Exception { } } @Nested @DisplayName(\u0026#34;when product is found\u0026#34;) class WhenProductIsFound { @Test @DisplayName(\u0026#34;return HTTP status OK\u0026#34;) void returnHttpStatusOk() throws Exception { } @Test @DisplayName(\u0026#34;return found product as JSON\u0026#34;) void returnFoundProductAsJson() throws Exception { } } } @Nested @DisplayName(\u0026#34;Deleting a product\u0026#34;) class Delete { @Nested @DisplayName(\u0026#34;when product is not found\u0026#34;) class WhenProductIsNotFound { @Test @DisplayName(\u0026#34;return HTTP status Not Found\u0026#34;) void returnHttpStatusNotFound() throws Exception { } } @Nested @DisplayName(\u0026#34;when product is found\u0026#34;) class WhenProductIsFound { @Test @DisplayName(\u0026#34;return HTTP status No Content\u0026#34;) void returnHttpStatusNoContent() throws Exception { } } } } 测试代码看起来更长，但我们也能发现描述信息和方法名称变的更简洁。\n现代IDE允许折叠和展开代码块，因此我们可以展开Post类和Delete类，可以只查看GeetById类。\n通过IDE执行测试能够展示出测试结果有多少层级，下图为Intellij IDEA中的运行结果：\n在Intellij IDEA中运行嵌套测试 在命令行中执行后，可发现输出结构中有更多的结构：\nProductControllerTest \u0026gt; Deleting a product \u0026gt; when product is found \u0026gt; return HTTP status No Content PASSED ProductControllerTest \u0026gt; Deleting a product \u0026gt; when product is not found \u0026gt; return HTTP status Not Found PASSED ProductControllerTest \u0026gt; Finding a product \u0026gt; when product is found \u0026gt; return found product as JSON PASSED ProductControllerTest \u0026gt; Finding a product \u0026gt; when product is found \u0026gt; return HTTP status OK PASSED ProductControllerTest \u0026gt; Finding a product \u0026gt; when product is not found \u0026gt; return HTTP status Not Found PASSED ProductControllerTest \u0026gt; Creating a product \u0026gt; when fields are valid \u0026gt; return HTTP status Created PASSED ProductControllerTest \u0026gt; Creating a product \u0026gt; when fields are missing \u0026gt; return HTTP status Bad Request PASSED ProductControllerTest \u0026gt; Creating a product \u0026gt; when fields are missing \u0026gt; do not create a product PASSED 输出结果受益于嵌套，相关联的结果更容易被找到，如果我们设法创建一个经过深思熟虑的结构，它就像导航结果的面包屑一样便于使用。\n避免陷阱 如果使用得当，JUnit 5嵌套测试可以成为一个强有力的工具，但是同其它的工具一样，使用嵌套测试也会伴随着一些陷阱。\n忽略代码异味 当我们有编写嵌套测试的冲动时，我们应该问下自己为什么要这样做，如果测试类变得越来越大并且需要进行组织，或许意味着测试类正在做太多的事情。\n我们应该问自己这些问题：\n是否能够将任一嵌套类从测试类中抽取出来让它们只关注自身逻辑？ 嵌套类中的任一假定测试是否意味着其在做不止一件事情？ 相对于添加更多的结构来测试，我们应该考虑是否有必要进行重构，添加层级结构也会增加测试的复杂性，应该尽可能的避免添加复杂性。\n试图消除重复 许多教程建议我们通过在@BeforeEach方法中构造共享对象并将它们定义为类成员变量来消除重复，这个建议的初衷是好的，但在测试代码中消除重复有更多的讲究。\n我们仔细看下之前的产品controller测试：\n@Nested @DisplayName(\u0026#34;when product is found\u0026#34;) class WhenProductIsFound { @Test @DisplayName(\u0026#34;return HTTP status OK\u0026#34;) void returnHttpStatusOk() throws Exception { Product product = new Product(1L, \u0026#34;Toothbrush\u0026#34;, BigDecimal.valueOf(5.0)); when(productRepository.findById(1L)).thenReturn(product); mockMvc.perform(get(\u0026#34;/product/{productId}\u0026#34;, 1L)) .andExpect(status().isOk()); } @Test @DisplayName(\u0026#34;return found product as JSON\u0026#34;) void returnFoundProductAsJson() throws Exception { Product product = new Product(1L, \u0026#34;Toothbrush\u0026#34;, BigDecimal.valueOf(5.0)); when(productRepository.findById(1L)).thenReturn(product); mockMvc.perform(get(\u0026#34;/product/{productId}\u0026#34;, 1L)) .andExpect(jsonPath(\u0026#34;$.id\u0026#34;, is(1))) .andExpect(jsonPath(\u0026#34;$.name\u0026#34;, is(\u0026#34;Toothbrush\u0026#34;))) .andExpect(jsonPath(\u0026#34;$.price\u0026#34;, is(5.0))); } } 由于在项目构造时存在重复代码，许多教程建议通过使用带有@BeforeEach注解的方法来消除重复：\n@Nested @DisplayName(\u0026#34;when product is found\u0026#34;) class WhenProductIsFound { @BeforeEach void productFound() { Product product = new Product(1L, \u0026#34;Toothbrush\u0026#34;, BigDecimal.valueOf(5.0)); when(productRepository.findById(1L)).thenReturn(product); } @Test @DisplayName(\u0026#34;return HTTP status OK\u0026#34;) void returnHttpStatusOk() throws Exception { mockMvc.perform(get(\u0026#34;/product/{productId}\u0026#34;, 1L)) .andExpect(status().isOk()); } @Test @DisplayName(\u0026#34;return found product as JSON\u0026#34;) void returnFoundProductAsJson() throws Exception { mockMvc.perform(get(\u0026#34;/product/{productId}\u0026#34;, 1L)) .andExpect(jsonPath(\u0026#34;$.id\u0026#34;, is(1))) .andExpect(jsonPath(\u0026#34;$.name\u0026#34;, is(\u0026#34;Toothbrush\u0026#34;))) .andExpect(jsonPath(\u0026#34;$.price\u0026#34;, is(5.0))); } } 不幸的是，该测试现在不是独立的，我们无法一眼看出与测试相关的所有内容，有更好的方法来消除重复，如辅助方法、测试数据构造器或对象母体。\n进一步的检查示例代码，会发现第一个测试不关心属性值，而在第二个测试中字段值是关联信息。\n现在可以看下使用构造器模式和辅助方法改写后的测试代码：\n@Nested @DisplayName(\u0026#34;when product is found\u0026#34;) class WhenProductIsFound { @Test @DisplayName(\u0026#34;return HTTP status OK\u0026#34;) void returnHttpStatusOk() throws Exception { havingPersisted(aProduct().withId(1L)); mockMvc.perform(get(\u0026#34;/product/{productId}\u0026#34;, 1L)) .andExpect(status().isOk()); } @Test @DisplayName(\u0026#34;return found product as JSON\u0026#34;) void returnFoundProductAsJson() throws Exception { havingPersisted(aProduct().withId(1L).withName(\u0026#34;Toothbrush\u0026#34;).withPrice(5.0)); mockMvc.perform(get(\u0026#34;/product/{productId}\u0026#34;, 1L)) .andExpect(jsonPath(\u0026#34;$.id\u0026#34;, is(1))) .andExpect(jsonPath(\u0026#34;$.name\u0026#34;, is(\u0026#34;Toothbrush\u0026#34;))) .andExpect(jsonPath(\u0026#34;$.price\u0026#34;, is(5.0))); } } 我们可以立即看到每个测试只有相关信息，同时还可以一眼看出测试方法的作用。\n可读性和消除重复是一个宽泛的话题，我们不准备在此处详细讨论，对于可读性和可维护性的深入分析会放到其它文章中。\n补充阅读\n在代码中实践DRY和DAMP 如何创建测试数据构造器 如何让测试代码易于阅读 总结 我们可通过嵌套测试来添加层级结构，可通过创建具有@Nested注解的内部类来创建嵌套测试。\n嵌套测试有助于我们更好的描述测试方法之间的关系，嵌套测试还能够提高测试代码和测试结果的可读性和导航性。\n本文的示例代码能在GitHub中找到。\n","date":"2023-05-02T13:12:24+08:00","permalink":"https://lucumt.info/post/translate/junit5/junit-5-nested-tests/","tags":["junit5","java","junit"],"title":"[译]JUnit 5 嵌套测试 - 将关联的测试分组在一起"},{"categories":["翻译","JUnit5翻译"],"contents":"本文翻译自JUnit 5 Assertions: Verifying Test Results。\n概览 在本文中，我们将学习如何通过JUnit 5断言来验证测试结果，我们将学习断言的基本方法吗、如何自定义错误消息，以及如何将多个断言作为一个分组运行。\n本文是JUnit 5 教程的一部分。\n断言 JUnit 5断言让测试结果与预期结果的验证变得更容易，只要一个测试中有断言失败，整个测试就会失败。类似的，只有单个测试中所有的断言都通过，测试才能通过。\nJUnit 5中的断言是org.junit.jupiter.api.Assertions中的静态方法，下面我们将会详细了解这些方法的使用场景。\n值比较 在验证结果时，一个最常见的场景是我们希望预期结果与实际结果相等，JUnit 5提供了assertEquals()与assertNotEquals()方法来对值进行相等性和不等性比较。\n在这个例子中，我们有一个简单的Calculator类用于将两数相加，我们希望计算结果是准确的：\n@Test void addNumbers() { Calculator calculator = new Calculator(); assertEquals(3, calculator.add(1, 2)); } 如果断言失败，我们可以在错误消息中同时看到错误值和期望值：\norg.opentest4j.AssertionFailedError: Expected :3 Actual :2 布尔值 通常，当我们希望返回的值为true或者false，可通过assertEquals()方法实现，但JUnit 5中提供了更简洁的assertTrue()与assertFalse()方法来实现此功能。\n在下面例子中我们可验证一个人的名字是否以特定字母开头：\n@Test void firstNameStartsWithJ() { Person person = new Person(\u0026#34;John\u0026#34;, \u0026#34;Doe\u0026#34;); assertTrue(person.getFirstName().startsWith(\u0026#34;J\u0026#34;)); } 类似的，若要断言返回值不为true，可通过assertFalse()实现。\n空值 有时候我们希望一个对象为空或者非空，要实现此目的，可通过JUnit 5中的断言方法assertNull()和assertNotNull()实现。\n在下面的例子中我们可验证一个人的名字是否不为空：\n@Test void personHasFirstName() { Person person = new Person(\u0026#34;John\u0026#34;, \u0026#34;Doe\u0026#34;); assertNotNull(person.getFirstName()); } 如果断言失败，我们将会看到类似如下的报错信息：\norg.opentest4j.AssertionFailedError: expected: not \u0026lt;null\u0026gt; 尽管有时候可能需要断言空值，但我们通常应该在程序中避免返回空值。\n补充阅读\n避免不必要的空值检测\n迭代器 有时候我们需要验证一个集合中包含我们期望的元素，例如，我们可能想验证自己的排序算法是否有效。\nJUnit 5中的assertIterableEquals()可用于验证一个迭代器对象是否包含我们期望的元素，我们可以比较任何实现了Iterable接口的类。\n在下面例子中我们可验证一个list在排序后元其素顺序是否正确：\n@Test void iterablesEqual() { final List\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;orange\u0026#34;, \u0026#34;mango\u0026#34;, \u0026#34;banana\u0026#34;); final List\u0026lt;String\u0026gt; expected = Arrays.asList(\u0026#34;banana\u0026#34;, \u0026#34;mango\u0026#34;, \u0026#34;orange\u0026#34;); Collections.sort(list); assertIterableEquals(expected, list); } 假如我们的排序算法没生效，没有对迭代器对象进行排序，则断言会失败并显示一条错误信息：\norg.opentest4j.AssertionFailedError: iterable contents differ at index [0], Expected :\u0026lt;banana\u0026gt; Actual :\u0026lt;orange\u0026gt; assertIterableEquals()同样可用来检查迭代器对象的长度是否匹配，如果我们添加1个对象到迭代器中，断言结果会失败并显示出另外一条错误信息：\norg.opentest4j.AssertionFailedError: iterable lengths differ, Expected :\u0026lt;3\u0026gt; Actual :\u0026lt;4\u0026gt; 两个迭代器只有在它们全部为空或包含相同的值时才相等。\n数组 断言数组与断言迭代器很类似，可通过JUnit 5中的assertArrayEquals()方法实现:\n@Test void arraysEqual() { final int[] array = { 3, 2, 1 }; final int[] expected = { 1, 2, 3 }; Arrays.sort(array); assertArrayEquals(expected, array); } 两个数组只有在都为空或者包含相同的元素时才相等1\n值对象 在断言两个对象是否相等时，我们需要考虑一些事项。\n在下面的例子中有一个Person类包含姓和名，我们想比较两个Person对象是否相同：\n@Test void personsAreSame() { Person john = new Person(\u0026#34;John\u0026#34;, \u0026#34;Doe\u0026#34;); Person doe = new Person(\u0026#34;John\u0026#34;, \u0026#34;Doe\u0026#34;); assertEquals(john, doe); } 运行该测试后，会提示测试失败并显示出一条相当神秘的错误消息：\norg.opentest4j.AssertionFailedError: Expected :com.arhohuttunen.junit5.assertions.Person@eec5a4a Actual :com.arhohuttunen.junit5.assertions.Person@2b2948e2 预期的对象和实际对象包含相同的属性值，但assertEquals()仍然失败，发生了什么事情？\n原因为Java中的相等性使用equals()方法进行比较实现,equals()方法的默认实现是检查两个对象是否引用相同的对象，由此导致断言测试失败。\n补充阅读\nJava hashCode() and equals()\n要解决此问题，我们需要自己实现equals()方法来比较类中的属性，在重写equals()方法后，需要一并重写hashCode()方法：\npublic class Person { // ... @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Person person = (Person) o; return firstName.equals(person.firstName) \u0026amp;\u0026amp; lastName.equals(person.lastName); } @Override public int hashCode() { return Objects.hash(firstName, lastName); } } 重新运行测试，可发现测试执行通过，重写equals()方法后在比较对象是否相等时通过属性比较实现。\n引用对象 有时我们想确保两个对象指向或者不指向同一个实例，例如，要验证某个方法返回的是对象副本而不是相同的对象,JUnit 5提供了assertSame()和assertNotSame()方法来实现此功能：\n@Test void personsAreNotSameInstance() { Person john = new Person(\u0026#34;John\u0026#34;, \u0026#34;Doe\u0026#34;); Person doe = new Person(\u0026#34;John\u0026#34;, \u0026#34;Doe\u0026#34;); assertNotSame(john, doe); } 即使两个对象具有相同的值，该示例也会如我们所期望的那样测试通过，因为它们是两个单独的实例吗，如果测试失败，我们将看到类似如下的错误消息:\norg.opentest4j.AssertionFailedError: expected: not same but was: \u0026lt;Person{firstName=\u0026#39;John\u0026#39;, lastName=\u0026#39;Doe\u0026#39;}\u0026gt; Expected :not same Actual :\u0026lt;Person{firstName=\u0026#39;John\u0026#39;, lastName=\u0026#39;Doe\u0026#39;}\u0026gt; 异常 要确保程序中的错误处理能正常工作，我们可以验证一段代码在某些条件下是否抛出特定的异常，这可以通过JUnit 5中的assertThrows()方法来实现：\n@Test void divideByZeroThrowsIllegalArgumentException() { Calculator calculator = new Calculator(); assertThrows(IllegalArgumentException.class, () -\u0026gt; calculator.divide(1, 0)); } 在上面例子中， 如果我们试图将0作为除数，程序将抛出throw IllegalArgumentException。\n如果没有抛出异常，测试将不通过同时显示出一条错误信息：\norg.opentest4j.AssertionFailedError: Expected java.lang.IllegalArgumentException to be thrown, but nothing was thrown. 类似的，如果程序抛出一个非预期的异常，测试同样会不通过并显示出一条不同的错误消息：\norg.opentest4j.AssertionFailedError: Unexpected exception type thrown ==\u0026gt; Expected :\u0026lt;java.lang.IllegalArgumentException\u0026gt; Actual :\u0026lt;java.lang.ArithmeticException\u0026gt; 在某些情况下，我们想要验证有关异常的信息，例如错误消息或原因，在这种情况下，我们可以捕获抛出的异常：\n@Test void divideByZeroThrowsIllegalArgumentException() { Calculator calculator = new Calculator(); Throwable thrown = assertThrows(IllegalArgumentException.class, () -\u0026gt; calculator.divide(1, 0)); assertEquals(\u0026#34;Cannot divide by zero\u0026#34;, thrown.getMessage()); } 超时 有时候我们想确保程序执行时间不能超过某个限制，此时我们可用assertTimeout()或assertTimeoutPreemptively()来实现。\n这两个方法的不同点在于assertTimeout()与调用者在同一个线程中执行，并且即使超时也不会中止，而assertTimeoutPreemptively()则与调用者在不同的线程中，在超时后会中止。\n前面的意思是第一种方式的测试将一直执行下去，而第二种方式测试如果超过超时程序就会立即停止。\n让我们看一个例子：\n@Test void returnValueBeforeTimeoutExceeded() { final String message = assertTimeout(Duration.ofMillis(50), () -\u0026gt; { Thread.sleep(100); return \u0026#34;a message\u0026#34;; }); assertEquals(\u0026#34;a message\u0026#34;, message); } 由于执行时间将超过限制，我们会看到一条错误信息：\norg.opentest4j.AssertionFailedError: execution exceeded timeout of 100 ms by 50 ms 如果我们想中止执行，可通过调用assertTimeoutPreemptively()方法来实现：\n@Test void abortWhenTimeoutExceeded() { final String message = assertTimeoutPreemptively(Duration.ofMillis(50), () -\u0026gt; { Thread.sleep(100); return \u0026#34;another message\u0026#34;; }); assertEquals(\u0026#34;another message\u0026#34;, message); } 此时如果程序执行时间超时，我们将会看到一条略有不同的错误消息：\norg.opentest4j.AssertionFailedError: execution timed out after 50 ms 这里的区别在于执行在超时处停止程序运行。\n自定义错误信息 为JUnit 5断言提供自定义错误消息很容易，所有断言方法都有一个可选的错误消息作为最后一个参数：\n@Test void addNumbers() { Calculator calculator = new Calculator(); assertEquals(3, calculator.add(1, 2), \u0026#34;1 \u0026#43; 2 should equal 3\u0026#34;); } 自定义错误消息不会替换默认错误消息，相反，断言失败时会将自定义消息添加到错误消息之前：\norg.opentest4j.AssertionFailedError: 1 \u0026#43; 2 should equal 3 ==\u0026gt; Expected :3 Actual :-1 在某些情况下，我们需要构建一些更复杂的错误消息，此时我们可将错误消息作为lambda表达式中的最后一个参数：\n@Test void addingEmployeesToPersonnel() { Person employee = new Person(\u0026#34;John\u0026#34;, \u0026#34;Doe\u0026#34;); Set\u0026lt;Person\u0026gt; personnel = new HashSet\u0026lt;\u0026gt;(); personnel.add(employee); assertTrue(personnel.contains(employee), () -\u0026gt; String.format(\u0026#34;Personnel file for %s was not found\u0026#34;, employee)); } 上述例子中的错误消息不是那么复杂，但是，通过使用此种方式JUnit 5只会在断言失败时才构造错误消息，我们只需在程序运行失败时耗费相应的计算成本。\n分组断言 在执行测试时，测试程序将在第一次断言失败时终止，而利用JUnit 5中的分组断言，我们可以在反馈失败之前运行完所有的断言测试，可以通过使用assertAll()方法并提供不同的断言作为该方法的参数来实现此功能。\n假设我们想要验证一个人的名字是否正确，这意味着我们需要验证姓和名都是正确的：\n@Test void firstAndLastNameMatches() { Person person = new Person(\u0026#34;John\u0026#34;, \u0026#34;Doe\u0026#34;); assertAll(\u0026#34;person\u0026#34; () -\u0026gt; assertEquals(\u0026#34;John\u0026#34;, person.getFirstName()), () -\u0026gt; assertEquals(\u0026#34;Doe\u0026#34;, person.getLastName()) ); } 如果上述例子执行失败，所有的断言在程序失败并统一反馈错误消息之前都会被执行：\norg.opentest4j.MultipleFailuresError: person (2 failures) expected: \u0026lt;John\u0026gt; but was: \u0026lt;Jane\u0026gt; expected: \u0026lt;Doe\u0026gt; but was: \u0026lt;Woodlawn\u0026gt; 可以看到，程序报告了所有的错误并让错误修复变得更容易。\n单个测试只能有一条原因导致测试失败，我们不应该试图通过在单个测试中验证多个条件来减少测试数量，但在某些场景下，当断言在语义上密切相关时，我们可在单个测试中添加多个断言。\n高级匹配 虽然JUnit 5中的断言足以满足许多测试场景，但有时我们需要更强的选项。例如验证一个列表是否为特定大小、列表是否包含具有特定属性值的元素、列表是否已排序并包含特定的元素等，我们可以自己编写代码逻辑来实现，但更好的方式是断言库替我们实现。\n此时JUnit 5断言是不够的，因此JUnit 5文档建议我们在这种场景下使用第三方断言库，其中最流行的是Hamcrest、AssertJ和Truth。\n我们不准备在此教程中介绍这些库的详细信息，但我们可以快速看一下这些类库中的一些断言方法是如何使用的。\nHamcrest Hamcrest是它们中最古老的一个，在下面的例子中我们想验证一个列表是否只包含一个元素，在JUnit 5中可通过如下方式实现：\n@Test void listHasOneItem() { List\u0026lt;String\u0026gt; list = new ArrayList(); list.add(\u0026#34;Hello\u0026#34;); assertEquals(list.size(), 1); } 这段代码看起来也不是那么差，可以看下Hamcrest的替代方案，可以通过向断言方法传递一个匹配器方法作为参数来编写断言：\n@Test void listHasOneItem() { List\u0026lt;String\u0026gt; list = new ArrayList(); list.add(\u0026#34;Hello\u0026#34;); assertThat(list, hasSize(1)); } 阅读此段代码，看起来更流畅，更接近自然语言，但我们可能会争论说第一个例子的可读性足够好，也许我们还没被说服。\nAssertJ 接下来，我们快速浏览下AssertJ,Hamcrest和AssertJ最主要的区别是Hamcrest依赖于匹配器方法，而在AssertJ中我们可以进行链式方法调用。\n如果我们想知道一个列表是否包含具有特定属性值的元素该怎么办？先只用JUnit 5编写测试代码：\n@Test void listHasPerson() { List\u0026lt;Person\u0026gt; peopleaa = new ArrayList\u0026lt;\u0026gt;(); people.add(new Person(\u0026#34;John\u0026#34;, \u0026#34;Doe\u0026#34;)); people.add(new Person(\u0026#34;Jane\u0026#34;, \u0026#34;Doe\u0026#34;)); assertTrue(people.stream().anyMatch(p -\u0026gt; p.getFirstName().equals(\u0026#34;John\u0026#34;))); } 嗯，看起来不是那么美观，另外，如果我们的测试代码逻辑出现错误怎么办？\n看下使用AssertJ断言是如何实现的：\n@Test void listHasPerson() { List\u0026lt;Person\u0026gt; people = new ArrayList\u0026lt;\u0026gt;(); people.add(new Person(\u0026#34;John\u0026#34;, \u0026#34;Doe\u0026#34;)); people.add(new Person(\u0026#34;Jane\u0026#34;, \u0026#34;Doe\u0026#34;)); assertThat(people).extracting(\u0026#34;firstName\u0026#34;).contains(\u0026#34;John\u0026#34;); } 很容易发现这种方式可读性更好，同时我们也在测试代码中移除了容易出错的代码逻辑。\nTruth 最后，我们来看下Truth,它和AssertJ很像，最显著的差异是Truth试图提供更简单的API，而AssertJ则有一系列更复杂的断言方法。\n看下第三个示例，我们想验证一个列表中是否来排序并且包含特定的元素，下面的代码是用Truth实现的效果：\n@Test void listHasItemsInOrder() { List\u0026lt;String\u0026gt; fruits = new ArrayList\u0026lt;\u0026gt;(); fruits.add(\u0026#34;Citron\u0026#34;); fruits.add(\u0026#34;Orange\u0026#34;); fruits.add(\u0026#34;Grapefruit\u0026#34;); assertThat(fruits).containsExactly(\u0026#34;Citron\u0026#34;, \u0026#34;Grapefruit\u0026#34;, \u0026#34;Orange\u0026#34;).inOrder(); } 再一次，变得更简洁和更容易阅读。\n总结 JUnit 5中的断言方法让预期结果与实际结果的验证变得更容易：\nJUnit 5中的断言是位于org.junit.jupiter.api.Assertions类中的静态方法\n失败的断言会在错误消息中显示预期值和实际值\n为了展示更多断言失败的信息，可在每个断言方法中传递一个自定义错误信息\n利用assertAll()方法可对断言进行分组，先执行里面的断言，然后统一返回错误信息\n对于更复杂的断言，JUnit 5官方文档建议使用第三方断言库，如Hamcrest、AssertJ或Truth\n本文的示例代码能在GitHub中找到。\nassertArrayEquals()不关注元素顺序，而assertIterableEquals()关注元素顺序是否相同。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-05-01T13:37:22+08:00","permalink":"https://lucumt.info/post/translate/junit5/junit-5-assertions/","tags":["junit5","java","junit"],"title":"[译]JUnit 5 断言 - 验证测试结果"},{"categories":["翻译","JUnit5翻译"],"contents":"本文翻译自Getting Started with JUnit 5: Writing Your First Test。\n在本文中，我们将学习如何编写和运行简单的JUnit5单元测试、如何设置前提条件、与我们想测试的对象进行交互，以及验证程序是否按照预期执行。\n本文是JUnit 5 教程的一部分。\n设置 附带的源码示例已经包含基于Maven和Gradle的配置，但为了方便起见，同时也提供了分步教程指南。\n补充阅读\nJUnit5 Maven示例 JUnit5 Gradle示例 编写第一个测试 当我们测试某段代码时，我们希望确保其能够按照预期来运行。在编写自动化测试时基于下述步骤：\n首先，对我们要测试的代码设置前提条件 接下来，对代码进行交互测试 最后，检查执行结果是否符合预期 这被称为Arrange,Act,Assert模式。\n接下来看一下我们想要测试的代码：\npublic class Calculator { public int add(int first, int second) { return first \u0026#43; second; } } 这是一个非常简单的计算器类，主要用于两数相加，在测试此段代码时，我们希望计算结果是正确的。\n我们可基于Arrange,Act,Assert模式按下述步骤实现：\n首先构造一个Calculator类的实例 然后传递调用add()方法并将结果存储起来 最后，通过调用assertEquals()来比较实际结果和预期结果 import org.junit.jupiter.api.Assertions; import org.junit.jupiter.api.Test; class CalculatorTest { @Test void addNumbers() { // Arrange Calculator calculator = new Calculator(); \u0026lt;strong\u0026gt;x\u0026lt;/strong\u0026gt; // Act int sum = calculator.add(1, 2); // Asset Assertions.assertEquals(3, sum); } } 测试类可以用任何名称，但在本文中我们将测试代码放入CalculatorTest类中，我们将测试类简单叫做addNumbers()以便能够描述我们正在尝试做的事情。\n为了能够执行测试，我们需要给测试方法加上@Test注解，通过这种方式测试执行器能将该方法识别为一个测试方法。\n运行测试 我们可以有多种方式运行测试代码，当使用IDE工具时可以从IDE工具中直接运行，我们也可以使用像Maven或Gradle这样的构建工具在命令行中执行测试。\n当软件(代码)按照预期执行时，测试结果为pass,当出现预期之外的结果时，测试结果为failed。\n在 Intellij IDEA中运行 在使用类似Intellij IDEA这类IDE工具时，我们可以直接右键点击测试类并且选择运行CalculatorTest，或者我们可以使用快捷键Ctrl+Shift+F10(Windows系统)和Ctrl+Shift+R(Mac系统)来运行测试。\n下图中可以查看在Intellij IDEA中执行JUnit 5测试通过的结果：\n在Maven中运行 若要使用Maven从命令行运行测试，可执行下述命令：\nmvn test 之后将能看见类似如下的输出：\n[INFO] ------------------------------------------------------- [INFO] T E S T S [INFO] ------------------------------------------------------- [INFO] Running com.arhohuttunen.CalculatorTest [INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.021 s - in com.arhohuttunen.CalculatorTest [INFO] [INFO] Results: [INFO] [INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0 [INFO] [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ 在Gradle中运行 若要使用Gradle从命令行运行测试，可执行下述命令：\ngradle test 之后将能看见类似如下输出:\n\u0026gt; Task :test com.arhohuttunen.CalculatorTest \u0026gt; addNumbers() PASSED BUILD SUCCESSFUL in 0s 总结 在这个JUnit 5入门示例中，我们学习了如何编写和运行简单的JUnit 5测试，本文的示例代码能在GitHub中找到。\n","date":"2023-05-01T09:51:22+08:00","permalink":"https://lucumt.info/post/translate/junit5/junit-5-getting-started/","tags":["junit5","java","junit"],"title":"[译]JUnit 5 入门 - 编写第一段测试代码"},{"categories":["持续集成"],"contents":"我司从2022年6月开始使用KubeSphere到目前为止快一年时间，简要记录下此过程中的经验积累和问题反馈。\n背景 公司当前有接近3000人的规模，主要业务为汽车配套相关的软硬件开发，其中专门从事软件开发约有800人，这其中Java开发的约占70%，余下的为C/C++嵌入式和C#桌面程序的开发。\n在Java开发部分约80%的都是Java EE开发，由于公司的业务主要是给外部客户提供软硬件产品和咨询服务，在早期公司和部门更关注的是如何将产品销售给更多的客户、获得更多的订单和尽快回款，对软件开发流程这块没有过多的重视，故早期在软件开发部分不是特别规范化。软件开发基于项目主要采用敏捷开发或瀑布模型，而对于软件部署和运维依旧采用的纯手工方式(PS:请不要鄙视我司!)\n随着公司规模的扩大与软件产品线的增多，上述方式逐渐暴露出一些问题：\n存在大量重复性工作，在软件快速迭代时，需要频繁的手工编译部署，耗费时间，且此过程缺乏日志记录，后续无法追踪审计 缺乏审核功能，对于测试环境和生产环境的操作需要审批流程，之前通过邮件和企业微信无法串联 缺乏准入功能，随着团队规模扩大，人员素质参差不齐，需要对软件开发流程、代码风格都需要强制固化 缺乏监控功能，后续不同团队、项目采用的监控方案不统一，不利于知识的积累 不同客户的定制化功能太多(logo,字体，ip地址，业务逻辑等)，采用手工打包的方式效率低，容易遗漏出错 在竞争日益激烈的市场环境下，公司需要把有限的人力资源优先用于业务迭代开发，解决上述问题变得愈发迫切。\n选型说明 基于前述原因，部门准备选用网络上开源的系统来尽可能的解决上述痛点，在技术选型时有如下考量点：\n采用尽量少的系统，最好一套系统能解决前述所有问题，避免多个系统维护和整合的成本 采用开源版本，避免公司内部手工开发，节约人力 安装过程简洁，不需要复杂的操作，能支持离线安装 文档丰富、社区活跃、使用人员较多，遇到问题能较容易的找到答案 支持容器化部署，公司和部门的业务中自动驾驶和云仿真相关的越来越多，此部分对算力和资源提出了更高的要求 最开始采用的是Jenkins，通过Jenkins基本上能解决我们90%的问题，但依旧有如下问题影使用体验:\n对于云原生支持不太好，不利于部门后续云仿真相关的业务使用 UI界面简陋，交互方式不友好(项目构建日志输出等) 对于项目，资源的权限分配与隔离过于简陋，不满足多项目多部门使用时细粒度的区分要求 在网络上查找后发现类似的工具有很多，经过初步对比筛选后倾向于KubeSphere，Zadig这2款产品，它们的基本功能都类似，进一步对比如下：\nKubeSphere Zadig 云原生支持 高 一般 UI美观度 高 一般 GitHub Star 12.4k 2k 社区活跃度 高 一般 知名使用客户 去哪儿网、农行、移动 飞书、腾讯、华为 KubeSphere在多个指标上优于Zadig，尤其是KubeSphere的UI界面十分美观比Zadig强很多，故最终选定KubeSphere作为部门内部的持续集成与容器化管理系统！\n至此，部门内部经历了手工操作-\u0026gt;Jenkins-\u0026gt;KubeSphere这3个阶段，各阶段的主要使用点如下：\n实践过程 KubeSphere在公司内部的整体部署架构如下图所示，其作为最顶层的应用程序直接与使用人员交互，提供主动 /定时触发构建、应用监控等功能，使用人员不必关心底层的Jenkins、Kubernetes等依赖组件，只需要与Gitlab和KubeSphere交互即可。\n持续集成 初始实现 在最初的尝试阶段只规划了4套环境:dev(开发环境)、sit(调试环境)、test(测试环境)、prod(生产环境)。\n出于简化使用与维护的考虑，计划对每个工程模块只维护一条流水线，通过构建时选择不同的环境参数来实现定制化打包与部署。\nKubeSphere和Kubernetes目前在部门是以单机版形式安装的，故对于不同环境的区分主要是通过分配不同端口来实现，具体实现时需要能在Jenkins和Kubernetes的yaml文件中都能动态的获取对应的端口参数和项目名称，参考实现代码如下：\n在基于Groovy的script中根据选择环境动态分配相关端口\nswitch(PRODUCT_PHASE) { case \u0026#34;sit\u0026#34;: env.NODE_PORT = 13003 env.DUBBO_PORT = 13903 break case \u0026#34;test\u0026#34;: env.NODE_PORT = 14003 env.DUBBO_PORT = 14903 break case \u0026#34;prod\u0026#34;: env.NODE_PORT = 15003 env.DUBBO_PORT = 15903 break } script中读取参数\nprint env.DUBBO_IP shell中读取参数\ndocker build -f kubesphere/Dockerfile \\ -t idp-data:$BUILD_TAG \\ --build-arg PROJECT_VERSION=$PROJECT_VERSION \\ --build-arg NODE_PORT=$NODE_PORT \\ --build-arg DUBBO_PORT=$DUBBO_PORT \\ --build-arg PRODUCT_PHASE=$PRODUCT_PHASE . yaml文件中读取参数\nspec: ports: - name: http port: $NODE_PORT protocol: TCP targetPort: $NODE_PORT nodePort: $NODE_PORT - name: dubbo port: $DUBBO_PORT protocol: TCP targetPort: $DUBBO_PORT nodePort: $DUBBO_PORT selector: app: lucumt-data-$PRODUCT_PHASE sessionAffinity: None type: NodePort 运行效果类似下图\n详细内容请参见KubeSphere使用心得。\n环境扩容 基于前述方式搭建的4套环境一开始使用较为顺利，但随着项目的推进以及开发人员的增多，同时有多个功能模块需要并行开发与测试，导致原有的4套环境不够用。经过一番摸索后，实现了结合Nacos在KubeSphere中动态配置多套环境功能，通过修改Nacos中的JSON配置文件可很容易的从4套扩展为16套甚至更多。\n结合项目实际情况以及避免后续再次修改KubeSphere流水线，为了实现灵活的配置多套环境，制定了如下2个规则：\n端口信息存放到配置文件中，KubeSphere在构建时去流水线读取相关配置 当需要扩展环境或修改端口时，不需要修改KubeSphere中的流水线，只需要修改对应的端口配置文件即可 由于项目中采用Nacos作为配置中心与服务管理平台，故决定采用Nacos作为端口的配置中心，实现流程如下：\n基于上述流程，在具体实现时面临如下问题：\n利用Groovy代码获取Nacos中特定的端口JSON配置文件，并能动态解析 利用Groovy代码根据输入输入参数动态的获取Nacos中对应的namespace 由于环境的增多，不可能每套环境都准备一个YAML文件，此时需要动态的读取并更新YAML文件 由于Jenkins默认不支持JSON、YAML的解析，需要在Jenkins中预先安装Pipeline Utility Steps插件，该插件提供了对JSON、YAML、CSV、PROPERTIES等常见文件格式的读取与修改操作。\nJSON文件设计如下，通过env、server、dubbo等属性记录环境和端口信息，通过project来记录具体的项目名称，由于配置文件中的key都是固定的，后续Groovy解析时会较为方便，在需要扩展环境时只需要更新此JSON文件即可。\n{ \u0026#34;portConfig\u0026#34;:[ { \u0026#34;project\u0026#34;:\u0026#34;lucumt-system\u0026#34;, \u0026#34;ports\u0026#34;:[ { \u0026#34;env\u0026#34;:\u0026#34;dev-1\u0026#34;, \u0026#34;server\u0026#34;:12001, \u0026#34;dubbo\u0026#34;:12002 }, { \u0026#34;env\u0026#34;:\u0026#34;dev-2\u0026#34;, \u0026#34;server\u0026#34;:12201, \u0026#34;dubbo\u0026#34;:12202 } ] }, { \u0026#34;project\u0026#34;:\u0026#34;lucumt-idp\u0026#34;, \u0026#34;ports\u0026#34;:[ { \u0026#34;env\u0026#34;:\u0026#34;dev-1\u0026#34;, \u0026#34;server\u0026#34;:13001, \u0026#34;dubbo\u0026#34;:13002 }, { \u0026#34;env\u0026#34;:\u0026#34;dev-2\u0026#34;, \u0026#34;server\u0026#34;:13201, \u0026#34;dubbo\u0026#34;:13202 } ] } ] } Nacos Open Api中可知查询namespace的请求为/nacos/v1/console/namespaces，查询配置文件的请求为/nacos/v1/cs/configs，基于Groovy的读取代码如下：\nresponse = sh(script: \u0026#34;curl -X GET \u0026#39;http://xxx.xxx.xxx.xxx:8848/nacos/v1/console/namespaces\u0026#39;\u0026#34;, returnStdout: true) jsonData = readJSON text: response namespaces = jsonData.data for(nm in namespaces){ if(BUILD_TYPE==nm.namespaceShowName){ NACOS_NAMESPACE = nm.namespace } } response = sh(script: \u0026#34;curl -X GET \u0026#39;http://xxx.xxx.xxx.xxx:8848/nacos/v1/cs/configs?dataId=idp-custom-config.json\u0026amp;group=idp-custom-config\u0026amp;tenant=0f894ca6-4231-43dd-b9f3-960c02ad20fa\u0026#39;\u0026#34;, returnStdout: true) jsonData = readJSON text: response configs = jsonData.portConfig for(config in configs){ project = config.project if(project!=PROJECT_NAME){ continue } ports = config.ports for(port in ports){ if(port.env!=BUILD_TYPE){ continue } env.NODE_PORT = port.server } } 动态更新yaml文件\nyamlFile = \u0026#39;src/main/resources/bootstrap-dev.yml\u0026#39; yamlData = readYaml file: yamlFile yamlData.spring.cloud.nacos.discovery.group = BUILD_TYPE yamlData.spring.cloud.nacos.discovery.namespace = NACOS_NAMESPACE yamlData.spring.cloud.nacos.config.namespace = NACOS_NAMESPACE sh \u0026#34;rm $yamlFile\u0026#34; writeYaml file: yamlFile, data: yamlData 详细内容请参见利用Nacos与KubeSphere创建多套开发与测试环境。\n扩展功能 在项目构建时添加审核功能，对于test和prod环境必须经过相关人的审核才能进行后续构建流程，避免破坏相关版本的稳定性\n在KubeSphere的容器组页面可以查看pod节点的CPU和内存消耗，可初步满足对代码潜在性能问题的排查\n在项目构建完成时发送邮件通知给相关人\n外部部署 部门内部的软件最终都会销售并交付给相关客户，由于客户网络与公司网络不通以及代码保密等要求，无法在客户现场使用原有的Jenkins流水线进行部署交付。基于此部门采取折中方案：在公司内部通过KubeSphere进行编译打包，导出docker镜像，拷贝到客户处然后基于docker镜像部署运行,具体请参见如下链接:\n在Jenkins中根据配置从不同的仓库中Checkout代码 利用shell脚本实现将微服务程序以docker容器方式自动部署 使用协助 在使用过程中确实遇到了不少问题，主要通过如下三条途径解决:\n阅读官方文档，根据文档说明操作 若官网文档没有，则去用户论坛查看是否有人遇到类似问题或直接发帖 通过微信群寻求协助 根据部门使用经验，90%的问题可通过官方文档或用户论坛获得答案。\n使用效果 部分同事习惯于原始的手工操作或基于docker部署，导致在推广过程中受到了一定的阻力，部门内部基于充分沟通和逐步替换的方式引导相关同事来慢慢适应。经过约一年的时间磨合，大家都认可了拥抱云原生和KubeSphere给我们带来的便利，使用过的同事都说很香!\n对我司而言，有如下几个方面的提升:\n研发人员几乎不用耗费时间在软件的部署和监控上，节省约20%时间，产品迭代速度更快 定制化的功能通过脚本实现，彻底杜绝了给客户交付软件时由于人工疏漏导致的偶发问题，在提高软件交付质量的同时也提升了客户我司的认可度 软件开发、测试流程更规范，通过在Jenkins流水线强制添加各种规范检查和审核流程，实现了软件研发的规范统一，代码质量更高，更利于扩展维护，同时也在一定程序上减少了由于人员流失/变更对项目造成的影响 基于KubeSphere的云原生部署结合Nacos可以更快速的分配多套环境，有效的实现了开发、测试、生产环境的隔离，在云仿真相关的业务场景中可基于业务场景更方便的对pod进行监控与调整，前瞻性的业务研发开展更顺利 规划 结合公司与部门的实际情况，短期的规划依然是完善基于Jenkins的CI/CD使用来完善打包与部署流程，部门内部在进行全面web化，基于此中长期拥抱云原生。\n接入企业微信，将构建与运行结果随时通知相关人，构建结果与项目监控更实时 将部门内部基于Eclipse RCP的桌面应用程序通过Jenkins实现标准化与自动化的构建 将底层的Kubernetes从单机升级为集群，支持更多pod的部署，支持公司内部需要大量pod并发运行的云仿真项目 部门内部的web项目全部通过KubeSphere构建部署，完善其使用文档，挖掘KubeSphere在部门业务中新的应用场景(如对设计文档、开发文档、bug修复的定时与强制检查通知等) 参考文章 KubeSphere使用心得 Kubesphere集成LDAP踩坑记录 利用Nacos与KubeSphere创建多套开发与测试环境 在Jenkins中根据配置从不同的仓库中Checkout代码 由于k8s中的错误配置导致无法创建新节点 ","date":"2023-04-17T14:31:45+08:00","permalink":"https://lucumt.info/post/devops/share-kubepshere-using-experience-for-current-company/","tags":["kubesphere","kubernetes","docker","jenkins","nacos","shell"],"title":"KubeSphere在当前公司提升研发效率的使用实践分享"},{"categories":["工具使用","系统集成"],"contents":"简要记录如何基于docker创建Gitlab并集成ldap1且仅允许LDAP账号登录。\n安装步骤 创建一个名为gitlab_test的文件夹，之后创建一个名为docker-compose.yml的文件，写入如下内容\nversion: \u0026#34;3\u0026#34; services: nacos: image: gitlab/gitlab-ce restart: always container_name: gitlab_custom ports: - 3555:80 environment: - TZ=Asia/Shanghai volumes: - $PWD/etc:/etc/gitlab - $PWD/log:/var/log/gitlab - $PWD/opt:/var/opt/gitlab 运行docker-compose up -d命令，结合服务器性能以及网络环境等因素，gitlab需要2-3分钟才能完成启动成功，之后在当前目录下会自动创建相关的挂载目录同时写入相关映射文件\n输入http://IP地址:3555可正常显示登录页面\n在终端运行docker exec -it gitlab_custom cat /etc/gitlab/initial_root_password会显示root账号的初始密码，可利用改密码登录系统然后修改成更易于记忆的密码\n在终端运行vim etc/gitlab.rb添加如下图所示的LDAP相关配置\n在终端运行docker exec -it gitlab_custom /bin/bash gitlab-ctl reconfigure来更新gitlab配置\n在终端运行docker exec -it gitlab_custom /bin/bash gitlab-rake gitlab:ldap:check，若出现类似如下结果则表示LDAP配置正常，可用单点账号登录\n重新登录gitlab时可发现其已经支持LDAP，至此集成LDAP的工作初步完成。\n添加额外的管理员 gitlab默认只有root这1个admin账号，当禁止非LDAP方式登录时会将root账号的登录一并禁止掉，故需要预先将一些LDAP账户设置为管理员账号，操作过程如下：\n在终端运行docker exec -it gitlab_custom /bin/bash gitlab-rails console进入ruby的交互式界面\n在控制台中依次执行如下命令\nuser = User.find_by(username: \u0026#39;yunqiang.lu\u0026#39;) user.admin = true user.save! exit 在终端重新执行docker exec -it gitlab_custom /bin/bash gitlab-ctl reconfigure\n采用前述过程中配置的账号登录gitlab，若在左上角的Menu菜单下出现Admin子菜单则表示管理员账号添加成功!\n只允许LDAP登录 主要参考How to disable standard authentication进行操作：\n以管理员账号登录gitlab，依次点击Admin-\u0026gt;Settings-\u0026gt;General\n在Sign-up restrictions下取消勾选sign-up enabled\n在Sign in restrictions下取消勾选Sign in restrictions\n测试之后重新打开gitlab登录页面，可发现其支持LDAP登录，至此全部过程操作完成!\n采用的是gitlab-ce而非gitlab-ee\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-04-14T11:22:34+08:00","permalink":"https://lucumt.info/post/ldap/add-ldap-support-for-gitlab/","tags":["ldap","docker"],"title":"给Gitlab添加LDAP登录认证"},{"categories":["python编程"],"contents":"简要介绍如何在基于Flask开发的程序中通过Nacos提供的nacos-sdk-python实现在Python程序中整合Nacos。\n完整代码在python-nacos-demo\n注册Nacos 官网文档的说明如下\n从中可看出只有service_name、ip与port 是必填项，而我们在实际使用中经常需要通过group进行区分，上述文档中并没有相关说明，翻看其源码发现add_naming_instance的方法签名如下，其中包含group相关信息，文档没有与源码保持一致，必须吐槽下Nacos官方！\ndef add_naming_instance(self, service_name, ip, port, cluster_name=None, weight=1.0, metadata=None, enable=True, healthy=True, ephemeral=True,group_name=DEFAULT_GROUP_NAME): 同时可发现要注册实例，必须先获得一个NacosClient对象之后才能进行对应操作，基于官方文档的实现如下：\nclient = nacos.NacosClient(server_address, namespace=namespace) client.add_naming_instance(service_name, service_address, port, group_name=group_name) 由于对Nacos的各种操作都涉及到NacosClient，故可将其定义为一个全局变量，后续在其它地方可直接使用\nglobal NACOS_CLIENT NACOS_CLIENT = nacos.NacosClient(server_address, namespace=namespace) NACOS_CLIENT.add_naming_instance(service_name, service_address, port, group_name=group_name) 程序启动后监听 安装完成后可在Nacos页面的服务菜单中看见对应的实例，但经过十几秒后该实例会显示为如下图所示的不健康状态，之后会自动从Nacos服务列表中移除掉：\n造成此现象的原因为nacos-sdk-python没有提供自动发送心跳的机制，需要自己实现代码来持续不断地发送心跳请求以维持健康状态，可通过异步线程的方式实现，相关代码如下：\nNACOS_SERVER = None NACOS_SERVICE = None NACOS_CLIENT = None logger = log.get_logger(__name__) def register_nacos(yml_data): # 服务器配置 port = yml_data[\u0026#39;nacos\u0026#39;][\u0026#39;server_port\u0026#39;] server_address = yml_data[\u0026#39;nacos\u0026#39;][\u0026#39;server_address\u0026#39;] global NACOS_SERVER NACOS_SERVER = NacosServer(port, server_address) # 调用方配置 namespace = yml_data[\u0026#39;nacos\u0026#39;][\u0026#39;namespace\u0026#39;] service_address = yml_data[\u0026#39;nacos\u0026#39;][\u0026#39;service_address\u0026#39;] service_port = yml_data[\u0026#39;nacos\u0026#39;][\u0026#39;service_port\u0026#39;] service_name = yml_data[\u0026#39;nacos\u0026#39;][\u0026#39;service_name\u0026#39;] group_name = yml_data[\u0026#39;nacos\u0026#39;][\u0026#39;group_name\u0026#39;] global NACOS_SERVICE NACOS_SERVICE = NacosService(namespace, group_name, service_name, service_address, service_port) global NACOS_CLIENT NACOS_CLIENT = nacos.NacosClient(server_address, namespace=namespace) NACOS_CLIENT.add_naming_instance(service_name, service_address, service_port, group_name=group_name) logger.info(\u0026#34;=========register nacos success===========\u0026#34;) thread = threading.Thread(target=send_heartbeat, name=\u0026#34;send_heartbeat_threads\u0026#34;, args=(NACOS_CLIENT, service_name, service_address, service_port, group_name), daemon=True) thread.start() def send_heartbeat(client, service_name, ip, port, group_name): while True: client.send_heartbeat(service_name, ip, port, group_name=group_name) time.sleep(5) 读取配置 在Java中通过引入spring-cloud-starter-alibaba-nacos-discovery依赖可直接解析相关的配置文件，非常方便，而在Python中相对没这么简洁，其使用方法如下\n使用代码类似如下\nconfig = NACOS_CLIENT.get_config(data_id, group, no_snapshot=True) 其返回值是一个dictionary对象，获取之后可根据实际情况做进一步处理\n日志系统启用 在How do I obtain logs from a Nacos client中有如下信息说明Nacos中的日志与logging模块保持一致，只需要通过logging开启日志即可。\nA Python Nacos client uses the logging module of Python, which is consistent with the logging module of your application. Logs of a Python Nacos client are displayed in application logs.\n可在app.py程序的头部添加类似如下代码即可开启Nacos日志\nlogger = logging.getLogger(name) logger.setLevel(logging.INFO) 开启后显示效果类似如下\n调用其它程序 在Spring中可通过OpenFeign或Dubbo来调用注册到Nacos中的服务接口，由于Python与Java是两套不同的体系，在Python只能通过Requests模块直接发送对应的HTTP请求实现，类似如下代码：\nurl = \u0026#39;http://127.0.0.1:8081/user/queryAll\u0026#39; response = requests.get(url).text print(response) 在上述代码中，url地址中的ip和port以硬编码的形式指定，实际使用环境的ip和port会动态变化，显然此种方式使用起来不灵活。结合Nacos本身的特性，可先通过服务名称获取对应的服务实例信息，则其中解析出ip和port，之后发送请求，从而消除动态配置。\n获取实例 获取实例的方法说明如下\n相关调用代码类似如下:\nnamespace = NACOS_SERVICE.namespace group_name = NACOS_SERVICE.group_name instances = NACOS_CLIENT.list_naming_instance(service_name, namespace_id=namespace,group_name=group_name,healthy_only=True) 执行后的结果类似如下，可通过在hosts中找到对应的ip和port为调用做准备\n调用接口 获取到ip和port之后，接下来就是正常的发送HTTP请求，此时已经和Nacos没有关系\ninstances = get_instance(service) ip = instances[\u0026#39;hosts\u0026#39;][0][\u0026#39;ip\u0026#39;] port = instances[\u0026#39;hosts\u0026#39;][0][\u0026#39;port\u0026#39;] url = \u0026#34;http://\u0026#34; \u0026#43; ip \u0026#43; \u0026#34;:\u0026#34; \u0026#43; str(port) \u0026#43; \u0026#34;/\u0026#34; \u0026#43; method response = requests.get(url).text print(response) ","date":"2023-04-11T09:25:53+08:00","permalink":"https://lucumt.info/post/nacos/integrate-python-program-to-nacos/","tags":["nacos","python"],"title":"在Python程序中使用Nacos"},{"categories":["个人博客","系统集成"],"contents":"基于在Hugo中开启图表支持一文，简要说明如何在Hugo中基于Markdown以优雅的方式集成Highcharts。\n修改过程 在assets/sass/_custom_custom.scss中添加如下代码\n.highcharts { border: 1px dashed #c9c9c9; } 在layouts/_default/_markup创建文件render-codeblock-highcharts.html并添加如下代码\n\u0026lt;div id=\u0026#34;highcharts_{{ .Ordinal }}\u0026#34; class=\u0026#34;highcharts\u0026#34;\u0026gt; {{- .Inner }} \u0026lt;/div\u0026gt; 在layouts/partials/scripts.html补充原有的代码，添加上初始化功能\n\u0026lt;!-- highcharts js --\u0026gt; {{- if and (or .Params.highchartsDiagrams.enable (and .Site.Params.highchartsDiagrams.enable (ne .Params.highchartsDiagrams.enable false))) (or .IsPage .IsHome) -}} \u0026lt;script src=\u0026#34;https://code.highcharts.com/highcharts.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://code.highcharts.com/highcharts-more.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://code.highcharts.com/highcharts-3d.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://code.highcharts.com/modules/heatmap.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://code.highcharts.com/modules/tilemap.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://code.highcharts.com/modules/sankey.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- depends on your requirements,needs to add more extra js file --\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; document.addEventListener(\u0026#39;DOMContentLoaded\u0026#39;, initHighcharts); function initHighcharts(){ let highchartsPageOptions = {{ .Page.Params.highchartsDiagrams.options }}; let highchartsSiteOptions = {{ .Site.Params.highchartsDiagrams.options }}; highchartsPageOptions = !!highchartsPageOptions ? highchartsPageOptions : \u0026#34;{}\u0026#34; highchartsSiteOptions = !!highchartsSiteOptions ? highchartsSiteOptions : \u0026#34;{}\u0026#34; highchartsPageOptions = eval(\u0026#34;(\u0026#34; \u0026#43; highchartsPageOptions \u0026#43; \u0026#34;)\u0026#34;) highchartsSiteOptions = eval(\u0026#34;(\u0026#34; \u0026#43; highchartsSiteOptions \u0026#43; \u0026#34;)\u0026#34;) // page options have high priority then site options let highchartsOptions = {...highchartsSiteOptions, ...highchartsPageOptions}; let highchartsConfigs = document.querySelectorAll(\u0026#34;[id^=highcharts_]\u0026#34;); console.log(highchartsOptions) for(config of highchartsConfigs){ let chartData = eval(\u0026#34;(\u0026#34; \u0026#43; config.innerText \u0026#43; \u0026#34;)\u0026#34;); chartData = {...highchartsOptions,...chartData} Highcharts.chart(config.id,chartData); } } \u0026lt;/script\u0026gt; {{- end }} 在对应的markdown页面头部开启highcharts的展示，可根据实际情况添加自定义配置\nhighchartsDiagrams: enable: true options: \u0026#34; { subtitle: { style: { color: \u0026#39;red\u0026#39; } } } \u0026#34; 仿照如下的代码，将Highcharts的代码块以JavaScript对象的形式加入特定Markdown代码标签中，注意 JavaScript代码中不要加入任何注释，否则会导致程序解析出错!\n​```highcharts { chart: { plotBackgroundColor: null, plotBorderWidth: null, plotShadow: false, type: \u0026#39;pie\u0026#39; }, title: { text: \u0026#39;Browser market shares in May, 2020\u0026#39;, align: \u0026#39;left\u0026#39; }, tooltip: { pointFormat: \u0026#39;{series.name}: \u0026lt;b\u0026gt;{point.percentage:.1f}%\u0026lt;/b\u0026gt;\u0026#39; }, accessibility: { point: { valueSuffix: \u0026#39;%\u0026#39; } }, plotOptions: { pie: { allowPointSelect: true, cursor: \u0026#39;pointer\u0026#39;, dataLabels: { enabled: true, format: \u0026#39;\u0026lt;b\u0026gt;{point.name}\u0026lt;/b\u0026gt;: {point.percentage:.1f} %\u0026#39; } } }, series: [{ name: \u0026#39;Brands\u0026#39;, colorByPoint: true, data: [{ name: \u0026#39;Chrome\u0026#39;, y: 70.67, sliced: true, selected: true }, { name: \u0026#39;Edge\u0026#39;, y: 14.77 }, { name: \u0026#39;Firefox\u0026#39;, y: 4.86 }, { name: \u0026#39;Safari\u0026#39;, y: 2.63 }, { name: \u0026#39;Internet Explorer\u0026#39;, y: 1.53 }, { name: \u0026#39;Opera\u0026#39;, y: 1.40 }, { name: \u0026#39;Sogou Explorer\u0026#39;, y: 0.84 }, { name: \u0026#39;QQ\u0026#39;, y: 0.51 }, { name: \u0026#39;Other\u0026#39;, y: 2.6 }] }] } ​``` 让Hugo重新选然后即可展示出类似如下效果\n{ chart: { plotBackgroundColor: null, plotBorderWidth: null, plotShadow: false, type: \u0026#39;pie\u0026#39; }, title: { text: \u0026#39;Browser market shares in May, 2020\u0026#39;, align: \u0026#39;left\u0026#39; }, tooltip: { pointFormat: \u0026#39;{series.name}: \u0026lt;b\u0026gt;{point.percentage:.1f}%\u0026lt;/b\u0026gt;\u0026#39; }, accessibility: { point: { valueSuffix: \u0026#39;%\u0026#39; } }, plotOptions: { pie: { allowPointSelect: true, cursor: \u0026#39;pointer\u0026#39;, dataLabels: { enabled: true, format: \u0026#39;\u0026lt;b\u0026gt;{point.name}\u0026lt;/b\u0026gt;: {point.percentage:.1f} %\u0026#39; } } }, series: [{ name: \u0026#39;Brands\u0026#39;, colorByPoint: true, data: [{ name: \u0026#39;Chrome\u0026#39;, y: 70.67, sliced: true, selected: true }, { name: \u0026#39;Edge\u0026#39;, y: 14.77 }, { name: \u0026#39;Firefox\u0026#39;, y: 4.86 }, { name: \u0026#39;Safari\u0026#39;, y: 2.63 }, { name: \u0026#39;Internet Explorer\u0026#39;, y: 1.53 }, { name: \u0026#39;Opera\u0026#39;, y: 1.40 }, { name: \u0026#39;Sogou Explorer\u0026#39;, y: 0.84 }, { name: \u0026#39;QQ\u0026#39;, y: 0.51 }, { name: \u0026#39;Other\u0026#39;, y: 2.6 }] }] } 展示效果 处于篇幅考虑，在展示部分只展示最终效果，原始代码请参见enable-highcharts-in-hugo.md\n图1-Bubble chart { chart: { type: \u0026#39;bubble\u0026#39;, plotBorderWidth: 1, zoomType: \u0026#39;xy\u0026#39; }, legend: { enabled: false }, title: { text: \u0026#39;Sugar and fat intake per country\u0026#39; }, subtitle: { text: \u0026#39;Source: \u0026lt;a href=\u0026#34;http://www.euromonitor.com/\u0026#34;\u0026gt;Euromonitor\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://data.oecd.org/\u0026#34;\u0026gt;OECD\u0026lt;/a\u0026gt;\u0026#39; }, accessibility: { point: { valueDescriptionFormat: \u0026#39;{index}. {point.name}, fat: {point.x}g, sugar: {point.y}g, obesity: {point.z}%.\u0026#39; } }, xAxis: { gridLineWidth: 1, title: { text: \u0026#39;Daily fat intake\u0026#39; }, labels: { format: \u0026#39;{value} gr\u0026#39; }, plotLines: [{ color: \u0026#39;black\u0026#39;, dashStyle: \u0026#39;dot\u0026#39;, width: 2, value: 65, label: { rotation: 0, y: 15, style: { fontStyle: \u0026#39;italic\u0026#39; }, text: \u0026#39;Safe fat intake 65g/day\u0026#39; }, zIndex: 3 }], accessibility: { rangeDescription: \u0026#39;Range: 60 to 100 grams.\u0026#39; } }, yAxis: { startOnTick: false, endOnTick: false, title: { text: \u0026#39;Daily sugar intake\u0026#39; }, labels: { format: \u0026#39;{value} gr\u0026#39; }, maxPadding: 0.2, plotLines: [{ color: \u0026#39;black\u0026#39;, dashStyle: \u0026#39;dot\u0026#39;, width: 2, value: 50, label: { align: \u0026#39;right\u0026#39;, style: { fontStyle: \u0026#39;italic\u0026#39; }, text: \u0026#39;Safe sugar intake 50g/day\u0026#39;, x: -10 }, zIndex: 3 }], accessibility: { rangeDescription: \u0026#39;Range: 0 to 160 grams.\u0026#39; } }, tooltip: { useHTML: true, headerFormat: \u0026#39;\u0026lt;table\u0026gt;\u0026#39;, pointFormat: \u0026#39;\u0026lt;tr\u0026gt;\u0026lt;th colspan=\u0026#34;2\u0026#34;\u0026gt;\u0026lt;h3\u0026gt;{point.country}\u0026lt;/h3\u0026gt;\u0026lt;/th\u0026gt;\u0026lt;/tr\u0026gt;\u0026#39; \u0026#43; \u0026#39;\u0026lt;tr\u0026gt;\u0026lt;th\u0026gt;Fat intake:\u0026lt;/th\u0026gt;\u0026lt;td\u0026gt;{point.x}g\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026#39; \u0026#43; \u0026#39;\u0026lt;tr\u0026gt;\u0026lt;th\u0026gt;Sugar intake:\u0026lt;/th\u0026gt;\u0026lt;td\u0026gt;{point.y}g\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026#39; \u0026#43; \u0026#39;\u0026lt;tr\u0026gt;\u0026lt;th\u0026gt;Obesity (adults):\u0026lt;/th\u0026gt;\u0026lt;td\u0026gt;{point.z}%\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026#39;, footerFormat: \u0026#39;\u0026lt;/table\u0026gt;\u0026#39;, followPointer: true }, plotOptions: { series: { dataLabels: { enabled: true, format: \u0026#39;{point.name}\u0026#39; } } }, series: [{ data: [ { x: 95, y: 95, z: 13.8, name: \u0026#39;BE\u0026#39;, country: \u0026#39;Belgium\u0026#39; }, { x: 86.5, y: 102.9, z: 14.7, name: \u0026#39;DE\u0026#39;, country: \u0026#39;Germany\u0026#39; }, { x: 80.8, y: 91.5, z: 15.8, name: \u0026#39;FI\u0026#39;, country: \u0026#39;Finland\u0026#39; }, { x: 80.4, y: 102.5, z: 12, name: \u0026#39;NL\u0026#39;, country: \u0026#39;Netherlands\u0026#39; }, { x: 80.3, y: 86.1, z: 11.8, name: \u0026#39;SE\u0026#39;, country: \u0026#39;Sweden\u0026#39; }, { x: 78.4, y: 70.1, z: 16.6, name: \u0026#39;ES\u0026#39;, country: \u0026#39;Spain\u0026#39; }, { x: 74.2, y: 68.5, z: 14.5, name: \u0026#39;FR\u0026#39;, country: \u0026#39;France\u0026#39; }, { x: 73.5, y: 83.1, z: 10, name: \u0026#39;NO\u0026#39;, country: \u0026#39;Norway\u0026#39; }, { x: 71, y: 93.2, z: 24.7, name: \u0026#39;UK\u0026#39;, country: \u0026#39;United Kingdom\u0026#39; }, { x: 69.2, y: 57.6, z: 10.4, name: \u0026#39;IT\u0026#39;, country: \u0026#39;Italy\u0026#39; }, { x: 68.6, y: 20, z: 16, name: \u0026#39;RU\u0026#39;, country: \u0026#39;Russia\u0026#39; }, { x: 65.5, y: 126.4, z: 35.3, name: \u0026#39;US\u0026#39;, country: \u0026#39;United States\u0026#39; }, { x: 65.4, y: 50.8, z: 28.5, name: \u0026#39;HU\u0026#39;, country: \u0026#39;Hungary\u0026#39; }, { x: 63.4, y: 51.8, z: 15.4, name: \u0026#39;PT\u0026#39;, country: \u0026#39;Portugal\u0026#39; }, { x: 64, y: 82.9, z: 31.3, name: \u0026#39;NZ\u0026#39;, country: \u0026#39;New Zealand\u0026#39; } ], colorByPoint: true }] } 图2-Basic column { chart: { type: \u0026#39;column\u0026#39; }, title: { text: \u0026#39;Monthly Average Rainfall\u0026#39; }, subtitle: { text: \u0026#39;Source: WorldClimate.com\u0026#39; }, xAxis: { categories: [ \u0026#39;Jan\u0026#39;, \u0026#39;Feb\u0026#39;, \u0026#39;Mar\u0026#39;, \u0026#39;Apr\u0026#39;, \u0026#39;May\u0026#39;, \u0026#39;Jun\u0026#39;, \u0026#39;Jul\u0026#39;, \u0026#39;Aug\u0026#39;, \u0026#39;Sep\u0026#39;, \u0026#39;Oct\u0026#39;, \u0026#39;Nov\u0026#39;, \u0026#39;Dec\u0026#39; ], crosshair: true }, yAxis: { min: 0, title: { text: \u0026#39;Rainfall (mm)\u0026#39; } }, tooltip: { headerFormat: \u0026#39;\u0026lt;span style=\u0026#34;font-size:10px\u0026#34;\u0026gt;{point.key}\u0026lt;/span\u0026gt;\u0026lt;table\u0026gt;\u0026#39;, pointFormat: \u0026#39;\u0026lt;tr\u0026gt;\u0026lt;td style=\u0026#34;color:{series.color};padding:0\u0026#34;\u0026gt;{series.name}: \u0026lt;/td\u0026gt;\u0026#39; \u0026#43; \u0026#39;\u0026lt;td style=\u0026#34;padding:0\u0026#34;\u0026gt;\u0026lt;b\u0026gt;{point.y:.1f} mm\u0026lt;/b\u0026gt;\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026#39;, footerFormat: \u0026#39;\u0026lt;/table\u0026gt;\u0026#39;, shared: true, useHTML: true }, plotOptions: { column: { pointPadding: 0.2, borderWidth: 0 } }, series: [{ name: \u0026#39;Tokyo\u0026#39;, data: [49.9, 71.5, 106.4, 129.2, 144.0, 176.0, 135.6, 148.5, 216.4, 194.1, 95.6, 54.4] }, { name: \u0026#39;New York\u0026#39;, data: [83.6, 78.8, 98.5, 93.4, 106.0, 84.5, 105.0, 104.3, 91.2, 83.5, 106.6, 92.3] }, { name: \u0026#39;London\u0026#39;, data: [48.9, 38.8, 39.3, 41.4, 47.0, 48.3, 59.0, 59.6, 52.4, 65.2, 59.3, 51.2] }, { name: \u0026#39;Berlin\u0026#39;, data: [42.4, 33.2, 34.5, 39.7, 52.6, 75.5, 57.4, 60.4, 47.6, 39.1, 46.8, 51.1] }] } 图3-Basic line { title: { text: \u0026#39;U.S Solar Employment Growth by Job Category, 2010-2020\u0026#39;, align: \u0026#39;left\u0026#39; }, subtitle: { text: \u0026#39;Source: \u0026lt;a href=\u0026#34;https://irecusa.org/programs/solar-jobs-census/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;IREC\u0026lt;/a\u0026gt;\u0026#39;, align: \u0026#39;left\u0026#39; }, yAxis: { title: { text: \u0026#39;Number of Employees\u0026#39; } }, xAxis: { accessibility: { rangeDescription: \u0026#39;Range: 2010 to 2020\u0026#39; } }, legend: { layout: \u0026#39;vertical\u0026#39;, align: \u0026#39;right\u0026#39;, verticalAlign: \u0026#39;middle\u0026#39; }, plotOptions: { series: { label: { connectorAllowed: false }, pointStart: 2010 } }, series: [{ name: \u0026#39;Installation \u0026amp; Developers\u0026#39;, data: [43934, 48656, 65165, 81827, 112143, 142383, 171533, 165174, 155157, 161454, 154610] }, { name: \u0026#39;Manufacturing\u0026#39;, data: [24916, 37941, 29742, 29851, 32490, 30282, 38121, 36885, 33726, 34243, 31050] }, { name: \u0026#39;Sales \u0026amp; Distribution\u0026#39;, data: [11744, 30000, 16005, 19771, 20185, 24377, 32147, 30912, 29243, 29213, 25663] }, { name: \u0026#39;Operations \u0026amp; Maintenance\u0026#39;, data: [null, null, null, null, null, null, null, null, 11164, 11218, 10077] }, { name: \u0026#39;Other\u0026#39;, data: [21908, 5548, 8105, 11248, 8989, 11816, 18274, 17300, 13053, 11906, 10073] }], responsive: { rules: [{ condition: { maxWidth: 500 }, chartOptions: { legend: { layout: \u0026#39;horizontal\u0026#39;, align: \u0026#39;center\u0026#39;, verticalAlign: \u0026#39;bottom\u0026#39; } } }] } } 图4-3D donut { chart: { type: \u0026#39;pie\u0026#39;, options3d: { enabled: true, alpha: 45 } }, title: { text: \u0026#39;Beijing 2022 gold medals by country\u0026#39;, align: \u0026#39;left\u0026#39; }, subtitle: { text: \u0026#39;3D donut in Highcharts\u0026#39;, align: \u0026#39;left\u0026#39; }, plotOptions: { pie: { innerSize: 100, depth: 45 } }, series: [{ name: \u0026#39;Medals\u0026#39;, data: [ [\u0026#39;Norway\u0026#39;, 16], [\u0026#39;Germany\u0026#39;, 12], [\u0026#39;USA\u0026#39;, 8], [\u0026#39;Sweden\u0026#39;, 8], [\u0026#39;Netherlands\u0026#39;, 8], [\u0026#39;ROC\u0026#39;, 6], [\u0026#39;Austria\u0026#39;, 7], [\u0026#39;Canada\u0026#39;, 4], [\u0026#39;Japan\u0026#39;, 3] ] }] } 图5-Tile map { chart: { type: \u0026#39;tilemap\u0026#39;, inverted: true, height: \u0026#39;80%\u0026#39; }, accessibility: { description: \u0026#39;A tile map represents the states of the USA by population in 2016. The hexagonal tiles are positioned to geographically echo the map of the USA. A color-coded legend states the population levels as below 1 million (beige), 1 to 5 million (orange), 5 to 20 million (pink) and above 20 million (hot pink). The chart is interactive, and the individual state data points are displayed upon hovering. Three states have a population of above 20 million: California (39.3 million), Texas (27.9 million) and Florida (20.6 million). The northern US region from Massachusetts in the Northwest to Illinois in the Midwest contains the highest concentration of states with a population of 5 to 20 million people. The southern US region from South Carolina in the Southeast to New Mexico in the Southwest contains the highest concentration of states with a population of 1 to 5 million people. 6 states have a population of less than 1 million people; these include Alaska, Delaware, Wyoming, North Dakota, South Dakota and Vermont. The state with the lowest population is Wyoming in the Northwest with 584,153 people.\u0026#39;, screenReaderSection: { beforeChartFormat: \u0026#39;\u0026lt;h5\u0026gt;{chartTitle}\u0026lt;/h5\u0026gt;\u0026#39; \u0026#43; \u0026#39;\u0026lt;div\u0026gt;{chartSubtitle}\u0026lt;/div\u0026gt;\u0026#39; \u0026#43; \u0026#39;\u0026lt;div\u0026gt;{chartLongdesc}\u0026lt;/div\u0026gt;\u0026#39; \u0026#43; \u0026#39;\u0026lt;div\u0026gt;{viewTableButton}\u0026lt;/div\u0026gt;\u0026#39; }, point: { valueDescriptionFormat: \u0026#39;{index}. {xDescription}, {point.value}.\u0026#39; } }, title: { text: \u0026#39;U.S. states by population in 2016\u0026#39; }, subtitle: { text: \u0026#39;Source:\u0026lt;a href=\u0026#34;https://simple.wikipedia.org/wiki/List_of_U.S._states_by_population\u0026#34;\u0026gt;Wikipedia\u0026lt;/a\u0026gt;\u0026#39; }, xAxis: { visible: false }, yAxis: { visible: false }, colorAxis: { dataClasses: [{ from: 0, to: 1000000, color: \u0026#39;#F9EDB3\u0026#39;, name: \u0026#39;\u0026lt; 1M\u0026#39; }, { from: 1000000, to: 5000000, color: \u0026#39;#FFC428\u0026#39;, name: \u0026#39;1M - 5M\u0026#39; }, { from: 5000000, to: 20000000, color: \u0026#39;#FF7987\u0026#39;, name: \u0026#39;5M - 20M\u0026#39; }, { from: 20000000, color: \u0026#39;#FF2371\u0026#39;, name: \u0026#39;\u0026gt; 20M\u0026#39; }] }, tooltip: { headerFormat: \u0026#39;\u0026#39;, pointFormat: \u0026#39;The population of \u0026lt;b\u0026gt; {point.name}\u0026lt;/b\u0026gt; is \u0026lt;b\u0026gt;{point.value}\u0026lt;/b\u0026gt;\u0026#39; }, plotOptions: { series: { dataLabels: { enabled: true, format: \u0026#39;{point.hc-a2}\u0026#39;, color: \u0026#39;#000000\u0026#39;, style: { textOutline: false } } } }, series: [{ name: \u0026#39;\u0026#39;, data: [{ \u0026#39;hc-a2\u0026#39;: \u0026#39;AL\u0026#39;, name: \u0026#39;Alabama\u0026#39;, region: \u0026#39;South\u0026#39;, x: 6, y: 7, value: 4849377 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;AK\u0026#39;, name: \u0026#39;Alaska\u0026#39;, region: \u0026#39;West\u0026#39;, x: 0, y: 0, value: 737732 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;AZ\u0026#39;, name: \u0026#39;Arizona\u0026#39;, region: \u0026#39;West\u0026#39;, x: 5, y: 3, value: 6745408 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;AR\u0026#39;, name: \u0026#39;Arkansas\u0026#39;, region: \u0026#39;South\u0026#39;, x: 5, y: 6, value: 2994079 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;CA\u0026#39;, name: \u0026#39;California\u0026#39;, region: \u0026#39;West\u0026#39;, x: 5, y: 2, value: 39250017 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;CO\u0026#39;, name: \u0026#39;Colorado\u0026#39;, region: \u0026#39;West\u0026#39;, x: 4, y: 3, value: 5540545 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;CT\u0026#39;, name: \u0026#39;Connecticut\u0026#39;, region: \u0026#39;Northeast\u0026#39;, x: 3, y: 11, value: 3596677 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;DE\u0026#39;, name: \u0026#39;Delaware\u0026#39;, region: \u0026#39;South\u0026#39;, x: 4, y: 9, value: 935614 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;DC\u0026#39;, name: \u0026#39;District of Columbia\u0026#39;, region: \u0026#39;South\u0026#39;, x: 4, y: 10, value: 7288000 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;FL\u0026#39;, name: \u0026#39;Florida\u0026#39;, region: \u0026#39;South\u0026#39;, x: 8, y: 8, value: 20612439 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;GA\u0026#39;, name: \u0026#39;Georgia\u0026#39;, region: \u0026#39;South\u0026#39;, x: 7, y: 8, value: 10310371 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;HI\u0026#39;, name: \u0026#39;Hawaii\u0026#39;, region: \u0026#39;West\u0026#39;, x: 8, y: 0, value: 1419561 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;ID\u0026#39;, name: \u0026#39;Idaho\u0026#39;, region: \u0026#39;West\u0026#39;, x: 3, y: 2, value: 1634464 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;IL\u0026#39;, name: \u0026#39;Illinois\u0026#39;, region: \u0026#39;Midwest\u0026#39;, x: 3, y: 6, value: 12801539 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;IN\u0026#39;, name: \u0026#39;Indiana\u0026#39;, region: \u0026#39;Midwest\u0026#39;, x: 3, y: 7, value: 6596855 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;IA\u0026#39;, name: \u0026#39;Iowa\u0026#39;, region: \u0026#39;Midwest\u0026#39;, x: 3, y: 5, value: 3107126 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;KS\u0026#39;, name: \u0026#39;Kansas\u0026#39;, region: \u0026#39;Midwest\u0026#39;, x: 5, y: 5, value: 2904021 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;KY\u0026#39;, name: \u0026#39;Kentucky\u0026#39;, region: \u0026#39;South\u0026#39;, x: 4, y: 6, value: 4413457 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;LA\u0026#39;, name: \u0026#39;Louisiana\u0026#39;, region: \u0026#39;South\u0026#39;, x: 6, y: 5, value: 4649676 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;ME\u0026#39;, name: \u0026#39;Maine\u0026#39;, region: \u0026#39;Northeast\u0026#39;, x: 0, y: 11, value: 1330089 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;MD\u0026#39;, name: \u0026#39;Maryland\u0026#39;, region: \u0026#39;South\u0026#39;, x: 4, y: 8, value: 6016447 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;MA\u0026#39;, name: \u0026#39;Massachusetts\u0026#39;, region: \u0026#39;Northeast\u0026#39;, x: 2, y: 10, value: 6811779 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;MI\u0026#39;, name: \u0026#39;Michigan\u0026#39;, region: \u0026#39;Midwest\u0026#39;, x: 2, y: 7, value: 9928301 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;MN\u0026#39;, name: \u0026#39;Minnesota\u0026#39;, region: \u0026#39;Midwest\u0026#39;, x: 2, y: 4, value: 5519952 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;MS\u0026#39;, name: \u0026#39;Mississippi\u0026#39;, region: \u0026#39;South\u0026#39;, x: 6, y: 6, value: 2984926 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;MO\u0026#39;, name: \u0026#39;Missouri\u0026#39;, region: \u0026#39;Midwest\u0026#39;, x: 4, y: 5, value: 6093000 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;MT\u0026#39;, name: \u0026#39;Montana\u0026#39;, region: \u0026#39;West\u0026#39;, x: 2, y: 2, value: 1023579 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;NE\u0026#39;, name: \u0026#39;Nebraska\u0026#39;, region: \u0026#39;Midwest\u0026#39;, x: 4, y: 4, value: 1881503 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;NV\u0026#39;, name: \u0026#39;Nevada\u0026#39;, region: \u0026#39;West\u0026#39;, x: 4, y: 2, value: 2839099 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;NH\u0026#39;, name: \u0026#39;New Hampshire\u0026#39;, region: \u0026#39;Northeast\u0026#39;, x: 1, y: 11, value: 1326813 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;NJ\u0026#39;, name: \u0026#39;New Jersey\u0026#39;, region: \u0026#39;Northeast\u0026#39;, x: 3, y: 10, value: 8944469 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;NM\u0026#39;, name: \u0026#39;New Mexico\u0026#39;, region: \u0026#39;West\u0026#39;, x: 6, y: 3, value: 2085572 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;NY\u0026#39;, name: \u0026#39;New York\u0026#39;, region: \u0026#39;Northeast\u0026#39;, x: 2, y: 9, value: 19745289 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;NC\u0026#39;, name: \u0026#39;North Carolina\u0026#39;, region: \u0026#39;South\u0026#39;, x: 5, y: 9, value: 10146788 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;ND\u0026#39;, name: \u0026#39;North Dakota\u0026#39;, region: \u0026#39;Midwest\u0026#39;, x: 2, y: 3, value: 739482 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;OH\u0026#39;, name: \u0026#39;Ohio\u0026#39;, region: \u0026#39;Midwest\u0026#39;, x: 3, y: 8, value: 11614373 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;OK\u0026#39;, name: \u0026#39;Oklahoma\u0026#39;, region: \u0026#39;South\u0026#39;, x: 6, y: 4, value: 3878051 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;OR\u0026#39;, name: \u0026#39;Oregon\u0026#39;, region: \u0026#39;West\u0026#39;, x: 4, y: 1, value: 3970239 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;PA\u0026#39;, name: \u0026#39;Pennsylvania\u0026#39;, region: \u0026#39;Northeast\u0026#39;, x: 3, y: 9, value: 12784227 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;RI\u0026#39;, name: \u0026#39;Rhode Island\u0026#39;, region: \u0026#39;Northeast\u0026#39;, x: 2, y: 11, value: 1055173 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;SC\u0026#39;, name: \u0026#39;South Carolina\u0026#39;, region: \u0026#39;South\u0026#39;, x: 6, y: 8, value: 4832482 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;SD\u0026#39;, name: \u0026#39;South Dakota\u0026#39;, region: \u0026#39;Midwest\u0026#39;, x: 3, y: 4, value: 853175 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;TN\u0026#39;, name: \u0026#39;Tennessee\u0026#39;, region: \u0026#39;South\u0026#39;, x: 5, y: 7, value: 6651194 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;TX\u0026#39;, name: \u0026#39;Texas\u0026#39;, region: \u0026#39;South\u0026#39;, x: 7, y: 4, value: 27862596 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;UT\u0026#39;, name: \u0026#39;Utah\u0026#39;, region: \u0026#39;West\u0026#39;, x: 5, y: 4, value: 2942902 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;VT\u0026#39;, name: \u0026#39;Vermont\u0026#39;, region: \u0026#39;Northeast\u0026#39;, x: 1, y: 10, value: 626011 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;VA\u0026#39;, name: \u0026#39;Virginia\u0026#39;, region: \u0026#39;South\u0026#39;, x: 5, y: 8, value: 8411808 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;WA\u0026#39;, name: \u0026#39;Washington\u0026#39;, region: \u0026#39;West\u0026#39;, x: 2, y: 1, value: 7288000 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;WV\u0026#39;, name: \u0026#39;West Virginia\u0026#39;, region: \u0026#39;South\u0026#39;, x: 4, y: 7, value: 1850326 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;WI\u0026#39;, name: \u0026#39;Wisconsin\u0026#39;, region: \u0026#39;Midwest\u0026#39;, x: 2, y: 5, value: 5778708 }, { \u0026#39;hc-a2\u0026#39;: \u0026#39;WY\u0026#39;, name: \u0026#39;Wyoming\u0026#39;, region: \u0026#39;West\u0026#39;, x: 3, y: 3, value: 584153 }] }] } 图6-Sankey diagram { title: { text: \u0026#39;Highcharts Sankey Diagram\u0026#39; }, accessibility: { point: { valueDescriptionFormat: \u0026#39;{index}. {point.from} to {point.to}, {point.weight}.\u0026#39; } }, series: [{ keys: [\u0026#39;from\u0026#39;, \u0026#39;to\u0026#39;, \u0026#39;weight\u0026#39;], data: [ [\u0026#39;Brazil\u0026#39;, \u0026#39;Portugal\u0026#39;, 5], [\u0026#39;Brazil\u0026#39;, \u0026#39;France\u0026#39;, 1], [\u0026#39;Brazil\u0026#39;, \u0026#39;Spain\u0026#39;, 1], [\u0026#39;Brazil\u0026#39;, \u0026#39;England\u0026#39;, 1], [\u0026#39;Canada\u0026#39;, \u0026#39;Portugal\u0026#39;, 1], [\u0026#39;Canada\u0026#39;, \u0026#39;France\u0026#39;, 5], [\u0026#39;Canada\u0026#39;, \u0026#39;England\u0026#39;, 1], [\u0026#39;Mexico\u0026#39;, \u0026#39;Portugal\u0026#39;, 1], [\u0026#39;Mexico\u0026#39;, \u0026#39;France\u0026#39;, 1], [\u0026#39;Mexico\u0026#39;, \u0026#39;Spain\u0026#39;, 5], [\u0026#39;Mexico\u0026#39;, \u0026#39;England\u0026#39;, 1], [\u0026#39;USA\u0026#39;, \u0026#39;Portugal\u0026#39;, 1], [\u0026#39;USA\u0026#39;, \u0026#39;France\u0026#39;, 1], [\u0026#39;USA\u0026#39;, \u0026#39;Spain\u0026#39;, 1], [\u0026#39;USA\u0026#39;, \u0026#39;England\u0026#39;, 5], [\u0026#39;Portugal\u0026#39;, \u0026#39;Angola\u0026#39;, 2], [\u0026#39;Portugal\u0026#39;, \u0026#39;Senegal\u0026#39;, 1], [\u0026#39;Portugal\u0026#39;, \u0026#39;Morocco\u0026#39;, 1], [\u0026#39;Portugal\u0026#39;, \u0026#39;South Africa\u0026#39;, 3], [\u0026#39;France\u0026#39;, \u0026#39;Angola\u0026#39;, 1], [\u0026#39;France\u0026#39;, \u0026#39;Senegal\u0026#39;, 3], [\u0026#39;France\u0026#39;, \u0026#39;Mali\u0026#39;, 3], [\u0026#39;France\u0026#39;, \u0026#39;Morocco\u0026#39;, 3], [\u0026#39;France\u0026#39;, \u0026#39;South Africa\u0026#39;, 1], [\u0026#39;Spain\u0026#39;, \u0026#39;Senegal\u0026#39;, 1], [\u0026#39;Spain\u0026#39;, \u0026#39;Morocco\u0026#39;, 3], [\u0026#39;Spain\u0026#39;, \u0026#39;South Africa\u0026#39;, 1], [\u0026#39;England\u0026#39;, \u0026#39;Angola\u0026#39;, 1], [\u0026#39;England\u0026#39;, \u0026#39;Senegal\u0026#39;, 1], [\u0026#39;England\u0026#39;, \u0026#39;Morocco\u0026#39;, 2], [\u0026#39;England\u0026#39;, \u0026#39;South Africa\u0026#39;, 7], [\u0026#39;South Africa\u0026#39;, \u0026#39;China\u0026#39;, 5], [\u0026#39;South Africa\u0026#39;, \u0026#39;India\u0026#39;, 1], [\u0026#39;South Africa\u0026#39;, \u0026#39;Japan\u0026#39;, 3], [\u0026#39;Angola\u0026#39;, \u0026#39;China\u0026#39;, 5], [\u0026#39;Angola\u0026#39;, \u0026#39;India\u0026#39;, 1], [\u0026#39;Angola\u0026#39;, \u0026#39;Japan\u0026#39;, 3], [\u0026#39;Senegal\u0026#39;, \u0026#39;China\u0026#39;, 5], [\u0026#39;Senegal\u0026#39;, \u0026#39;India\u0026#39;, 1], [\u0026#39;Senegal\u0026#39;, \u0026#39;Japan\u0026#39;, 3], [\u0026#39;Mali\u0026#39;, \u0026#39;China\u0026#39;, 5], [\u0026#39;Mali\u0026#39;, \u0026#39;India\u0026#39;, 1], [\u0026#39;Mali\u0026#39;, \u0026#39;Japan\u0026#39;, 3], [\u0026#39;Morocco\u0026#39;, \u0026#39;China\u0026#39;, 5], [\u0026#39;Morocco\u0026#39;, \u0026#39;India\u0026#39;, 1], [\u0026#39;Morocco\u0026#39;, \u0026#39;Japan\u0026#39;, 3] ], type: \u0026#39;sankey\u0026#39;, name: \u0026#39;Sankey demo series\u0026#39; }] } 图7-Gauge series { chart: { type: \u0026#39;gauge\u0026#39;, plotBackgroundColor: null, plotBackgroundImage: null, plotBorderWidth: 0, plotShadow: false, height: \u0026#39;80%\u0026#39; }, title: { text: \u0026#39;Speedometer\u0026#39; }, pane: { startAngle: -90, endAngle: 89.9, background: null, center: [\u0026#39;50%\u0026#39;, \u0026#39;75%\u0026#39;], size: \u0026#39;110%\u0026#39; }, yAxis: { min: 0, max: 200, tickPixelInterval: 72, tickPosition: \u0026#39;inside\u0026#39;, tickColor: Highcharts.defaultOptions.chart.backgroundColor || \u0026#39;#FFFFFF\u0026#39;, tickLength: 20, tickWidth: 2, minorTickInterval: null, labels: { distance: 20, style: { fontSize: \u0026#39;14px\u0026#39; } }, plotBands: [{ from: 0, to: 120, color: \u0026#39;#55BF3B\u0026#39;, thickness: 20 }, { from: 120, to: 160, color: \u0026#39;#DDDF0D\u0026#39;, thickness: 20 }, { from: 160, to: 200, color: \u0026#39;#DF5353\u0026#39;, thickness: 20 }] }, series: [{ name: \u0026#39;Speed\u0026#39;, data: [80], tooltip: { valueSuffix: \u0026#39; km/h\u0026#39; }, dataLabels: { format: \u0026#39;{y} km/h\u0026#39;, borderWidth: 0, color: ( Highcharts.defaultOptions.title \u0026amp;\u0026amp; Highcharts.defaultOptions.title.style \u0026amp;\u0026amp; Highcharts.defaultOptions.title.style.color ) || \u0026#39;#333333\u0026#39;, style: { fontSize: \u0026#39;16px\u0026#39; } }, dial: { radius: \u0026#39;80%\u0026#39;, backgroundColor: \u0026#39;gray\u0026#39;, baseWidth: 12, baseLength: \u0026#39;0%\u0026#39;, rearLength: \u0026#39;0%\u0026#39; }, pivot: { backgroundColor: \u0026#39;gray\u0026#39;, radius: 6 } }] } 图8-Arc diagram { colors: [\u0026#39;#293462\u0026#39;, \u0026#39;#a64942\u0026#39;, \u0026#39;#fe5f55\u0026#39;, \u0026#39;#fff1c1\u0026#39;, \u0026#39;#5bd1d7\u0026#39;, \u0026#39;#ff502f\u0026#39;, \u0026#39;#004d61\u0026#39;, \u0026#39;#ff8a5c\u0026#39;, \u0026#39;#fff591\u0026#39;, \u0026#39;#f5587b\u0026#39;, \u0026#39;#fad3cf\u0026#39;, \u0026#39;#a696c8\u0026#39;, \u0026#39;#5BE7C4\u0026#39;, \u0026#39;#266A2E\u0026#39;, \u0026#39;#593E1A\u0026#39;], title: { text: \u0026#39;Main train connections in Europe\u0026#39; }, accessibility: { description: \u0026#39;Arc diagram chart with circles of different sizes along the X axis, and connections drawn as arcs between them. From the chart we can see that Paris is the city with the most connections to other cities.\u0026#39;, point: { valueDescriptionFormat: \u0026#39;Connection from {point.from} to {point.to}.\u0026#39; } }, series: [{ keys: [\u0026#39;from\u0026#39;, \u0026#39;to\u0026#39;, \u0026#39;weight\u0026#39;], type: \u0026#39;arcdiagram\u0026#39;, name: \u0026#39;Train connections\u0026#39;, linkWeight: 1, centeredLinks: true, dataLabels: { rotation: 90, y: 30, align: \u0026#39;left\u0026#39;, color: \u0026#39;black\u0026#39; }, offset: \u0026#39;65%\u0026#39;, data: [ [\u0026#39;Hamburg\u0026#39;, \u0026#39;Stuttgart\u0026#39;, 1], [\u0026#39;Hamburg\u0026#39;, \u0026#39;Frankfurt\u0026#39;, 1], [\u0026#39;Hamburg\u0026#39;, \u0026#39;München\u0026#39;, 1], [\u0026#39;Hannover\u0026#39;, \u0026#39;Wien\u0026#39;, 1], [\u0026#39;Hannover\u0026#39;, \u0026#39;München\u0026#39;, 1], [\u0026#39;Berlin\u0026#39;, \u0026#39;Wien\u0026#39;, 1], [\u0026#39;Berlin\u0026#39;, \u0026#39;München\u0026#39;, 1], [\u0026#39;Berlin\u0026#39;, \u0026#39;Stuttgart\u0026#39;, 1], [\u0026#39;Berlin\u0026#39;, \u0026#39;Frankfurt\u0026#39;, 1], [\u0026#39;Berlin\u0026#39;, \u0026#39;Köln\u0026#39;, 1], [\u0026#39;Berlin\u0026#39;, \u0026#39;Düsseldorf\u0026#39;, 1], [\u0026#39;München\u0026#39;, \u0026#39;Düsseldorf\u0026#39;, 1], [\u0026#39;München\u0026#39;, \u0026#39;Wien\u0026#39;, 1], [\u0026#39;München\u0026#39;, \u0026#39;Frankfurt\u0026#39;, 1], [\u0026#39;München\u0026#39;, \u0026#39;Köln\u0026#39;, 1], [\u0026#39;München\u0026#39;, \u0026#39;Amsterdam\u0026#39;, 1], [\u0026#39;Stuttgart\u0026#39;, \u0026#39;Wien\u0026#39;, 1], [\u0026#39;Frankfurt\u0026#39;, \u0026#39;Wien\u0026#39;, 1], [\u0026#39;Frankfurt\u0026#39;, \u0026#39;Amsterdam\u0026#39;, 1], [\u0026#39;Frankfurt\u0026#39;, \u0026#39;Paris\u0026#39;, 1], [\u0026#39;Frankfurt\u0026#39;, \u0026#39;Budapest\u0026#39;, 1], [\u0026#39;Düsseldorf\u0026#39;, \u0026#39;Wien\u0026#39;, 1], [\u0026#39;Düsseldorf\u0026#39;, \u0026#39;Hamburg\u0026#39;, 1], [\u0026#39;Amsterdam\u0026#39;, \u0026#39;Paris\u0026#39;, 1], [\u0026#39;Paris\u0026#39;, \u0026#39;Brest\u0026#39;, 1], [\u0026#39;Paris\u0026#39;, \u0026#39;Nantes\u0026#39;, 1], [\u0026#39;Paris\u0026#39;, \u0026#39;Bayonne\u0026#39;, 1], [\u0026#39;Paris\u0026#39;, \u0026#39;Bordeaux\u0026#39;, 1], [\u0026#39;Paris\u0026#39;, \u0026#39;Toulouse\u0026#39;, 1], [\u0026#39;Paris\u0026#39;, \u0026#39;Montpellier\u0026#39;, 1], [\u0026#39;Paris\u0026#39;, \u0026#39;Marseille\u0026#39;, 1], [\u0026#39;Paris\u0026#39;, \u0026#39;Nice\u0026#39;, 1], [\u0026#39;Paris\u0026#39;, \u0026#39;Milano\u0026#39;, 1], [\u0026#39;Nantes\u0026#39;, \u0026#39;Nice\u0026#39;, 1], [\u0026#39;Bordeaux\u0026#39;, \u0026#39;Lyon\u0026#39;, 1], [\u0026#39;Nantes\u0026#39;, \u0026#39;Lyon\u0026#39;, 1], [\u0026#39;Milano\u0026#39;, \u0026#39;München\u0026#39;, 1], [\u0026#39;Milano\u0026#39;, \u0026#39;Roma\u0026#39;, 1], [\u0026#39;Milano\u0026#39;, \u0026#39;Bari\u0026#39;, 1], [\u0026#39;Milano\u0026#39;, \u0026#39;Napoli\u0026#39;, 1], [\u0026#39;Milano\u0026#39;, \u0026#39;Brindisi\u0026#39;, 1], [\u0026#39;Milano\u0026#39;, \u0026#39;Lamezia Terme\u0026#39;, 1], [\u0026#39;Torino\u0026#39;, \u0026#39;Roma\u0026#39;, 1], [\u0026#39;Venezia\u0026#39;, \u0026#39;Napoli\u0026#39;, 1], [\u0026#39;Roma\u0026#39;, \u0026#39;Bari\u0026#39;, 1], [\u0026#39;Roma\u0026#39;, \u0026#39;Catania\u0026#39;, 1], [\u0026#39;Roma\u0026#39;, \u0026#39;Brindisi\u0026#39;, 1], [\u0026#39;Catania\u0026#39;, \u0026#39;Milano\u0026#39;, 1] ] }] } 特殊图表 对于某些复杂的Highcharts图表，可尝试将其转化为一个JavaScript对象以兼容前述的实现方案，保持优雅。若实现难度较大，可将相关的html代码直接嵌入markdown中来实现相关功能，但通过此种方式会导致无法对相关的图表进行动态配置。\n下述为一个示例展示，个人推荐直接嵌入html代码。\n","date":"2023-04-02T16:39:51+08:00","permalink":"https://lucumt.info/post/hugo/enable-highcharts-in-hugo/","tags":["hugo","highcharts","go"],"title":"在Hugo中开启Highcharts图表支持"},{"categories":["个人博客","系统集成"],"contents":"说明\n若页面中图表显示不正常，可能是由于js文件加载和图表渲染需要时间，请多等待几秒钟！\n简要介绍在如何在Hugo博客中基于Even主题开启flowchart、sequence和mermaid图表的支持。\n背景 个人Hugo博客切换为Even已经有好几年了，相关功能也是基于此主题扩展而来，不过Even主题的作者已经很久没有此主题,GitHub上大量的issue都由于过期而自动关闭1，同时个人发现该主题下layouts/partials/scripts.html对于flowchart和sequence的实现并不完善，缺少对应的初始化代码，基于此我决定在该主题的基础上自己实现相关功能！\nPS: Even主题2很受欢迎，希望作者早日恢复维护!\n修改说明 由于Hugo支持代码高亮，当图表相关的数据当采用Markdown的codeblock方式写入时，如下图所示默认情况下，其会以代码高亮的方式显示，很明显此种方式不满足要求。\n从上图可知经过高亮处理后的图表代码已经与html标签混杂在一起，为了能正常展示图表数据，必须要有一种方式能够准确的获取原始的图表代码，此时需要借助Hugo的Render Hooks功能，其主要功能是让我们通过自定义的模板来覆盖Hugo默认的功能实现。如下图所示经过Markup处理后的，会将原始的代码文件基于对应codeblock文件中的代码来展示，在对应的html中包含我们原始的代码块文件，采用JavaScript或jQuery都能快速的获取到对应代码，之后调用对应图表JavaScript库来进行渲染或初始化即可。\n根据Hugo官方Render Hooks上的说明，需要在layouts/_default/_markup文件夹下建立对应的html文件，其命名规则为render-xxx-[yyy].html,其中xxx为一级类别，yyy为二级类别(可选的)，如要重写所有的代码展示可创建文件render-codeblock.html，要重写所有的图片展示可创建文件render-image.html,要重写所有的mermaid代码展示则需要添加上二级分类render-codeblock-mermiad.html。\nlayouts/ └── _default/ └── _markup/ ├── render-codeblock-bash.html ├── render-codeblock.html ├── render-heading.html ├── render-image.html ├── render-image.rss.xml └── render-link.html 注意\n当我们最终修改完毕后，若页面上没有正常展示相关的图表且浏览器控制台出现如下错误，需要在layouts/partials/scripts.html或config.toml中重新修改相关报错文件的integrity值，或在static/lib下重新下载相关的文件，确保其校验值一致，即可消除错误。\nflowchart图表 修改过程 在layouts/_default/_markup创建文件render-codeblock-flow.html并添加如下代码\n\u0026lt;div id=\u0026#34;flow_{{ .Ordinal }}\u0026#34;\u0026gt; {{- .Inner | safeHTML }} \u0026lt;/div\u0026gt; 在layouts/partials/scripts.html补充原有的代码，添加上初始化功能\n\u0026lt;!-- flowchart --\u0026gt; {{- if and (or .Params.flowchartDiagrams.enable (and .Site.Params.flowchartDiagrams.enable (ne .Params.flowchartDiagrams.enable false))) (or .IsPage .IsHome) -}} {{- if .Site.Params.publicCDN.enable -}} {{ .Site.Params.publicCDN.flowchartDiagramsJS | safeHTML }} {{- else -}} \u0026lt;script src=\u0026#34;{{ \u0026#34;lib/flowchartDiagrams/raphael-2.2.7.min.js\u0026#34; | relURL }}\u0026#34; integrity=\u0026#34;sha256-67By\u0026#43;NpOtm9ka1R6xpUefeGOY8kWWHHRAKlvaTJ7ONI=\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;{{ \u0026#34;lib/flowchartDiagrams/flowchart-1.8.0.min.js\u0026#34; | relURL }}\u0026#34; integrity=\u0026#34;sha256-zNGWjubXoY6rb5MnmpBNefO0RgoVYfle9p0tvOQM\u0026#43;6k=\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; {{- end -}} \u0026lt;script\u0026gt; /*{{- if .Params.flowchartDiagrams.options -}} window.flowchartDiagramsOptions = {{ .Params.flowchartDiagrams.options | safeJS }}; {{- else if .Site.Params.flowchartDiagrams.options -}} window.flowchartDiagramsOptions = {{ .Site.Params.flowchartDiagrams.options | safeJS }}; {{- end -}}*/ \u0026lt;!-- below is newly added code --\u0026gt; let flowPageOptions = {{ .Page.Params.flowchartDiagrams.options }}; let flowSiteOptions = {{ .Site.Params.flowchartDiagrams.options }}; flowPageOptions = !!flowPageOptions ? flowPageOptions : \u0026#34;{}\u0026#34; flowSiteOptions = !!flowSiteOptions ? flowSiteOptions : \u0026#34;{}\u0026#34; flowPageOptions = eval(\u0026#34;(\u0026#34; \u0026#43; flowPageOptions \u0026#43; \u0026#34;)\u0026#34;) flowSiteOptions = eval(\u0026#34;(\u0026#34; \u0026#43; flowSiteOptions \u0026#43; \u0026#34;)\u0026#34;) // page options have high priority then site options let flowOptions = {...flowSiteOptions, ...flowPageOptions}; $(\u0026#34;[id^=flow_]\u0026#34;).flowChart(flowOptions); \u0026lt;/script\u0026gt; {{- end -}} 上述代码中通过let flowOptions = {...flowSiteOptions, ...flowPageOptions};来确保页面上的配置覆盖全局配置，优先级更高。\n在对应的markdown页面头部开启flowchart的展示，可根据实际情况添加自定义配置，保存对应markdown文件后页面会自动刷新并展示对应效果3。\nflowchartDiagrams: enable: true options: \u0026#34;{ \u0026#39;x\u0026#39;: 0, \u0026#39;y\u0026#39;: 0, \u0026#39;width\u0026#39;:1, \u0026#39;line-width\u0026#39;: 1, \u0026#39;line-length\u0026#39;: 50, \u0026#39;text-margin\u0026#39;: 10 }\u0026#34; 自定义样式 不同于sequence,flowchart的使用很灵活，其官网上虽然只有4个demo，但已经覆盖了大部分功能，本小节简要介绍如何对其中的flowstate进行配置从而让图表展示不同的样式。\n为了实现自定义样式的展示，需要了解flowchart的语法,下图展示了其主要语法，更具体的可参见4，实际使用中我们主要通过对flowstate来实现自定义样式显示。\n下图展示了一个通过设置不同flowstate来设置流程图不同组件样式的示例。 展示效果 基于对应markdown页面的下述配置展示相关效果\nflowchartDiagrams: enable: true options: \u0026#34;{ \u0026#39;x\u0026#39;: 0, \u0026#39;y\u0026#39;: 0, \u0026#39;width\u0026#39;:1, \u0026#39;line-width\u0026#39;: 1, \u0026#39;line-length\u0026#39;: 50, \u0026#39;text-margin\u0026#39;: 10, \u0026#39;font-size\u0026#39;: 14, \u0026#39;font-color\u0026#39;: \u0026#39;black\u0026#39;, \u0026#39;line-color\u0026#39;: \u0026#39;black\u0026#39;, \u0026#39;element-color\u0026#39;: \u0026#39;black\u0026#39;, \u0026#39;fill\u0026#39;: \u0026#39;white\u0026#39;, \u0026#39;yes-text\u0026#39;: \u0026#39;yes\u0026#39;, \u0026#39;no-text\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;arrow-end\u0026#39;: \u0026#39;block\u0026#39;, \u0026#39;scale\u0026#39;: 1, \u0026#39;symbols\u0026#39;: { \u0026#39;start\u0026#39;: { \u0026#39;font-color\u0026#39;: \u0026#39;red\u0026#39;, \u0026#39;element-color\u0026#39;: \u0026#39;green\u0026#39;, \u0026#39;fill\u0026#39;: \u0026#39;yellow\u0026#39; }, \u0026#39;end\u0026#39;: { \u0026#39;class\u0026#39;: \u0026#39;end-element\u0026#39;, \u0026#39;element-color\u0026#39;: \u0026#39;green\u0026#39; } }, \u0026#39;flowstate\u0026#39;: { \u0026#39;aaa\u0026#39;: {\u0026#39;fill\u0026#39;: \u0026#39;pink\u0026#39;}, \u0026#39;approved\u0026#39;: {\u0026#39;fill\u0026#39;: \u0026#39;peru\u0026#39;} } }\u0026#34; 图表1 原始代码\n​```flow st=\u0026gt;start: 开始框 op=\u0026gt;operation: 处理框 cond=\u0026gt;condition: 判断框(是或否?) sub1=\u0026gt;subroutine: 子流程 io=\u0026gt;inputoutput: 输入输出框|approved e=\u0026gt;end: 结束框 st-\u0026gt;op-\u0026gt;cond cond(yes)-\u0026gt;io-\u0026gt;e cond(no)-\u0026gt;sub1(right)-\u0026gt;op ​``` 展示效果\nst=\u003estart: 开始框 op=\u003eoperation: 处理框 cond=\u003econdition: 判断框(是或否?) sub1=\u003esubroutine: 子流程 io=\u003einputoutput: 输入输出框|approved e=\u003eend: 结束框 st-\u003eop-\u003econd cond(yes)-\u003eio-\u003ee cond(no)-\u003esub1(right)-\u003eop 图表2 原始代码\n​```flow st=\u0026gt;start: 开始节点 in=\u0026gt;inputoutput: 输入 e=\u0026gt;end: 结束节点 op=\u0026gt;operation: 操作节点 cond=\u0026gt;condition: 条件节点 sub=\u0026gt;subroutine: 子例程 out=\u0026gt;inputoutput: 输出 st(right)-\u0026gt;in-\u0026gt;op-\u0026gt;cond cond(yes,right)-\u0026gt;out-\u0026gt;e cond(no)-\u0026gt;sub ​``` 展示效果\nst=\u003estart: 开始节点 in=\u003einputoutput: 输入 e=\u003eend: 结束节点 op=\u003eoperation: 操作节点 cond=\u003econdition: 条件节点 sub=\u003esubroutine: 子例程 out=\u003einputoutput: 输出 st(right)-\u003ein-\u003eop-\u003econd cond(yes,right)-\u003eout-\u003ee cond(no)-\u003esub 图表3 原始代码\n​```flow st=\u0026gt;start: Start|past:\u0026gt;http://www.google.com[blank] e=\u0026gt;end: End:\u0026gt;http://www.google.com op1=\u0026gt;operation: My Operation|past op2=\u0026gt;operation: Stuff|aaa sub1=\u0026gt;subroutine: My Subroutine|invalid cond=\u0026gt;condition: Yes or No?|approved:\u0026gt;http://www.google.com c2=\u0026gt;condition: Good idea|rejected io=\u0026gt;inputoutput: catch something...|aaa st-\u0026gt;op1(right)-\u0026gt;cond cond(yes, right)-\u0026gt;c2 cond(no)-\u0026gt;sub1(left)-\u0026gt;op1 c2(yes)-\u0026gt;io-\u0026gt;e c2(no)-\u0026gt;op2-\u0026gt;e ​``` 展示效果\nst=\u003estart: Start|past:\u003ehttp://www.google.com[blank] e=\u003eend: End:\u003ehttp://www.google.com op1=\u003eoperation: My Operation|past op2=\u003eoperation: Stuff|aaa sub1=\u003esubroutine: My Subroutine|invalid cond=\u003econdition: Yes or No?|approved:\u003ehttp://www.google.com c2=\u003econdition: Good idea | rejected io=\u003einputoutput: catch something...|aaa st-\u003eop1(right)-\u003econd cond(yes, right)-\u003ec2 cond(no)-\u003esub1(left)-\u003eop1 c2(yes)-\u003eio-\u003ee c2(no)-\u003eop2-\u003ee sequence图表 修改过程 在layouts/_default/_markup创建文件render-codeblock-sequence.html并添加如下代码\n\u0026lt;div id=\u0026#34;sequence_{{ .Ordinal }}\u0026#34;\u0026gt; {{- .Inner | safeHTML }} \u0026lt;/div\u0026gt; 在layouts/partials/scripts.html补充原有的代码，添加上初始化功能\n\u0026lt;!-- js-sequence-diagrams --\u0026gt; {{- if and (or .Params.sequenceDiagrams.enable (and .Site.Params.sequenceDiagrams.enable (ne .Params.sequenceDiagrams.enable false))) (or .IsPage .IsHome) -}} {{- if .Site.Params.publicCDN.enable -}} {{ .Site.Params.publicCDN.sequenceDiagramsJS | safeHTML }} {{ .Site.Params.publicCDN.sequenceDiagramsCSS | safeHTML }} {{- else -}} \u0026lt;script src=\u0026#34;{{ \u0026#34;lib/js-sequence-diagrams/webfontloader-1.6.28.js\u0026#34; | relURL }}\u0026#34; integrity=\u0026#34;sha256-4O4pS1SH31ZqrSO2A/2QJTVjTPqVe\u0026#43;jnYgOWUVr7EEc=\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;{{ \u0026#34;lib/js-sequence-diagrams/snap.svg-0.5.1.min.js\u0026#34; | relURL }}\u0026#34; integrity=\u0026#34;sha256-oI\u0026#43;elz\u0026#43;sIm\u0026#43;jpn8F/qEspKoKveTc5uKeFHNNVexe6d8=\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;{{ \u0026#34;lib/js-sequence-diagrams/underscore-1.8.3.min.js\u0026#34; | relURL }}\u0026#34; integrity=\u0026#34;sha256-obZACiHd7gkOk9iIL/pimWMTJ4W/pBsKu\u0026#43;oZnSeBIek=\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;{{ \u0026#34;lib/js-sequence-diagrams/sequence-diagram.js\u0026#34; | relURL }}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!--\u0026lt;script src=\u0026#34;{{ \u0026#34;lib/js-sequence-diagrams/sequence-diagram-2.0.1.min.js\u0026#34; | relURL }}\u0026#34; integrity=\u0026#34;sha384-8748Vn52gHJYJI0XEuPB2QlPVNUkJlJn9tHqKec6J3q2r9l8fvRxrgn/E5ZHV0sP\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;--\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;{{ \u0026#34;lib/js-sequence-diagrams/sequence-diagram-2.0.1.min.css\u0026#34; | relURL }}\u0026#34; integrity=\u0026#34;sha384-6QbLKJMz5dS3adWSeINZe74uSydBGFbnzaAYmp\u0026#43;tKyq60S7H2p6V7g1TysM5lAaF\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; {{- end -}} \u0026lt;script\u0026gt; /*{{- if .Params.sequenceDiagrams.options -}} window.sequenceDiagramsOptions = {{ .Params.sequenceDiagrams.options | safeJS }}; {{- else if .Site.Params.sequenceDiagrams.options -}} window.sequenceDiagramsOptions = {{ .Site.Params.sequenceDiagrams.options | safeJS }}; {{- end -}}*/ \u0026lt;!-- below is newly added code --\u0026gt; let seqPageOptions = {{ .Page.Params.sequenceDiagrams.options }}; let seqSiteOptions = {{ .Site.Params.sequenceDiagrams.options }}; seqPageOptions = !!seqPageOptions ? seqPageOptions : \u0026#34;{}\u0026#34; seqSiteOptions = !!seqSiteOptions ? seqSiteOptions : \u0026#34;{}\u0026#34; seqPageOptions = eval(\u0026#34;(\u0026#34; \u0026#43; seqPageOptions \u0026#43; \u0026#34;)\u0026#34;) seqSiteOptions = eval(\u0026#34;(\u0026#34; \u0026#43; seqSiteOptions \u0026#43; \u0026#34;)\u0026#34;) // page options have high priority then site options let seqOptions = {...seqSiteOptions, ...seqPageOptions}; $(\u0026#34;[id^=sequence_]\u0026#34;).sequenceDiagram(seqOptions); \u0026lt;/script\u0026gt; {{- end }} 可以看出，其实现代码与flowchart的类似。\n在对应的markdown页面头部开启sequence的展示，可根据实际情况添加自定义配置，保存对应markdown文件后页面会自动刷新并展示对应效果。\nsequenceDiagrams: enable: true options: \u0026#34;{ \u0026#39;theme\u0026#39;: \u0026#39;simple\u0026#39;, \u0026#39;font-size\u0026#39;: 14, \u0026#39;font-family\u0026#39;: \u0026#39;Andale Mono, monospace\u0026#39; }\u0026#34; 自定义样式 在sequence的官方网站上对于该图表的初始化只提供的theme这一个属性而且其值也只有simple和hand两个选项，对于字体，背景色等没有像flowchart那么丰富的支持。\n经过多次尝试后发现支持theme、fonts-size和font-family这3个属性配置，显然不能满足使用要求。\n一开始自己以为是自己没找到地方，翻遍其GitHub项目后在sequence-diagram.js上找到了如下说明，作者自己承认实现不够完善，但此项目已经至少3年没有维护！\nWhat，于是乎我只能自己fork源码自己修改了，修改好的代码参见sequence-diagram.js,在使用时用此文件或者压缩后的替换原有的，然后修改integrity即可。\nsequence图表是基于SVG实现，故而自己的修改也是从SVG着手，由于时间关系自己只修改了SVG Line和SVG Rectangle两个组件，修改后的使用效果如下：\n展示效果 基于对应markdown页面的下述配置展示相关效果\nsequenceDiagrams: enable: true options: \u0026#34;{ \u0026#39;theme\u0026#39;: \u0026#39;simple\u0026#39;, \u0026#39;width\u0026#39;:1, \u0026#39;line-width\u0026#39;: 1, \u0026#39;font-size\u0026#39;: 14, \u0026#39;font-family\u0026#39;: \u0026#39;Andale Mono, monospace\u0026#39;, \u0026#39;line\u0026#39;:{ \u0026#39;stroke-width\u0026#39;: 1 }, \u0026#39;rect\u0026#39;:{ \u0026#39;stroke-width\u0026#39;: 1, \u0026#39;fill\u0026#39;:\u0026#39;#deffcc\u0026#39; }, \u0026#39;text\u0026#39;:{ \u0026#39;fill\u0026#39;:\u0026#39;#219b15\u0026#39;, \u0026#39;stroke-width\u0026#39;:1, \u0026#39;stroke\u0026#39;:\u0026#39;#219b15\u0026#39; } }\u0026#34; 图表1 原始代码\n​```sequence Title: Here is a title A-\u0026gt;B: Normal line B--\u0026gt;C: Dashed line C-\u0026gt;\u0026gt;D: Open arrow D--\u0026gt;\u0026gt;A: Dashed open arrow ​``` 展示效果\nTitle: Here is a title A-\u003eB: Normal line B--\u003eC: Dashed line C-\u003e\u003eD: Open arrow D--\u003e\u003eA: Dashed open arrow 图表2 原始代码\n​```sequence # Example of a comment. Note left of A: Note to the\\n left of A Note right of A: Note to the\\n right of A Note over A: Note over A Note over A,B: Note over both A and B ​``` 展示效果\n# Example of a comment. Note left of A: Note to the\\n left of A Note right of A: Note to the\\n right of A Note over A: Note over A Note over A,B: Note over both A and B 图表3 原始代码\n​```sequence participant C participant B participant A Note right of A: By listing the participants\\n you can change their order ​``` 展示效果\nparticipant C participant B participant A Note right of A: By listing the participants\\n you can change their order 图表4 原始代码\n​```sequence Andrew-\u0026gt;China: Says Hello Note right of China: China thinks\\nabout it China--\u0026gt;Andrew: How are you? Andrew-\u0026gt;\u0026gt;China: I am good thanks! ​``` 展示效果\nAndrew-\u003eChina: Says Hello Note right of China: China thinks\\nabout it China--\u003eAndrew: How are you? Andrew-\u003e\u003eChina: I am good thanks! 图表5 原始代码\n​```sequence participant System participant App System-\u0026gt;\u0026gt;App: Do you hear me App--\u0026gt;\u0026gt;Module: Alive? Module--\u0026gt;\u0026gt;App: Yay! App-\u0026gt;\u0026gt;System: Stop ​``` 展示效果\nparticipant System participant App System-\u003e\u003eApp: Do you hear me App--\u003e\u003eModule: Alive? Module--\u003e\u003eApp: Yay! App-\u003e\u003eSystem: Stop mermaid图表 mermaid是一个功能强大的Markdown图表显示控件，其本身的功能已经包含前述的flowchart和sequence，但由于Even主题的作者默认并没有加上此图表的支持，同时Hugo的官网有专门的配置说明5，故本次一并加上。\n修改过程 在layouts/_default/_markup创建文件render-codeblock-mermaid.html并添加如下代码\n\u0026lt;div class=\u0026#34;mermaid\u0026#34;\u0026gt; {{- .Inner | safeHTML }} \u0026lt;/div\u0026gt; {{ .Page.Store.Set \u0026#34;hasMermaid\u0026#34; true }} 在layouts/partials/scripts.html添加如下代码\n\u0026lt;!-- mermaid js --\u0026gt; {{- if and (or .Params.mermaidDiagrams.enable (and .Site.Params.mermaidDiagrams.enable (ne .Params.mermaidDiagrams.enable false))) (or .IsPage .IsHome) -}} {{ if .Page.Store.Get \u0026#34;hasMermaid\u0026#34; }} \u0026lt;script type=\u0026#34;module\u0026#34;\u0026gt; import mermaid from \u0026#39;https://cdn.jsdelivr.net/npm/mermaid@10.0.2/\u0026#43;esm\u0026#39; //import mermaid from \u0026#39;{{ \u0026#34;lib/mermaid/mermaid.esm.min.mjs\u0026#34; | relURL }}\u0026#39; let mermaidPageOptions = {{ .Page.Params.mermaidDiagrams.options }}; let mermaidSiteOptions = {{ .Site.Params.mermaidDiagrams.options }}; mermaidPageOptions = !!mermaidPageOptions ? mermaidPageOptions : \u0026#34;{}\u0026#34; mermaidSiteOptions = !!mermaidSiteOptions ? mermaidSiteOptions : \u0026#34;{}\u0026#34; mermaidPageOptions = eval(\u0026#34;(\u0026#34; \u0026#43; mermaidPageOptions \u0026#43; \u0026#34;)\u0026#34;) mermaidSiteOptions = eval(\u0026#34;(\u0026#34; \u0026#43; mermaidSiteOptions \u0026#43; \u0026#34;)\u0026#34;) // page options have high priority then site options let mermaidOptions = {...mermaidSiteOptions, ...mermaidPageOptions}; mermaid.initialize(mermaidOptions); \u0026lt;/script\u0026gt; {{ end }} {{- end }} 在对应的markdown页面头部开启mermaid的展示，可根据实际情况添加自定义配置，保存对应markdown文件后页面会自动刷新并展示对应效果\nmermaidDiagrams: enable: true options: \u0026#34;{ \u0026#39;theme\u0026#39;:\u0026#39;forest\u0026#39; }\u0026#34; 自定义样式 mermaid图表的自定义配置主要基于themes来实现，在其官网文档上有很详细的说明，下图为一个简单的示例\n展示效果 基于对应markdown页面的下述配置展示相关效果\nmermaidDiagrams: enable: true options: \u0026#34;{ \u0026#39;theme\u0026#39;:\u0026#39;forest\u0026#39; }\u0026#34; 图表1-Sequence 原始代码\n​```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ​``` 展示效果\nsequenceDiagram Alice-\u003e\u003eJohn: Hello John, how are you? loop Healthcheck John-\u003e\u003eJohn: Fight against hypochondria end Note right of John: Rational thoughts! John--\u003e\u003eAlice: Great! John-\u003e\u003eBob: How about you? Bob--\u003e\u003eJohn: Jolly good! 图表2-Flow 原始代码\n​```mermaid flowchart TD A[Christmas] --\u0026gt;|Get money| B(Go shopping) B --\u0026gt; C{Let me think} C --\u0026gt;|One| D[Laptop] C --\u0026gt;|Two| E[iPhone] C --\u0026gt;|Three| F[fa:fa-car Car] ​``` 展示效果\nflowchart TD A[Christmas] --\u003e|Get money| B(Go shopping) B --\u003e C{Let me think} C --\u003e|One| D[Laptop] C --\u003e|Two| E[iPhone] C --\u003e|Three| F[fa:fa-car Car] 图表3-Class 原始代码\n​```mermiad classDiagram Animal \u0026lt;|-- Duck Animal \u0026lt;|-- Fish Animal \u0026lt;|-- Zebra Animal : \u0026#43;int age Animal : \u0026#43;String gender Animal: \u0026#43;isMammal() Animal: \u0026#43;mate() class Duck{ \u0026#43;String beakColor \u0026#43;swim() \u0026#43;quack() } class Fish{ -int sizeInFeet -canEat() } class Zebra{ \u0026#43;bool is_wild \u0026#43;run() } ​``` 展示效果\nclassDiagram Animal \u003c|-- Duck Animal \u003c|-- Fish Animal \u003c|-- Zebra Animal : +int age Animal : +String gender Animal: +isMammal() Animal: +mate() class Duck{ +String beakColor +swim() +quack() } class Fish{ -int sizeInFeet -canEat() } class Zebra{ +bool is_wild +run() } 图表4-State 原始代码\n​```mermaid stateDiagram-v2 [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*] ​``` 显示效果\nstateDiagram-v2 [*] --\u003e Still Still --\u003e [*] Still --\u003e Moving Moving --\u003e Still Moving --\u003e Crash Crash --\u003e [*] 图表5-ER 原始代码\n​```mermaid erDiagram CUSTOMER }|..|{ DELIVERY-ADDRESS : has CUSTOMER ||--o{ ORDER : places CUSTOMER ||--o{ INVOICE : \u0026#34;liable for\u0026#34; DELIVERY-ADDRESS ||--o{ ORDER : receives INVOICE ||--|{ ORDER : covers ORDER ||--|{ ORDER-ITEM : includes PRODUCT-CATEGORY ||--|{ PRODUCT : contains PRODUCT ||--o{ ORDER-ITEM : \u0026#34;ordered in\u0026#34; ​``` 展示效果\nerDiagram CUSTOMER }|..|{ DELIVERY-ADDRESS : has CUSTOMER ||--o{ ORDER : places CUSTOMER ||--o{ INVOICE : \"liable for\" DELIVERY-ADDRESS ||--o{ ORDER : receives INVOICE ||--|{ ORDER : covers ORDER ||--|{ ORDER-ITEM : includes PRODUCT-CATEGORY ||--|{ PRODUCT : contains PRODUCT ||--o{ ORDER-ITEM : \"ordered in\" 图表6-Gantt 原始代码\n​```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, d Parallel 3 : des5, after des3, 3d Parallel 4 : des6, after des2, 1d ​``` 展示效果\ngantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, d Parallel 3 : des5, after des3, 3d Parallel 4 : des6, after des2, 1d 图表7-UserJourney 原始代码\n​```mermaid journey title My working day section Go to work Make tea: 5: Me Go upstairs: 3: Me Do work: 1: Me, Cat section Go home Go downstairs: 5: Me Sit down: 3: Me ​``` 展示效果\njourney title My working day section Go to work Make tea: 5: Me Go upstairs: 3: Me Do work: 1: Me, Cat section Go home Go downstairs: 5: Me Sit down: 3: Me 图表8-Git 原始代码\n​```mermaid gitGraph commit commit branch develop checkout develop commit commit checkout main merge develop commit commit ​``` 展示效果\ngitGraph commit commit branch develop checkout develop commit commit checkout main merge develop commit commit 图表9-Pie 原始代码\n​```mermaid pie title Pets adopted by volunteers \u0026#34;Dogs\u0026#34; : 386 \u0026#34;Cats\u0026#34; : 85 \u0026#34;Rats\u0026#34; : 15 ​``` 展示效果\npie title Pets adopted by volunteers \"Dogs\" : 386 \"Cats\" : 85 \"Rats\" : 15 图表10-Mindmap 原始代码\n​```mermaid mindmap root((mindmap)) Origins Long history ::icon(fa fa-book) Popularisation British popular psychology author Tony Buzan Research On effectivness\u0026lt;br/\u0026gt;and features On Automatic creation Uses Creative techniques Strategic planning Argument mapping Tools Pen and paper Mermaid ​``` 展示效果\nmindmap root((mindmap)) Origins Long history ::icon(fa fa-book) Popularisation British popular psychology author Tony Buzan Research On effectivnessand features On Automatic creation Uses Creative techniques Strategic planning Argument mapping Tools Pen and paper Mermaid 图表11-timeline 原始代码\n​```mermaid timeline title 我的日常 section 努力搬砖 上午 : 早会: 收邮件/回复邮件 : 查看线上问题 下午 : 需求评审会 : 小组周会: coding 晚上: 加班coding ​``` 展示效果\ntimeline title 我的日常 section 努力搬砖 上午 : 早会: 收邮件/回复邮件 : 查看线上问题 下午 : 需求评审会 : 小组周会: coding 晚上: 加班coding 图表12-graph 原始代码\n​```mermaid graph TB c1--\u0026gt;a2 subgraph one a1--\u0026gt;a2 end subgraph two b1--\u0026gt;b2 end subgraph three c1--\u0026gt;c2 end ​``` 展示效果\ngraph TB c1--\u003ea2 subgraph one a1--\u003ea2 end subgraph two b1--\u003eb2 end subgraph three c1--\u003ec2 end 参考文章:\nhttps://snowdreams1006.github.io/write/mermaid-flow-chart.html https://github.com/olOwOlo/hugo-theme-even/issues?q=is%3Aissue+is%3Aclosed\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n作者个人网站地址为https://olowolo.com，GitHub地址为https://github.com/olOwOlo/hugo-theme-even\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n此处假设我们采用hugo server -w -D来开启草稿模式和动态监测模式\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/adrai/flowchart.js\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://gohugo.io/content-management/diagrams/#mermaid-diagrams\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-03-27T09:46:50+08:00","permalink":"https://lucumt.info/post/hugo/enable-diagrams-in-hugo/","tags":["hugo","go"],"title":"在Hugo中开启图表支持"},{"categories":["容器化"],"contents":"Nacos官方的docker镜像不支持LDAP1同时在连接mysql方面在某些版本中会出现No Datasource Set 的异常，而其官方的release版本则很很稳定，同时又支持LDAP。目前部门很多项目都是基于docker部署的，处于简化使用，基于部署维护等原因，我决定通过Dockerfile来构建符合自己要求的nacos镜像，在确保性能稳定的同时也能支持ldap登录。\n构建过程 初始构建 一开始自己基于Nacos2.2.1下载的tar.gz文件进行构建，主要有如下几个步骤：\n通过FROM拉取openjdk-8基础镜像 拷贝并解压nacos压缩文件 通过sed命令来替换application.properties中的相关配置 通过startup.sh -m standalone 启动nacos 初步的Dockerfile如下\nFROM openjdk:8-jdk MAINTAINER 卢运强 \u0026#34;yunqiang.lu@hirain.com\u0026#34; # 在联网环境下可以通过wget直接下载压缩文件 COPY nacos-server-2.2.1.tar.gz /home/nacos-server-2.2.1.tar.gz WORKDIR /home RUN echo \u0026#34;解压nacos文件\u0026#34; RUN tar -zxvf nacos-server-2.2.1.tar.gz RUN rm -rf nacos-server-2.2.1.tar.gz nacos/conf/*.sql nacos/conf/*.example nacos/bin/* COPY startup.sh /home/nacos/bin/startup.sh RUN mkdir -p /home/nacos/logs #开始修改配置文件 ARG conf=nacos/conf/application.properties RUN sed -i \u0026#34;s/server.servlet.contextPath=\\/nacos/server.servlet.contextPath=\\${SERVER_SERVLET_CONTEXTPATH:\\/nacos}/g\u0026#34; $conf RUN sed -i \u0026#34;s/server.port=8848/server.port=\\${NACOS_SERVER_PORT:8848}/g\u0026#34; $conf #RUN sed -i \u0026#34;s/\\#.*spring.datasource.platform=mysql/spring.datasource.platform=\\${SPRING_DATASOURCE_PLATFORM:\\\u0026#34;mysql\\\u0026#34;}/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*spring.sql.init.platform=mysql/spring.sql.init.platform=\\${SPRING_DATASOURCE_PLATFORM:mysql}/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.num=1/db.num=1/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.url.0.*/db.url.0=jdbc:mysql:\\/\\/\\${MYSQL_SERVICE_HOST}:\\${MYSQL_SERVICE_PORT:3306}\\/\\${MYSQL_SERVICE_DB_NAME}\\?characterEncoding=utf8\\\u0026amp;connectTimeout=1000\\\u0026amp;socketTimeout=3000\\\u0026amp;autoReconnect=true/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.user.0=nacos/db.user=\\${MYSQL_SERVICE_USER:root}/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.password.0=nacos/db.password=\\${MYSQL_SERVICE_PASSWORD}/g\u0026#34; $conf RUN sed -i \u0026#34;s/.*server.tomcat.accesslog.enabled.*/server.tomcat.accesslog.enabled=\\${TOMCAT_ACCESSLOG_ENABLED:false}/g\u0026#34; $conf RUN sed -i \u0026#34;s/.*nacos.core.auth.plugin.nacos.token.secret.key=.*/nacos.core.auth.plugin.nacos.token.secret.key=SecretKey012345678901234567890123456789012345678901234567890123456789/g\u0026#34; $conf; fi RUN chmod \u0026#43;x /home/nacos/bin/startup.sh ENTRYPOINT [\u0026#34;/bin/bash\u0026#34;,\u0026#34;/home/nacos/bin/startup.sh\u0026#34;,\u0026#34;-m\u0026#34;,\u0026#34;standalone\u0026#34;] 基于上述文件构建的镜像通过docker run指令执行时一直启动不成功，而在Linux终端中通过bash startup.sh -m standlone的方式则可以顺利启动nacos，初次尝试失败!\n改进版本 对startup.sh进行检查之后，发现其主要是通过如下的nohup指令启动的\nif [[ \u0026#34;$JAVA_OPT_EXT_FIX\u0026#34; == \u0026#34;\u0026#34; ]]; then nohup \u0026#34;$JAVA\u0026#34; ${JAVA_OPT} nacos.nacos \u0026gt;\u0026gt; ${BASE_DIR}/logs/start.out 2\u0026gt;\u0026amp;1 \u0026amp; else nohup \u0026#34;$JAVA\u0026#34; \u0026#34;$JAVA_OPT_EXT_FIX\u0026#34; ${JAVA_OPT} nacos.nacos \u0026gt;\u0026gt; ${BASE_DIR}/logs/start.out 2\u0026gt;\u0026amp;1 \u0026amp; fi 而docker默认支不支持nohup2,无奈之下只能去nacos官网寻找帮助，在其官方GtiHub中找到了一个文档Dockerfile，其中的启动脚本为docker-startup.sh，对比startup.sh发现主要的差异是前者是采用exec而非 nohup，于是将Dockerfile仿照官方说明修改如下，之后能正常启动\nFROM openjdk:8-jdk MAINTAINER 卢运强 \u0026#34;lucumt@gmail.com\u0026#34; RUN echo $JAVA_HOME #ENV BASE_DIR=\u0026#34;/home/nacos\u0026#34; ENV MODE=\u0026#34;standalone\u0026#34; \\ PREFER_HOST_MODE=\u0026#34;ip\u0026#34;\\ BASE_DIR=\u0026#34;/home/nacos\u0026#34; \\ CLASSPATH=\u0026#34;.:/home/nacos/conf:$CLASSPATH\u0026#34; \\ FUNCTION_MODE=\u0026#34;all\u0026#34; \\ JAVA_HOME=\u0026#34;/usr/local/openjdk-8\u0026#34; \\ NACOS_USER=\u0026#34;nacos\u0026#34; \\ JAVA=\u0026#34;/usr/local/openjdk-8/bin/java\u0026#34; \\ JVM_XMS=\u0026#34;1g\u0026#34; \\ JVM_XMX=\u0026#34;1g\u0026#34; \\ JVM_XMN=\u0026#34;512m\u0026#34; \\ JVM_MS=\u0026#34;128m\u0026#34; \\ JVM_MMS=\u0026#34;320m\u0026#34; \\ NACOS_DEBUG=\u0026#34;y\u0026#34; \\ TOMCAT_ACCESSLOG_ENABLED=\u0026#34;false\u0026#34; \\ TIME_ZONE=\u0026#34;Asia/Shanghai\u0026#34; # 在联网环境下可以通过wget直接下载压缩文件 COPY nacos-server-2.2.1.tar.gz /home/nacos-server-2.2.1.tar.gz WORKDIR /home RUN echo \u0026#34;解压nacos文件\u0026#34; RUN tar -zxvf nacos-server-2.2.1.tar.gz RUN rm -rf nacos-server-2.2.1.tar.gz nacos/conf/*.sql nacos/conf/*.example nacos/bin/* COPY docker-startup.sh /home/nacos/bin/docker-startup.sh RUN mkdir -p /home/nacos/logs #开始修改配置文件 ARG conf=nacos/conf/application.properties RUN sed -i \u0026#34;s/server.servlet.contextPath=\\/nacos/server.servlet.contextPath=\\${SERVER_SERVLET_CONTEXTPATH:\\/nacos}/g\u0026#34; $conf RUN sed -i \u0026#34;s/server.port=8848/server.port=\\${NACOS_SERVER_PORT:8848}/g\u0026#34; $conf #RUN sed -i \u0026#34;s/\\#.*spring.datasource.platform=mysql/spring.datasource.platform=\\${SPRING_DATASOURCE_PLATFORM:\\\u0026#34;mysql\\\u0026#34;}/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*spring.sql.init.platform=mysql/spring.sql.init.platform=\\${SPRING_DATASOURCE_PLATFORM:mysql}/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.num=1/db.num=1/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.url.0.*/db.url.0=jdbc:mysql:\\/\\/\\${MYSQL_SERVICE_HOST}:\\${MYSQL_SERVICE_PORT:3306}\\/\\${MYSQL_SERVICE_DB_NAME}\\?characterEncoding=utf8\\\u0026amp;connectTimeout=1000\\\u0026amp;socketTimeout=3000\\\u0026amp;autoReconnect=true/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.user.0=nacos/db.user=\\${MYSQL_SERVICE_USER:root}/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.password.0=nacos/db.password=\\${MYSQL_SERVICE_PASSWORD}/g\u0026#34; $conf RUN sed -i \u0026#34;s/.*server.tomcat.accesslog.enabled.*/server.tomcat.accesslog.enabled=\\${TOMCAT_ACCESSLOG_ENABLED:false}/g\u0026#34; $conf RUN sed -i \u0026#34;s/.*nacos.core.auth.plugin.nacos.token.secret.key=.*/nacos.core.auth.plugin.nacos.token.secret.key=SecretKey012345678901234567890123456789012345678901234567890123456789/g\u0026#34; $conf RUN chmod \u0026#43;x /home/nacos/bin/docker-startup.sh ENTRYPOINT [\u0026#34;/bin/bash\u0026#34;,\u0026#34;/home/nacos/bin/docker-startup.sh\u0026#34;,\u0026#34;-m\u0026#34;,\u0026#34;standalone\u0026#34;] 支持LDAP 结合公司的实际情况，在部门内部使用时一般采用LDAP登录，而交付给客户时更多的采用普通账号登录，为此需要2份Dockerfile来构建2个不同的镜像，处于简化维护的考虑，自己决定采用1份Dockerfile文件根据构建参数来动态的生成不同的镜像。\n在网络上搜索后发现可以在Dockerfile中执行类似if else的指令3，于是在原有的Dockerfile基础上添加如下指令即可动态的支持LDAP登录\nARG LOGIN_TYPE=nacos RUN sed -i \u0026#34;s/nacos.core.auth.system.type=.*/nacos.core.auth.system.type=${LOGIN_TYPE}/g\u0026#34; $conf RUN if [ $LOGIN_TYPE = \u0026#34;nacos\u0026#34; ];then echo \u0026#34;基于普通登录方式构建\u0026#34;;else echo \u0026#34;基于ldap登录方式构建\u0026#34;; fi # ldap登录认证方式的额外处理 RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.url=.*/nacos.core.auth.ldap.url=\\${LDAP_URL}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.basedc=.*/nacos.core.auth.ldap.basedc=\\${LDAP_BASE_DC}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.userDn=.*/nacos.core.auth.ldap.userDn=\\${LDAP_USER_DN}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.password=.*/nacos.core.auth.ldap.password=\\${LDAP_USER_PASSWORD}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.filter.prefix=.*/nacos.core.auth.ldap.filter.prefix=\\${LDAP_UID}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.case.sensitive=.*/nacos.core.auth.ldap.case.sensitive\\${LDAP_CASE_SENSITIVE}/g\u0026#34; $conf; fi 最终文件 Dockerfile FROM openjdk:8-jdk MAINTAINER 卢运强 \u0026#34;lucumt@gmail.com\u0026#34; RUN echo $JAVA_HOME #ENV BASE_DIR=\u0026#34;/home/nacos\u0026#34; ENV MODE=\u0026#34;standalone\u0026#34; \\ PREFER_HOST_MODE=\u0026#34;ip\u0026#34;\\ BASE_DIR=\u0026#34;/home/nacos\u0026#34; \\ CLASSPATH=\u0026#34;.:/home/nacos/conf:$CLASSPATH\u0026#34; \\ FUNCTION_MODE=\u0026#34;all\u0026#34; \\ JAVA_HOME=\u0026#34;/usr/local/openjdk-8\u0026#34; \\ NACOS_USER=\u0026#34;nacos\u0026#34; \\ JAVA=\u0026#34;/usr/local/openjdk-8/bin/java\u0026#34; \\ JVM_XMS=\u0026#34;1g\u0026#34; \\ JVM_XMX=\u0026#34;1g\u0026#34; \\ JVM_XMN=\u0026#34;512m\u0026#34; \\ JVM_MS=\u0026#34;128m\u0026#34; \\ JVM_MMS=\u0026#34;320m\u0026#34; \\ NACOS_DEBUG=\u0026#34;y\u0026#34; \\ TOMCAT_ACCESSLOG_ENABLED=\u0026#34;false\u0026#34; \\ TIME_ZONE=\u0026#34;Asia/Shanghai\u0026#34; # 在联网环境下可以通过wget直接下载压缩文件 COPY nacos-server-2.2.1.tar.gz /home/nacos-server-2.2.1.tar.gz WORKDIR /home RUN echo \u0026#34;解压nacos文件\u0026#34; RUN tar -zxvf nacos-server-2.2.1.tar.gz RUN rm -rf nacos-server-2.2.1.tar.gz nacos/conf/*.sql nacos/conf/*.example nacos/bin/* COPY docker-startup.sh /home/nacos/bin/docker-startup.sh RUN mkdir -p /home/nacos/logs #开始修改配置文件 ARG conf=nacos/conf/application.properties RUN sed -i \u0026#34;s/server.servlet.contextPath=\\/nacos/server.servlet.contextPath=\\${SERVER_SERVLET_CONTEXTPATH:\\/nacos}/g\u0026#34; $conf RUN sed -i \u0026#34;s/server.port=8848/server.port=\\${NACOS_SERVER_PORT:8848}/g\u0026#34; $conf #RUN sed -i \u0026#34;s/\\#.*spring.datasource.platform=mysql/spring.datasource.platform=\\${SPRING_DATASOURCE_PLATFORM:\\\u0026#34;mysql\\\u0026#34;}/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*spring.sql.init.platform=mysql/spring.sql.init.platform=\\${SPRING_DATASOURCE_PLATFORM:mysql}/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.num=1/db.num=1/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.url.0.*/db.url.0=jdbc:mysql:\\/\\/\\${MYSQL_SERVICE_HOST}:\\${MYSQL_SERVICE_PORT:3306}\\/\\${MYSQL_SERVICE_DB_NAME}\\?characterEncoding=utf8\\\u0026amp;connectTimeout=1000\\\u0026amp;socketTimeout=3000\\\u0026amp;autoReconnect=true/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.user.0=nacos/db.user=\\${MYSQL_SERVICE_USER:root}/g\u0026#34; $conf RUN sed -i \u0026#34;s/\\#.*db.password.0=nacos/db.password=\\${MYSQL_SERVICE_PASSWORD}/g\u0026#34; $conf RUN sed -i \u0026#34;s/.*server.tomcat.accesslog.enabled.*/server.tomcat.accesslog.enabled=\\${TOMCAT_ACCESSLOG_ENABLED:false}/g\u0026#34; $conf RUN sed -i \u0026#34;s/.*nacos.core.auth.plugin.nacos.token.secret.key=.*/nacos.core.auth.plugin.nacos.token.secret.key=SecretKey012345678901234567890123456789012345678901234567890123456789/g\u0026#34; $conf ARG LOGIN_TYPE=nacos RUN sed -i \u0026#34;s/nacos.core.auth.system.type=.*/nacos.core.auth.system.type=${LOGIN_TYPE}/g\u0026#34; $conf RUN if [ $LOGIN_TYPE = \u0026#34;nacos\u0026#34; ];then echo \u0026#34;基于普通登录方式构建\u0026#34;;else echo \u0026#34;基于ldap登录方式构建\u0026#34;; fi # ldap登录认证方式的额外处理 RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.url=.*/nacos.core.auth.ldap.url=\\${LDAP_URL}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.basedc=.*/nacos.core.auth.ldap.basedc=\\${LDAP_BASE_DC}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.userDn=.*/nacos.core.auth.ldap.userDn=\\${LDAP_USER_DN}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.password=.*/nacos.core.auth.ldap.password=\\${LDAP_USER_PASSWORD}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.filter.prefix=.*/nacos.core.auth.ldap.filter.prefix=\\${LDAP_UID}/g\u0026#34; $conf; fi RUN if [ $LOGIN_TYPE = \u0026#34;ldap\u0026#34; ];then sed -i \u0026#34;s/\\#nacos.core.auth.ldap.case.sensitive=.*/nacos.core.auth.ldap.case.sensitive\\${LDAP_CASE_SENSITIVE}/g\u0026#34; $conf; fi RUN chmod \u0026#43;x /home/nacos/bin/docker-startup.sh ENTRYPOINT [\u0026#34;/bin/bash\u0026#34;,\u0026#34;/home/nacos/bin/docker-startup.sh\u0026#34;,\u0026#34;-m\u0026#34;,\u0026#34;standalone\u0026#34;] 构建方式 在构建时需要将Dockerfile、docker-startup.sh以及对应的nacos压缩文件放到同一个目录下\n普通登录方式构建\n# 不传递登录参数 docker build -t nacos_custom:v1.0 . # 显示指定登录参数 docker build -t nacos_custom:v1.0 --build-arg LOGIN_TYPE=nacos . LDAP登录方式构建\ndocker build -t nacos_custom:v1.0 --build-arg LOGIN_TYPE=ldap . 使用方式 假设存储数据库为mysql采用docker-compose方式登录，相关的docker-compose.yml文件如下:\n普通方式登录\nversion: \u0026#34;3\u0026#34; services: nacos: image: nacos_custom:v1.0 restart: always container_name: nacos_custom ports: - 8858:8858 environment: - TZ=Asia/Shanghai - NACOS_SERVER_PORT=8858 - SPRING_DATASOURCE_PLATFORM=mysql - MYSQL_SERVICE_HOST=xxxx - MYSQL_SERVICE_PORT=xxxx - MYSQL_SERVICE_DB_NAME=nacos_test - MYSQL_SERVICE_USER=root - MYSQL_SERVICE_PASSWORD=654321 volumes: - $PWD/logs:/home/nacos/logs/ LDAP登录\nversion: \u0026#34;3\u0026#34; services: nacos: image: nacos_custom:v1.0 restart: always container_name: nacos_custom ports: - 8858:8858 environment: - TZ=Asia/Shanghai - NACOS_SERVER_PORT=8858 - SPRING_DATASOURCE_PLATFORM=mysql - MYSQL_SERVICE_HOST=xxxx - MYSQL_SERVICE_PORT=3316 - MYSQL_SERVICE_DB_NAME=nacos_test - MYSQL_SERVICE_USER=root - MYSQL_SERVICE_PASSWORD=xxxx - LDAP_URL=ldap://xxxx:389 - LDAP_BASE_DC=dc=xxx,dc=xxx - LDAP_USER_DN=cn=xxx,dc=xxx,dc=com - LDAP_USER_PASSWORD=xxxx - LDAP_UID=uid - LDAP_CASE_SENSITIVE=false volumes: - $PWD/logs:/home/nacos/logs/ 镜像参数说明 属性 作用 默认值 可选值 NACOS_SERVER_PORT nacos服务器端口 8848 SPRING_DATASOURCE_PLATFORM 指定nacos的数据源 mysql mysql或空 MYSQL_SERVICE_HOST mysql服务器地址 MYSQL_SERVICE_PORT mysql服务器端口 3306 MYSQL_SERVICE_DB_NAME mysql数据库名称 MYSQL_SERVICE_USER mysql数据库用户名 root MYSQL_SERVICE_PASSWORD mysql数据据密码 LDAP_URL ldap服务的地址和端口号 LDAP_BASE_DC ldap搜索范围 LDAP_USER_DN ldap绑定账号4 LDAP_USER_PASSWORD ldap绑定账号的密码 LDAP_UID 用户账号字段 LDAP_CASE_SENSITIVE ldap认证时是否大小写敏感 https://github.com/alibaba/nacos/issues/9751\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://unix.stackexchange.com/questions/268284/nohup-doesnt-work-as-expected-in-docker-script\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://stackoverflow.com/questions/43654656/dockerfile-if-else-condition-with-external-arguments\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n部分LDAP数据库不支持匿名登录，此时需要管理员账号来绑定登录\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-03-24T15:59:58+08:00","permalink":"https://lucumt.info/post/docker/build-custom-nacos-image-to-support-ldap-and-mysql/","tags":["docker","nacos","ldap"],"title":"构建自定义的Nacos镜像支持MySQL数据源与LDAP认证"},{"categories":["脚本操作","持续集成"],"contents":"基于在Jenkins中根据配置从不同的仓库中Checkout代码一文，说明如何利用shell脚本在Linux系统中实现自动化的部署与升级。\n流程图 整体流程如下图所示：\n首先让用户选择要升级的类别和模块，并对用户选择进行校验，若不合法则升级过程终止 根据用户选择去相关目录下查看对应的文件是否存在，若不存在则升级过程终止 若文件存在则对其进行解压，并读取其中的配置文件信息1 检查对应的容器，将其停止并删除 导入相关镜像 拼接docker语句并执行，展示执行结果 flowchart TD START((开始部署)):::start FAIL((部署失败)):::failed SUCCESS((部署成功)):::success subgraph deploy_select [输入选择] A1[选择类别]:::input --\u003e A2{类别是否有效} A2 --\u003e|类别有效| A3[选择模块]:::input A3 --\u003e A4{模块是否有效} A4 --\u003e|模块有效| A5[(记录用户选择)] end subgraph parse_file [解析文件] B1[查找文件] --\u003e B2{文件是否存在} B2 --\u003e|文件存在| B3[解压文件] B3 --\u003e B4[读取ini配置文件] B4 --\u003e B5[/输出用户选择与配置文件信息/] end subgraph deploy_process [开始部署] C1{容器是否运行} --\u003e|容器运行|C2[停止容器] C1 --\u003e|容器未运行| C3[删除容器] C2 --\u003e C3 C3 --\u003e C4[导入镜像]:::input C4 --\u003e C5[拼接docker字符串] C5 --\u003e C6[打印要执行的docker语句] C6 --\u003e C7[执行docker语句] C7 --\u003e C8{docker容器是否执行成功} C8 --\u003e|docker执行成功|C9 end START --\u003e A1 A2 --\u003e|类别无效| FAIL A4 --\u003e|模块无效| FAIL A5 --\u003e B1 B2 --\u003e|文件不存在|FAIL B5 --\u003e C5 C8 --\u003e|docker执行失败|FAIL C9 --\u003e SUCCESS classDef start fill:#374bad,color:#ffffff,font-weight:bold,stroke-width:0 classDef failed fill:#f5425d,color:#ffffff,font-weight:bold,stroke-width:0 classDef input fill:#ad5537,color:#ffffff,stroke-width:0 classDef success fill:#37ad61,color:#ffffff,font-weight:bold,stroke-width:0 使用说明 此部分操作主要基于前述的流程以shell脚本的形式实现，相关源码参见deploy.sh，具体操作流程如下：\n将deploy.sh拷贝到Linux服务器的某个目录下，然后在该目录下建立一个名为**target**的目录，将导出的镜像文件放到target目录下\n执行./deploy命令并按下Enter键，终端会出现如下输出，让我们选择要升级的系统为前端还是后端\n根据提示选择对应的类别，若升级类型为前端则输入1，若升级类型为后端则输入2，之后按下Enter键则系统会进一步提示选择对应的模块\n若输入的类型不合法，则升级脚本会给出对应的提示，同时整个升级过程立即终止\n若要部署的模块在target目录下不存在或选择的模块不是选择列表的模块，升级脚本同样会给出提示，同时整个升级过程立即终止\n若部署的模块在target目录下存在多份，则会根据文件名中附带的时间戳进行排序，寻找最近的一份文件进行升级\n# 校验升级文件是否存在 file=$(ls target|sort -r|grep ${module}_20|head -1) # 此条指令根据文件名按时间倒排，取第一个文件来升级 if [[ -z \u0026#34;$file\u0026#34; ]] then printf \u0026#34;\\033[31mtarget目录下没有对应的文件，升级操作终止，请重新执行./deploy.sh\\033[0m\\n\u0026#34; exit 0 fi 若选择的模块合法，且升级过程一切顺利，Linux终端会输出类似如下信息，提示整个升级过程完成!\n若升级过程中遇到错误，系统同样会给出提示，可根据错误信息进行初步排查\n待优化点 升级过程缺少记录，无法查看在特定时间范围通过该脚本执行升级的次数，可通过写入文件实现简单的数据库记录 缺少回退功能，在最后启动docker容器失败是，应能将之前关闭的服务启动，确保能持续对外提供服务 对于集群方式部署的docker容器缺少兼容性 此信息在部署过程中会输出，用于确认版本和配是否正确\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-03-16T11:22:47+08:00","permalink":"https://lucumt.info/post/linux/using-script-to-deploy-microservice-application-in-docker/","tags":["linux","docker","shell"],"title":"利用shell脚本实现将微服务程序以docker容器方式自动部署"},{"categories":["脚本操作"],"contents":"简要介绍在Windows系统中采用基于CMD的批处理脚本进行自动化部署时，对通过\u0026amp;\u0026amp;拼接的指令以更优雅的方式实现，以提高批处理脚本的可读性和可维护性。\n问题说明 项目背景 公司有个基于Python开发的项目近期要交付给客户，为了便于安装和后续升级，之前都是采用PyInstaller安装成exe可执行文件实现傻瓜式的操作，而这个项目出于避免与客户服务器其它Python环境冲突以及便于后续扩展的考量，在软件部署和升级时采用了Anaconda进行隔离式部署，其部署流程如下1\nstart=\u003estart: 开始 end=\u003eend: 结束 conda_create=\u003eoperation: 创建conda环境 conda_active=\u003eoperation: 激活conda环境 pip_install=\u003eoperation: pip安装依赖 python_run=\u003eoperation: 执行python程序 start-\u003econda_create conda_create-\u003econda_active conda_active-\u003epip_install pip_install-\u003epython_run python_run-\u003eend 各步骤涉及到的操作主要有:\n创建conda环境，conda create -n lyq_test -y 激活conda环境，conda activate lyq_test 安装pip依赖，pip install -r requirements.txt 执行python程序，python hello.py 这些步骤对于专业的开发人员而言操作起来很快速，但对于相关的使用客户而言，他们不一定具有相关的编程经验，执行上述指令容易出错，便利性有待提高。\n由于目标客户的环境为Windows，同项目成员沟通后决定采用CMD批处理脚本来包含上述命令，实际部署或升级时只需要运行该批处理脚本即可。\n面临的问题 最开始采用的install.bat批处理脚本类似如下\n@echo off title 一键部署与升级脚本 echo ===========开始创建conda环境============== conda create -n lyq_test -y conda activate lyq_test pip install -r requirements.txt python hello.py pause 运行结果如下，可发现从conda create -n lyq_test -y之后的指令均没有执行\n一开始自己以为是由于Anaconda的创建需要时间，于是参考Stackoverflow中的说明2在conda activate之前添加了一条睡眠指令，测试结果和上图一样，问题依旧。\n@echo off title 一键部署与升级脚本 echo ===========开始创建conda环境============== conda create -n lyq_test -y rem 睡眠10秒钟 ping -n 10 127.0.0.1 \u0026gt; nul conda activate lyq_test pip install -r requirements.txt python hello.py pause 参考网上的资料和自己尝试后发现将批处理脚本中的命令用\u0026amp;\u0026amp;3拼接起来然后一起执行就能达到要求\n@echo off title 一键部署与升级脚本 echo ===========开始创建conda环境============== conda create -n lyq_test -y \u0026amp;\u0026amp; conda activate lyq_test \u0026amp;\u0026amp; pip install -r requirements.txt \u0026amp;\u0026amp; python hello.py pause 运行结果如下，虽然批处理脚本的执行结果符合自己的预期，但此种解决方案带来了一个很严重的副作用\n通过\u0026amp;\u0026amp;将多条指令拼接在一起的结果是脚本中只有一条超长的指令，会导致批处理脚本的可读性和可维护性都严重降低！\n解决方案 由于随着项目的进行，install.bat脚本肯定会进行不断地修正与更新，install.bat脚本的可维护性与可读性是必须要解决的问题，但采用\u0026amp;\u0026amp;拼接的方式也不能放弃，只能另想它法。\n继续寻求Stackoverflow4的协助5，将install.bat通过SET来重新赋值的方式进行变量拼接，修改后的代码如下\n@echo off title 一键部署与升级脚本 echo ===========开始创建conda环境============== set command=conda create -n lyq_test -y set command=%command% \u0026amp;\u0026amp; conda activate lyq_test set command=%command% \u0026amp;\u0026amp; pip install -r requirements.txt set command=%command% \u0026amp;\u0026amp; python hello.py echo 拼接后的命令如下 echo %command% echo 开始执行拼接后的命令 %command% pause 执行结果如下，虽然能成功进入Anaconda环境，但是后续的指令都没有执行。\n看起来似乎是胜利在望，但仔细分析后发现只所以能进入Anaconda环境是由于第1个\u0026amp;\u0026amp;配置生效，导致批处理文件提前执行，而后续的拼接指令没有机会执行6，还是没法实现最终目的。\n为了避免提前执行，尝试用双引号将相关指令封装起来，在拼接完成后统一执行\n@echo off title 一键部署与升级脚本 echo ===========开始创建conda环境============== set \u0026#34;command=conda create -n lyq_test -y\u0026#34; set \u0026#34;command=%command% \u0026amp;\u0026amp; conda activate lyq_test\u0026#34; set \u0026#34;command=%command% \u0026amp;\u0026amp; pip install -r requirements.txt\u0026#34; set \u0026#34;command=%command% \u0026amp;\u0026amp; python hello.py\u0026#34; echo 拼接后的命令如下 echo %command% echo 开始执行拼接后的命令 %command% pause 执行结果如下，虽然最终的执行结果符合预期，但很明显打印出来的拼接数据不是我们想要的，不利于后续分析，同时一些echo打印指令没有执行，此方案存在瑕疵，实际使用中风险很大。\n经过一段时间的搜索后没有找到自己想要的答案，只能在Stackoverflow上提问希望能获得帮助，最终通过7得到了一个较为满意的解决方案。\n该方案主要通过字符串截取来实现8，修改后的脚本如下\n@echo off title 一键部署与升级脚本 echo ===========开始创建conda环境============== set command=conda create -n lyq_test -y rem 要特别注意第1次拼接时不能加上:~1,-1 set command=\u0026#34;%command% \u0026amp;\u0026amp; conda activate lyq_test\u0026#34; set command=\u0026#34;%command:~1,-1% \u0026amp;\u0026amp; pip install -r requirements.txt\u0026#34; set command=\u0026#34;%command:~1,-1% \u0026amp;\u0026amp; python hello.py\u0026#34; echo ==========拼接后的命令如下=========== echo %command% echo ==========开始执行拼接后的命令============ %command:~1,-1% pause 脚本执行结果如下，结果符合预期，在确保脚本能正常执行的前提下也满足了可维护性与可读性，问题解决!\n此处出于简化篇幅的考虑，只列出了这4个步骤，实际项目中的步骤会更多\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://stackoverflow.com/questions/735285/how-to-wait-in-a-batch-script\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026amp;\u0026amp;在批处理文件中表示只有当前面的指令执行成功时才执行后面的指令，\u0026amp;则表示无论前述指令是否执行成功，都执行后面的指令\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://stackoverflow.com/questions/17743757/how-to-concatenate-strings-in-windows-batch-file-for-loop\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n或许求助ChatGPT是一个更好的方案\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n此处是基于个人理解的说明，不一定正确，主要是为了说明通过常规的变量重新赋值方式不可行\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://stackoverflow.com/questions/75646525/how-to-use-in-command-line-in-variable-in-windows\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://superuser.com/questions/228794/how-to-extract-part-of-a-string-in-windows-batch-file\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-03-10T22:48:56+08:00","permalink":"https://lucumt.info/post/cmd/combine-mutiple-command-with-ampersand-elegant-in-cmd/","tags":["cmd"],"title":"在批处理脚本中利用\u0026\u0026命令将多条命令优雅的拼接在一起"},{"categories":["持续集成"],"contents":" 简要介绍如何在KubeSphere中使用Jenkins基于用户选择的不同GitLab工程模块利用Git进行动态的代码下载和编译构建，将多条流水线缩减为一条，减少Jenkins流水线的开发与维护成本。\n背景 在利用Nacos与KubeSphere创建多套开发与测试环境一文中介绍了部门基于KubeSphere和Nacos来动态的创建多套开发与测试环境，此种方式虽然在公司内部使用起来很灵活，但当需要交付给客户时会存在如下问题导致KubeSphere不适合部署给客户使用:\n客户使用环境的网络无法接入公司网络，无法下载代码 客户使用环境不一定有Kubernetes环境，无法部署pod节点 由于docker的安装相对Kubernetes而言会简单很多，故决定采用docker容器的形式在客户现场部署运行软件，相关流程如下： 实际使用时在公司内部提前打包好对应的docker镜像并导出，然后在客户环境导入对应的docker镜像并运行即可，通过此种方式可有效的避免对于公司内部特定环境和配置的依赖。\n为实现上述目的，可通过docker save先导出镜像，然后使用Jenkins的archiveArtifacts功能导出镜像文件即可，这样看来问题似乎很容易解决，直接修改原有的Jenkins流水线即可。由于不同项目模块在使用上会有细微的差异，同时处于简化开发和维护的考虑，目前部门的使用方式是每个工程对应一条Jenkins流水线，这样导致每条流水线都需要修改，工作量且不利于后续的扩展！\n基于上述原因，最终的实现方案如下\n实现方案\n部门内部研发测试使用的构建流水线与要交付给客户的产品构建流水线分开创建与使用，且交付构建的流水线数目要尽可能少，便于后续维护与定制化扩展\n下图展示了更详细的使用流程，在该图中引出了我们的问题\n问题\n如何在Jenkins中只通过一条流水线根据用户选择的工程模块来动态的下载代码?\nflowchart TD subgraph A1(开始构建) --\u003eA2{选择对应参数} A2 --\u003e|用于获取端口等配置| A3[打包环境] A2 --\u003e A4[选择工程]:::checkstyle A2 --\u003e|对应工程Gitlab分支| A5[选择分支]:::checkstyle A4 --\u003e A6[[Checkout代码]]:::checkstyle A5 --\u003e A6 A6 --\u003e |更新yaml等配置文件| A7[更新配置] A3 --\u003e A7 A7 --\u003e A8[[代码编译]] A8 --\u003e A9[(导出jar文件)] A8 --\u003e A10[镜像构建] A10 --\u003e A11[(导出镜像)] A9 --\u003e A12(((构建结束))) A11 --\u003e A12 end subgraph B1(导入镜像) --\u003e B2[文件校验] --\u003e B3[[容器部署]] end subgraph C1(导入jar) --\u003e C2[文件校验] --\u003e C3[[运行jar]] end A11 --\u003e|docker方式部署| B1 A9 --\u003e |直接运行jar文件| C1 classDef checkstyle fill:#6bacf2,color:#ffffff,font-weight:bold 解决思路 由于最初是每个工程项目都有一个单独的Jenkins流水线，故在通过Git下载代码时采用的是类似下图的直接写死Gitlab工程仓库地址的方式，很明显此种方式不满足要求。\nstage(\u0026#39;拉取代码\u0026#39;) { agent none steps { // git仓库地址直接以字符串方式写死 git(credentialsId: \u0026#39;gitlab-account\u0026#39;, url: \u0026#39;http://gitlab.xxx.com/lucumt-group/system.git\u0026#39;, branch: \u0026#39;$BRANCH_NAME\u0026#39;, changelog: true, poll: false) } } 在网上搜索后发现一篇文章dynamically-selecting-git-repo-in-jenkins-job,其采用parameters实现，将Gitlab仓库的地址存储在一个变量中，然后Git下载时实际计算变量值并进行下载。此方案看起来符合要求，进一步查找后发现parameters本身无法直接修改1，不满足使用要求。\n由于先前对代码分支名称的获取可通过$BRANCH_NAME来实现，自己尝试采用类似的方式来验证，最终找到了符合要求的实现方案\n下图展示了完整的使用链路，可发现其实现复杂度不是很高\n展示效果 运行结果如下：\n相关流水线参考如下：\n流水线 作用 备注 lucumt-server-image-build.groovy 服务器端打包流水线，产出物为docker镜像 lucumt-front-image-build.groovy 前端打包流水线，产出物为docker镜像 lucumt-server-jar-build.groovy 服务器端打包流水线，产出物为jar文件 可直接用Java运行该jar文件 lucumt-front-dist-build.groovy 服务器端打包流水线，产出物为zip文件 nodejs编译后的文件压缩 https://stackoverflow.com/questions/61789938/change-jenkins-param-variable-value\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-03-10T22:48:50+08:00","permalink":"https://lucumt.info/post/devops/git-checkout-by-dynamic-repository-in-jenkins/","tags":["kubesphere","jenkins","git"],"title":"在Jenkins中根据配置从不同的仓库中Checkout代码"},{"categories":[],"contents":"一个混迹于帝都的程序猿，主要从事Java、Python和Golang相关的开发工作，欢迎互相交流!\n编程领域 Java，日常编程主要使用的语言，吃饭的家伙 Python，主要用它进行网络爬虫开发和web开发 Golang,个人业余爱好，希望在此领域长期发展 MySQL、MongoDB HTML、Javascript、jQuery、CSS 个人信息 教育信息 中国矿业大学 (2006.9-2010.6) 计算机科学与技术 (本科) 自我评价 热爱学习和使用新技术； 有着十分强烈的代码洁癖； 喜欢重构代码，善于分析和解决问题； 个人爱好 编程 英语 学习 联系方式 Email: lucumt@gmail.com,cumtlu@126.com Skype: lu.rosen QQ: 317801876 领英: 卢运强 友情链接 Frantic log#1048 cold\u0026rsquo;s world 邪恶二进制 Javmain\u0026rsquo;s Blog 小林Coding 云原生实验室 ","date":"2023-02-27T18:44:29+08:00","permalink":"https://lucumt.info/about/","tags":[],"title":"关于我"},{"categories":["Java编程"],"contents":"在软件开发领域，大部分时间精确到秒或毫秒即可满足日常需求，但在某些对时间要求严格的场景中需要使用微秒、纳秒等更精确的时间值，本文简要记录如何在Java中通过LocalDateTime实现对于微秒、纳秒的精确解析以及转化为long型时间戳。\njava.util.Date中相关实现 格式化测试 首先采用采用如下代码验证java.util.Date和java.text.SimpleDateFormat对于时间戳的支持情况。\npublic class TestDateConvert1 { public static void main(String[] args) { String text1 = \u0026#34;2023/01/04 17:54:38\u0026#34;; String text2 = \u0026#34;2023/01/04 17:54:38.610\u0026#34;; String text3 = \u0026#34;2023/01/04 17:54:38.610502\u0026#34;; String text4 = \u0026#34;2023/01/04 17:54:38.610502567\u0026#34;; try { testDate1(text1); testDate2(text2); testDate3(text3); testDate4(text4); } catch (ParseException e) { throw new RuntimeException(e); } } public static void testDate1(String text) throws ParseException { DateFormat df = new SimpleDateFormat(\u0026#34;yyyy/MM/dd HH:mm:ss\u0026#34;); //精确到秒 Date newDate = df.parse(text); System.out.println(\u0026#34;----------------精确到秒------------------------------\u0026#34;); System.out.println(\u0026#34;原始时间:\\t\u0026#34; \u0026#43; text); System.out.println(\u0026#34;解析后的时间:\\t\u0026#34; \u0026#43; df.format(newDate)); System.out.println(); } public static void testDate2(String text) throws ParseException { DateFormat df = new SimpleDateFormat(\u0026#34;yyyy/MM/dd HH:mm:ss.SSS\u0026#34;); // 精确到毫秒 Date newDate = df.parse(text); System.out.println(\u0026#34;----------------精确到毫秒----------------------------\u0026#34;); System.out.println(\u0026#34;原始时间:\\t\u0026#34; \u0026#43; text); System.out.println(\u0026#34;解析后的时间:\\t\u0026#34; \u0026#43; df.format(newDate)); System.out.println(); } public static void testDate3(String text) throws ParseException { DateFormat df = new SimpleDateFormat(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSS\u0026#34;); //精确到微秒 Date newDate = df.parse(text); System.out.println(\u0026#34;----------------精确到微秒----------------------------\u0026#34;); System.out.println(\u0026#34;原始时间:\\t\u0026#34; \u0026#43; text); System.out.println(\u0026#34;解析后的时间:\\t\u0026#34; \u0026#43; df.format(newDate)); System.out.println(); } public static void testDate4(String text) throws ParseException { DateFormat df = new SimpleDateFormat(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSSSSS\u0026#34;); //精确到微秒 Date newDate = df.parse(text); System.out.println(\u0026#34;----------------精确到纳秒----------------------------\u0026#34;); System.out.println(\u0026#34;原始时间:\\t\u0026#34; \u0026#43; text); System.out.println(\u0026#34;解析后的时间:\\t\u0026#34; \u0026#43; df.format(newDate)); } } 运行结果如下：\n从上图中可以看出时间精确到微秒之后，采用java.util.Date和java.text.SimpleDateFormat进行输出时前后的结果已经不一致。同时也可以大致猜测，当使用java.util.Date时不能用其进行微秒或纳秒等高精度的时间存储展示，但此问题是由java.util.Date还是java.text.SimpleDateFormat造成的暂不确定。\n对比数据测试 为了测试结果的准确性，在www.timestamp-converter.com中获取一个可用于验证的时间戳信息如下所示\n其中基于毫秒的时间戳为1676628010725，格式化后的显示为2023-02-17T10:00:10.725Z，采用下述代码进行验证：\npublic static void testDateCreate() { DateFormat df1 = new SimpleDateFormat(\u0026#34;yyyy/MM/dd HH:mm:ss\u0026#34;); DateFormat df2 = new SimpleDateFormat(\u0026#34;yyyy/MM/dd HH:mm:ss.SSS\u0026#34;); DateFormat df3 = new SimpleDateFormat(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSS\u0026#34;); DateFormat df4 = new SimpleDateFormat(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSSSSS\u0026#34;); long timestamp1 = 1676628010725L;//前述获取到的时间戳 Date date = new Date(timestamp1); long timestamp2 = date.getTime(); System.out.println(\u0026#34;timestamp1:\\t\u0026#34; \u0026#43; timestamp1); System.out.println(\u0026#34;timestamp2:\\t\u0026#34; \u0026#43; timestamp2); System.out.println(\u0026#34;精确到秒:\\t\u0026#34; \u0026#43; df1.format(date)); System.out.println(\u0026#34;精确到毫秒:\\t\u0026#34; \u0026#43; df2.format(date)); System.out.println(\u0026#34;精确到微秒:\\t\u0026#34; \u0026#43; df3.format(date)); System.out.println(\u0026#34;精确到纳秒:\\t\u0026#34; \u0026#43; df4.format(date)); } 运行结果如下\n从结果中可知微秒与纳秒的结果与网站中展示的不一致，但是仍然无法确定到底是java.util.Date还是java.text.SimpleDateFormat的原因。\n在java.util.Date的官方文档中可找到如下说明，从图中可知当采用时间戳来构造java.util.Date时，其接收的参数为毫秒相对数据值，不支持微秒和纳秒。\n在java.text.SimpleDateFormate的官方文档中有如下说明，同样可知道java.text.SimpleDateFormat不支持微秒和纳秒级别的时间精度。\n初步结论:\njava.util.Date和java.text.SimpleDateFormat均不支持微秒和纳秒级别的时间精度。\nLocalDateTime中实现 由于JDK8中引入了LocalDateTime，故将最开始的测试代码都修改为使用java.time.LocalDateTime和java.time.format.DateTimeFormatter进行测试\npublic class TestDateConvert3 { public static void main(String[] args) { String text1 = \u0026#34;2023/01/04 17:54:38\u0026#34;; String text2 = \u0026#34;2023/01/04 17:54:38.610\u0026#34;; String text3 = \u0026#34;2023/01/04 17:54:38.610502\u0026#34;; String text4 = \u0026#34;2023/01/04 17:54:38.610502567\u0026#34;; try { testDate1(text1); testDate2(text2); testDate3(text3); testDate4(text4); } catch (ParseException e) { throw new RuntimeException(e); } } public static void testDate1(String text) throws ParseException { DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy/MM/dd HH:mm:ss\u0026#34;); //精确到秒 LocalDateTime newDate = LocalDateTime.parse(text,formatter); System.out.println(\u0026#34;----------------精确到秒------------------------------\u0026#34;); System.out.println(\u0026#34;原始时间:\\t\u0026#34; \u0026#43; text); System.out.println(\u0026#34;解析后的时间:\\t\u0026#34; \u0026#43; formatter.format(newDate)); System.out.println(); } public static void testDate2(String text) throws ParseException { DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy/MM/dd HH:mm:ss.SSS\u0026#34;); //精确到毫秒 LocalDateTime newDate = LocalDateTime.parse(text,formatter); System.out.println(\u0026#34;----------------精确到毫秒----------------------------\u0026#34;); System.out.println(\u0026#34;原始时间:\\t\u0026#34; \u0026#43; text); System.out.println(\u0026#34;解析后的时间:\\t\u0026#34; \u0026#43; formatter.format(newDate)); System.out.println(); } public static void testDate3(String text) throws ParseException { DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSS\u0026#34;); //精确到微秒 LocalDateTime newDate = LocalDateTime.parse(text,formatter); System.out.println(\u0026#34;----------------精确到微秒----------------------------\u0026#34;); System.out.println(\u0026#34;原始时间:\\t\u0026#34; \u0026#43; text); System.out.println(\u0026#34;解析后的时间:\\t\u0026#34; \u0026#43; formatter.format(newDate)); System.out.println(); } public static void testDate4(String text) throws ParseException { DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSSSSS\u0026#34;); //精确到纳秒 LocalDateTime newDate = LocalDateTime.parse(text,formatter); System.out.println(\u0026#34;----------------精确到纳秒----------------------------\u0026#34;); System.out.println(\u0026#34;原始时间:\\t\u0026#34; \u0026#43; text); System.out.println(\u0026#34;解析后的时间:\\t\u0026#34; \u0026#43; formatter.format(newDate)); System.out.println(); } } 测试结果如下：\n从中可知当联合采用java.time.LocalDateTime和java.time.format.DateTimeFormatter时，能够支持到纳秒级别，可满足要求。\n在java.time.LocalDateTime的官方文档中有如下说明，从图中可知java.time.LocalDateTime支持到纳秒级别的时间精度\n在java.time.format.DateTimeFormatter的官方文档中有如下说明,从图中可知java.time.format.DateTimeFormatter也支持纳秒级别的格式化。\n最终结论:\njava.time.LocalDateTime支持纳秒级别的时间存储，支持java.time.format.DateTimeFormatter支持纳秒级别的时间显示。\nLocalDateTime与时间戳互转 在java.util.Date中可以很容易的通过Date().getTime()和new Date(long timestamp)来分别获取时间戳和基于时间戳构造时间，而在java.time.LocalDateTime中要实现类似功能则稍微复杂点。\n当要获取long类型的时间戳时，需要先获取秒，再获取微秒或纳秒，然后根据他们之前的换算关系进行累加返回，相关公式如下：\n$微秒时间戳=秒 \\times 10^6 +微秒$ $纳秒时间戳=秒 \\times 10^9 +纳秒$ 有了时间戳之后根据上述公式进行反向操作，分别获取秒与微秒(纳秒)，然后根据这2个数值通过Instant构建即可。\n与微秒互转 public class TestDateConvert4 { public static void main(String[] args) { long time = convertTimeToMills(\u0026#34;2023/01/04 17:54:38.610502\u0026#34;); convertMillsToTime(time); } public static long convertTimeToMills(String originalText) { DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSS\u0026#34;); System.out.println(originalText); LocalDateTime dateTime = LocalDateTime.parse(originalText, formatter); ZoneId zoneId = ZoneId.systemDefault(); Instant instant = dateTime.atZone(zoneId).toInstant(); long seconds = instant.getEpochSecond(); int micros = instant.get(ChronoField.MICRO_OF_SECOND); long total = seconds * 1_000_000 \u0026#43; micros; return total; } public static LocalDateTime convertMillsToTime(long time) { long sec = time / 1_000_000; long mic = time % 1_000_000; Instant instant1 = Instant.ofEpochSecond(sec).plus(mic, ChronoUnit.MICROS); ZoneId zoneId = ZoneId.systemDefault(); LocalDateTime localDateTime = LocalDateTime.ofInstant(instant1, zoneId); DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSS\u0026#34;); System.out.println(formatter.format(localDateTime)); return localDateTime; } } 测试结果如下，符合预期\n与纳秒互转 public class TestDateConvert5 { public static void main(String[] args) { long time = convertTimeToMills(\u0026#34;2023/01/04 17:54:38.610502987\u0026#34;); convertMillsToTime(time); } public static long convertTimeToMills(String originalText) { DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSSSSS\u0026#34;); System.out.println(originalText); LocalDateTime dateTime = LocalDateTime.parse(originalText, formatter); ZoneId zoneId = ZoneId.systemDefault(); Instant instant = dateTime.atZone(zoneId).toInstant(); long seconds = instant.getEpochSecond(); int micros = instant.get(ChronoField.NANO_OF_SECOND); long total = seconds * 1_000_000_000 \u0026#43; micros; return total; } public static LocalDateTime convertMillsToTime(long time) { long sec = time / 1_000_000_000; long mic = time % 1_000_000_000; Instant instant1 = Instant.ofEpochSecond(sec).plus(mic, ChronoUnit.NANOS); ZoneId zoneId = ZoneId.systemDefault(); LocalDateTime localDateTime = LocalDateTime.ofInstant(instant1, zoneId); DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy/MM/dd HH:mm:ss.SSSSSSSSS\u0026#34;); System.out.println(formatter.format(localDateTime)); return localDateTime; } } 测试结果如下，符合预期\n参考文章：\nhttps://www.cnblogs.com/yangxunwu1992/p/5769533.html https://stackoverflow.com/questions/30135025/java-date-parsing-with-microsecond-or-nanosecond-accuracy ","date":"2023-02-17T13:48:05+08:00","permalink":"https://lucumt.info/post/java-core/parse-and-store-microsecond-nanosecond-in-java/","tags":["Java"],"title":"在Java中解析和存储包含微秒与纳秒的时间"},{"categories":["容器化"],"contents":"工作中涉及到Kubernetes相关知识，自己之前一直没有系统性的学习Kubernetes，近期在腾讯云上想安装Kubernetes时一直遇到在执行kubeadm init时6443和10280端口无法访问导致操作失败进而无法顺利安装Kubernetes。一番排查后发现是由于从1.24.0之后Kubernetes默认采用containerd作为运行时容器，其默认镜像为registry.k8s.io，该镜像在国内无法访问导致的，简单记录下。\n安装过程主要参考1，相关配置与安装步骤如下：\n系统配置与依赖 关闭防火墙 # 关闭交换内存 swapoff -a #关闭selinux getenforce setenforce 0 sed -i \u0026#39;s/^SELINUX=enforcing$/SELINUX=disabled/\u0026#39; /etc/selinux/config #关闭防火墙 firewall-cmd --state systemctl stop firewalld.service systemctl disable firewalld.service 配置docker参数 mkdir /etc/docker/ vim /etc/docker/daemon.json { \u0026#34;storage-driver\u0026#34;: \u0026#34;overlay2\u0026#34;, \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://registry.docker-cn.com\u0026#34;, \u0026#34;http://hub-mirror.c.163.com\u0026#34; ], \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;] } 配置内核参数 ## 配置网卡转发,看值是否为1 sysctl -a |grep \u0026#39;net.ipv4.ip_forward = 1\u0026#39; sysctl -a |grep \u0026#39;net.bridge.bridge-nf-call-iptables = 1\u0026#39; sysctl -a |grep \u0026#39;net.bridge.bridge-nf-call-ip6tables = 1\u0026#39; ## 若未配置，需要执行如下 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/sysctl.d/k8s.conf net.ipv4.ip_forward=1 net.bridge.bridge-nf-call-ip6tables=1 net.bridge.bridge-nf-call-iptables=1 EOF sysctl -p /etc/sysctl.d/k8s.conf 安装docker #安装相关依赖 yum install -y yum-utils device-mapper-persistent-data lvm2 epel-release #添加阿里云docker-ce源 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo yum clean all yum install -y docker-ce containerd.io #设置docker开机自启 systemctl enable docker #启动docker服务 systemctl start docker #查看docker信息 docker info 配置container containerd config default \u0026gt; /etc/containerd/config.toml systemctl daemon-reload systemctl restart containerd 安装Kubernetes 添加k8s源 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF 安装kubelet和kubeadm 执行下述指令，安装kubelet kubeadm\nyum -y install kubectl kubelet kubeadm 执行下述指令，修改kubelet配置 （把kubelet驱动方式改为和docker驱动方式一致，否则会有报错）\ncat \u0026lt;\u0026lt;EOF \u0026gt;/etc/sysconfig/kubelet KUBELET_CGROUP_ARGS=\u0026#34;--cgroup-driver=systemd\u0026#34; EOF 执行下述执行添加自启动\nsystemctl enable kubelet 前序步骤执行完成后，执行kubectl version输出结果如下，可以看出其无法访问8080端口，结果输出不完整。造成此现象的原因为没有执行kubeadm init\n执行kubeadm init 执行下述命令进行初始化\nkubeadm init --v=5 --upload-certs --image-repository k8s.m.daocloud.io 前述命令的输出如下，可以看出创建过程一直阻塞\n经过一段时间的等待，最终在控制台中出现如下错误信息，kubeadm init过程失败!\n问题分析\u0026amp;解决 由于原始的报错信息没有提供太多有用的信息，故通过下述命令来输出其完整的日志2\nsystemctl status kubelet -l \u0026gt; logs.txt cat logs.txt 查看logs.txt的内容，输出如下\n从上图中可知报错信息是由于无法下载registry.k8s.io/pause:3.6导致的，由于registry.k8s.io在国内被墙，但是自己在执行kubeadm init的时候已经通过--image-repository k8s.m.daocloud.io制定了国内的镜像，为啥还会访问旧的镜像呢？奇怪！\n网上搜索一番后，在其官网说明中3的首页有如下说明\nAfter its deprecation in v1.20, the dockershim component has been removed from the kubelet. From v1.24 onwards, you will need to either use one of the other supported runtimes (such as containerd or CRI-O) or use cri-dockerd if you are relying on Docker Engine as your container runtime. For more information about ensuring your cluster is ready for this removal, please see this guide.\n而在前面通过kubectl version命令可知当前的版本为v1.26.0，很明显其使用的是containerd，而自己没有对其进行相关配置。\n执行cat /etc/containerd/config.toml|grep registry.k8s.io后的结果如下，containerd使用的还是默认镜像，至此问题原因找出！\n依次执行下述命令来重新配置containerd\nsed -i \u0026#39;s/registry.k8s.io/registry.aliyuncs.com\\/google_containers/\u0026#39; /etc/containerd/config.toml systemctl daemon-reload systemctl restart containerd 之后重新执行下述命令\n# 移除之前的旧配置 kubeadm reset -f # 初始化 kubeadm init --v=5 --upload-certs --image-repository k8s.m.daocloud.io 运行上述命令后的输出类似如下，可以看出kubeadm init顺利执行成功，整个过程耗时不超过1分钟，至此问题解决!\nhttps://www.cnblogs.com/cerberus43/p/15881294.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n之所以要写入文件是由于直接执行systemctl status kubelet时其输出信息较多，在屏幕中显示不完整，不利于分析\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.24.md\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-01-11T11:31:45+08:00","permalink":"https://lucumt.info/post/k8s/kubeadm-init-not-working-due-to-default-registry-config/","tags":["kubernetes","linux"],"title":"利用kubeadm init初始化时由于registry.k8s.io/pause:3.6导致初始化失败"},{"categories":["python编程"],"contents":"简要介绍如何在Python中利用global关键字定义的全局变量在不同模块间共享，避免后续重复犯错。\n背景 它们位于同一个模块下：\n$ ls __pycache__/ app1.py main.py 各自内容分别如下\napp1.py有一个 global修饰的全局变量，通过set_variables方法对其值进行修改\nMESSAGE = None def set_variables(): global MESSAGE MESSAGE = \u0026#34;Hello Python\u0026#34; main.py主程序，调用上述方法并打印出MESSAGE的值\nfrom app1 import set_variables if __name__ == \u0026#39;__main__\u0026#39;: set_variables() # print(MESSAGE) 不生效用法 一开始自己想复用import xxx from xxx 这种用法，将main.py修改为如下\nfrom app1 import set_variables, MESSAGE if __name__ == \u0026#39;__main__\u0026#39;: set_variables() print(MESSAGE) 结果输出值为None，没有达到预期的结果。\n正确用法 直接用import xxx实现\nimport app1 if __name__ == \u0026#39;__main__\u0026#39;: app1.set_variables() print(app1.MESSAGE) 或用import xxx as xxx给其加上一个别名\nimport app1 as a if __name__ == \u0026#39;__main__\u0026#39;: a.set_variables() print(a.MESSAGE) 原因分析 参见Global variable not changing between files in python中的大佬回答如下：\nThe syntax from globals.py import * makes copies of the variables within globals.py into your local file. To access the variables themselves without making copies, import globals and use the variable directly: globals.filename. You no longer need the global keyword if you access the variable this way.\n","date":"2023-01-05T10:55:48+08:00","permalink":"https://lucumt.info/post/python/using-global-variable-in-different-module/","tags":["python"],"title":"在Python的不同模块中使用全局变量"},{"categories":["工具使用","容器化"],"contents":"简要介绍如何在docker环境下利用Grafana和Prometheus对系统进行监控。\n软件安装 在给Grafana软件集成LDAP实现单点登录一文中简要说明了如何基于docker安装Grafana，本节出于简化使用与维护的目的，将Grafana与Prometheus合并到一个docker-compose.yml文件中，相关的文件如下\ndocker-compose.yml文件\nversion: \u0026#34;3\u0026#34; services: prometheus: image: prom/prometheus:latest container_name: \u0026#34;prometheus_custom\u0026#34; restart: always ports: - \u0026#34;9090:9090\u0026#34; volumes: - \u0026#34;$PWD/prometheus.yml:/etc/prometheus/prometheus.yml\u0026#34; - \u0026#34;$PWD/prometheus_data:/prometheus\u0026#34; grafana: image: grafana/grafana container_name: \u0026#34;grafana_custom\u0026#34; ports: - \u0026#34;3000:3000\u0026#34; restart: always volumes: - \u0026#34;$PWD/grafana_data:/var/lib/grafana\u0026#34; - \u0026#34;$PWD/ldap.toml:/etc/grafana/ldap.toml\u0026#34; environment: # 管理员账号 - GF_SECURITY_ADMIN_USER=admin # 管理员密码 - GF_SECURITY_ADMIN_PASSWORD=xxx - GF_AUTH_LDAP_ENABLED=true ldap.toml文件，用于Grafana接入LDAP\n[[servers]] host = \u0026#34;10.10.0.55\u0026#34; port = 389 use_ssl = false start_tls = false ssl_skip_verify = false bind_dn = \u0026#34;cn=xxx,dc=chinahirain,dc=com\u0026#34; bind_password = \u0026#39;xxx\u0026#39; search_filter = \u0026#34;(uid=%s)\u0026#34; search_base_dns = [\u0026#34;dc=chinahirain,dc=com\u0026#34;] [servers.attributes] name = \u0026#34;givenName\u0026#34; surname = \u0026#34;displayName\u0026#34; username = \u0026#34;uid\u0026#34; #member_of = \u0026#34;cn\u0026#34; email = \u0026#34;mail\u0026#34; [[servers.group_mappings]] group_dn = \u0026#34;grafana-admins\u0026#34; org_role = \u0026#34;Admin\u0026#34; [[servers.group_mappings]] group_dn = \u0026#34;grafana-editors\u0026#34; org_role = \u0026#34;Editor\u0026#34; [[servers.group_mappings]] group_dn = \u0026#34;*\u0026#34; org_role = \u0026#34;Viewer\u0026#34; prometheus.yml文件用于配置要接入Prometheus的系统\nglobal: scrape_interval: 15s # 默认抓取周期 external_labels: monitor: \u0026#39;codelab-monitor\u0026#39; scrape_configs: - job_name: \u0026#39;node-exporter\u0026#39; #服务的名称 scrape_interval: 5s metrics_path: /metrics #获取指标的url static_configs: # 这个为监听指定服务服务的ip和port - targets: [\u0026#39;10.30.31.56:9188\u0026#39;,\u0026#39;10.30.5.113:9188\u0026#39;] 上述这些文件必须位于同一目录下，之后通过docker-compose启动\nroot@lucumt:~/grafana# ls docker-compose.yml grafana_data ldap.toml prometheus.yml prometheus_data root@lucumt:~/grafana# docker-compose up -d 系统接入 主要基于node exporter实现，参考 centos7安装node export 一文进行相关操作。\n在安装有node exporter服务器上的/usr/local/bin/目录下复制名为node_exporter的文件到目标机器的/usr/local/bin/目录下，并将其赋予可执行权限\nchmod \u0026#43;x /usr/local/bin/node_exporter 执行vi /etc/systemd/system/node_exporter.service并输入下述内容\n[Unit] Description=cicd_exporter After=network.target [Service] ExecStart=/usr/local/bin/node_exporter --web.listen-address=:9188 Restart=on-failure [Install] WantedBy=multi-user.target 执行下述命令将其设置为Linux服务同时开机自启动\nsystemctl daemon-reload \u0026amp;\u0026amp; systemctl start node_exporter \u0026amp;\u0026amp; systemctl enable node_exporter 在目标机器的浏览器中输入http://127.0.0.1:9188若能正常显示，则表示node_exporter安装成功\n在安装Grafana的服务器上找到前述的prometheus.yml，在其targets下面添加对应的node_exporter服务，然后通过docker-compose restart重启相关服务\n在Grafana中查看新添加的服务器是否集成成功\n","date":"2022-12-15T10:56:54+08:00","permalink":"https://lucumt.info/post/devops/using-grafana-and-prometheus-to-monitor-systems/","tags":["devops","grafana","docker"],"title":"利用Grafana和Prometheus对系统进行监控"},{"categories":["工具使用","系统集成"],"contents":"Grafana是一款用Go语言开发的开源数据可视化工具，可以做数据监控和数据统计，带有告警功能，本文简要说明如何将基于docker安装的Grafana与LDAP集成实现快捷登录。\n创建一个名为grafana的文件夹，在其下建立一个名为docker-compose.yml的文件，输入如下内容\nversion: \u0026#34;3\u0026#34; services: grafana: image: grafana/grafana container_name: \u0026#34;grafana\u0026#34; privileged: true ports: - \u0026#34;3000:3000\u0026#34; restart: always volumes: - \u0026#34;$PWD/grafana_data:/var/lib/grafana\u0026#34; environment: - GF_SECURITY_ADMIN_USER=admin - GF_SECURITY_ADMIN_PASSWORD=Pass@word 输入下述命令创建相关的挂载目录\nmkdir grafana_data \u0026amp;\u0026amp; chmod 777 grafana_data 输入docker-compose up -d启动容器，等待2-3分钟后利用docker logs grafana查看其日志，若日志中出现类似如下信息，则表示SonarQube初步安装成功\n输入http://ip:3000可打开如下图所示的登录界面，采用前述设置的账号密码可正常登录\n在$PWD/grafana目录下建立一个名为ldap.toml的文件，写入类似如下内容\n[[servers]] host = \u0026#34;10.xxx.xx.xx\u0026#34; port = 389 use_ssl = false start_tls = false ssl_skip_verify = false bind_dn = \u0026#34;cn=xxx,dc=xxx,dc=com\u0026#34; bind_password = \u0026#39;xxx\u0026#39; search_filter = \u0026#34;(uid=%s)\u0026#34; search_base_dns = [\u0026#34;dc=xxx,dc=com\u0026#34;] [servers.attributes] name = \u0026#34;givenName\u0026#34; surname = \u0026#34;displayName\u0026#34; username = \u0026#34;uid\u0026#34; #member_of = \u0026#34;cn\u0026#34; email = \u0026#34;mail\u0026#34; [[servers.group_mappings]] group_dn = \u0026#34;grafana-admins\u0026#34; org_role = \u0026#34;Admin\u0026#34; [[servers.group_mappings]] group_dn = \u0026#34;grafana-editors\u0026#34; org_role = \u0026#34;Editor\u0026#34; [[servers.group_mappings]] group_dn = \u0026#34;*\u0026#34; org_role = \u0026#34;Viewer\u0026#34; 同时将docker-compose.yml修改如下\nversion: \u0026#34;3\u0026#34; services: grafana: image: grafana/grafana container_name: \u0026#34;grafana\u0026#34; privileged: true ports: - \u0026#34;3000:3000\u0026#34; restart: always volumes: - \u0026#34;$PWD/grafana_data:/var/lib/grafana\u0026#34; - \u0026#34;$PWD/ldap.toml:/etc/grafana/ldap.toml\u0026#34; environment: - GF_SECURITY_ADMIN_USER=admin - GF_SECURITY_ADMIN_PASSWORD=Pass@word - GF_AUTH_LDAP_ENABLED=true 输入docker-compose restart重启之后即可采用LDAP账户登录。\n若需要同时安装Prometheus，则可将docker-compose.yml修改为类似如下：\nversion: \u0026#34;3\u0026#34; services: prometheus: image: prom/prometheus:latest container_name: \u0026#34;prometheus\u0026#34; restart: always ports: - \u0026#34;9090:9090\u0026#34; volumes: - \u0026#34;./prometheus.yml:/etc/prometheus/prometheus.yml\u0026#34; - \u0026#34;./prometheus_data:/prometheus\u0026#34; grafana: image: grafana/grafana container_name: \u0026#34;grafana\u0026#34; ports: - \u0026#34;3000:3000\u0026#34; restart: always volumes: - \u0026#34;./grafana_data:/var/lib/grafana\u0026#34; - \u0026#34;./ldap.toml:/etc/grafana/ldap.toml\u0026#34; environment: - GF_SECURITY_ADMIN_USER=admin - GF_SECURITY_ADMIN_PASSWORD=Pass@word - GF_AUTH_LDAP_ENABLED=true ","date":"2022-12-11T10:39:47+08:00","permalink":"https://lucumt.info/post/ldap/add-ldap-support-for-grafana/","tags":["ldap","docker","grafana"],"title":"给Grafana软件集成LDAP实现单点登录"},{"categories":["工具使用","系统集成"],"contents":"SonarQube是管理代码质量一个开放平台，可以快速的定位代码中潜在的或者明显的错误，本文简要说明如何将基于docker安装的SonarQube与LDAP集成实现快捷登录。\n创建一个名为sonarqube的文件夹，在其下建立一个名为docker-compose.yml的文件，输入如下内容\nversion: \u0026#39;3\u0026#39; services: postgres: image: postgres:14.4 restart: always privileged: true container_name: postgres ports: - 5432:5432 volumes: - $PWD/postgres/postgres-data:/var/lib/postgresql/data environment: TZ: Asia/Shanghai POSTGRES_USER: sonar POSTGRES_PASSWORD: sonar123 POSTGRES_DB: sonar networks: - sonar-network sonar: image: sonarqube:8.9-community restart: always container_name: sonar depends_on: - postgres volumes: - $PWD/sonarqube/extensions:/opt/sonarqube/extensions - $PWD/sonarqube/logs:/opt/sonarqube/logs - $PWD/sonarqube/data:/opt/sonarqube/data - $PWD/sonarqube/conf:/opt/sonarqube/conf ports: - 9990:9000 environment: SONARQUBE_JDBC_USERNAME: sonar SONARQUBE_JDBC_PASSWORD: sonar123 SONARQUBE_JDBC_URL: jdbc:postgresql://postgres:5432/sonar networks: - sonar-network networks: sonar-network: driver: bridge 输入docker-compose up -d启动容器，等待2-3分钟后利用docker logs sonar查看其日志，若日志中出现类似如下信息，则表示SonarQube初步安装成功\n输入http://ip:9990可打开如下图所示的登录界面，默认的账号和密码均为admin，可用此账号登录\n在$PWD/sonarqube/conf目录下建立一个名为sonar.properties的文件，写入类似如下内容\n#LDAP settings #admin sonar.security.realm=LDAP ldap.url=ldap://10.10.xxx.xxx:389 ldap.bindDn=cn=xxx,dc=xxx,dc=com ldap.bindPassword=xxx ldap.user.baseDn=dc=xxx,dc=com ldap.user.request=(\u0026amp;(objectClass=inetOrgPerson)(uid={login})) ldap.user.realNameAttribute=displayName ldap.user.emailAttribute=mail 输入docker-compose restart重启之后即可采用LDAP账户登录！\n","date":"2022-12-04T11:29:12+08:00","permalink":"https://lucumt.info/post/ldap/add-ldap-support-for-sonarqube/","tags":["ldap","docker"],"title":"给Sonarqube软件集成LDAP实现单点登录"},{"categories":["工具使用","系统集成"],"contents":"YApi 是高效、易用、功能强大的 api 管理平台，旨在为开发、产品、测试人员提供更优雅的接口管理服务1，由去哪儿网开发，本文基于为 Yapi 定制 apline 版 Docker 镜像简要说明如何将基于docker安装的Yapi与LDAP集成。\n利用docker创建MongoDB数据库\ndocker run -d \\ --name mongo-yapi \\ -v $PWD/mongo-data:/data/db \\ -e MONGO_INITDB_ROOT_USERNAME=anoyi \\ -e MONGO_INITDB_ROOT_PASSWORD=anoyi.com \\ mongo 在当前目录下创建一个config.json文件，内容如下\n{ \u0026#34;port\u0026#34;: \u0026#34;3000\u0026#34;, \u0026#34;adminAccount\u0026#34;: \u0026#34;admin@anoyi.com\u0026#34;, \u0026#34;timeout\u0026#34;:120000, \u0026#34;db\u0026#34;: { \u0026#34;servername\u0026#34;: \u0026#34;mongo\u0026#34;, \u0026#34;DATABASE\u0026#34;: \u0026#34;yapi\u0026#34;, \u0026#34;port\u0026#34;: 27017, \u0026#34;user\u0026#34;: \u0026#34;anoyi\u0026#34;, \u0026#34;pass\u0026#34;: \u0026#34;anoyi.com\u0026#34;, \u0026#34;authSource\u0026#34;: \u0026#34;admin\u0026#34; } } 执行下述命令初始化 YAPI 数据库索引及管理员账号\ndocker run -it --rm \\ --link mongo-yapi:mongo \\ --entrypoint npm \\ --workdir /yapi/vendors \\ -v $PWD/config.json:/yapi/config.json \\ anoyi/yapi \\ run install-server 若执行成功会出现下述界面\n执行下述命令启动yapi\ndocker run -d \\ --name yapi \\ --link mongo-yapi:mongo \\ --workdir /yapi/vendors \\ -p 3000:3000 \\ -v $PWD/config.json:/yapi/config.json \\ anoyi/yapi \\ server/app.js 执行完毕后用docker logs yapi查看日志，若出现如下日志则表示启动成功\n根据上述提示在浏览器中打开yapi，其主页类似如下\n点击登录/注册 之后会打开如下图所示的登录界面，可用管理员账号登录(用户名admin@anoyi.com、密码ymfe.org)，可发现此时其不支持LDAP登录\n在config.json中添加LDAP相关的配置，之后输入docker restart yapi \u0026amp;\u0026amp; docker logs yapi重启并观察日志\n{ \u0026#34;port\u0026#34;: \u0026#34;3000\u0026#34;, \u0026#34;adminAccount\u0026#34;: \u0026#34;admin@anoyi.com\u0026#34;, \u0026#34;timeout\u0026#34;:120000, \u0026#34;db\u0026#34;: { \u0026#34;servername\u0026#34;: \u0026#34;mongo\u0026#34;, \u0026#34;DATABASE\u0026#34;: \u0026#34;yapi\u0026#34;, \u0026#34;port\u0026#34;: 27017, \u0026#34;user\u0026#34;: \u0026#34;anoyi\u0026#34;, \u0026#34;pass\u0026#34;: \u0026#34;anoyi.com\u0026#34;, \u0026#34;authSource\u0026#34;: \u0026#34;admin\u0026#34; }, \u0026#34;ldapLogin\u0026#34;:{ \u0026#34;enable\u0026#34;:true, \u0026#34;server\u0026#34;: \u0026#34;ldap://10.10.xx.xxx:389\u0026#34;, \u0026#34;searchDn\u0026#34;: \u0026#34;dc=xxx,dc=com\u0026#34;, \u0026#34;searchStandard\u0026#34;:\u0026#34;uid\u0026#34;, \u0026#34;usernameKey\u0026#34;:\u0026#34;uid\u0026#34; } } 重新打开yapi，其登录页中会出现类似如下的LDAP选项，至此，操作完成！\nhttp://yapi.smart-xwork.cn/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022-12-01T11:23:00+08:00","permalink":"https://lucumt.info/post/ldap/add-ldap-support-for-yapi/","tags":["ldap","docker"],"title":"给Yapi添加LDAP登录认证"},{"categories":["Java编程"],"contents":"在项目中某个请求的参数采用了较为复杂的规则拼接而成，在服务器端查询时需要将其解析成符合要求的Map与List组合的格式。一开始自己采用的是传统的遍历方式实现，后续发现用Java8中引入的lambda表达式后代码变的更简洁、更优雅，故简单记录下。\n问题描述 项目中有类似如下的字符串输入参数\n010$$fengtai,010$$chaoyang,010$$haidain,027$$wuchang,027$$hongshan,027$$caidan,021$$changnin,021$$xuhui,020$$tianhe 调用方期望将输入参数转化为如下格式(即首先根据,进行分割，然后在根据$$进行进一步的拆分，最终的结果是按照$$前面的数据为key，$$后面的数据分别放入同一个数组中，最终结果以Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt;的格式返回)。\n{027=[wuchang, hongshan, caidan], 020=[tianhe], 010=[fengtai, chaoyang, haidain], 021=[changnin, xuhui]} 传统方式 最开始由于需要尽快部署调试，自己才用的是传统的遍历方式，此种方式编码起来很简单，具备简单的Java基础即可实现。\npublic Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; parseParametersByIterate(String sensors) { List\u0026lt;String[]\u0026gt; dataList = Arrays.stream(sensors.split(\u0026#34;,\u0026#34;)).map(s -\u0026gt; s.split(\u0026#34;\\\\$\\\\$\u0026#34;)).collect(Collectors.toList()); Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; resultMap = new HashMap\u0026lt;\u0026gt;(); for (String[] d : dataList) { List\u0026lt;String\u0026gt; list = resultMap.get(d[0]); if (list == null) { list = new ArrayList\u0026lt;\u0026gt;(); list.add(d[1]); resultMap.put(d[0], list); } else { list.add(d[1]); } } return resultMap; } 基于Lambda实现 在Stack Overflow上咨询后，发现用lambda实现更简洁，只用一行代码就能搞定!\npublic Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; parseByLambda(String data) { Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; resultMap = Arrays.stream(data.split(\u0026#34;,\u0026#34;)) .map(s -\u0026gt; s.split(\u0026#34;\\\\$\\\\$\u0026#34;)) .collect(Collectors.groupingBy(s -\u0026gt; s[0], Collectors.mapping(s -\u0026gt; s[1], Collectors.toList()))); return resultMap; } 上述代码的核心是采用Java8中引入的Collectors类，采用其中的groupingBy和mapping方法实现，而自己用的最多的只是toList和toMap，基本功有待加强！\n","date":"2022-11-15T16:20:57+08:00","permalink":"https://lucumt.info/post/java-core/using-lambda-to-parse-and-group-data/","tags":["Java"],"title":"利用Java8中的lambda来实现字符串的解析与分组"},{"categories":[],"contents":"","date":"2022-11-15T11:49:21+08:00","permalink":"https://lucumt.info/search/","tags":[],"title":"搜索结果展示"},{"categories":["持续集成","容器化"],"contents":"记录下自己在使用KubeSphere过程中由于YAML中错误的配置导致Kubernetes经常资源紧张而无法创建与部署新节点的问题。\n问题描述 部门在使用KubeSphere过程中经常遇到类似如下图所示的由于kubernetes无法调度而导致的无法部署的问题\n进一步查看报错节点信息会发现提示CPU资源不足，从而导致无法部署。\n之前自己采取的解决方案是暴力的删除一部分节点来释放CPU资源，但此种方式治标不治本，且随着KubeSphere在部门内部使用的普及，此问题发生的频率越来越高，只能想办法从根源上处理。\n分析与解决 由于提示的是CPU资源不足，首先检查是否为CPU的问题，采用lscpu | egrep 'Model name|Socket|Thread|NUMA|CPU\\(s\\)'和free -g分别查看CPU和内存信息，结果如下\n从查询结果可知系统的CPU配置和内存配置都很高，而自己在KubeSphere中部署的都是一些普通的Java程序，不可能占用特别多的CPU和内存资源，Linux服务器本身的配置问题排除。\n接下来利用kubectl describe node查看节点信息，输出结果如下\n在上图中可发现相关节点汇总后的CPU和内存占用的百分比非常大，其中CPU在Requests部分占比为84%，由于Linux系统自身运行和运行Kubesphere与Kubernetes都需要占用一定的CPU资源，从而导致当Kubersphere中部署的项目超过一定数量时，Linux系统无法给Kubernetes分配足够的CPU资源导致部署失败。至此，问题的表面原因找出来了。\n进一步分析上面的问题，自己觉得很好奇的是为啥Requests部分占用的资源，自己在对应的YAML文件中压根就没指定Requests相关的参数，检查代码发现Limits配置的值比较大\nresources: limits: cpu: 500m memory: 2000Mi 同时基于kubectl describe node发现相关节点的Requests和Limits的值都相同，猜测是否Kubernetes默认将Ruquests的值设置为与Limits的值相同。\n在Kubernetes官网发现如下说明\nNote: If you specify a limit for a resource, but do not specify any request, and no admission-time mechanism has applied a default request for that resource, then Kubernetes copies the limit you specified and uses it as the requested value for the resource.\n上述文字说明当我们在YAML文件中只设置了Limits但是没有指定Requests，则Kubernetes会将Request的值默认设置为与Limits相同，从而导致CPU和内存资源占用都很高，至此问题根源找到！\n解决的方式也很简单，要么移除掉Limits，让Kubernetes根据Linux系统资源和节点状况给我们动态的分配节点，或者同时指定Requests和Limits即可。\n# 屏蔽此部分代码 #resources: # limits: # cpu: 500m # memory: 2000Mi # 或者显示配置request和limits resources: limits: cpu: 500m memory: 2000Mi requests: cpu: 20m memory: 64Mi 经验教训： 需要对自己项目中的代码要有更深入的理解，尤其是配置文件，要做到理解每一行的作用，不能简单的复制别人的代码。\n参考文档：\nhttps://kubesphere.io/zh/blogs/deep-dive-into-the-k8s-request-and-limit/\nhttps://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\n","date":"2022-11-11T18:19:12+08:00","permalink":"https://lucumt.info/post/k8s/cpu-resource-not-enough-due-to-invalid-k8s-config/","tags":["kubernetes","kubesphere","linux"],"title":"由于k8s中的错误配置导致无法创建新节点"},{"categories":["java编程"],"contents":"记录如何在Log4j2中使用traceId实现链路追踪时只有在请求header中有trace-id时才显示前端发送过来的trace-id值。\n前置工作 完整代码参见spring-mybatis-demo。\n假设使用的程序框架为Spring Boot并通过Maven管理依赖，需要预先添加如下代码配置：\npom.xml中排除Spring Boot自带的日志框架并添加log4j2依赖\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.boot.version}\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-logging\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.boot.version}\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-logging\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-log4j2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.boot.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 添加Filter用于从请求header中获取前端传递的trace-id并传入MDC中\n@Order(0) @Component @WebFilter(filterName = \u0026#34;traceIdFilter\u0026#34;, urlPatterns = \u0026#34;/*\u0026#34;) public class TraceIdFilter implements Filter { public static final String TRACE_ID = \u0026#34;TRACE_ID\u0026#34;; public static final String TRACE_ID_HEADER = \u0026#34;trace-id\u0026#34;; @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws ServletException, IOException { HttpServletRequest request = (HttpServletRequest) req; String traceId = request.getHeader(TRACE_ID_HEADER); MDC.put(TRACE_ID, traceId); chain.doFilter(req, res); } @Override public void destroy() { MDC.clear(); } } 在主启动类中添加如下配置用于在线程间传递MDC值\n@SpringBootApplication public class TestApplication { // 用于在线程间传递mdc值 static { System.setProperty(\u0026#34;log4j2.isThreadContextMapInheritable\u0026#34;, \u0026#34;true\u0026#34;); } public static void main(String[] args) { SpringApplication.run(TestApplication.class, args); } } log4j2.xml配置如下\n\u0026lt;Configuration status=\u0026#34;warn\u0026#34;\u0026gt; \u0026lt;Appenders\u0026gt; \u0026lt;!-- Console appender configuration --\u0026gt; \u0026lt;Console name=\u0026#34;console\u0026#34; target=\u0026#34;SYSTEM_OUT\u0026#34;\u0026gt; \u0026lt;PatternLayout pattern=\u0026#34;%yellow{[%d{yyyy-MM-dd HH:mm:ss.SSS}]} %clr{[%-5level]} %green{[TraceId-%X{TRACE_ID}]} %cyan{[%c]}- %msg%n\u0026#34; /\u0026gt; \u0026lt;/Console\u0026gt; \u0026lt;/Appenders\u0026gt; \u0026lt;Loggers\u0026gt; \u0026lt;!-- Root logger referring to console appender --\u0026gt; \u0026lt;Root level=\u0026#34;info\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;console\u0026#34; /\u0026gt; \u0026lt;/Root\u0026gt; \u0026lt;/Loggers\u0026gt; \u0026lt;/Configuration\u0026gt; 其中的%green{[TraceId-%X{TRACE_ID}]}就是将获取到的trace-id在控制台中按照TraceId-xxx的格式以绿色打印出来，该段配置是我们进行链路最终的核心。\n其中%X专门用于获取MDC中的值，在log4j2官网对应的说明如下\n测试\u0026amp;问题 测试代码如下\n@Slf4j @RestController @RequestMapping(\u0026#34;user\u0026#34;) public class UserController { @Resource private UserService userService; @RequestMapping(\u0026#34;queryAll\u0026#34;) public List\u0026lt;UserModel\u0026gt; all() { List\u0026lt;UserModel\u0026gt; userList = userService.queryAllUsers(); log.info(\u0026#34;==========all user size: {}\u0026#34;, userList.size()); return userList; } } 在Postman中发送类似如下请求，在header中将trace-id的值设置为123456\n在控制台可发现类似如下输出，可发现前面几条系统启动时输出的日志也会按照trace-id格式进行输出，由于此时还没接收到前端发送的请求，故其值为空导致只显示一个TraceId-前缀，看起来不美观且影响使用。\n解决方案 终极目标是实现在有trace-id时按照格式输出，没有时则正常输出，很明显要达成此效果需要判断trace-id是否为空。\n最开始Google和Stackoverflow搜索的结果建议使用ScriptPatternSelector，在官网给出的使用示例如下，看起来有一丢丢复杂，在有多个Appenders时不适合扩展。\n\u0026lt;PatternLayout\u0026gt; \u0026lt;ScriptPatternSelector defaultPattern=\u0026#34;[%-5level] %c{1.} %C{1.}.%M.%L %msg%n\u0026#34;\u0026gt; \u0026lt;Script name=\u0026#34;BeanShellSelector\u0026#34; language=\u0026#34;bsh\u0026#34;\u0026gt;\u0026lt;![CDATA[ if (logEvent.getLoggerName().equals(\u0026#34;NoLocation\u0026#34;)) { return \u0026#34;NoLocation\u0026#34;; } else if (logEvent.getMarker() != null \u0026amp;\u0026amp; logEvent.getMarker().isInstanceOf(\u0026#34;FLOW\u0026#34;)) { return \u0026#34;Flow\u0026#34;; } else { return null; }]]\u0026gt; \u0026lt;/Script\u0026gt; \u0026lt;PatternMatch key=\u0026#34;NoLocation\u0026#34; pattern=\u0026#34;[%-5level] %c{1.} %msg%n\u0026#34;/\u0026gt; \u0026lt;PatternMatch key=\u0026#34;Flow\u0026#34; pattern=\u0026#34;[%-5level] %c{1.} ====== %C{1.}.%M:%L %msg ======%n\u0026#34;/\u0026gt; \u0026lt;/ScriptPatternSelector\u0026gt; \u0026lt;/PatternLayout\u0026gt; 上述方式需要设置两个Pattern且在不同的Appender中都需要动态配置，使用起来不是特别灵活。\n有木有可能通过一个Pattern同时兼容这两种情况呢？\n经过网络搜索和查看log4j2中关于Pattern Layout的说明之后，最终找到了解决方案，那就是%notEmpty!\n官方文档中关于%notEmpty的说明如下\n基于上述说明可尝试将%green{%notEmpty{[TraceId-%X{TRACE_ID}]}}修改为%green{%notEmpty{[TraceId-%X{TRACE_ID}]}}，最终完整的PatternLayout如下\n\u0026lt;PatternLayout pattern=\u0026#34;%yellow{[%d{yyyy-MM-dd HH:mm:ss.SSS}]} %clr{[%-5level]} %green{%notEmpty{[TraceId-%X{TRACE_ID}]}} %cyan{[%c]}- %msg%n\u0026#34; /\u0026gt; 重新调用Postman的输出结果如下，完美实现功能！\n服务间调用 在微服务中通常会有多个模块协同工作，各个模块之间也可能会互相调用，在此种情况下也需要将trace-id准确的传递与获取，确保单次请求调用链路中的trace-id都一样才能体现链路追踪的意义。\nFeign调用 当使用Feign作为远程调用实现时，需在被调用方中添加如下配置代码才能确保trace-id被正常传递与获取。\nimport com.hirain.orienlink.mfs.filter.TraceIdFilter; import feign.RequestInterceptor; import feign.RequestTemplate; import org.slf4j.MDC; import org.springframework.context.annotation.Configuration; @Configuration public class FeignConfig implements RequestInterceptor { @Override public void apply(RequestTemplate requestTemplate) { String traceId = String.valueOf(MDC.get(TraceIdFilter.TRACE_ID)); requestTemplate.header(TraceIdFilter.TRACE_ID_HEADER, traceId); } } ","date":"2022-10-13T17:47:46+08:00","permalink":"https://lucumt.info/post/log4j/show-trace-id-only-if-exists-in-log4j2/","tags":["java","log4j"],"title":"在Log4j2中实现只有在traceId有值时才输出"},{"categories":["web编程"],"contents":"简要记录下自己对于JavaScript中reduce()函数的学习小结。\n原始问题来源于How to sum an array for each ID and create new array in react，问题如下：\n有一个数组\nconst data = [ {\u0026#34;id\u0026#34;: \u0026#34;One\u0026#34;, \u0026#34;number\u0026#34;: 100}, {\u0026#34;id\u0026#34;: \u0026#34;One\u0026#34;, \u0026#34;number\u0026#34;: 150}, {\u0026#34;id\u0026#34;: \u0026#34;One\u0026#34;, \u0026#34;number\u0026#34;: 200}, {\u0026#34;id\u0026#34;: \u0026#34;Two\u0026#34;, \u0026#34;number\u0026#34;: 50}, {\u0026#34;id\u0026#34;: \u0026#34;Two\u0026#34;, \u0026#34;number\u0026#34;: 100}, {\u0026#34;id\u0026#34;: \u0026#34;Three\u0026#34;, \u0026#34;number\u0026#34;: 10}, {\u0026#34;id\u0026#34;: \u0026#34;Three\u0026#34;, \u0026#34;number\u0026#34;: 90} ]; 提问者希望基于id对number进行累加，并输出一个新的数组：\n[ {\u0026#34;id\u0026#34;: \u0026#34;One\u0026#34;, \u0026#34;number\u0026#34;: 450}, {\u0026#34;id\u0026#34;: \u0026#34;Two\u0026#34;, \u0026#34;number\u0026#34;: 150}, {\u0026#34;id\u0026#34;: \u0026#34;Three\u0026#34;, \u0026#34;number\u0026#34;: 100}, ] 由于自己当时正在Stackoverflow上刷reputation，所以看到这个问题后，毫不犹豫的写下了自己的答案\nlet result = data.reduce((a, v) =\u0026gt; { let obj = a.find(i =\u0026gt; i.id == v.id); if (obj) { obj.number \u0026#43;= v.number; } else { a.push({...v}); } return a; }, []) console.log(result); console.log(\u0026#34;-------------------------------\u0026#34;) 虽然我的手速比较快，但是最后被原提问者选中的答案如下\nlet result = data.reduce((acc, {id, number}) =\u0026gt; ({...acc, [id]: {id, number: acc[id] ? acc[id].number \u0026#43; number: number}}), {}); console.log(Object.values(result)); 该写法通过给reduce函数的输出结果设置为{}对象的方式避免了需要判断是是否为空，最后通过Object.values()将结果转化为数组，相对于我之前的多行代码，此种写法只需要2行即可实现目的，更简洁更优化，学习了！\n","date":"2022-09-26T09:39:47+08:00","permalink":"https://lucumt.info/post/js/using-reduce-function-on-array/","tags":["javascript"],"title":"JavaScript学习-reduce函数"},{"categories":["个人博客"],"contents":"记录下个人Hugo博客使用Even主题时的一些使用心得与个人改进。\nGitHub Actions自动部署 参见利用GitHub Action实现Hugo博客在GitHub Pages自动部署。\n改进Back to top 背景 原始的返回顶部按钮太小且背景提示色不明显，查看起来不直观。\n修改代码 在assets/sass/_partial/_back-to-top.scss中修改如下配置\n.back-to-top {\rdisplay: none;\rtransition-property: transform;\rtransition-timing-function: ease-out;\rtransition-duration: 0.3s;\rz-index: 10;\rbackground-color: $content-blockquote-backgroud;\rposition: fixed;\rright: 10px;\rbottom: 10px;\rheight: 30px;\rwidth: 50px;\rtext-align: center;\rpadding-top: 20px;\rborder-radius: 20%;\roverflow: hidden;\r\u0026amp;:hover {\rtransform: translateY(-5px); }\r.icon-up {\rvertical-align: top;\r}\r} 运行效果 改进后的效果如下所示，不仅按钮变大，而且也能根据不同的主题颜色动态的进行改变。\n其它 在assets/sass/_partial/_back-to-top.scss中有如下代码用于控制此按钮只有在非手机浏览器的环境下显示，此方式可用于其它需要在手机浏览器环境禁用的场景。\n@include max-screen() {\r.back-to-top {\rdisplay: none !important;\r}\r} 区分Draft与非Draft 背景 有时候会遇到一些典型场景或者灵感突发，想把它们写入博客中，但由于时间限制一时半会又难以完成，可创建对应的markdown文件，将draft设置为true，然后在正常打包时即可排除这些草稿文章，在本地编写时可用类似hugo server -w -D的指令来包含草稿文章。\n当采用hugo server -w -D时在文章列表中不会显示是否为草稿文章，使用上有些不方便\n修改代码 测试assets/sass/_partial/_archive.scss添加如下代码\n.archive-post-status {\rcolor: $theme-color;\r} layouts/_default/section.html中添加如下代码\n\u0026lt;span class=\u0026#34;archive-post-time\u0026#34;\u0026gt;\r{{ $element.Date.Format \u0026#34;01-02\u0026#34; }}\r\u0026lt;/span\u0026gt;\r\u0026lt;!-- show draft status in none production environment --\u0026gt;\r{{- if not (in (slice (getenv \u0026#34;HUGO_ENV\u0026#34;) hugo.Environment) \u0026#34;production\u0026#34;) -}}\r\u0026lt;span class=\u0026#34;archive-post-status\u0026#34;\u0026gt;\r{{ if .Draft }} \u0026amp;#9711;\r{{ else }}\r\u0026amp;#9632;\r{{ end }}\r\u0026lt;/span\u0026gt;\r{{ end }}\r\u0026lt;span class=\u0026#34;archive-post-title\u0026#34;\u0026gt;\r\u0026lt;a href=\u0026#34;{{ $element.RelPermalink }}\u0026#34; class=\u0026#34;archive-post-link\u0026#34;\u0026gt;\r{{ .Title }}\r{{ .Title }}\r\u0026lt;/a\u0026gt;\r\u0026lt;/span\u0026gt; layouts/_default/taxonomy.html中添加如下代码\n\u0026lt;span class=\u0026#34;archive-post-time\u0026#34;\u0026gt;\r{{ .Date.Format (.Site.Params.dateFormatToUse | default \u0026#34;2006-01-02\u0026#34;) }}\r\u0026lt;/span\u0026gt;\r\u0026lt;!-- show draft status in none production environment --\u0026gt;\r{{- if not (in (slice (getenv \u0026#34;HUGO_ENV\u0026#34;) hugo.Environment) \u0026#34;production\u0026#34;) -}}\r\u0026lt;span class=\u0026#34;archive-post-status\u0026#34;\u0026gt;\r{{ if .Draft }} \u0026amp;#9711;\r{{ else }}\r\u0026amp;#9632;\r{{ end }}\r\u0026lt;/span\u0026gt;\r{{ end }}\r\u0026lt;span class=\u0026#34;archive-post-title\u0026#34;\u0026gt;\r\u0026lt;a href=\u0026#34;{{ .RelPermalink }}\u0026#34; class=\u0026#34;archive-post-link\u0026#34;\u0026gt;\r{{ .Title }}\r{{ .Title }}\r\u0026lt;/a\u0026gt;\r\u0026lt;/span\u0026gt; 运行效果 部署时才添加访问统计 背景 在本地编写博客时，需要多次访问未完成的页面，此种页面没必要添加记录到网站访问次数统计中。\n修改代码 在layouts/partials/scripts.html中修改如下，在最外层添加 if (in (slice (getenv \u0026quot;HUGO_ENV\u0026quot;) hugo.Environment) \u0026quot;production\u0026quot;)来判断环境\n\u0026lt;!-- only work in production mode --\u0026gt;\r{{- if (in (slice (getenv \u0026#34;HUGO_ENV\u0026#34;) hugo.Environment) \u0026#34;production\u0026#34;) -}}\r\u0026lt;!-- Analytics --\u0026gt;\r{{- if .Site.GoogleAnalytics -}}\r{{ template \u0026#34;_internal/google_analytics_async.html\u0026#34; . }}\r{{- end -}}\r{{- with .Site.Params.baiduAnalytics -}}\r\u0026lt;script id=\u0026#34;baidu_analytics\u0026#34;\u0026gt;\rvar _hmt = _hmt || [];\r(function() {\rif (window.location.hostname === \u0026#39;localhost\u0026#39;) return;\rvar hm = document.createElement(\u0026#34;script\u0026#34;); hm.async = true;\rhm.src = \u0026#34;https://hm.baidu.com/hm.js?{{.}}\u0026#34;;\rvar s = document.getElementsByTagName(\u0026#34;script\u0026#34;)[0];\rs.parentNode.insertBefore(hm, s);\r})();\r\u0026lt;/script\u0026gt;\r{{- end }}\r\u0026lt;!-- baidu push --\u0026gt;\r{{- if .Site.Params.baiduPush -}}\r\u0026lt;script id=\u0026#34;baidu_push\u0026#34;\u0026gt;\r(function(){\rif (window.location.hostname === \u0026#39;localhost\u0026#39;) return;\rvar bp = document.createElement(\u0026#39;script\u0026#39;); bp.async = true;\rvar curProtocol = window.location.protocol.split(\u0026#39;:\u0026#39;)[0];\rif (curProtocol === \u0026#39;https\u0026#39;) {\rbp.src = \u0026#39;https://zz.bdstatic.com/linksubmit/push.js\u0026#39;;\r}\relse {\rbp.src = \u0026#39;http://push.zhanzhang.baidu.com/push.js\u0026#39;;\r}\rvar s = document.getElementsByTagName(\u0026#34;script\u0026#34;)[0];\rs.parentNode.insertBefore(bp, s);\r})();\r\u0026lt;/script\u0026gt;\r{{- end }}\r{{- end -}} 使用方式 在项目部署时通过添加-e \u0026quot;production\u0026quot;来指定为生产环境，如hugo -b \u0026quot;https://lucumt.info/\u0026quot; -e \u0026quot;production\u0026quot;。\nFork me on Github 原始代码来源https://github.com/olOwOlo/hugo-theme-even/pull/4121，参考代码见如何在博客园添加 Fork me on GitHub 彩带效果\n修改代码 config.toml中添加如下配置，若ithubForkURL值为空，则不显示Fork me on GitHub\n[params]\rgithubForkURL = \u0026#34;\u0026#34; # Fork me on Github repository address # Fork me on Github仓库地址 layouts/_default/baseof.html中添加如下代码\n{{ with .Site.Params.githubForkURL }}\r\u0026lt;!-- fork me on github ---\u0026gt;\r\u0026lt;!-- see https://github.blog/2008-12-19-github-ribbons/ --\u0026gt;\r\u0026lt;a href=\u0026#34;{{ . }}\u0026#34; title=\u0026#34;{{ . }}\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt; \u0026lt;img style=\u0026#34;position: fixed; top: 0; right: 0; border: 0; z-index:9999;\u0026#34; src=\u0026#34;/forkme_right_gray.png\u0026#34; alt=\u0026#34;Fork me on GitHub\u0026#34;\u0026gt;\r\u0026lt;/a\u0026gt;\r{{ end }}\r\u0026lt;!-- 在此代码块之前添加 --\u0026gt;\r\u0026lt;main id=\u0026#34;main\u0026#34; class=\u0026#34;main\u0026#34;\u0026gt;\r\u0026lt;div class=\u0026#34;content-wrapper\u0026#34;\u0026gt; static目录下添加一个名为forkme_right_gray.png的图片，\n运行效果 代码块可复制 原始代码来源https://github.com/olOwOlo/hugo-theme-even/pull/413\n修改代码 config.toml中添加如下配置，用于控制是否开启代码复制功能\n[params]\renableCopyCode = true assets/sass/_partial/_post/_code.scss添加如下代码\n.copy-code {\rposition: absolute;\rright: 0;\rz-index: 2;\rfont-size: .9em !important;\rpadding: 0px 1.5rem !important;\rcolor: #b1b1b1;\rfont-family: Arial;\rfont-weight: bold;\rcursor: pointer;\ruser-select: none;\r} 在layouts/partials/scripts.html底部添加如下代码\n\u0026lt;!-- copy to clipboard --\u0026gt;\r{{- if .Site.Params.enableCopyCode -}}\r\u0026lt;script\u0026gt;\rfunction createCopyButton(highlightDiv) {\rconst div = document.createElement(\u0026#34;div\u0026#34;);\rdiv.className = \u0026#34;copy-code\u0026#34;;\rdiv.innerText = \u0026#34;Copy\u0026#34;;\rdiv.addEventListener(\u0026#34;click\u0026#34;, () =\u0026gt;\rcopyCodeToClipboard(div, highlightDiv)\r);\raddCopyButtonToDom(div, highlightDiv);\r}\rasync function copyCodeToClipboard(button, highlightDiv) {\rconst codeToCopy = highlightDiv.querySelector(\u0026#34;:last-child \u0026gt; .chroma \u0026gt; code\u0026#34;)\r.innerText;\rawait navigator.clipboard.writeText(codeToCopy);\rbutton.blur();\rbutton.innerText = \u0026#34;Copied!\u0026#34;;\rsetTimeout(() =\u0026gt; button.innerText = \u0026#34;Copy\u0026#34;, 2000);\r}\rfunction addCopyButtonToDom(button, highlightDiv) {\rhighlightDiv.insertBefore(button, highlightDiv.firstChild);\rconst wrapper = document.createElement(\u0026#34;div\u0026#34;);\rwrapper.className = \u0026#34;highlight-wrapper\u0026#34;;\rhighlightDiv.parentNode.insertBefore(wrapper, highlightDiv);\rwrapper.appendChild(highlightDiv);\r}\rvar isMobile = /iPhone|iPad|iPod|Android/i.test(navigator.userAgent);\rif(!isMobile){\rdocument.querySelectorAll(\u0026#34;.highlight\u0026#34;).forEach((highlightDiv) =\u0026gt; createCopyButton(highlightDiv));\r}\r\u0026lt;/script\u0026gt; {{ end }} 运行效果 在非手机浏览器中当开启enableCopyCode开关后，在代码左侧会出现如下效果2\n添加搜索功能 修改代码 此部分的代码主要参考给hugo添加搜索功能基于fuse实现的，由于基于此博文实现的搜索效果展示比较简陋，故个人做了如下改进:\n在layouts/_default/search.html下添加了，用于将搜索结果用博客默认的风格包装起来\n{{ define \u0026#34;main\u0026#34; }} … {{ end }} 在layouts/_default/baseof.html实现前述步骤中相关的定义\n{{ block \u0026#34;main\u0026#34; . }}\r\u0026lt;main id=\u0026#34;main\u0026#34; class=\u0026#34;main\u0026#34;\u0026gt;\r\u0026lt;div class=\u0026#34;content-wrapper\u0026#34;\u0026gt;\r\u0026lt;div id=\u0026#34;content\u0026#34; class=\u0026#34;content\u0026#34;\u0026gt;\r{{ block \u0026#34;content\u0026#34; . }}{{ end }}\r\u0026lt;/div\u0026gt;\r{{ partial \u0026#34;comments.html\u0026#34; . }}\r\u0026lt;/div\u0026gt;\r\u0026lt;/main\u0026gt;\r{{ end }} 在assets/sass/_base.scss添加下述样式，用于分隔显示不同的检索结果\n#search-results-info {\rdisplay: none;\r}\r.search_list {\rborder-top: $post-border;\r} 运行效果3 默认的搜索界面\n输入关键字后，有显示结果的界面\n截至本文编写时(2022年9月)Even主题的作者尚未merge这些pull request\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n此部分的提示文字采用硬编码copy，尚未做成通用的国际化代码\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n由于分词的原因，中文检测结果可能存在一定误差\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022-09-18T09:43:19+08:00","permalink":"https://lucumt.info/post/hugo/share-experience-for-using-hugo-even-theme/","tags":["hugo","Go"],"title":"个人Hugo博客关于Even主题的一些使用改进"},{"categories":["持续集成"],"contents":"基于KubeSphere使用心得给部门搭建了dev、sit、test、prod这4套环境之后，一开始使用较为顺利，但随着项目的推进以及开发人员的增多，同时有多个功能模块需要并行开发与测试，导致原有的4套环境不够用。经过一番摸索后，实现了结合Nacos在KubeSphere中动态配置多套环境功能，通过修改Nacos中的JSON配置文件可很容易的从4套扩展为16套甚至更多。\n原实现方式 最开始自己只准备了dev、sit、test、prod这4套环境，由于环境数量不多，对于不同环境的端口配置自己是在代码中直接实现的1\nswitch(PRODUCT_PHASE) { case \u0026#34;dev\u0026#34;: env.NODE_PORT = 12002 break case \u0026#34;sit\u0026#34;: env.NODE_PORT = 13002 break case \u0026#34;test\u0026#34;: env.NODE_PORT = 14002 break case \u0026#34;prod\u0026#34;: env.NODE_PORT = 15002 break } 此种方式将相关环境相关的配置全都集中到Jenkins流水线中，在最初的使用阶段可减少配置文件数量，能够快速编写流水线，快速交付使用。但随着项目规模与人员的扩大，当需要灵活配置多套环境时，此种方式采用硬编码的方式会显得捉襟见肘。\n修改后的方式 结合项目实际情况以及避免后续再次修改KubeSphere流水线，为了实现灵活的配置多套环境，自己制定了如下2个规则：\n端口信息存放到配置文件中，KubeSphere在构建时去流水线读取相关配置 当需要扩展环境或修改端口时，不需要修改KubeSphere中的流水线，只需要修改对应的端口配置文件即可2 由于项目中采用Nacos作为配置中心与服务管理平台，故决定采用Nacos作为端口的配置中心，实现流程如下：\n基于上述流程，在个人项目中面临如下问题：\n利用Groovy代码获取Nacos中特定的端口JSON配置文件，并能动态解析 利用Groovy代码根据输入输入参数动态的获取Nacos中对应的namespace 由于环境的增多，不可能每套环境都准备一个YAML文件，此时需要动态的读取并更新YAML文件 安装Pipeline Utility Steps插件 Jenkins默认不支持JSON、YAML的解析，需要在Jenkins中预先安装Pipeline Utility Steps插件，该插件提供了对JSON、YAML、CSV、PROPERTIES等常见文件格式的读取与修改操作。\nJSON文件设计 JSON文件设计如下，通过env、server、dubbo等属性记录环境和端口信息，通过project来记录具体的项目名称，由于配置文件中的key都是固定的，后续Groovy解析时会较为方便，在需要扩展环境时只需要更新此JSON文件即可。\n{ \u0026#34;portConfig\u0026#34;:[ { \u0026#34;project\u0026#34;:\u0026#34;lucumt-system\u0026#34;, \u0026#34;ports\u0026#34;:[ { \u0026#34;env\u0026#34;:\u0026#34;dev-1\u0026#34;, \u0026#34;server\u0026#34;:12001, \u0026#34;dubbo\u0026#34;:12002 }, { \u0026#34;env\u0026#34;:\u0026#34;dev-2\u0026#34;, \u0026#34;server\u0026#34;:12201, \u0026#34;dubbo\u0026#34;:12202 } ] }, { \u0026#34;project\u0026#34;:\u0026#34;lucumt-idp\u0026#34;, \u0026#34;ports\u0026#34;:[ { \u0026#34;env\u0026#34;:\u0026#34;dev-1\u0026#34;, \u0026#34;server\u0026#34;:13001, \u0026#34;dubbo\u0026#34;:13002 }, { \u0026#34;env\u0026#34;:\u0026#34;dev-2\u0026#34;, \u0026#34;server\u0026#34;:13201, \u0026#34;dubbo\u0026#34;:13202 } ] } ] } 读取namespace 在Nacos Open Api中可知查询namespace的请求为/nacos/v1/console/namespaces，基于Groovy的读取代码如下：\nresponse = sh(script: \u0026#34;curl -X GET \u0026#39;http://xxx.xxx.xxx.xxx:8848/nacos/v1/console/namespaces\u0026#39;\u0026#34;, returnStdout: true) jsonData = readJSON text: response namespaces = jsonData.data for(nm in namespaces){ if(BUILD_TYPE==nm.namespaceShowName){ NACOS_NAMESPACE = nm.namespace } } 读取Nacos配置文件 在Nacos Open Api中可知查询配置文件的请求为/nacos/v1/cs/configs，基于Groovy的读取代码如下：\nresponse = sh(script: \u0026#34;curl -X GET \u0026#39;http://xxx.xxx.xxx.xxx:8848/nacos/v1/cs/configs?dataId=idp-custom-config.json\u0026amp;group=idp-custom-config\u0026amp;tenant=0f894ca6-4231-43dd-b9f3-960c02ad20fa\u0026#39;\u0026#34;, returnStdout: true) jsonData = readJSON text: response configs = jsonData.portConfig for(config in configs){ project = config.project if(project!=PROJECT_NAME){ continue } ports = config.ports for(port in ports){ if(port.env!=BUILD_TYPE){ continue } env.NODE_PORT = port.server } } 根据YAML文件 由于自己将项目中变化的部分已经单独抽取为了一个YAML文件，故只需要修改此单独配置文件即可，在修改过程中，处于简化考虑，自己先将原有的YAML文件删除，之后重新写入，相关代码如下\nyamlFile = \u0026#39;src/main/resources/bootstrap-dev.yml\u0026#39; yamlData = readYaml file: yamlFile yamlData.spring.cloud.nacos.discovery.group = BUILD_TYPE yamlData.spring.cloud.nacos.discovery.namespace = NACOS_NAMESPACE yamlData.spring.cloud.nacos.config.namespace = NACOS_NAMESPACE sh \u0026#34;rm $yamlFile\u0026#34; writeYaml file: yamlFile, data: yamlData 运行效果 上述的配置均需要在项目编译之前进行，配置完毕的流水线运行效果如下，程序可正常运行，改造目的实现。\n参考代码 前端Jenkins流水线，参见lucumt-system-web-new.groovy 后端Jenkins流水线，参见lucumt-system-new.groovy 参见lucumt-system.groovy\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n在个人项目中Jenkins流水线不需要修改，但需要修改Kubesphere中的默认输入配置，将新增的环境加到下拉列表中，便于使用\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022-09-15T15:46:24+08:00","permalink":"https://lucumt.info/post/devops/using-nacos-and-kubesphere-to-create-multiple-environments/","tags":["kubesphere","jenkins","nacos"],"title":"利用Nacos与KubeSphere创建多套开发与测试环境"},{"categories":["位操作","Java编程"],"contents":"近期在工作中遇到由于HTTP返回的内容较多导致系统响应延迟的问题，最终自己结合gzip、Protocol Buffers、位运算等将HTTP响应返回的数据从15M减少到1M从而解决系统无卡顿问题。其中对于位运算部分自己是结合业务实际，将3个小型int转化为1个long，将数据量减少三分之一，简单记录下其实现(以Java实现为例)。\n背景 某个项目模块要将一系列的坐标数据返回给前端页面，坐标数据由x、y、z这3个维度来定义且用float表示，它们的约束条件如下：\n$|x|$\u0026lt;150、$|y|$\u0026lt;50、$|z|$\u0026lt;50\n示例文件如下：\n123.45\t34.56\t23.78 111.35\t-32.56\t21.78 103.77\t24.83\t-13.78 #...共有超过10万行数据 99.83\t21.35\t43.39 最开始自己是采用自己是将它们逐行读取并以String的形式封装到JSON中返回给前端，此种原始的方式很明显会导致返回给前端的数据量巨大从而严重影响性能。\n接下来自己从如下几个方面着手优化\n将返回的数据从String转化为float，减少整体响应的字节数 采用gzip压缩，将响应数据的体积缩小到原始的三分之一 采用Protocol Buffers在加快解析速度的同时进一步缩小请求响应的数据包体积 通过上述操作之后，响应速度从原来的4-5s缩短到1s之内，基本上达到优化目的，在后续的总结中发现请求响应慢的主要原因是由于响应头的体积过大造成的，于是继续寻找减少响应体积的办法。\n分析 在Java中int和float都占用4个字节共32bit位，将上述示例文件中的坐标数据从float转化为int并不会造成响应数据的体积变化，但由于业务的特殊性限制了x、y、z这3个坐标的取值范围(有前述所述的范围限制)，尝试分析它们的占用的最大bit位数：\nx = 14999 = 0b100100100111101111 // 占用18bit位 y = 4999 = 0b1100001101001111 // 占用16bit位 z = 4999 = 0b1100001101001111 // 占用16bit位 在不考虑负数的情况下，x、y、z累计占用的bit位数为50，而一个long类型占用8个字节共64bit位，理论分析是可以将3个int合并为1个long型数据。\n存储设计 考虑到坐标数据可能有负数,可用1个bit位专门记录对应的坐标数是否为负数，此时加上正负数的标记也总共只占用53个bit位，没有超过单个long型数据的最大bit位数。\n从便于编码的角度对x、y、z在long型中的存储做出如下划分:\n每个int占用20个bit位，最前面一个bit位记录正负数(为正数时该bit位为0，为负数时该bit位为1)\n移位操作 前述理论分析可能，但在实际操作过程中会遇到如下2个问题：\n如何在对应的正负数标识bit位上写入和读取值 如何给特定的坐标值准确写入对应的bit位且能准确读取 结合位运算本身特性以及实际业务需求，上述问题的解决方案如下：\n若特定坐标为负数，可将第20或40或60bit位设置为1\n为了准确记录各坐标数的值，需要将它们与一个类似0b1111111111111111111（十六进制表示为0x7ffff）的基准值进行\u0026amp;运算，由于要在单个long中记录下3个int的数值，此时就涉及到对坐标数据进行移位运算，如下图所示\n具体的分析如下：\nx为第3个存储，需要与0b10000000000000000000做|运算来记录正负数，需要与0b01111111111111111111做\u0026amp;来记录具体值 y为第2个存储，需要与0b1000000000000000000000000000000000000000做|运算来记录正负数，需要与0b0111111111111111111111111111111111111111做\u0026amp;来记录具体值 z为第1个存储，需要与0b100000000000000000000000000000000000000000000000000000000000做|运算来记录正负数，需要与0b011111111111111111111111111111111111111111111111111111111111做\u0026amp;来记录具体值 上述涉及到的6个基准数据用二进制表示太复杂，其精简表示如下：\n0b10000000000000000000 =\u0026gt; 1\u0026lt;\u0026lt;19 0b1000000000000000000000000000000000000000 =\u0026gt; 1L\u0026lt;\u0026lt;391 0b100000000000000000000000000000000000000000000000000000000000=\u0026gt; 1L\u0026lt;\u0026lt;59 0b01111111111111111111 =\u0026gt; 0x7ffff 0b0111111111111111111111111111111111111111 =\u0026gt; 0x7ffffL\u0026lt;\u0026lt;20 0b011111111111111111111111111111111111111111111111111111111111= \u0026gt;0x7ffffL\u0026lt;\u0026lt;40 若用position2表示第几个坐标数，则基准数据可进一步精简如下：\n正负数的记录位1L \u0026lt;\u0026lt; (position * 20 - 1) 数据值的记录位0x7ffffL \u0026lt;\u0026lt; ((position - 1) * 20) 实现 基于前述分析过程，坐标数据写入的代码如下，需要注意的是在写入过程中要传递一个类型为long的target3变量，通过target变量来记录对应的坐标的具体数据和正负数标识。\npublic static long bitWrite(int position, long original, long target) { // 记录是否为正负数的标识位 long typeBase = 1L \u0026lt;\u0026lt; (position * 20 - 1); // 记录具体的坐标数值 long valueBase = 0x7ffffL \u0026lt;\u0026lt; ((position - 1) * 20); // 若为负数，则需要将对应标识位记为1，同时将其变为正数 if (original \u0026lt; 0) { target = target | typeBase; original = -original; } // 坐标数与数据值bit位做或操作记录下其值 original = original \u0026lt;\u0026lt; (position - 1) * 20; original = original \u0026amp; valueBase; // 将坐标数写入long型结果中 target = target | original; return target; } 坐标数据的读取过程则是写入操作的反向操作，需要将\u0026amp;变为|，将|变为\u0026amp;，同写入操作类似，需要传入之前写入的target变量，以便程序反向识别出相关数据\npublic static long bitRead(int position, long target) { long value; long typeBase = 1L \u0026lt;\u0026lt; (position * 20 - 1); //识别是否为负数 boolean isNegative = (target \u0026amp; typeBase) == typeBase; // 读取具体的数值，此时读取的均为正数 long valueBase = 0x7ffffL \u0026lt;\u0026lt; ((position - 1) * 20); value = target \u0026amp; valueBase; value = value \u0026gt;\u0026gt; (position - 1) * 20; // 若为负数，则要进行恢复操作 if (isNegative) { value = -value; } return value; } 基于上述方法利用如下代码进行测试\npublic static void testData() { int x = -14997; int y = 3349; int z = -2377; long target = 0; target = bitWrite(1, x, target); target = bitWrite(2, y, target); target = bitWrite(3, z, target); System.out.println(Long.toBinaryString(target)); System.out.println(bitRead(1, target)); System.out.println(bitRead(2, target)); System.out.println(bitRead(3, target)); } 测试结果如下，程序输出结果符合预期\n完整代码参见SmallIntBitCompressTest.java\n由于int型最大的位数为32位，左移39位时超过其限制会编译出错，故需要使用1L\u0026lt;\u0026lt;39替代1\u0026lt;\u0026lt;39\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n与Java中的下标表示保持一致，position从0开始，故其值只能为0、1、2三者之一\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ntarget变量的类型初始值需要设置为0\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022-09-08T10:04:59+08:00","permalink":"https://lucumt.info/post/bit/merge-three-int-number-into-a-long-number/","tags":["bit"],"title":"将3个小int整数合并到1个long中从而缩小数据量"},{"categories":["持续集成","系统集成"],"contents":"之前在公司内部推广KubeSphere用于持续集成和部署，取得了不错的反馈，考虑到大规模使用的便利性以及之前已有LDAP整合其它系统的成熟经验，很自然的想将LDAP集成到KubeSphere中。原以为会很容易，一番折腾下来费了不好功夫(KubeSphere要求使用LDAP时必须设置管理员账号和密码)，简单记录下。\n公司内部的LDAP系统支持匿名登录，在给其它系统(如yapi)集成LDAP时，只需要输入对应的host、uid、searchDN即可，整合起来十分便捷，类似如下：\n\u0026#34;ldapLogin\u0026#34;:{\r\u0026#34;enable\u0026#34;:\u0026#34;true\u0026#34;,\r\u0026#34;server\u0026#34;:\u0026#34;ldap://192.168.0.2:389\u0026#34;,\r\u0026#34;searchDn\u0026#34;:\u0026#34;dc=lucumt,dc=info\u0026#34;,\r\u0026#34;searchStandard\u0026#34;:\u0026#34;uid\u0026#34;,\r\u0026#34;usernameKey\u0026#34;:\u0026#34;uid\u0026#34;\r} 公司内部的KubeSphere版本为v3.1.1，在集成LDAP之前先去官网查看了相关说明，在LDAP身份提供者中有如下说明：\nspec:\rauthentication:\rjwtSecret: \u0026#39;\u0026#39;\rmaximumClockSkew: 10s\rmultipleLogin: true\roauthOptions:\raccessTokenMaxAge: 1h\raccessTokenInactivityTimeout: 30m\ridentityProviders:\r- name: LDAP\rtype: LDAPIdentityProvider\rmappingMethod: auto\rprovider:\rhost: 192.168.0.2:389\rmanagerDN: uid=root,cn=users,dc=nas\rmanagerPassword: ********\ruserSearchBase: cn=users,dc=nas\rloginAttribute: uid\rmailAttribute: mail 可以看出其默认多了managerDN和managerPassword这两个管理员属性，但由于公司的LDAP默认对外不提供管理员账号和密码，只能匿名登录认证，且自己之前在其它系统中匿名配置LDAP都很顺畅，于是通过匿名方式配置如下：\nprovider:\rhost: 192.168.1.22:389\r#managerDN: uid=root,cn=users,dc=nas\r#managerPassword: ********\ruserSearchBase: dc=lucumt,dc=info\rloginAttribute: uid\rmailAttribute: mail 将官方文档中要求的managerDN和managerPassword屏蔽掉，接着重启KubeSphere系统，登录过程出现如下提示：\n错误信息提示说密码不能为空，但是我们登录的时候肯定有输入密码的，那只可能是managerPassword为空导致的。\n查找KubeSphere官网相关说明发现其对于managerDN和managerPassword没有说明是选填项，结合前面的报错信息，可得出如下结论\nKubeSphere不支持LDAP匿名登录\n于是只能找公司相关部门申请LDAP具有只读账号的管理员权限，配置类似如下，之后重启KubeSphere可正常集成LDAP登录。\nprovider:\rhost: 192.168.1.22:389\rmanagerDN: admin=cn,dc=lucumt,dc=info\rmanagerPassword: ********\ruserSearchBase: dc=lucumt,dc=info\rloginAttribute: uid\rmailAttribute: mail 只能说KubeSphere在这方面做的不太好，已经在其官网反馈此问题!\n","date":"2022-09-04T09:35:50+08:00","permalink":"https://lucumt.info/post/devops/setting-ldap-for-kubesphere/","tags":["kubesphere","jenkins","LDAP"],"title":"Kubesphere集成LDAP踩坑记录"},{"categories":["个人博客"],"contents":"作为一名IT民工，善于利用各种工具提升工作效率才算合格，本文简单记录自己如何利用GitHub Actions实现个人Hugo博客在GitHub Pages中的自动化部署。\n传统方式 自己的个人博客创建于2016年，在这期间自己一直基于如下方式创建并部署更新博客：\n1.利用hugo命令创建对应的博客markdown文件\nhugo new post/hugo/using-github-action-to-auto-build-deploy.md 2.利用下述命令开启hugo博客的动态监听展示，并进行编写\nhugo server -w -D 3.博客内容编写完成后，利用下述命令将其切换到实际部署环境\nhugo server --baseUrl=\u0026#34;https://lucumt.info/\u0026#34; --watch=false --appendPort=false --renderToDisk --environment production 4.执行下述命令提交到master分支\ngit add -A\rgit commit -a -m \u0026#34;xxxx\u0026#34;\rgit push origin master 5.利用下述命令将public目录中的内容从master 分支同步到gh-pages分支\ngit subtree push --prefix=public git@github.com:lucumt/ghblog.git gh-pages 上述过程中的1,2,4阶段是编写博客的必经阶段，而3,5阶段其实没太多必要，完全可以用工具自动化实现。作为IT从业者，我们需要尽可能的减少不必要的操作。\n改进方式 结合网络上的相关资料，自己把实现方案定在了GitHub Actions和Travis CI二者之一，考虑到GitHub中已经内置了GitHub Actions ，最终解决采用其作为实现方案。\n在Hugo的官方文档Build Hugo With GitHub Action中也推荐采用GitHub Actions作为持续集成部署方案，并提供了相应的流水线配置代码:\nname: github pages\ron:\rpush:\rbranches:\r- main # Set a branch to deploy\rpull_request:\rjobs:\rdeploy:\rruns-on: ubuntu-20.04\rsteps:\r- uses: actions/checkout@v2\rwith:\rsubmodules: true # Fetch Hugo themes (true OR recursive)\rfetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod\r- name: Setup Hugo\ruses: peaceiris/actions-hugo@v2\rwith:\rhugo-version: \u0026#39;latest\u0026#39;\r# extended: true\r- name: Build\rrun: hugo --minify\r- name: Deploy\ruses: peaceiris/actions-gh-pages@v3\rif: github.ref == \u0026#39;refs/heads/main\u0026#39;\rwith:\rgithub_token: ${{ secrets.GITHUB_TOKEN }}\rpublish_dir: ./public 该配置代码已经很完善，个人根据实际情况对其做了如下修改：\n1.在Build阶段，将hugo命令改为适合个人环境的hugo -b \u0026quot;https://lucumt.info/\u0026quot; -e \u0026quot;production\u0026quot;\n2.在个人GitHub中设置github_token\n其中关于github_token的配置可按如下步骤配置：\n1.在个人GitHub页面，依次点击Settings-\u0026gt;Developer settings-\u0026gt;Personal access tokens进入如下页面：\n2.点击Generate new token出现如下界面，在Note中输入名称，在Select scopes选择workflow\n3.将生成的token复制出来为后续创建secret做准备，注意必须及时复制，一旦离开此页面后续就无法查看其值，只能重新创建新token：\n4.进入对应的GitHub项目下，依次点击Settings-\u0026gt;Secrets-\u0026gt;Actions进入添加Action secrets的界面，点击New repository secret按钮\n5.在出现的界面中name部分输入我们设置的值，Secret部分输入步骤3中记录的token值，然后点击Add secret按钮\n需要注意的是name的值不能以GITHUB_开头，否则创建会出错\n6.在流水线中将github_token值设置为步骤5中secret的名称，类似${{ secrets.GH_PAGE_ACTION_TOKEN }}s，至此github_token设置过程完毕。\n配置后完整的流水线代码如下：\nname: pages-auto-build-deploy\ron:\r# workflow_dispatch: push:\rbranches:\r- master\rjobs:\rbuild-and-deploy:\rruns-on: ubuntu-latest\rsteps:\r- uses: actions/checkout@v2\rwith:\rsubmodules: true\rfetch-depth: 0\r- name: Setup Hugo\ruses: peaceiris/actions-hugo@v2\rwith:\rhugo-version: \u0026#39;0.100.2\u0026#39;\rextended: true\r- name: Build Hugo\rrun: hugo -b \u0026#34;https://lucumt.info/\u0026#34; -e \u0026#34;production\u0026#34;\r- name: Deploy\ruses: peaceiris/actions-gh-pages@v3\rwith:\rgithub_token: ${{ secrets.GH_PAGE_ACTION_TOKEN }}\rpublish_dir: ./public\rcommit_message: ${{ github.event.head_commit.message }} 将该yaml文件放到对应GitHub项目下的.github/workflows目录下即完成全部配置。\n当执行git push origin master后，GitHub Actions会开启自动构建部署，运行结果如下，至此整个设置过程完毕！\n其它 由于GitHub Action支持定时语法，将流水线触发条件修改如下\non:\rpush:\rbranches:\r- master\rschedule:\r# Runs everyday at 8:00 AM\r- cron: \u0026#34;0 8 * * *\u0026#34; 可实现每天上午8点自动触发构建，由于构建过程中会往gh-pages分支下提交代码，从而间接达成在GitHub中每天提交代码，在GitHub主页面展示时保持全绿的功能！1\n参考文档:\nhttps://www.ruanyifeng.com/blog/2019/09/getting-started-with-github-actions.html https://www.pseudoyu.com/zh/2022/05/29/deploy_your_blog_using_hugo_and_github_action/ 个人观点质量优于数量，不推荐这么做\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022-09-03T18:35:57+08:00","permalink":"https://lucumt.info/post/hugo/using-github-action-to-auto-build-deploy/","tags":["hugo","Github Pages","github","go"],"title":"利用GitHub Action实现Hugo博客在GitHub Pages自动部署"},{"categories":["Java编程"],"contents":"公司项目采用MinIO作为数据存储，最近遇到一个需求是将其中的某个文件夹的数据基于其原有的结构下载为ZIP文件，网上有很多下载为ZIP的代码，个人觉得其中好多不够精简，简单记录下自己的实现。\n文件夹下载 该文件夹在MinIO中存储的路径为2022-07/80/iodp-dataset-demo，其下包含多个文件夹\n在特定文件夹下包含多个数据文件\n由于在MinIO中是按照文件夹存储，一开始自己很显然的是想用直接去MinIO官网查看有没有直接下载文件夹的方式，在其官网java-client-api-reference中没有找到支持文件夹下载的方式。\n接下来自己通过ListObjectsArgs传入文件夹名称2022-07/80/iodp-dataset-demo的方式想一次性把文件都获取到，在此种方式下程序执行结果为空。\n至此，可知道 MinIO不支持原生的文件夹下载，只能按照文件挨个下载，为了获取所有文件，需要通过递归程序实现，相关代码如下\n@Log4j2 @Service public class MinioServiceImpl implements IMinioService { @Autowired private MinioClient mClient; @Override public InputStream downloadFile(String fileName, String bucket) { GetObjectArgs getArgs = GetObjectArgs.builder().bucket(bucket).object(fileName).build(); try { InputStream is = mClient.getObject(getArgs); return is; } catch (ErrorResponseException | InsufficientDataException | InternalException | InvalidKeyException | InvalidResponseException | IOException | NoSuchAlgorithmException | ServerException | XmlParserException e) { throw new RuntimeException(e); } } @Override public List\u0026lt;String\u0026gt; listFolderFiles(String folderName, String bucket) { List\u0026lt;String\u0026gt; fileList = new ArrayList\u0026lt;\u0026gt;(); listFolderFiles(folderName, bucket, fileList); return fileList; } private void listFolderFiles(String folderName, String bucket, List\u0026lt;String\u0026gt; fileList) { ListObjectsArgs listArgs = ListObjectsArgs.builder().bucket(bucket).prefix(folderName).build(); Iterable\u0026lt;Result\u0026lt;Item\u0026gt;\u0026gt; results = mClient.listObjects(listArgs); try { for (Result\u0026lt;Item\u0026gt; result : results) { Item item = result.get(); String objectName = item.objectName(); if (item.isDir()) { // 采用递归的方式遍历文件夹 listFolderFiles(objectName, bucket, fileList); } else { fileList.add(objectName); } } } catch (ErrorResponseException | InsufficientDataException | InternalException | InvalidKeyException | InvalidResponseException | IOException | NoSuchAlgorithmException | ServerException | XmlParserException e) { throw new RuntimeException(e); } } } 基于上述代码从MinIO中返回的文件信息类似如下所示：\n写入ZIP文件 由于MinIO中返回的文件信息已经具有层级结构，故在进行ZIP压缩时可基于文件路径直接设置其存储位置1\n@Override public void downloadDataset(int id, HttpServletResponse response) { DatasetModel dsModel = queryDataset(id); String path = dsModel.getPath(); int prefixLen = StringUtils.substringBeforeLast(path, \u0026#34;/\u0026#34;).length(); // 设置文件名 String zipFileName = StringUtils.substringAfterLast(path, \u0026#34;/\u0026#34;) \u0026#43; \u0026#34;.zip\u0026#34;; response.setCharacterEncoding(\u0026#34;UTF-8\u0026#34;); response.setContentType(\u0026#34;application/octet-stream\u0026#34;); try { response.addHeader(\u0026#34;Content-Disposition\u0026#34;, \u0026#34;attachment;filename=\u0026#34; \u0026#43; URLEncoder.encode(zipFileName, \u0026#34;UTF-8\u0026#34;)); } catch (UnsupportedEncodingException e) { throw new RuntimeException(e); } List\u0026lt;String\u0026gt; fileList = minioService.listFolderFiles(path, collectFilesBucket); try (OutputStream out = response.getOutputStream(); ZipOutputStream zs = new ZipOutputStream(new BufferedOutputStream(out))) { for (String filePath : fileList) { String fileName = filePath.substring(prefixLen \u0026#43; 1); InputStream is = minioService.downloadFile(filePath, collectFilesBucket); ZipEntry entry = new ZipEntry(fileName); zs.putNextEntry(entry); IOUtils.copy(is, zs); zs.closeEntry(); } zs.setMethod(ZipOutputStream.DEFLATED); //设置压缩方法 } catch (Exception e) { e.printStackTrace(); } } 下载后的ZIP文件如下所示，可见其层级结构与MinIO中原始存储的层级结构相同，功能正常实现。\n通过new ZipEntry(fileName)在fileName中指定其完整路径即可实现\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022-08-20T20:35:44+08:00","permalink":"https://lucumt.info/post/minio/download-minio-folder-as-zip-file/","tags":["MinIO","Java"],"title":"将MinIO中的文件夹下载为ZIP文件"},{"categories":["持续集成","容器化"],"contents":"近期在公司内部搭建基于KubeSphere的持续集成平台时，发现其底层的Kubernetes默认的端口范围为30000-32767而公司有多个采用微服务模块的项目在使用，默认的端口范围不便于分配使用，在基于网上文档修改的过程中自己踩到了一个坑，简单记录下。\n一开始时自己也是从网上查找相关资料，查找出来的结果和修改NodePort的范围中的基本都相同，自己也是按照其对应的方法进行操作:\n将/etc/kubernetes/manifests/目录下的kube-apiserver.yaml在当前目录下备份一份kube-apiserver.yaml.bak作为备份文件\n在kube-apiserver.yaml中加入--service-node-port-range=1-65537\napiVersion: v1 kind: Pod metadata: creationTimestamp: null labels: component: kube-apiserver tier: control-plane name: kube-apiserver namespace: kube-system spec: containers: - command: - kube-apiserver - --service-node-port-range=1-65537 # other config 之后执行下述命令来重启api-server\n# 获得 apiserver 的 pod 名字 export apiserver_pods=$(kubectl get pods --selector=component=kube-apiserver -n kube-system --output=jsonpath={.items..metadata.name}) # 删除 apiserver 的 pod kubectl delete pod $apiserver_pods -n kube-system 然后执行kubectl describe pod $apiserver_pods -n kube-system | grep \u0026quot;service-node-port-range\u0026quot;却发现输出结果为空，也就是说自己添加的动态端口配置并没有生效！\n之后搜索网上的各种解决方案，都是和前述的操作类似，尝试后都不生效，没办法只能继续搜索，直到发现https://www.modb.pro/db/146676这篇文章，在其中有如下说明\n之后检查自己系统的/etc/kubernetes/manifests/目录，发现果然有备份文件!\n将备份文件删除后，重新执行kubectl delete pod $apiserver_pods -n kube-system，经过若干秒的等待后，发现service-node-port-range已经生效，至此问题解决!\n总结：\n虽然这次问题是由于备份文件引起的，但是在Linux中修改重要配置文件时提前进行备份是个好习惯，从这次修改过程中学到的经验是不要在同目录下备份，要去专门的目录下备份。 Kubernetes底层的动态加载配置文件的原理需要进一步学习！ 感谢https://www.modb.pro/db/146676的作者埋头过坎，由于其无私分享避免了我走更多的弯路。 ","date":"2022-08-15T18:27:59+08:00","permalink":"https://lucumt.info/post/k8s/service-node-port-range-config-not-working-in-k8s/","tags":["kubernetes"],"title":"在Kubernetes中配置service-node-port-range不生效的问题"},{"categories":["持续集成"],"contents":"目前公司的开发方式都是手工编译\u0026amp;部署，十分低效，最近将Web开发相关的项目都基于KubeSphere通过基于Jenkins的流水线方式实现了自动部署，在此过程中遇到了一些阻塞点，简单记录下它们的解决方案。\n在KubeSphere的Github仓库中有如下说明：\nKubeSphere是什么\nKubeSphere 愿景是打造一个以 Kubernetes 为内核的 云原生分布式操作系统，它的架构可以非常方便地使第三方应用与云原生生态组件进行即插即用（plug-and-play）的集成，支持云原生应用在多云与多集群的统一分发和运维管理。 KubeSphere 也是一个多租户容器平台，提供全栈的 IT 自动化运维的能力，简化企业的 DevOps 工作流\nKubernetes DevOps\n提供开箱即用的基于 Jenkins 的 CI/CD，并内置自动化流水线插件，包括 Binary-to-Image (B2I) 和 Source-to-Image (S2I)\n从上述描述可知KubeSphere的两大底层支柱为Kubernetes与Jenkins，本文也主要基于这两部分进行记录。\n流水线设计 基于部门现状以及参考网上资料，将产品部署环境划分为如下4种类型:\ndev，本地开发阶段 sit，前后端各模块联调阶段 test，软件功能测试阶段 prod，正式使用阶段 虽然通过上述划分方式可有效的避免不同环境的互相干扰，但由于目前部门大部分产品都采用了微服务实现，软件架构类似下图所示，每个微服务模块都有单独的代码管理，导致若给前后端的每个功能模块在不同环境下都配置一套Jenkins流水线则实际的流水线数目会十分庞大，不便于管理和维护。\n若对于每个功能模块在所有不同环境中都分别使用一套流水线，则其数量为功能模块数X环境种类数，造成流水线数目过大，使用不便同时也不利于后期的维护。\n基于此，我们对Jenkins流水线的构建和使用方式提出了如下要求：\n一套Gitlab代码库对应一条Jenkins流水线，实际上就是前后端的一个功能模块，使用时可动态选择分支 一套Jenkins流水线可以根据使用需求灵活的往dev、sit、test、prod这4套环境之一进行部署 dev、sit、test、prod对于同一套代码而言是分别部署的，即4套环境互不影响 动态参数 上图展示了Jenkins进行软件构建的主要流程，从中可知若达到上述精简流水线条目的要求，则需要进行动态参数配置，基于项目实际情况，整理出如下场景：\n软件版本，主要是后端基于Maven的项目需要正确的获取版本号 容器端口，SpringBoot应用程序对外暴露的端口，此部分需要在使用Dockerfile构建时动态对外暴露1 容器端口，Kubernetes中创建容器时对外暴露的端口，主要用于程序访问 镜像版本，前后端程序构建镜像时，对应tag的动态设置 在Jenkins中的脚本类型主要有shell脚本和script脚本2种类型，其中script是基于Grovvy实现的，而Groovy是基于JVM实现的，其在时使用上比shell更灵活，故在流水线实现时对于参数设置与获取确定了一个如下的大致原则:\n能通过Groovy脚本获取的变量与参数尽量通过Grovvy获取，Shell脚本只负责使用\nscript中定义参数 在script中输入符合 Groovy语法的代码即可，为了在多个steps之间实现参数共享，需要在定义参数时加上env.前缀2，类似如下：\nswitch(PRODUCT_PHASE) {\rcase \u0026#34;sit\u0026#34;:\renv.NODE_PORT = 13003\renv.DUBBO_PORT = 13903\rbreak\rcase \u0026#34;test\u0026#34;:\renv.NODE_PORT = 14003\renv.DUBBO_PORT = 14903\rbreak\rcase \u0026#34;prod\u0026#34;:\renv.NODE_PORT = 15003\renv.DUBBO_PORT = 15903\rbreak\r}\renv.DUBBO_IP = \u0026#34;10.30.5.170\u0026#34; script中读取参数 print env.DUBBO_IP shell中读取参数 需要采用$参数名(去掉env.前缀)的方式，类似如下\ndocker build -f kubesphere/Dockerfile \\\r-t idp-data:$BUILD_TAG \\\r--build-arg PROJECT_VERSION=$PROJECT_VERSION \\\r--build-arg NODE_PORT=$NODE_PORT \\\r--build-arg DUBBO_PORT=$DUBBO_PORT \\\r--build-arg PRODUCT_PHASE=$PRODUCT_PHASE . yaml文件中读取参数 在Kubernetes中需要一个yaml文件来配置要生成的pod，其参数的获取也是采用$参数名的方式\nspec:\rports:\r- name: http\rport: $NODE_PORT\rprotocol: TCP\rtargetPort: $NODE_PORT\rnodePort: $NODE_PORT\r- name: dubbo\rport: $DUBBO_PORT\rprotocol: TCP\rtargetPort: $DUBBO_PORT\rnodePort: $DUBBO_PORT\rselector:\rapp: lucumt-data-$PRODUCT_PHASE\rsessionAffinity: None\rtype: NodePort Dockerfile中读取参数 当在docker的build阶段传递正确的参数后，在Dockerfile中需要采用${参数名}的方式获取参数\n# 基础镜像\rFROM openjdk:8-jdk\r# author\rLABEL maintainer=luyunqiang\r# 创建目录\rRUN mkdir -p /home/lucumt\r# 指定路径\rWORKDIR /home/lucumt\rARG PRODUCT_PHASE\rARG NODE_PORT\rARG DUBBO_PORT\rENV PARAMS=\u0026#34;--server.port=${NODE_PORT} --spring.application.name=lucumt-data --spring.profiles.active=${PRODUCT_PHASE} --dubbo.protocol.port=${DUBBO_PORT}\u0026#34;\rRUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \u0026amp;\u0026amp; echo \u0026#39;Asia/Shanghai\u0026#39; \u0026gt;/etc/timezone 编译与部署 由于公司研发环境与互联网隔离，故需要在前后端分别设置可用的镜像才能确保编译正常。\n前端 Nodejs版本号升级：\n由于KubeSphere中的Node.js的版本落后于项目中使用的版本，故需要通过如下命令升级其版本：\nnpm install node@16.13.1 --registry https://mirrors.xxx.com/repository/NPM/\nNginx默认的端口为80，且其默认的conf文件较为简陋，为了实现nginx的个性化配置，可以自己预先配置好一个conf文件，然后在docker构建时，将其覆盖即可\nFROM nginx\rRUN mkdir -p /usr/share/nginx/html/lucumt-web\rCOPY dist /usr/share/nginx/html/lucumt-web\r# 采用自己定义的配置文件\rCOPY kubesphere/idp.conf /etc/nginx/conf.d/\rEXPOSE 8080 后端 获取Maven版本号：\nmvn help:evaluate -Dexpression=project.version -q -DforceStdout 由于在shell中不方便定义全局变量，而Maven的版本号只能在执行相关命令时获取，为了实现版本号的共享，可将两者结合起来，在shell中利用maven命令获取版本号，然后再由Groovy脚本将其赋值为全局环境变量:\nenv.PROJECT_VERSION = sh(script: \u0026#39;mvn help:evaluate -Dexpression=project.version -q -DforceStdout\u0026#39;, returnStdout: true)\renv.BUILD_TIME = new Date().format(\u0026#34;yyyyMMdd-HHmmss\u0026#34;)\renv.BUILD_TAG = PROJECT_VERSION \u0026#43; \u0026#34;-\u0026#34; \u0026#43; BUILD_TIME K8S容器探活 KubeSphere对于容器的启动、就绪和存活的探测依赖于Kubernetes的相关实现，实际使用中KubeSphere只需要能正常检测到就绪状态即可，现阶段项目中也只基于就绪探测来实现。\n后端 SpringBoot程序可基于Spring Boot Actuator中提供的actuator/health进行就绪检测，相关配置如下:\ncontainers:\r- image: \u0026#39;$REGISTRY/$DOCKERHUB_NAMESPACE/lucumt-system:${BUILD_TAG}\u0026#39;\rreadinessProbe:\rhttpGet:\rpath: lucumt-system/actuator/health\rport: $NODE_PORT\rtimeoutSeconds: 10\rfailureThreshold: 30\rperiodSeconds: 5 前端 由于前端没有单独的接口对外暴露，故可采用在Docker容器中执行linux命令的方式来检测是否就绪，个人采用uname，相关配置如下：\ncontainers:\r- image: \u0026#39;$REGISTRY/$DOCKERHUB_NAMESPACE/lucumt-system-web:${BUILD_TAG}\u0026#39;\rreadinessProbe:\rexec:\rcommand:\r- uname\rtimeoutSeconds: 10\rfailureThreshold: 30\rperiodSeconds: 5 运行效果 运行效果如下，可实现动态的指定测试阶段和代码分支：\n参考代码 前端部分: Dockerfile，参见lucumt-common-web.dockerfile depoly.yml，参见lucumt-common-web.yaml Jenkins流水线，参见lucumt-common-web.groovy Nginx配置文件，参见lucumt-common-web-nginx.conf 后端部分: Dockerfile，参见lucumt-system.dockerfile depoly.yml，参见lucumt-system.yaml Jenkins流水线，参见lucumt-system.groovy 参考:\nhttps://askubuntu.com/questions/76808/how-do-i-use-variables-in-a-sed-command 理论上来说此处的端口不用暴露，只需要在容器创建时进行对应的端口映射即可，不过由于公司项目采用nacos进行动态配置与服务发现，为了方便统一管理，故也将此处的端口做成动态配置\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n实际测试发现不加env.也能在其它的步骤中正常获取\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022-08-06T18:00:08+08:00","permalink":"https://lucumt.info/post/devops/share-experiences-for-using-kubesphere/","tags":["kubesphere","jenkins"],"title":"KubeSphere使用心得"},{"categories":["容器化"],"contents":"由于公司的docker容器在运行一段时间后日志变得很大，通过shell脚本或者结合docker stop、docker rm和docker run来重新创建实例方式都觉得太麻烦，按照网络上的建议在/etc/docker/daemon.json中进行相关修改后却一直无法启动，同时错误信息一直提示unable to configure the Docker daemon with file /etc/docker/daemon.json: the following directives are specified both as a flag and in the config…e: json-file)，经过一番排查后终于找到原因，故记录下。\n问题复现 系统环境 操作系统，uname -a输出如下：\nLinux AEHPD 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux docker info输出的主要信息如下:\nContainers: 0 Running: 0 Paused: 0 Stopped: 0 Images: 0 Server Version: 1.13.1 Storage Driver: overlay2 Backing Filesystem: xfs Supports d_type: true Native Overlay Diff: true Logging Driver: journald Cgroup Driver: systemd Plugins: Volume: local Network: bridge host macvlan null overlay Swarm: inactive Runtimes: docker-runc runc Default Runtime: docker-runc 操作过程 在/etc/docker/daemon.json的配置如下:\n{ \u0026#34;registry-mirrors\u0026#34;:[\u0026#34;https://docker.hirain.com\u0026#34;], \u0026#34;log-driver\u0026#34;: \u0026#34;json-file\u0026#34;, \u0026#34;log-opts\u0026#34;: { \u0026#34;max-size\u0026#34;: \u0026#34;50m\u0026#34;, \u0026#34;max-file\u0026#34;:\u0026#34;3\u0026#34; } } 之后执行systemctl daemon-reload \u0026amp;\u0026amp; systemctl restart docker会提示docker启动失败，根据输出提示利用systemctl status docker.service获取详细的输出信息如下:\n从输出中可看见系统提示如下报错信息:\nunable to configure the Docker daemon with file /etc/docker/daemon.json: the following directives are specified both as a flag and in the config\u0026hellip;e: json-file)\n基于前述步骤的提示信息，在/etc/docker/daemon.json移除\u0026quot;log-driver\u0026quot;: \u0026quot;json-file\u0026quot;这行配置然后执行相关命令重启会发现 docker依旧启动失败！\n从输出中可看见如下提示信息:\ndockerd-current[14912]: Failed to set log opts: unknown log opt \u0026lsquo;max-size\u0026rsquo; for journald log driver\n在/etc/docker/daemon.json将log-opts相关配置移除后，发现docker能启动成功！至此可以得出如下2条结论:\nlog-driver配置由于与其它指令冲突了，导致docker服务无法启动，后续去docker官网查询也确实有此说明1 log-opts单独在/etc/docker/daemon.json也不生效 排查与解决 在可正常启动docker服务的环境下利用docker info --format '{{.LoggingDriver}}'命令发现其输出为journald，显然之前的log-driver配置与其冲突了，从而导致docker`服务无法启动\n前面的步骤中提示有/etc/docker/seccomp.json ，查看其中的内容没有发现有价值的信息\n通过systemctl status docker.service -l输出如下，在其中发现关键信息--log-driver=journald ，很明显是其它地方有对应设置\n查找网络资料，利用cat /lib/systemd/system/docker.service查看是由有其它配置文件，发现配置文件 /etc/sysconfig/docker\n输出 /etc/sysconfig/docker结果如下，发现关键信息--log-driver=journald ，它就是我们之前修改/etc/docker/daemon.json后一直无法启动的罪魁祸首！\n接下来在/etc/sysconfig/docker中的相关位置将--log-driver=journald 这条指令去掉，然后在/etc/docker/daemon.json中重新加上相关之后后docker容器可正常启动，问题解决！\nTroubleshoot conflicts between the daemon.json and startup scripts\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022-08-04T16:56:18+08:00","permalink":"https://lucumt.info/post/docker/can-not-set-log-driver-and-log-opts-in-docker-daemon-json/","tags":["docker"],"title":"由于daemon.json中的配置与其它启动项冲突导致docker服务无法启动"},{"categories":["个人博客"],"contents":"自己一直特别羡慕博客园上某些博主的博文样式（如武培轩,JavaGuide)，这些博文样式第一眼看起来就很清爽,让人很有阅读的欲望，而我总感觉自己博客的样式特丑陋。即使不关注内容，只看排版布局和样式，有时候自己写完一篇文章自己都不想去看，何况别人！\n终于有一天我受不了自己的博客样式，决定对其升级一版，在这个过程中发现个人采用的博客主题Even功能很强大，基于上没做啥修改就达到了自己想要的效果，特此记录下。\n风格对比 个人博客基于Golang语言开发的Hugo最开始是采用hugo-redlounge主题来实现的，经过一段时间的使用之后感觉hugo-redlounge主题功能不丰富且左侧会固定占用一部分宽度来展示个人信息，而这部分其实并无太大意义，故后来将其切换为如今的Even样式。\nhugo-redlounge主题的博客：\nEven主题的博客\nEven主题的代码和引用样式\n切换后虽然相对于与hugo-redlounge主题当前博客的功能和界面美观性有一定提升，但是和博客园中的博文样式比起来直观感觉还是有一定差距，尤其是在包含代码段时淡黄色的背景看起来略微不舒服(如上图)。\n源码分析 个人对于Even主题最不满意的是在显示代码段时其样式不太符合自己预期，在浏览器中分析代码段对应的CSS样式，可看出是由如下CSS代码控制的：\n.post .post-content code, .post .post-content pre { padding: 7px; font-size: .9em; font-family: Consolas,Monaco,Menlo,dejavu sans mono,bitstream vera sans mono,courier new,monospace; background: #f8f5ec; } 分析Even主题的源码后发现其主要是基于Sass框架通过_code.scss和_content.scss联合实现的，其中背景设置是通过background: $code-background;实现\n由于Sass支持通过变量来动态的设置CSS属性值，故$code-background显然也是一个变量，查看源码后发现其在_variables.scss中有如下定义:\n// Color of the code background. $code-background: $deputy-color !default; 在_variables.scss中继续查找$deputy-color的定义，可找出在该文件开头有如下代码，其中$deputy-color是通过$theme-color-config在$theme-color-map中查找相关的颜色设置，自己博客之前默认淡黄色的代码块样式就是通过Default样式设置的。\n// ============================== // Variables // ============================== // ========== Theme Color ========== // // Config here to change theme color // Default | Mint Green | Cobalt Blue | Hot Pink | Dark Violet $theme-color-config: \u0026#39;Mint Green\u0026#39;; // Default theme color map $theme-color-map: ( \u0026#39;Default\u0026#39;: #c05b4d #f8f5ec, \u0026#39;Mint Green\u0026#39;: #16982B #f5f5f5, \u0026#39;Cobalt Blue\u0026#39;: #0047AB #f0f2f5, \u0026#39;Hot Pink\u0026#39;: #FF69B4 #f8f5f5, \u0026#39;Dark Violet\u0026#39;: #9932CC #f5f4fa ); // Check theme color config. // if it does not exist, use default theme color. @if not(map-has-key($theme-color-map, $theme-color-config)) { $theme-color-config: \u0026#39;Default\u0026#39;; } $theme-color-list: map-get($theme-color-map, $theme-color-config); // Default theme color of the site. $theme-color: nth($theme-color-list, 1) !default; // Deputy theme color of the site. $deputy-color: nth($theme-color-list, 2) !default; 进一步分析后发现$deputy-color在_variables.scss中的多个地方都有使用，从而可以确定通过修改$theme-color-config的值就能达到动态更改博客主题样式的目的。\n// Deputy theme color of the site. $deputy-color: nth($theme-color-list, 2) !default; // Backgroud color of the post toc. $post-toc-backgroud: rgba($deputy-color, 0.6) !default; // Border color of the table. $content-table-border-color: darken($deputy-color, 3%) !default; // Color of the code background. $code-background: $deputy-color !default; 样式修改 由于SCSS文件需要编译成CSS文件后才能被使用，而Hugo默认版本是不支持SCSS编译的，故需要下载Hugo Extended版本\n下载完毕后，需将其添加到环境变量，其各种指令的用法与默认版Hugo的用法相同，根据实际情况在_variables.scss中修改$theme-color-config的值，然后调用hugo server -w -D等命令即可实时展示修改效果。\n结果展示 Default样式 Mint Green样式 Cobalt Blue样式 Hot Pink样式 Dark Violet样式 扩展 可根据个人喜好在_variables.scss动态的添加自己喜欢的颜色配置\n// ========== Theme Color ========== // // Config here to change theme color // Default | Mint Green | Cobalt Blue | Hot Pink | Dark Violet $theme-color-config: \u0026#39;Mint Green\u0026#39;; // Default theme color map $theme-color-map: ( \u0026#39;Default\u0026#39;: #c05b4d #f8f5ec, \u0026#39;Mint Green\u0026#39;: #16982B #f5f5f5, \u0026#39;Cobalt Blue\u0026#39;: #0047AB #f0f2f5, \u0026#39;Hot Pink\u0026#39;: #FF69B4 #f8f5f5, \u0026#39;Dark Violet\u0026#39;: #9932CC #f5f4fa ); 致谢 https://github.com/olOwOlo/hugo-theme-even https://github.com/ahonn/hexo-theme-even ","date":"2022-08-01T17:04:09+08:00","permalink":"https://lucumt.info/post/hugo/change-hugo-style-in-even-theme/","tags":["hugo","Go"],"title":"在Hugo生成的博客中动态的修改样式"},{"categories":["容器化"],"contents":"简要记录下近期在项目中遇到的多个docker-compose.yml文件容器启动时发生冲突的原因分析。\n问题背景 出于多方面的考虑，公司的一些项目都逐渐的采用Docker作为部署环境，相对于互联网公司我们的Docker容器数据量没那么多，在容器管理工具的选型上我们采用的是Docker Compose而非常见的Kubernetes。\nDocker Compose需要我们将相关的Docker指令都写入到yaml文件中，相对于通过纯命令行操作Docker其在可维护性和可阅读性上都有很大的便利，故很快在部门内部推广使用了。\n在此过程中，有同事偶然遇到多个docker-compose.yml文件启动时会冲突的问题，一番分析后虽然最终解决该问题，但由于该问题在多个docker-compose.yml文件时容易产生，简单记录下已被不时之需。\n简化版的问题描述如下：\n在某个目录下有两个docker-compose.yml文件，分别为nginx_test_1.yml和nginx_test_2.yml\n[root@fox docker_test]# pwd /root/docker_test [root@fox docker_test]# ls nginx_test_1.yml nginx_test_2.yml 它们的内容分别如下\nnginx_test_1.yml配置：\nversion: \u0026#34;3\u0026#34; services: nginx: privileged: true image: nginx restart: always container_name: nginx_test_1 ports: - \u0026#34;8081:80\u0026#34; nginx_test_2.yml配置：\nversion: \u0026#34;3\u0026#34; services: nginx: privileged: true image: nginx restart: always container_name: nginx_test_2 ports: - \u0026#34;8082:80\u0026#34; 基于nginx_test_1.yml文件可正常启动\n基于nginx_test_1.yml文件进行测试时，虽然也能启动，但结果不符合我们的预期，其把名为nginx_test_1的容器关闭了，而我们期望的是基于两个文件启动时，能分别启动不同的容器\n利用docker ps -a查询也只有1个容器\n发生了什么？ 理论上不应该是采用不同的文件可分别正常启动么？！\n原因分析 一开始自己以为是docker-compose.yml文件的问题，以为有语法问题，反复对这两个文件进行检查后并没有找出啥。\n同时nginx_test_1.yml和nginx_test_2.yml按照下述的指令操作，可正常启动：\ndocker-compose -f nginx_test_1.yml up -d docker ps docker-compose -f nginx_test_1.yml down docker-compose -f nginx_test_2.yml up -d docker ps docker-compose -f nginx_test_1.yml down 若按照之前的方式操作依旧有问题，至此可以确认的是单个docker-compose.yml使用时没有问题，多个docker-compose.yml文件一起使用时会有问题。\n需要从docker-compos.yml的使用机制着手。\n在网上搜索后，发现有人已经遇到类似的问题Docker is not creating new container but recreates running one，通过对该文章的阅读发现了问题根源：\nDocker Compose通过项目名称和服务名称的组合来识别一个指定的服务 ，启动和关闭时基于该组合进行操作。\n其中服务名称是在yaml文件中指定的，而服务名称可通过启动时-p参数指定，若没有该参数，则去环境变量中查找COMPOSE_PROJECT_NAME的值，若还是没有则以当前yaml文件的文件夹作为项目名称。\n具体到本问题中，在启动时没有指定-p参数，也没有指定COMPOSE_PROJECT_NAME环境变量，同时这两个yaml文件都位于docker_test目录下，则项目名称为docker_test，查看其源码，发现其服务名称都为nginx，由此导致问题产生！\nversion: \u0026#34;3\u0026#34; services: # 服务名称都为nginx nginx: privileged: true image: nginx restart: always container_name: nginx_test_1 ports: - \u0026#34;8081:80\u0026#34; 解决方案 在Docker Compose的官网找到关于COMPOSE_PROJECT_NAME的说明如下\n上述说明前半部分说明了Docker Compose会将项目名和服务名组合作为容器名称供启动使用，基于该描述前述两个yaml文件理论上的容器名称都为docker_test_nginx-11，故而导致启动时冲突。\n查看本文开始的截图，发现容器名并不是docker_test_nginx，其原因为我们在yaml文件中手工指定了container_name，若取消该配置重新启动，则会发现容器名称已经变为docker_test_nginx_1:\n后半部分说明项目名称的计算规则，按照优先级从高到低如下：\n启动容器时，在命令行中通过-p指定 基于环境变量COMPOSE_PROJECT_NAME获取 基于docker-compose.yml文件最顶层的name属性获取，有多个yaml文件时以最后一个为准 包含要当前运行的yaml文件的最底层文件夹名称 当前要运行的yaml文件所在的文件夹名称 其中4和5的表达的意思基本一样，主要是为是否通过文件夹指定yaml文件。\n如通过docker-compose -f a/b/nginx_test_1.yml up -d来执行时，基于规则4其容器名称为Creating c_nginx_1 而通过docker-compose -f nginx_test_1.yml up -d来执行时，则是基于规则5来指定容器名。\n接下来演示通过前述规则解决冲突。\n基于命令行参数\n基于不同文件夹\n基于name属性，个人在v2.26.1版本上测试通过\n基于COMPOSE_PROJECT_NAME环境变量，个人在v2.2.2版本上测试通过\n其中的-1是Docker Compose自动添加的序号\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022-07-25T22:53:33+08:00","permalink":"https://lucumt.info/post/docker/multiple-docker-compose-conflict-analysis/","tags":["docker"],"title":"多个docker-compose.yml文件启动时容器冲突的原因分析"},{"categories":["翻译","个人博客"],"contents":"本文翻译自How to check if a Hugo site is in development or production\n有时我们希望能在使用Hugo的时候基于开发环境或生产环境展示不同的内容，在之前我使用过$.Site.IsServer来检查是否运行于开发服务器，不过其无法实现在开发环境查看生产环境的显示样式。\n检查环境 实际上Hugo有一系列的方式来区分生产环境和开发环境，不过Hugo文档中关于如何区分它们的说明不太友好。\n下述代码展示了在Hugo中检测环境的两种方式：\n{{ hugo.Environment }} returns \u0026#34;development\u0026#34; or \u0026#34;production\u0026#34; {{ hugo.IsProduction }} returns true or false 当使用hugo server在本地开发时，默认被设置为development，当使用hugo来构建站点时，默认被设置为production。\n基于环境动态展示 若想实现根据环境动态展示，可使用下述代码中的几种方法之一：\n{{ if eq hugo.Environment \u0026#34;development\u0026#34; }} I render when in development {{ end }} {{ if eq hugo.Environment \u0026#34;production\u0026#34; }} I render when in production {{ end }} {{ if hugo.IsProduction }} I render when in production {{ end }} {{ if not hugo.IsProduction }} I render when \u0026lt;strong\u0026gt;not\u0026lt;/strong\u0026gt; in production, which means I would render if the environment were manually set to \u0026#34;test\u0026#34; {{ end }} 手工设置环境变量 若要在编写博文时将环境设置为production，可使用下述命令启动Hugo服务器：\n# 短命令 hugo server -e production # 长命令 hugo server --environment production 也可通过设置系统环境变量来实现：\nHUGO_ENVIRONMENT=production hugo server Hugo要求能改变其配置的环境变量必须以HUGO_前缀开头，可在Hugo环境变量说明中了解具体信息。\n如果我们想在构建时将环境变量设置为除了production之外的其它值，可使用下述几种方法之一，在这些方法中，我们将环境变量设置为development，也可设置为我们期望的其它任何值。\nhugo -e development hugo --environment development HUGO_ENVIRONMENT=development hugo 希望此文能帮助你来构建自己的Hugo站点，喜欢此文章的话可以的点赞或评论！\n","date":"2022-06-19T12:09:19+08:00","permalink":"https://lucumt.info/post/hugo/check-if-a-hugo-site-is-in-development-or-production/","tags":["hugo","go"],"title":"[译]如何检测一个Hugo站点是开发环境还是生产环境"},{"categories":["Java编程","翻译"],"contents":"本文翻译自Same-threading。\n同线程系统(Same-threading)1 是由一个单线程横向扩展为N个线程系统并行执行的并发模型。\n同线程系统不是纯粹的单线程系统，因为它包含多个线程。 但其中每个线程都像单线程系统一样运，因此采用术语同线程而不是单线程。\n单线程和同线程设计视频教程 如果你更喜欢看视频，我也准备了一个相应的视频单线程和同线程设计。\n为什么选择单线程系统 你可能会很好奇为什么今天还有人设计并使用单线程系统，单线程系统之所以受欢迎，是因为它的并发模型比多线程系统简单的多，单线程系统并不同其它线程共享状态(数据/对象)，这使得单线程系统可以更好的利用非并发数据结构、CPU以及CPU缓存。\n不幸的是单线程系统没有重复利用现代CPU的特性，一颗现代CPU通常带有 2, 4, 6, 8或更多的内核，每个内核在功能上都可以当做一个单独的CPU，如下图所示，单线程系统只能利用这些内核中的一个。\n同线程系统\u0026ndash;单线程的横向扩展 为了利用CPU中的所有内核，可以通过横向扩展单线程系统来达到此目的。\n每个CPU一个线程 同线程系统，通常在每个CPU中运行一个线程，如果一台计算机包含4个CPU或者一个CPU包含4个内核，那么运行4个相同的线程实例(4个单线程系统)是正常的，下图展示了这一原理：\n无共享状态 由于一个同线程系统有多个线程在其中执行，其看起来与传统的单线程系统很相似，实际上它们有一些细微的差别。\n同线程系统和传统多线程系统的主要区别是同线程系统中不同线程间不共享状态，没有并发访问的共享内存，也没有并发数据结构等可以用来实现线程间的数据共享，下图展示了这种区别\n缺乏共享状态导致同线程系统的中每个线程看起来都像一个单线程系统，但是，由于一个同线程系统可以包含多个线程使得它们并不是真正的“单线程系统”。由于没有更好的名称，我认为将这样的系统称之为同线程系统(Same-threading )更准确，而不是“采用单线程设计的多线程系统”。\n同线程系统在本质上意味着数据都在同一个线程中处理，并且没有线程并发的共享数据，这种场景有时称之为无共享状态并发或者隔离的状态并发。\n负载分配 很显然，同线程系统需要在运行的单个线程之间分配工作负载，如果只有一个线程被分配工作负载，那么此系统实际上变成了一个单线程系统。\n如何在不同的线程间精准的分配工作负载取决于你的系统设计，以下部分将介绍一些相关内容。\n单线程微服务 如果系统由多个微服务组成，则每个微服务都能以单线程模式运行，当将多个微服务系统部署到一台服务器上时，其中的每个微服务都能以单线程的方式在单个CPU上执行。\n微服务系统本质上不共享任何数据，因而是同线程系统的一个很好的实例。\n服务间数据分片 如果系统间确实需要共享数据或者共享数据库，则可以对其进行分片，它意味着将数据在多个数据库之间进行划分。数据通常都被划分，以便彼此相关的数据都位于统一数据库中。例如，所有属于某个“所有者”的数据都将被插入同一个数据库中。不过，数据分片超出了本篇的范围，你需要自己去搜索相关教程。\n线程间通信 若同线程系统中的线程间需要通信，可通过传递消息来实现。如果线程 A 想要向线程 B 发送消息，线程 A 可以通过生成消息（字节序列）来实现。 然后线程 B 可以复制该消息（字节序列）并读取它。 通过复制消息，线程 B 确保线程 A 在线程 B 读取消息时不能修改消息，复制后线程 A 无法访问消息副本。\n下图展示了线程间通过消息传递实现通信\n线程间通信可以通过队列、管道、unix 套接字、TCP 套接字等进行，只要适合您的系统。\n更简单的并发模型 在同线程系统中每个线程中运行的系统都可以像单线程一样实现，这意味着其内部的线程共享模型比并发状态要更简单，因此也不用担心并发数据结构以及由此导致的各种问题。\n图示说明 以下是单线程、多线程和同线程的示例图解，以便我们可以更容易的了解它们之间的区别。\n首先展示的是单线程系统\n第二幅图展示的是线程间共享数据的多线程系统\n第三幅图展示了由2个包含隔离数据线程组成的同线程系统，它们之间通过传递消息进行通信\n在Java中使用Thread Ops Thread Ops for Java 是一个开源工具包，旨在帮助您更轻松地实现不同状态的同线程系统。 Thread Ops 包含用于启动和停止单个线程以及在单个线程中实现某种程度的并发的工具。 如果您对使用相同线程的应用程序设计感兴趣，那么看看 Thread Ops 可能会很有趣。 您可以在我的 Thread Ops for Java 教程中阅读有关 Thread Ops 的更多信息。\n注：原文为Same-threading，由于中文网络中没有合适的名词，故将其翻译为同线程系统，表示在一个系统中的相同相似的线程。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022-06-16T12:16:44+08:00","permalink":"https://lucumt.info/post/translate/java-concurrency/same-threading/","tags":["Java","Java Concurrency"],"title":"5.[译]同线程系统"},{"categories":["web编程"],"contents":"项目中有个模块支持按文件夹选中批量上传，用户希望在真正上传之前能够在浏览器中实时预览选中的文件夹层级结构，本文基于Chrome浏览器为例，简要说明这一实现。\n若要Chrome浏览器中支持批量上传文件夹，需要在input控件中添加webkitdirectory属性，如下图所示\n\u0026lt;body\u0026gt; 上传文件夹 \u0026lt;input type=\u0026#34;file\u0026#34; webkitdirectory onchange=\u0026#34;getfolder(event)\u0026#34;\u0026gt; \u0026lt;/body\u0026gt; 以一个典型的Maven功能做为测试目录，其文件结构如下，用户希望选中SpringTest文件夹后在前端上传之前就能够在网页上展示出类似的结构\n当基于前述的HTML代码选中上面的工程目录上传时，Chrome浏览器会提示如下警告框，此警告框是浏览器出于安全原因提示1，可不用理会。\n结构分析 在getfolder方法中分析event变量时，可发现event.target.files属性下包含我们所上传的全部文件，将其打印输出的结果如下：\n进一步观察可发现其中的webkitRelativePath中包含文件的完整路径，类似SpringTest/target/classes/com/lucumt/bean/User.class，这个路径虽然包含了上传文件的完整路径，但其为一个字符串，无法直接用于展示层级结构，进一步分析event变量的其它属性也没有找到有用的信息，看来只能从webkitRelativePath着手更改。\n修改思路 为了展示层级结构，首先需要定义一个如下所示的Node结构，其中path用于存储对应的文件名(不含父路径)，children在为文件夹时存储子文件(文件夹)的信息：\nfunction Node(path){ this.path = path; this.children = []; } 最终的结果都是基于Node进行组合处理。\n逐层处理 如上图所示，由于通过JavaScript获取的都是节点的完整路径，从简化实现的角度考虑，系统按照文件夹层级自底向上逐级解析，解析到根目录时则停止。在此过程中，获取到的文件路径不断缩小，直至处理到根节点，以SpringTest/target/test-classes/com/lucumt/TestGetBean.class为例，其解析过程说明如下：\n初始路径为SpringTest/target/test-classes/com/lucumt/TestGetBean.class 将前述路径拆分为TestGetBean.class(为其创建节点node1)和SpringTest/target/test-classes/com/lucumt(为其创建节点node2)，node2的子节点包含node1 将node2的路径拆分为lucumt(更新node2节点的路径)和SpringTest/target/test-classes/com(为其创建node3节点)，node3节点的子节点包含node2 将node3节点的路径拆分为com(更新node3节点的路径)和SpringTest/target/test-classes(为其创建节点node4) 将node4节点的路径拆分为test-classes(更新node4节点的路径)和SpringTest/target(为其创建节点node5) 将node5节点的路径拆分为target(更新node5节点路径)和SpringTest(为其创建节点node6) 节点node6已经是根节点，整个过程完毕，至此从node6基于children属性可一直往下招到node1文件节点。 处理重复 基于上述实现方案时有一个问题待解决，如SpringTest/target/test-classes/com/lucumt/TestGetBean.class和SpringTest/target/classes/com/lucumt/TestApplication.class在拆分到第2层级时，都会识别到lucumt文件夹，若都去创建该文件夹节点数据则会导致重复。\n回顾前面的逐层处理实现方案可知，当处理SpringTest/target/classes/com/lucumt/TestApplication.class时，SpringTest/target/test-classes/com/lucumt/TestGetBean.class已经被处理完比，在这一过程中会给我们创建好lucumt目录，在接下来处理SpringTest/target/test-classes/com/lucumt/TestGetBean.class时我们只需要找到lucumt对应的父节点，然后检查父节点下有没有该目录即可。\n基于上述分析，要在逐级遍历的过程中添加如下处理：\n遍历到当前文件或文件夹节点时，需要查找其父节点，若父节点不存在则创建，同时将当前节点加入到父节点的子节点集合中去 若当前节点的父节点存在，则需要获取其所有的子节点，并与当前节点进行避免，判断当前节点是否存在，若存在则不需要重复创建 为了记录当前节点的父节点，可在JavaScript中采用Map数据结构，其中key为节点的路径，value为Node节点自身。\n代码实现 function getfolder(event) { let files = event.target.files; let map = {}; var rootPath = files[0].webkitRelativePath.split(\u0026#39;/\u0026#39;)[0]; // 循环遍历，检测所有的文件路径 for (var i in files) { var node = files[i]; var path = node.webkitRelativePath; if (!path) { continue; } while (true) { // 处理到最顶层文件夹时，就不用往上继续处理 if (!path || path.indexOf(\u0026#34;/\u0026#34;) == -1) { break; } var index = path.lastIndexOf(\u0026#34;/\u0026#34;); var parentPath = path.substring(0, index); var file = path.substring(index \u0026#43; 1); var node; if (!map[path]) { node = new Node(file); map[path] = node; } else { node = map[path]; } // 父节点没有则创建 if (!map[parentPath]) { var parentFile = parentPath.substring(parentPath.lastIndexOf(\u0026#34;/\u0026#34;) \u0026#43; 1) var pNode = new Node(parentFile); // 动态的更新父节点的子节点，为后续检查重复节点做准备 pNode.children.push(node); map[parentPath] = pNode; } else { var pNode = map[parentPath]; var children = pNode.children; var addNode = true; // 通过检查父节点下的子节点来避免重复创建 for (var k in children) { if (children[k].path == file) { addNode = false; break; } } if (addNode) { pNode.children.push(node); } } // 逐级缩短父节点的路径，直到回到最顶层 path = parentPath; } } console.log(map[rootPath]); } 执行上述代码后在Chrome控制台的输出如下，可见root中已能够正确的输出层级结构，进行到这一步后续在页面上展示就很容易了，此处不再叙述。\nJava版本实现 public class TestFilePathConvert { public static void main(String[] args) { String[] paths = { \u0026#34;a/b1/c1/d1.txt\u0026#34;, \u0026#34;a/b1/c1/d2.txt\u0026#34;, \u0026#34;a/b1/c1/d2/e1/f.txt\u0026#34;, \u0026#34;a/b2/c2/d1\u0026#34;, \u0026#34;a/b3/c1\u0026#34;, \u0026#34;a/b4/c1/d1/e1/f1\u0026#34;, \u0026#34;a/b4/c1/d1/e1/f2/g1.png\u0026#34;, \u0026#34;a/b5/c1\u0026#34; }; convertPathToTreeNode(paths); } public static void convertPathToTreeNode(String[] paths) { Map\u0026lt;String, Node\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); for (String path : paths) { while (true) { Node node, pNode; String nodeName; if (map.containsKey(path)) { node = map.get(path); nodeName = node.getName(); } else { int index = path.lastIndexOf(\u0026#34;/\u0026#34;); nodeName = path.substring(index \u0026#43; 1); node = new Node(nodeName); map.put(path, node); } String parentPath = StringUtils.substringBeforeLast(path, \u0026#34;/\u0026#34;); if (path.equals(parentPath)) { break; } // 处理父节点 if (map.containsKey(parentPath)) { pNode = map.get(parentPath); } else { int index = parentPath.lastIndexOf(\u0026#34;/\u0026#34;); String pName = parentPath.substring(index \u0026#43; 1); pNode = new Node(pName); map.put(parentPath, pNode); } //检查当前节点是否存在 boolean add = true; for (Node n : pNode.getChildren()) { if (nodeName.equals(n.getName())) { add = false; break; } } // 避免当前节点的重复添加 if (add) { pNode.getChildren().add(node); } path = parentPath; } } String root = StringUtils.substringBefore(paths[0], \u0026#34;/\u0026#34;); Node rootNode = map.get(root); Gson gson = new Gson(); System.out.println(gson.toJson(rootNode)); } static class Node { private String name; private List\u0026lt;Node\u0026gt; children = new ArrayList\u0026lt;\u0026gt;(); public String getName() { return name; } public void setName(String name) { this.name = name; } public List\u0026lt;Node\u0026gt; getChildren() { return children; } public void setChildren(List\u0026lt;Node\u0026gt; children) { this.children = children; } public Node(String name) { this.name = name; } @Override public String toString() { return \u0026#34;Node{\u0026#34; \u0026#43; \u0026#34;name=\u0026#39;\u0026#34; \u0026#43; name \u0026#43; \u0026#39;\\\u0026#39;\u0026#39; \u0026#43; \u0026#34;, children=\u0026#34; \u0026#43; children.size() \u0026#43; \u0026#39;}\u0026#39;; } } } https://stackoverflow.com/questions/50225019/how-to-remove-warning-message-in-chrome-when-uploading-a-directory\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022-02-20T20:38:18+08:00","permalink":"https://lucumt.info/post/web/convert-folder-upload-data-to-tree-node-in-chrome/","tags":["html5","JavaScript"],"title":"在Chrome中将上传的文件夹数据转化为按树结构展示"},{"categories":["Spring系列"],"contents":"BeanFactory和FactoryBean的区别与使用场景是Spring面试中的高频题之一，本文基于网上资料和个人理解，简要说明他们之间的异同以及使用场景。\n组件说明 BeanFactory 在BeanFactory的API中，一开始就有如下一句描述\nThe root interface for accessing a Spring bean container\n这句话指明了BeanFactory在Spring家族中的地位，它是操作Spring容器、获取Spring Bean的根接口。从字面意思可以看出它是一个Bean工厂，其内部采用了工厂模式，通过它们我们可进行创建Bean、获取Bean等操作1。\n在学习与使用Spring过程中接触到的ApplicaitonContext、AnnotationConfigApplicastionContext、ClassPathXmlApplicationContext等都是其子接口和具体的实现类，它是我们在Spring框架中接触最多的系统接口，下图中的UML展示了BeanFactory及其子接口和实现类之间的关系2\n下述代码展示了BeanFactory所包含的全部15个接口方法，它们涵盖了Spring中对Bean对象的各种读取操作，若经常使用Spring这些接口方法看起来就会很熟悉。\nBeanFactory接口(点击可展开) public interface BeanFactory { String FACTORY_BEAN_PREFIX = \u0026#34;\u0026amp;\u0026#34;; Object getBean(String name) throws BeansException; \u0026lt;T\u0026gt; T getBean(String name, Class\u0026lt;T\u0026gt; requiredType) throws BeansException; Object getBean(String name, Object... args) throws BeansException; \u0026lt;T\u0026gt; T getBean(Class\u0026lt;T\u0026gt; requiredType) throws BeansException; \u0026lt;T\u0026gt; T getBean(Class\u0026lt;T\u0026gt; requiredType, Object... args) throws BeansException; \u0026lt;T\u0026gt; ObjectProvider\u0026lt;T\u0026gt; getBeanProvider(Class\u0026lt;T\u0026gt; requiredType); \u0026lt;T\u0026gt; ObjectProvider\u0026lt;T\u0026gt; getBeanProvider(ResolvableType requiredType); boolean containsBean(String name); boolean isSingleton(String name) throws NoSuchBeanDefinitionException; boolean isPrototype(String name) throws NoSuchBeanDefinitionException; boolean isTypeMatch(String name, ResolvableType typeToMatch) throws NoSuchBeanDefinitionException; boolean isTypeMatch(String name, Class\u0026lt;?\u0026gt; typeToMatch) throws NoSuchBeanDefinitionException; @Nullable Class\u0026lt;?\u0026gt; getType(String name) throws NoSuchBeanDefinitionException; @Nullable Class\u0026lt;?\u0026gt; getType(String name, boolean allowFactoryBeanInit) throws NoSuchBeanDefinitionException; String[] getAliases(String name); } 由于BeanFactory是操作Spring容器和对象的根接口，Spring官方要求它尽可能的支持Bean生命周期的各种接口，基于Spring官方API的描述，其完整的方法链和顺序如下：\nBeanNameAware\u0026rsquo;s setBeanName BeanClassLoaderAware\u0026rsquo;s setBeanClassLoader BeanFactoryAware\u0026rsquo;s setBeanFactory EnvironmentAware\u0026rsquo;s setEnvironment EmbeddedValueResolverAware\u0026rsquo;s setEmbeddedValueResolver ResourceLoaderAware\u0026rsquo;s setResourceLoader (only applicable when running in an application context) ApplicationEventPublisherAware\u0026rsquo;s setApplicationEventPublisher (only applicable when running in an application context) MessageSourceAware\u0026rsquo;s setMessageSource (only applicable when running in an application context) ApplicationContextAware\u0026rsquo;s setApplicationContext (only applicable when running in an application context) ServletContextAware\u0026rsquo;s setServletContext (only applicable when running in a web application context) postProcessBeforeInitialization methods of BeanPostProcessors InitializingBean\u0026rsquo;s afterPropertiesSet a custom init-method definition postProcessAfterInitialization methods of BeanPostProcessors 上述初始化链可很好的帮我们回答面试中另外几个常见的问题：\nSpring中Bean如何初始化 描述Spring中Bean的生命周期 FactoryBean FactoryBean从名字就能看出来是一个Bean，但不是普通的Bean，否则Spring作者为啥要单独的创建这个接口呢？FactoryBean也是一个接口，其源码如下，从中可以看出该接口只有3个方法，与BeanFactory相比数量大为减少，同时这3个接口方法的作用也同BeanFactory中的相关方法类似。\npublic interface FactoryBean\u0026lt;T\u0026gt; { String OBJECT_TYPE_ATTRIBUTE = \u0026#34;factoryBeanObjectType\u0026#34;; @Nullable T getObject() throws Exception; @Nullable Class\u0026lt;?\u0026gt; getObjectType(); default boolean isSingleton() { return true; } } 通过上述代码能够获取的信息依旧有限，在FactoryBean的官方API中有如下描述\nInterface to be implemented by objects used within a BeanFactory which are themselves factories for individual objects. If a bean implements this interface, it is used as a factory for an object to expose, not directly as a bean instance that will be exposed itself.\nNB: A bean that implements this interface cannot be used as a normal bean. A FactoryBean is defined in a bean style, but the object exposed for bean references (getObject()) is always the object that it creates.\n上述文档的主要结论如下：\nFactoryBean不是一个普通的Bean，它实际上是一个用于创建特定bean的工厂 通过实现FactoryBean接口，可通过暴露对象的方式创建特定bean对象，而这个bean对象本身不会暴露 到这里虽然二者的区别清楚了，但是FactoryBean的使用场景还是不清晰，在https://spring.io/blog/2011/08/09/what-s-a-factorybean这篇文章中，Spring的作者之一JOSH LONG用如下文字阐述了FactoryBean的使用场景\nA FactoryBean is a pattern to encapsulate interesting object construction logic in a class. It might be used, for example, to encode the construction of a complex object graph in a reusable way. Often this is used to construct complex objects that have many dependencies. It might also be used when the construction logic itself is highly volatile and depends on the configuration. A FactoryBean is also useful to help Spring construct objects that it couldn’t easily construct itself.\n从上述文字中可以看出FactoryBean主要用于构建一些实例化过程较为复杂或有配置依赖的对象(即非普通POJO)，并将其交给Spring容器管理。\nSpring框架本身就自带了实现FactoryBean的70多个接口，如ProxyFactoryBean、MapFactoryBean、PropertiesFactoryBean等，从个人角度来看它们要么理解起来较为复杂，要么使用较少不具有代表性，下面以MyBatis-Spring中的SqlSessionFactoryBean为例来了解其用法\n@Override public SqlSessionFactory getObject() throws Exception { if (this.sqlSessionFactory == null) { afterPropertiesSet(); } return this.sqlSessionFactory; } // 参数校验与对象创建 public void afterPropertiesSet() throws Exception { notNull(dataSource, \u0026#34;Property \u0026#39;dataSource\u0026#39; is required\u0026#34;); notNull(sqlSessionFactoryBuilder, \u0026#34;Property \u0026#39;sqlSessionFactoryBuilder\u0026#39; is required\u0026#34;); state((configuration == null \u0026amp;\u0026amp; configLocation == null) || !(configuration != null \u0026amp;\u0026amp; configLocation != null), \u0026#34;Property \u0026#39;configuration\u0026#39; and \u0026#39;configLocation\u0026#39; can not specified with together\u0026#34;); this.sqlSessionFactory = buildSqlSessionFactory(); } // 基于配置文件创建具体的SqlSessionFactory protected SqlSessionFactory buildSqlSessionFactory() throws Exception { // 各种检查代码 return this.sqlSessionFactoryBuilder.build(targetConfiguration); } 在创建SqlSessionFactory时需要依赖数据库的配置等一些配置信息，但这些配置信息若通过BeanFactory以传统的实例化-\u0026gt;初始化的方式创建时是很难办到的，虽然可以通过BeanPostProcessors的接口中的回调方法来实现，但会导致代码复杂并且不能满足某些特殊场景下的需求，而通过FactoryBean我们只需要根据实际业务逻辑在getObject()方法中创建对应的对象并返回即可，由于对象的创建由我们自己把控，在达到代码简洁的同时，创建的对象也能被Spring容器管理。\n使用示例 假设有如下所示的Group类\n@Service public class Group { private String groupName; // getter setter } 在使用BeanFactory获取对象的方法如下\npublic static void main(String[] args) { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class); Group group = context.getBean(Group.class); System.out.println(group.hashCode()); } 输出结果为Group@25d250c6，可以看到已经正确的获取到了Bean对象。\n定义一个实现了FactoryBean接口的GroupFactoryBean，其代码如下：\npublic class GroupFactoryBean implements FactoryBean\u0026lt;Group\u0026gt; { @Override public Group getObject() throws Exception { return new Group(); } @Override public Class\u0026lt;?\u0026gt; getObjectType() { return Group.class; } } 测试代码如下：\npublic static void main(String[] args) { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(GroupFactoryBean.class); Object object = context.getBean(\u0026#34;groupFactoryBean\u0026#34;); System.out.println(object); } 输出结果为Group@fdefd3f，如前面通过BeanFactory 创建的对象类似，接下来将groupFactoryBean添加一个\u0026amp;前缀，变为\u0026amp;groupFactoryBean后再次进行测试\npublic static void main(String[] args) { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(GroupFactoryBean.class); Object object = context.getBean(\u0026#34;\u0026amp;groupFactoryBean\u0026#34;); System.out.println(object); } 输出结果为GroupFactoryBean@1990a65e，由此可得出如下结论 ：\n当直接通过FactoryBean实现类的接口名称获取对象时，得到的是该FactoryBean实现类中创建的对象本身，也是我们正常的使用方式 当在FactoryBean接口对象名前面加上\u0026amp;前缀时，得到的是FactoryBean实现类本身，一般用于调试分析。 二者之间的区别 相同点： 都是接口类，需要使用者自己实现相应的方法 接口中创建bean对象都能被Spring容器管理 不同点: BeanFactory提供的接口方法更多，更具有灵活性，如能获取别名、bean对象类型等 BeanFactory基于Spring规范实现，其创建的bean会在Spring容器中经历完整的生命周期，能够调用@PostConstruct、BeanPostProcessors等接口和方法 Spring容器只负责FactoryBean创建的bean对象的生命周期管理，不负责bean对象的创建和销毁(因为由我们自己实现了嘛!)，所以调用@PostConstruct和@PreDestroy方法不会生效，需要实现DisposableBean等接口来达到该目的 相关使用场景 BeanFactory: 项目中各种常规的POJO、Dao、Service等不涉及复杂构造的场景 FactoryBean: 对象的构造(实例化)较为复杂，通常是系统中的一些底层组件，如SqlSessionFactoryBean、ProxyFactoryBean等 参考文档 https://www.cnblogs.com/aspirant/p/9082858.html\nhttps://spring.io/blog/2011/08/09/what-s-a-factorybean\nhttps://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/beans/factory/FactoryBean.html\n实际上Bean的创建、销毁都是由容器来负责的，使用时更多关注的是Bean对象的配置以及如何获取Bean对象\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n出于篇幅的考虑，实际上这张UML类图展示的并不完整，可在IDEA中基于BeanFactory自己生成完整的UML图\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022-01-16T11:00:01+08:00","permalink":"https://lucumt.info/post/spring/spring-core/difference-between-factorybean-and-beanfactory/","tags":["Spring"],"title":"Spring中BeanFactory和FactoryBean的区别以及使用场景"},{"categories":["容器化","持续集成"],"contents":"简要说明如何通过Linux指令将特定的Docker镜像手工上传到Harbor仓库\nHarbor系统的访问地址为http://aeectss.xxxx.local:30005/，在要操作的电脑上确保已经给/etc/docker/daemon.json添加了insecure-registries的配置，使得Harbor在非HTTPS协议下也能上传\n{ \u0026#34;insecure-registries\u0026#34;: [\u0026#34;aeectss.xxxx.local:30005\u0026#34;], } 若没有上述配置，在添加完毕之后需要通过systemctl daemon-reload \u0026amp;\u0026amp; systemctl restart docker让修改生效\n确保要操作人员的账户在harbor中对应的项目下具有项目管理员权限，类似如下图所示\n在对应电脑的终端上执行下述指令，此处的账号为前一个步骤配置好的具有权限的账号\nimage=orienlink-frame-extraction:1.3.4.3 \\ \u0026amp;\u0026amp; docker login -u yunqaing.lu -p xxxx aeectss.xxxx.local:30005 \\ \u0026amp;\u0026amp; docker tag orienlink-frame-extraction:1.3.4.4 aeectss.xxxx.local:30005/orienlink-product-library/$image \\ \u0026amp;\u0026amp; docker push aeectss.xxxx.local:30005/orienlink-product-library/$image \\ \u0026amp;\u0026amp; docker rmi aeectss.xxxx.local:30005/orienlink-product-library/$image \\ \u0026amp;\u0026amp; docker logout aeectss.xxxx.local:30005 或将上述命令修改为更灵活的shell脚本，类似如下：\n#!/bin/bash printf \u0026#34;请输入对应的用户名:\u0026#34; read username read -s -p \u0026#34;请输入对应的密码:\u0026#34; password printf \u0026#34;\\n请输入要上传的镜像与版本:\u0026#34; read tag docker login -u $username -p $password aeectss.xxxx.local:30005 docker tag $tag aeectss.xxxx.local:30005/orienlink-product-library/$tag docker push aeectss.xxxx.local:30005/orienlink-product-library/$tag docker rmi aeectss.xxxx.local:30005/orienlink-product-library/$tag docker logout aeectss.xxxx.local:30005 若一切正常，执行结果类似如下所示\n去harbor仓库检测后可发现对应的镜像已经上传成功\n若重复上传同一个tag的镜像，则第二次上传会较快。\n","date":"2021-06-24T20:38:59+08:00","permalink":"https://lucumt.info/post/devops/upload-docker-image-to-harbor-via-shell/","tags":["docker","harbor"],"title":"利用Linux脚本将Docker镜像手工上传到Harbor仓库"},{"categories":["java编程"],"contents":"在进行Java编程时有时候会涉及到时区相关的操作，本文简要介绍一种通过使用JDK内置的时区常量来进行时区相关操作。\nZoneId使用 在涉及到时区的操作时，通常采用类似如下的代码以硬编码方式实现相关功能。\nLocalDateTime datetime1 = LocalDateTime.ofInstant(Instant.now(), ZoneId.of(\u0026#34;Asia/Shanghai\u0026#34;)); System.out.println(datetime1); LocalDateTime datetime2 = LocalDateTime.ofInstant(Instant.now(), ZoneId.of(\u0026#34;America/Chicago\u0026#34;)); System.out.println(datetime2); 上述代码中涉及到的时区名称虽然可通过网络查询获得，但使用起来不是特别方便，有木有可能通过JDK内置的API实现呢？\n通过查阅网络资料以及JDK的官方文档，最终找到了答案，那就是ZoneId! 在其官方文档中有如下说明\n基于上述说明在ZoneId的源码中，可找到如下代码段，该代码段中内置了一些常用时区表示，通过它们可以用更简洁的方式实现。\npublic static final Map\u0026lt;String, String\u0026gt; SHORT_IDS; static { Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(64); map.put(\u0026#34;ACT\u0026#34;, \u0026#34;Australia/Darwin\u0026#34;); map.put(\u0026#34;AET\u0026#34;, \u0026#34;Australia/Sydney\u0026#34;); map.put(\u0026#34;AGT\u0026#34;, \u0026#34;America/Argentina/Buenos_Aires\u0026#34;); map.put(\u0026#34;ART\u0026#34;, \u0026#34;Africa/Cairo\u0026#34;); map.put(\u0026#34;AST\u0026#34;, \u0026#34;America/Anchorage\u0026#34;); map.put(\u0026#34;BET\u0026#34;, \u0026#34;America/Sao_Paulo\u0026#34;); map.put(\u0026#34;BST\u0026#34;, \u0026#34;Asia/Dhaka\u0026#34;); map.put(\u0026#34;CAT\u0026#34;, \u0026#34;Africa/Harare\u0026#34;); map.put(\u0026#34;CNT\u0026#34;, \u0026#34;America/St_Johns\u0026#34;); map.put(\u0026#34;CST\u0026#34;, \u0026#34;America/Chicago\u0026#34;); map.put(\u0026#34;CTT\u0026#34;, \u0026#34;Asia/Shanghai\u0026#34;); map.put(\u0026#34;EAT\u0026#34;, \u0026#34;Africa/Addis_Ababa\u0026#34;); map.put(\u0026#34;ECT\u0026#34;, \u0026#34;Europe/Paris\u0026#34;); map.put(\u0026#34;IET\u0026#34;, \u0026#34;America/Indiana/Indianapolis\u0026#34;); map.put(\u0026#34;IST\u0026#34;, \u0026#34;Asia/Kolkata\u0026#34;); map.put(\u0026#34;JST\u0026#34;, \u0026#34;Asia/Tokyo\u0026#34;); map.put(\u0026#34;MIT\u0026#34;, \u0026#34;Pacific/Apia\u0026#34;); map.put(\u0026#34;NET\u0026#34;, \u0026#34;Asia/Yerevan\u0026#34;); map.put(\u0026#34;NST\u0026#34;, \u0026#34;Pacific/Auckland\u0026#34;); map.put(\u0026#34;PLT\u0026#34;, \u0026#34;Asia/Karachi\u0026#34;); map.put(\u0026#34;PNT\u0026#34;, \u0026#34;America/Phoenix\u0026#34;); map.put(\u0026#34;PRT\u0026#34;, \u0026#34;America/Puerto_Rico\u0026#34;); map.put(\u0026#34;PST\u0026#34;, \u0026#34;America/Los_Angeles\u0026#34;); map.put(\u0026#34;SST\u0026#34;, \u0026#34;Pacific/Guadalcanal\u0026#34;); map.put(\u0026#34;VST\u0026#34;, \u0026#34;Asia/Ho_Chi_Minh\u0026#34;); map.put(\u0026#34;EST\u0026#34;, \u0026#34;-05:00\u0026#34;); map.put(\u0026#34;MST\u0026#34;, \u0026#34;-07:00\u0026#34;); map.put(\u0026#34;HST\u0026#34;, \u0026#34;-10:00\u0026#34;); SHORT_IDS = Collections.unmodifiableMap(map); } 基于上述代码段改进后的使用方式如下，可以看出相对于初始实现稍微简洁那么一丢丢~\nLocalDateTime datetime3 = LocalDateTime.ofInstant(Instant.now(), ZoneId.of(ZoneId.SHORT_IDS.get(\u0026#34;CTT\u0026#34;))); System.out.println(datetime3); LocalDateTime datetime4 = LocalDateTime.ofInstant(Instant.now(), ZoneId.of(ZoneId.SHORT_IDS.get(\u0026#34;CST\u0026#34;))); System.out.println(datetime4); ZoneId分析 由于前述ZoneId.SHORT_IDS中的时区都是通过字符串表示的，在上网查询的情况下可通过如下代码获取各个时区与UTC偏移量的对应关系\nMap\u0026lt;String, String\u0026gt; zoneIdMap = ZoneId.SHORT_IDS; zoneIdMap.forEach((k, v) -\u0026gt; { ZoneOffset offset = ZoneId.of(v).getRules().getStandardOffset(Instant.EPOCH); System.out.println(k \u0026#43; \u0026#34;\\t\\t\u0026#34; \u0026#43; offset \u0026#43; \u0026#34;\\t\\t\u0026#34; \u0026#43; v); }); 执行结果如下\nCTT\t\u0026#43;08:00\tAsia/Shanghai ART\t\u0026#43;02:00\tAfrica/Cairo CNT\t-03:30\tAmerica/St_Johns PRT\t-04:00\tAmerica/Puerto_Rico PNT\t-07:00\tAmerica/Phoenix PLT\t\u0026#43;05:00\tAsia/Karachi AST\t-10:00\tAmerica/Anchorage BST\t\u0026#43;06:00\tAsia/Dhaka CST\t-06:00\tAmerica/Chicago EST\t-05:00\t-05:00 HST\t-10:00\t-10:00 JST\t\u0026#43;09:00\tAsia/Tokyo IST\t\u0026#43;05:30\tAsia/Kolkata AGT\t-03:00\tAmerica/Argentina/Buenos_Aires NST\t\u0026#43;12:00\tPacific/Auckland MST\t-07:00\t-07:00 AET\t\u0026#43;10:00\tAustralia/Sydney BET\t-03:00\tAmerica/Sao_Paulo PST\t-08:00\tAmerica/Los_Angeles ACT\t\u0026#43;09:30\tAustralia/Darwin SST\t\u0026#43;11:00\tPacific/Guadalcanal VST\t\u0026#43;08:00\tAsia/Ho_Chi_Minh CAT\t\u0026#43;02:00\tAfrica/Harare ECT\t\u0026#43;01:00\tEurope/Paris EAT\t\u0026#43;03:00\tAfrica/Addis_Ababa IET\t-05:00\tAmerica/Indiana/Indianapolis MIT\t-11:00\tPacific/Apia NET\t\u0026#43;04:00\tAsia/Yerevan 上述输出结果是无序的，不便于对比使用，可将代码改进如下以便其能按顺序输出\nMap\u0026lt;String, String\u0026gt; zoneIdMap = ZoneId.SHORT_IDS; zoneIdMap.entrySet().stream() .sorted((c1, c2) -\u0026gt; { ZoneOffset o1 = ZoneId.of(c1.getValue()).getRules().getStandardOffset(Instant.EPOCH); ZoneOffset o2 = ZoneId.of(c2.getValue()).getRules().getStandardOffset(Instant.EPOCH); return o1.compareTo(o2); }) .forEach(e -\u0026gt; { String value = e.getValue(); ZoneOffset offset = ZoneId.of(value).getRules().getStandardOffset(Instant.EPOCH); System.out.println(e.getKey() \u0026#43; \u0026#34;\\t\\t\u0026#34; \u0026#43; offset \u0026#43; \u0026#34;\\t\\t\u0026#34; \u0026#43; value); }); 改进后的输出结果如下，除了个别时区之外基本上都覆盖到了。\nNST\t\u0026#43;12:00\tPacific/Auckland SST\t\u0026#43;11:00\tPacific/Guadalcanal AET\t\u0026#43;10:00\tAustralia/Sydney ACT\t\u0026#43;09:30\tAustralia/Darwin JST\t\u0026#43;09:00\tAsia/Tokyo CTT\t\u0026#43;08:00\tAsia/Shanghai VST\t\u0026#43;08:00\tAsia/Ho_Chi_Minh BST\t\u0026#43;06:00\tAsia/Dhaka IST\t\u0026#43;05:30\tAsia/Kolkata PLT\t\u0026#43;05:00\tAsia/Karachi NET\t\u0026#43;04:00\tAsia/Yerevan EAT\t\u0026#43;03:00\tAfrica/Addis_Ababa ART\t\u0026#43;02:00\tAfrica/Cairo CAT\t\u0026#43;02:00\tAfrica/Harare ECT\t\u0026#43;01:00\tEurope/Paris AGT\t-03:00\tAmerica/Argentina/Buenos_Aires BET\t-03:00\tAmerica/Sao_Paulo CNT\t-03:30\tAmerica/St_Johns PRT\t-04:00\tAmerica/Puerto_Rico EST\t-05:00\t-05:00 IET\t-05:00\tAmerica/Indiana/Indianapolis CST\t-06:00\tAmerica/Chicago PNT\t-07:00\tAmerica/Phoenix MST\t-07:00\t-07:00 PST\t-08:00\tAmerica/Los_Angeles AST\t-10:00\tAmerica/Anchorage HST\t-10:00\t-10:00 MIT\t-11:00\tPacific/Apia SHORT_IDS中内置的时区总共有28条，但从上述输出结果来看，仍有个别时区遗漏在其中，在ZoneId的API文档中说明SHORT_IDS是来源于TZDB 2005r，不过我没有在网上找到这方面的详细资料。对于不在SHORT_IDS中的，可从List of tz database time zones中获取响应的时区然后通过硬编码方式实现。\n","date":"2021-06-08T16:01:47+08:00","permalink":"https://lucumt.info/post/java-core/get-datetime-in-specific-timezone/","tags":["java"],"title":"利用JDK8时区常量进行时区相关操作"},{"categories":["容器化","持续集成"],"contents":"简要介绍基于docker-compose安装Harbor的过程，供后续参考。\n下载Harbor的离线安装文件并解压\nwget https://github.com/goharbor/harbor/releases/download/v2.1.4/harbor-offline-installer-v2.1.4.tgz # 解压后会生成名称harbor的目录 tar xvf harbor-offline-installer-v2.1.4.tgz 进入harbor目录下可发现其有对应的文件\nroot@test:~/lyq# cd harbor root@test:~/lyq/harbor# ls common.sh harbor.v2.1.4.tar.gz harbor.yml.tmpl install 在harbor根目录下执行下述命令生成配置文件\ncp harbor.yml.tmpl harbor.yml 修改前一个步骤中生成的harbor.yml，出于简化考虑屏蔽掉HTTPS相关的配置，根据实际情况修改其对外端口和密码\n运行bash install.sh开启安装过程，若第一次安装，则该脚本会首先下载对应的镜像，之后才会进行真正的安装过程\n若安装过程中一切正常，则最后会有类似如下输出\n再次查看该目录下的文件，发现多了一个名为docker-compose.yml的文件，此文件是由安装脚本自动生成的\nroot@test:~/lyq/harbor# ls common common.sh docker-compose.yml harbor.v2.1.4.tar.gz harbor.yml harbor.yml.tmpl install.sh LICENSE prepare 输入docker-compose ps可查看Harbor相关的Docker容器状态\n基于harbor.yml中的配置，可知其访问地址为http://10.0.8.147:8087 ，在浏览器中输入该地址，可正常打开\n使用默认配置的账号密码admin/Harbor12345登录系统，显示如下，至此Harbor安装完毕！\n若要停止或重启Harbor，可在该目录下执行如下指令\n# 停止harbor docker-compose down # 启动harbor docker-compose up -d # 重启harbor docker-compose restart ","date":"2021-05-25T10:05:48+08:00","permalink":"https://lucumt.info/post/docker/install-harbor-via-docker/","tags":["docker","harbor","devops"],"title":"基于Docker创建Harbor镜像仓库系统"},{"categories":["容器化"],"contents":"介绍如何在Docker容器内部获取当前容器名称的方法，特别感谢Get container name inside the docker container。\n背景 某个项目模块采用了分布式部署，对于某个工程模块部署了多个副本，生成了多个Docker容器，在查看系统日志时，需要能够显示出具体是哪个容器执行的。\n虽然采用Docker容器对应的64位或12位的字符串id也可唯一标识，但在阅读时不太直观，用容器名称会更直观。\n如果在容器外，可通过docker inspect --format='{{.Name}}' 容器id指令很容易的获取容器名称，而在容器内部可通过echo $HOSTNAME快速的获取容器id，但对于容器名称的获取却不是很方便。\n通过环境变量 直接通过-e命令将容器名称传入，然后通过$获取容器名称。\n# 指定名称创建容器 docker run -e \u0026#34;containerName=nginx-custom-test\u0026#34; --name nginx-custom-test -d nginx # 直接在宿主机中执行，不进入容器内部 docker exec nginx-custom-test env | grep containerName # 先进入容器内部，然后执行 docker exec -it nginx-custom-test /bin/bash echo $containerName 此种方式实现起来比较简单，但最大的问题是容器名称需要提前设置好，不太灵活，当容器名称随机生成时，此种方式就彻底失效了。\n通过socket通信 # 容器名称随机生成 docker run -v /run/docker.sock:/run/docker.sock:ro -d nginx # 进入容器内部 docker exec -it [容器id] /bin/bash # 在容器里面执行下述命令 # 获取容器的详细信息 dockerInfo=$(curl -s --unix-socket /run/docker.sock http://docker/containers/$HOSTNAME/json) # 利用awk获取name名称 containerName=$(echo $dockerInfo | awk -F\u0026#39;[:,}]\u0026#39; \u0026#39;{for(i=1;i\u0026lt;=NF;i\u0026#43;\u0026#43;){if($i==\u0026#34;\\\u0026#34;Name\\\u0026#34;\u0026#34;){print $(i\u0026#43;1);exit} }}\u0026#39;) # 格式化输出 echo \u0026#34;This is container $containerName\u0026#34; | tr -d \u0026#39;\u0026#34;/\u0026#39; 执行结果如下，可看出对于随机生成的容器名也能正常获取。\n$dockerInfo的格式化输出如下\n{ \u0026#34;Id\u0026#34;: \u0026#34;c6b9dbccd51c211690194f13a8f37c7bc6858aa7c8d627bec11faa143d315bba\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2024-04-23T07:30:23.641193169Z\u0026#34;, \u0026#34;Path\u0026#34;: \u0026#34;/docker-entrypoint.sh\u0026#34;, \u0026#34;Args\u0026#34;: [ \u0026#34;nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off;\u0026#34; ], \u0026#34;State\u0026#34;: { \u0026#34;Status\u0026#34;: \u0026#34;running\u0026#34;, \u0026#34;Running\u0026#34;: true, \u0026#34;Paused\u0026#34;: false, \u0026#34;Restarting\u0026#34;: false, \u0026#34;OOMKilled\u0026#34;: false, \u0026#34;Dead\u0026#34;: false, \u0026#34;Pid\u0026#34;: 17102, \u0026#34;ExitCode\u0026#34;: 0, \u0026#34;Error\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;StartedAt\u0026#34;: \u0026#34;2024-04-23T07:30:23.885312035Z\u0026#34;, \u0026#34;FinishedAt\u0026#34;: \u0026#34;0001-01-01T00:00:00Z\u0026#34; }, \u0026#34;Image\u0026#34;: \u0026#34;sha256:2ac752d7aeb1d9281f708e7c51501c41baf90de15ffc9bca7c5d38b8da41b580\u0026#34;, \u0026#34;ResolvConfPath\u0026#34;: \u0026#34;/var/lib/docker/containers/c6b9dbccd51c211690194f13a8f37c7bc6858aa7c8d627bec11faa143d315bba/resolv.conf\u0026#34;, \u0026#34;HostnamePath\u0026#34;: \u0026#34;/var/lib/docker/containers/c6b9dbccd51c211690194f13a8f37c7bc6858aa7c8d627bec11faa143d315bba/hostname\u0026#34;, \u0026#34;HostsPath\u0026#34;: \u0026#34;/var/lib/docker/containers/c6b9dbccd51c211690194f13a8f37c7bc6858aa7c8d627bec11faa143d315bba/hosts\u0026#34;, \u0026#34;LogPath\u0026#34;: \u0026#34;/var/lib/docker/containers/c6b9dbccd51c211690194f13a8f37c7bc6858aa7c8d627bec11faa143d315bba/c6b9dbccd51c211690194f13a8f37c7bc6858aa7c8d627bec11faa143d315bba-json.log\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;/exciting_hoover\u0026#34;, \u0026#34;RestartCount\u0026#34;: 0, \u0026#34;Driver\u0026#34;: \u0026#34;overlay2\u0026#34;, \u0026#34;Platform\u0026#34;: \u0026#34;linux\u0026#34;, \u0026#34;MountLabel\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ProcessLabel\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;AppArmorProfile\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ExecIDs\u0026#34;: [ \u0026#34;95bf150c2a4f263e42df000693b51b00b583ebba7228044f6bd1bcdb86c1a22d\u0026#34; ], \u0026#34;HostConfig\u0026#34;: { \u0026#34;Binds\u0026#34;: [ \u0026#34;/run/docker.sock:/run/docker.sock:ro\u0026#34; ], \u0026#34;ContainerIDFile\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;LogConfig\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;json-file\u0026#34;, \u0026#34;Config\u0026#34;: { } }, \u0026#34;NetworkMode\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;PortBindings\u0026#34;: { }, \u0026#34;RestartPolicy\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;no\u0026#34;, \u0026#34;MaximumRetryCount\u0026#34;: 0 }, \u0026#34;AutoRemove\u0026#34;: false, \u0026#34;VolumeDriver\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;VolumesFrom\u0026#34;: null, \u0026#34;ConsoleSize\u0026#34;: [ 59, 185 ], \u0026#34;CapAdd\u0026#34;: null, \u0026#34;CapDrop\u0026#34;: null, \u0026#34;CgroupnsMode\u0026#34;: \u0026#34;host\u0026#34;, \u0026#34;Dns\u0026#34;: [ ], \u0026#34;DnsOptions\u0026#34;: [ ], \u0026#34;DnsSearch\u0026#34;: [ ], \u0026#34;ExtraHosts\u0026#34;: null, \u0026#34;GroupAdd\u0026#34;: null, \u0026#34;IpcMode\u0026#34;: \u0026#34;private\u0026#34;, \u0026#34;Cgroup\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Links\u0026#34;: null, \u0026#34;OomScoreAdj\u0026#34;: 0, \u0026#34;PidMode\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Privileged\u0026#34;: false, \u0026#34;PublishAllPorts\u0026#34;: false, \u0026#34;ReadonlyRootfs\u0026#34;: false, \u0026#34;SecurityOpt\u0026#34;: null, \u0026#34;UTSMode\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;UsernsMode\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ShmSize\u0026#34;: 67108864, \u0026#34;Runtime\u0026#34;: \u0026#34;runc\u0026#34;, \u0026#34;Isolation\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;CpuShares\u0026#34;: 0, \u0026#34;Memory\u0026#34;: 0, \u0026#34;NanoCpus\u0026#34;: 0, \u0026#34;CgroupParent\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;BlkioWeight\u0026#34;: 0, \u0026#34;BlkioWeightDevice\u0026#34;: [ ], \u0026#34;BlkioDeviceReadBps\u0026#34;: [ ], \u0026#34;BlkioDeviceWriteBps\u0026#34;: [ ], \u0026#34;BlkioDeviceReadIOps\u0026#34;: [ ], \u0026#34;BlkioDeviceWriteIOps\u0026#34;: [ ], \u0026#34;CpuPeriod\u0026#34;: 0, \u0026#34;CpuQuota\u0026#34;: 0, \u0026#34;CpuRealtimePeriod\u0026#34;: 0, \u0026#34;CpuRealtimeRuntime\u0026#34;: 0, \u0026#34;CpusetCpus\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;CpusetMems\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Devices\u0026#34;: [ ], \u0026#34;DeviceCgroupRules\u0026#34;: null, \u0026#34;DeviceRequests\u0026#34;: null, \u0026#34;MemoryReservation\u0026#34;: 0, \u0026#34;MemorySwap\u0026#34;: 0, \u0026#34;MemorySwappiness\u0026#34;: null, \u0026#34;OomKillDisable\u0026#34;: false, \u0026#34;PidsLimit\u0026#34;: null, \u0026#34;Ulimits\u0026#34;: [ ], \u0026#34;CpuCount\u0026#34;: 0, \u0026#34;CpuPercent\u0026#34;: 0, \u0026#34;IOMaximumIOps\u0026#34;: 0, \u0026#34;IOMaximumBandwidth\u0026#34;: 0, \u0026#34;MaskedPaths\u0026#34;: [ \u0026#34;/proc/asound\u0026#34;, \u0026#34;/proc/acpi\u0026#34;, \u0026#34;/proc/kcore\u0026#34;, \u0026#34;/proc/keys\u0026#34;, \u0026#34;/proc/latency_stats\u0026#34;, \u0026#34;/proc/timer_list\u0026#34;, \u0026#34;/proc/timer_stats\u0026#34;, \u0026#34;/proc/sched_debug\u0026#34;, \u0026#34;/proc/scsi\u0026#34;, \u0026#34;/sys/firmware\u0026#34;, \u0026#34;/sys/devices/virtual/powercap\u0026#34; ], \u0026#34;ReadonlyPaths\u0026#34;: [ \u0026#34;/proc/bus\u0026#34;, \u0026#34;/proc/fs\u0026#34;, \u0026#34;/proc/irq\u0026#34;, \u0026#34;/proc/sys\u0026#34;, \u0026#34;/proc/sysrq-trigger\u0026#34; ] }, \u0026#34;GraphDriver\u0026#34;: { \u0026#34;Data\u0026#34;: { \u0026#34;LowerDir\u0026#34;: \u0026#34;/var/lib/docker/overlay2/d2b523e9b47aed738b4015a9591b8f4e17065b9f779cdec6cebd3250e0576e56-init/diff:/var/lib/docker/overlay2/68ad234bdb5026df1c2dfc72f7d26cfeac037e4684461b3428996d76a351b89b/diff:/var/lib/docker/overlay2/ab73b553d5915120731a9c64a25f8fa51b6530e7e467403d122e362a231b766f/diff:/var/lib/docker/overlay2/07a24b0cb136ba5bed299dcc16155f25e43760610029743554577e524ec144b1/diff:/var/lib/docker/overlay2/034c1bbdaa560ad684ad6de966f49c4e9a0cb434717476446ab27ecad5e1a495/diff:/var/lib/docker/overlay2/c631330de17b59a6e7836e832a4dff4abe5068955f8bf6441dffd72bc1679111/diff:/var/lib/docker/overlay2/f937882465a97a6b70532e87a6ed43281e94bfbd66bdf8d5a79e9842ae7e12f8/diff:/var/lib/docker/overlay2/6ef77dde042f0b96eb12de6b5dc8c7224c91afbce6716cdcadd449ab7cb2b7d0/diff\u0026#34;, \u0026#34;MergedDir\u0026#34;: \u0026#34;/var/lib/docker/overlay2/d2b523e9b47aed738b4015a9591b8f4e17065b9f779cdec6cebd3250e0576e56/merged\u0026#34;, \u0026#34;UpperDir\u0026#34;: \u0026#34;/var/lib/docker/overlay2/d2b523e9b47aed738b4015a9591b8f4e17065b9f779cdec6cebd3250e0576e56/diff\u0026#34;, \u0026#34;WorkDir\u0026#34;: \u0026#34;/var/lib/docker/overlay2/d2b523e9b47aed738b4015a9591b8f4e17065b9f779cdec6cebd3250e0576e56/work\u0026#34; }, \u0026#34;Name\u0026#34;: \u0026#34;overlay2\u0026#34; }, \u0026#34;Mounts\u0026#34;: [ { \u0026#34;Type\u0026#34;: \u0026#34;bind\u0026#34;, \u0026#34;Source\u0026#34;: \u0026#34;/run/docker.sock\u0026#34;, \u0026#34;Destination\u0026#34;: \u0026#34;/run/docker.sock\u0026#34;, \u0026#34;Mode\u0026#34;: \u0026#34;ro\u0026#34;, \u0026#34;RW\u0026#34;: false, \u0026#34;Propagation\u0026#34;: \u0026#34;rprivate\u0026#34; } ], \u0026#34;Config\u0026#34;: { \u0026#34;Hostname\u0026#34;: \u0026#34;c6b9dbccd51c\u0026#34;, \u0026#34;Domainname\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;User\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;AttachStdin\u0026#34;: false, \u0026#34;AttachStdout\u0026#34;: false, \u0026#34;AttachStderr\u0026#34;: false, \u0026#34;ExposedPorts\u0026#34;: { \u0026#34;80/tcp\u0026#34;: { } }, \u0026#34;Tty\u0026#34;: false, \u0026#34;OpenStdin\u0026#34;: false, \u0026#34;StdinOnce\u0026#34;: false, \u0026#34;Env\u0026#34;: [ \u0026#34;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\u0026#34;, \u0026#34;NGINX_VERSION=1.25.5\u0026#34;, \u0026#34;NJS_VERSION=0.8.4\u0026#34;, \u0026#34;PKG_RELEASE=1~bookworm\u0026#34; ], \u0026#34;Cmd\u0026#34;: [ \u0026#34;nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off;\u0026#34; ], \u0026#34;Image\u0026#34;: \u0026#34;nginx\u0026#34;, \u0026#34;Volumes\u0026#34;: null, \u0026#34;WorkingDir\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Entrypoint\u0026#34;: [ \u0026#34;/docker-entrypoint.sh\u0026#34; ], \u0026#34;OnBuild\u0026#34;: null, \u0026#34;Labels\u0026#34;: { \u0026#34;maintainer\u0026#34;: \u0026#34;NGINX Docker Maintainers \u0026lt;docker-maint@nginx.com\u0026gt;\u0026#34; }, \u0026#34;StopSignal\u0026#34;: \u0026#34;SIGQUIT\u0026#34; }, \u0026#34;NetworkSettings\u0026#34;: { \u0026#34;Bridge\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;SandboxID\u0026#34;: \u0026#34;9961035f980f2ce740f148a6db9ca19bcfba040bb42e7eba8f36704df4f7f473\u0026#34;, \u0026#34;SandboxKey\u0026#34;: \u0026#34;/var/run/docker/netns/9961035f980f\u0026#34;, \u0026#34;Ports\u0026#34;: { \u0026#34;80/tcp\u0026#34;: null }, \u0026#34;HairpinMode\u0026#34;: false, \u0026#34;LinkLocalIPv6Address\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;LinkLocalIPv6PrefixLen\u0026#34;: 0, \u0026#34;SecondaryIPAddresses\u0026#34;: null, \u0026#34;SecondaryIPv6Addresses\u0026#34;: null, \u0026#34;EndpointID\u0026#34;: \u0026#34;87973a9191829be1647399a85ed29c615bf86dbb3f8952fce326ba404a93c473\u0026#34;, \u0026#34;Gateway\u0026#34;: \u0026#34;172.17.0.1\u0026#34;, \u0026#34;GlobalIPv6Address\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;GlobalIPv6PrefixLen\u0026#34;: 0, \u0026#34;IPAddress\u0026#34;: \u0026#34;172.17.0.2\u0026#34;, \u0026#34;IPPrefixLen\u0026#34;: 16, \u0026#34;IPv6Gateway\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:11:00:02\u0026#34;, \u0026#34;Networks\u0026#34;: { \u0026#34;bridge\u0026#34;: { \u0026#34;IPAMConfig\u0026#34;: null, \u0026#34;Links\u0026#34;: null, \u0026#34;Aliases\u0026#34;: null, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:11:00:02\u0026#34;, \u0026#34;NetworkID\u0026#34;: \u0026#34;41c4546cd26c02078696ba9e74b0ee9e737778f82bfce41c5ab557dd8666a533\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;87973a9191829be1647399a85ed29c615bf86dbb3f8952fce326ba404a93c473\u0026#34;, \u0026#34;Gateway\u0026#34;: \u0026#34;172.17.0.1\u0026#34;, \u0026#34;IPAddress\u0026#34;: \u0026#34;172.17.0.2\u0026#34;, \u0026#34;IPPrefixLen\u0026#34;: 16, \u0026#34;IPv6Gateway\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;GlobalIPv6Address\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;GlobalIPv6PrefixLen\u0026#34;: 0, \u0026#34;DriverOpts\u0026#34;: null, \u0026#34;DNSNames\u0026#34;: null } } } } ","date":"2021-05-06T13:16:52+08:00","permalink":"https://lucumt.info/post/docker/get-docker-name-inside-docker-container/","tags":["docker"],"title":"在Docker容器内部获取当前容器实例的名称"},{"categories":["Java编程","MyBatis系列"],"contents":"简单记录下如何在MyBatis中插入JSON，以备参考。\n基本信息 完整代码参见spring-mybatis-example，核心代码为JsonNodeTypeHandler配置类。\n项目结构 表结构 CREATE TABLE `user_info` (\r`id` int(11) NOT NULL AUTO_INCREMENT,\r`name` varchar(100) COLLATE utf8_bin NOT NULL,\r`info` json NOT NULL,\rPRIMARY KEY (`id`)\r) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin pom文件 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt;\r\u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34;\rxsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt;\r\u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt;\r\u0026lt;groupId\u0026gt;com.lucumt\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-mybatis-test\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt;\r\u0026lt;name\u0026gt;SpringTest\u0026lt;/name\u0026gt;\r\u0026lt;url\u0026gt;https://lucumt.info\u0026lt;/url\u0026gt;\r\u0026lt;properties\u0026gt;\r\u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt;\r\u0026lt;maven.compiler.source\u0026gt;1.8\u0026lt;/maven.compiler.source\u0026gt;\r\u0026lt;maven.compiler.target\u0026gt;1.8\u0026lt;/maven.compiler.target\u0026gt;\r\u0026lt;spring.boot.version\u0026gt;2.7.3\u0026lt;/spring.boot.version\u0026gt;\r\u0026lt;/properties\u0026gt;\r\u0026lt;dependencies\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.mybatis.spring.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;mybatis-spring-boot-starter\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.2.2\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;8.0.30\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;${spring.boot.version}\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;${spring.boot.version}\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;${spring.boot.version}\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.junit.platform\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;junit-platform-launcher\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.9.0\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.18.24\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.fasterxml.jackson.core\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;jackson-databind\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.13.3\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;/dependencies\u0026gt;\r\u0026lt;/project\u0026gt; 模型类 @Data\r@AllArgsConstructor\r@NoArgsConstructor\rpublic class UserModel {\rprivate Integer id;\rprivate String name;\rprivate JsonNode info;\r} Handler类 @MappedTypes(JsonNode.class)\rpublic class JsonNodeTypeHandler extends BaseTypeHandler\u0026lt;JsonNode\u0026gt; {\r/**\r* 设置非空参数\r*\r* @param ps\r* @param i\r* @param parameter\r* @param jdbcType\r* @throws SQLException\r*/\r@Override\rpublic void setNonNullParameter(PreparedStatement ps, int i, JsonNode parameter, JdbcType jdbcType) throws SQLException {\rps.setString(i, parameter.toString());\r}\r/**\r* 根据列名，获取可以为空的结果\r*\r* @param rs\r* @param columnName\r* @return\r* @throws SQLException\r*/\r@Override\rpublic JsonNode getNullableResult(ResultSet rs, String columnName) throws SQLException {\rString sqlJson = rs.getString(columnName);\rreturn getResultFromJSON(sqlJson);\r}\r/**\r* 根据列索引，获取可以为内控的接口\r*\r* @param rs\r* @param columnIndex\r* @return\r* @throws SQLException\r*/\r@Override\rpublic JsonNode getNullableResult(ResultSet rs, int columnIndex) throws SQLException {\rString sqlJson = rs.getString(columnIndex);\rreturn getResultFromJSON(sqlJson);\r}\r/**\r* @param cs\r* @param columnIndex\r* @return\r* @throws SQLException\r*/\r@Override\rpublic JsonNode getNullableResult(CallableStatement cs, int columnIndex) throws SQLException {\rString sqlJson = cs.getNString(columnIndex);\rreturn getResultFromJSON(sqlJson);\r}\rprivate JsonNode getResultFromJSON(String sqlJson) {\rif (sqlJson == null) {\rreturn null;\r}\rtry {\rreturn new ObjectMapper().readTree(sqlJson);\r} catch (JsonProcessingException e) {\rthrow new RuntimeException(e);\r}\r}\r} 配置文件 server:\rport: 8081\rlogging:\rlevel:\rroot: info\rspring:\rdatasource:\rdriver-class-name: com.mysql.cj.jdbc.Driver\rurl: jdbc:mysql://10.10.2.98:3316/db_test?serverTimezone=UTC\u0026amp;useUnicode=true\u0026amp;characterEncoding=utf-8\rusername: root\rpassword: 654321\rmybatis:\rmapper-locations: classpath:mapper/*.xml\rconfiguration:\rmap-underscore-to-camel-case: true\rtype-aliases-package: com.lucumt.model,com.lucumt.vo\rtype-handlers-package: com.lucumt.handler.mybatis Mapper类 public interface UserMapper {\rvoid addUser(UserModel userModel);\rUserModel findById(Integer id);\rvoid deleteUser(Integer id);\r} Mapper文件 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt;\r\u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt;\r\u0026lt;mapper namespace=\u0026#34;com.lucumt.mapper.UserMapper\u0026#34;\u0026gt;\r\u0026lt;select id=\u0026#34;findById\u0026#34; parameterType=\u0026#34;Integer\u0026#34; resultType=\u0026#34;userModel\u0026#34;\u0026gt;\rSELECT id,name,info FROM user_info WHERE id=#{id}\r\u0026lt;/select\u0026gt;\r\u0026lt;insert id=\u0026#34;addUser\u0026#34; parameterType=\u0026#34;userModel\u0026#34; useGeneratedKeys=\u0026#34;true\u0026#34; keyProperty=\u0026#34;id\u0026#34; keyColumn=\u0026#34;id\u0026#34;\u0026gt;\rINSERT INTO user_info(name,info) VALUES\r(#{name},#{info})\r\u0026lt;/insert\u0026gt;\r\u0026lt;delete id=\u0026#34;deleteUser\u0026#34; parameterType=\u0026#34;Integer\u0026#34;\u0026gt;\rDELETE FROM user_info WHERE id= #{id}\r\u0026lt;/delete\u0026gt;\r\u0026lt;/mapper\u0026gt; Service类 @Service\rpublic class UserService {\r@Autowired\rprivate UserMapper userMapper;\rpublic void addUser(UserModel userModel) {\ruserMapper.addUser(userModel);\r}\rpublic UserModel getUser(Integer id) {\rreturn userMapper.findById(id);\r}\rpublic void deleteUser(Integer id) {\ruserMapper.deleteUser(id);\r}\r} 测试 测试类 @SpringBootTest\r@TestMethodOrder(MethodOrderer.OrderAnnotation.class)\rpublic class TestUserService {\r@Autowired\rprivate UserService userService;\rprivate static Integer userId;\r@Order(1)\r@Test\rpublic void testAddUser() throws JsonProcessingException {\rString time = LocalDateTime.now().format(DateTimeFormatter.ofPattern(\u0026#34;yyyy-MM-dd_HH:mm:ss:SSS\u0026#34;));\rString info = \u0026#34;{\\\u0026#34;city\\\u0026#34;:\\\u0026#34;beijing\\\u0026#34;,\\\u0026#34;location\\\u0026#34;:\\\u0026#34;jiuxianqiao__\u0026#34; \u0026#43; time \u0026#43; \u0026#34;\\\u0026#34;,\\\u0026#34;skills\\\u0026#34;:[\\\u0026#34;Java\\\u0026#34;,\\\u0026#34;Golang\\\u0026#34;,\\\u0026#34;Python\\\u0026#34;]}\u0026#34;;\rObjectMapper mapper = new ObjectMapper();\rJsonNode node = mapper.readTree(info);\rUserModel userModel = new UserModel();\ruserModel.setName(\u0026#34;lucumt\u0026#34;);\ruserModel.setInfo(node);\ruserService.addUser(userModel);\ruserId = userModel.getId();\rassertTrue(userId \u0026gt; 0);\r}\r@Order(2)\r@Test\rpublic void testGetUser() {\rUserModel user = userService.getUser(userId);\rJsonNode info = user.getInfo();\rassertNotNull(info);\rSystem.out.println(info);\r}\r@Order(3)\r@Test\rpublic void testDeleteUser() {\ruserService.deleteUser(userId);\r}\r} 测试结果 ","date":"2021-04-15T09:37:41+08:00","permalink":"https://lucumt.info/post/mybatis/insert-json-data-in-mybatis/","tags":["Java","MyBatis"],"title":"MyBatis中插入JSON格式数据"},{"categories":["容器化"],"contents":"简单记录利用nginx结合docker实现一个简易的静态文件下载服务器。\ndocker-compose.yml配置\nversion: \u0026#34;3\u0026#34; services: nginx: privileged: true image: nginx restart: always container_name: nginx_file_server environment: - \u0026#34;TZ=Asia/Shanghai\u0026#34; ports: - \u0026#34;8788:8788\u0026#34; volumes: - $PWD/html:/usr/share/nginx/html - $PWD/conf.d:/etc/nginx/conf.d - $PWD/nginx.conf:/etc/nginx/nginx.conf - $PWD/logs:/var/log/nginx nginx.conf配置\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } conf.d/file.conf配置\nserver { listen 8788; server_name zip-download; location ~.*\\.(zip)$ { root /usr/share/nginx/html/; # 自动创建目录文件列表为首页 autoindex on; # 自动首页的格式为html autoindex_format html; # 关闭文件大小转换 autoindex_exact_size off; # 按照服务器时间显示文件时间 autoindex_localtime on; default_type application/octet-stream; # 开启零复制。默认配置中，文件会先到nginx缓冲区，开启零复制后，文件跳过缓冲区，可以加快文件传输速度。 sendfile on; # 限制零复制过程中每个连接的最大传输量 sendfile_max_chunk 1m; # tcp_nopush与零复制配合使用，当数据包大于最大报文长度时才执行网络发送操作，从而提升网络利用率。 tcp_nopush on; # 启用异步IO，需要配合direcio使用 # aio on; # 大于10MB的文件会采用直接IO的当时进行缓冲读取 directio 10m; # 对齐文件系统块大小4096 directio_alignment 4096; # 启用分块传输标识 chunked_transfer_encoding on; # 文件输出的缓冲区大小为128KB output_buffers 4 32k; } location / { root html; index index.html index.htm; } # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } 将zip文件放入html目录下，之后通过http://IP地址:8788/docsify.zip即可下载扩展名为zip文件\n","date":"2021-03-23T10:46:12+08:00","permalink":"https://lucumt.info/post/docker/download-file-from-nginx-installed-via-docker/","tags":["docker","nginx"],"title":"在利用docker安装的nginx中实现静态文件下载"},{"categories":["容器化","翻译"],"contents":"本文翻译自Docker RUN vs CMD vs ENTRYPOINT。\nDockerfile使用时的CMD与ENTRYPOINT指令其作用很相似，经常让人容易混淆，网络上有不少关于它们对比说明的文章，但个人感觉都不直观明晰。\n本来自己想专门写一篇关于它们差异的博文，后来在网上发现国外有个作者已经写了类似的文章，同时读了之后有醍醐灌顶之感，故出于对作者的尊重与感谢，决定直接将其翻译成中文！\n\u0026lt;!-正文开始 -\u0026gt;\nDocker中的一些指令看起来很相似，它们容易导致初学者的困惑和不恰当的使用，本文将以具体示例来说明CMD、RUN和ENTRYPOINT这3者的差异。\n概要说明 RUN用于在一个镜像层中执行指令并创建一个新的镜像，如通常用来安装软件包 CMD用于设置默认的命令或参数，它们可以在容器运行时通过命令行覆盖 ENTRYPOINT用于将容器设置为通过可执行文件来运行1 如果还是不太明白或者想了解更详细的信息，请继续往下阅读。\nDocker镜像与分层 Docker运行一个容器时实际上是运行容器里面的镜像，这些镜像通常是通过Docker指令构建的，这些指令在已有的镜像层或操作系统发行版的顶层添加新的分层，操作系统发行版是一个初始镜像，所有在其上添加的分层都会创建一个新的镜像。\n最终的Docker镜像就像一个洋葱，里面包含由操作系统发行版以及其上的许多镜像分层，例如可通过基于Ubuntu 14.04发行版安装一系列的deb软件包来构建自己的镜像。\nShell和Exec模式 这3条指令(RUN、CMD、ENTRYPOINT)都可基于shell模式和exec模式运行，由于这些模式相对于指令更容易让人困惑，我们先熟悉下这些指令。\nShell模式 \u0026lt;instruction\u0026gt; \u0026lt;command\u0026gt;\n示例:\nRUN apt-get install python3 CMD echo \u0026#34;Hello world\u0026#34; ENTRYPOINT echo \u0026#34;Hello world\u0026#34; 当以shell模式执行指令时，会在后台调用/bin/sh -c \u0026lt;command\u0026gt;并进行正常的shell处理，以下述Dockerfile中的代码片段为例\nENV name John Dow ENTRYPOINT echo \u0026#34;Hello, $name\u0026#34; 当以docker run -it \u0026lt;image\u0026gt;的形式运行容器时，会有如下输出\nHello, John Dow 可以看出在输出结果中变量name已经被其实际值替换了。\nExec模式 此模式是CMD和ENTRYPOINT指令说明中推荐的模式。\n\u0026lt;instruction\u0026gt; [\u0026quot;executable\u0026quot;, \u0026quot;param1\u0026quot;, \u0026quot;param2\u0026quot;, ...]\n示例:\nRUN [\u0026#34;apt-get\u0026#34;, \u0026#34;install\u0026#34;, \u0026#34;python3\u0026#34;] CMD [\u0026#34;/bin/echo\u0026#34;, \u0026#34;Hello world\u0026#34;] ENTRYPOINT [\u0026#34;/bin/echo\u0026#34;, \u0026#34;Hello world\u0026#34;] 当指令以exec模式执行时，其会直接调用可执行文件，同时shell处理不会生效，以下述Dockerfile中的代码片段为例：\nENV name John Dow ENTRYPOINT [\u0026#34;/bin/echo\u0026#34;, \u0026#34;Hello, $name\u0026#34;] 当以docker run -it \u0026lt;image\u0026gt;的形式运行容器时，会有如下输出\nHello, $name 可看出输出结果中的name变量并没有被解析替换。\n运行bash脚本 如果需要运行bash脚本(或其它的shell脚本)，可通过在exec模式中使用/bin/bash来将其设置为可运行，在这种方式下，常规的shell处理会生效，以下述Dockerfile中的代码片段为例：\nENV name John Dow ENTRYPOINT [\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;echo Hello, $name\u0026#34;] 当以docker run -it \u0026lt;image\u0026gt;的形式运行容器时，会有如下输出\nHello, John Dow RUN指令 RUN指令允许我们在已有的镜像中安装所需的程序和软件包，它在当前镜像的顶层执行相关指令并通过提交执行结果的方式创建一个新的镜像封层，通常可在一个Dockerfile中看见多个RUN指令。\nRUN指令有2种使用方式:\nRUN \u0026lt;command\u0026gt; (shell模式) RUN [\u0026quot;executable\u0026quot;, \u0026quot;param1\u0026quot;, \u0026quot;param2\u0026quot;] (exec模式) (这两种模式在前面已有详细的说明)\nRUN指令一个典型的使用场景为安装多个版本控制软件包\nRUN apt-get update \u0026amp;\u0026amp; apt-get install -y \\ bzr \\ cvs \\ git \\ mercurial \\ subversion 需要注意的是apt-get update和apt-get install是在一条指令中执行，这样操作是为了确保安装最新的软件包。如果apt-get install是在单独的指令中执行，则其会复用apt-get update生成的镜像层，而该镜像层可能会在很久之前就被创建2。\nCMD指令 CMD指令允许我们设置一个默认的命令，当我们在运行容器时没有显示指定要运行的命令，默认命令将会执行，若Docker容器运行时指定了命令，则其将会被忽略。如果一个Dockerfile中有多个CMD指令，除了最后一个之外的其余CMD指令都会被忽略。\nCMD指令有3种使用方式：\nCMD [\u0026quot;executable\u0026quot;,\u0026quot;param1\u0026quot;,\u0026quot;param2\u0026quot;] （exec模式，首选） CMD [\u0026quot;param1\u0026quot;,\u0026quot;param2\u0026quot;] （在exec模式下给ENTRYPOINT指令添加额外的参数） CMD command param1 param2 (shell模式) 再次说明，前面已对第1种和第3种方式进行了解释，第2种方式则是在exec模式下和ENTRYPOINT组合使用，如果容器在没有命令行参数的情况下运行，它会设置将在ENTRYPOINT指令之后附加的默认参数。具体请查看ENTRYPOINT相关的说明。\n我们以下述Dockerfile中的代码片段为例，来看下CMD指令是如何运行的\nCMD echo \u0026#34;Hello world\u0026#34; 当以docker run -it \u0026lt;image\u0026gt;的形式运行容器时，会有如下输出\nHello world 但若运行容器时有附带的命令，如docker run -it \u0026lt;image\u0026gt; /bin/bash，此时CMD指令会被忽略，默认的bash会执行\nroot@7de4bed89922:/# ENTRYPOINT指令 ENTRYPOINT用于将容器设置为通过可执行文件来运行，由于它也能通过设置附带参数的命令，其看起来和CMD指令很相似，不同之处为ENTRYPOINT命令和参数在Docker容器以带参数的命令运行时不会被忽略。(虽然有办法来让Docker容器忽略ENTRYPOINT命令和参数，但一般我们不会这么做)\nENTRYPOINT指令有2种使用方式:\nENTRYPOINT [\u0026quot;executable\u0026quot;, \u0026quot;param1\u0026quot;, \u0026quot;param2\u0026quot;] (exec模式，首选) ENTRYPOINT command param1 param2 (shell模式) 当使用ENTRYPOINT模式时需要非常小心，这是由于不同方式的行为差异很大。\nExec模式 ENTRYPOINT指令中的Exec模式允许我们设置命令和参数，然后使用任一形式的CMD模式来设置有可能有可能发生变化的附带参数。ENTRYPOINT指令中的参数会一直被用到，而CMD中的相关参数则可在Docker容器运行覆盖，以下述Dockerfile中的代码片段为例\nENTRYPOINT [\u0026#34;/bin/echo\u0026#34;, \u0026#34;Hello\u0026#34;] CMD [\u0026#34;world\u0026#34;] 当以docker run -it \u0026lt;image\u0026gt;的形式运行容器时，输出如下\nHello world 但当Docker容器以docker run -it \u0026lt;image\u0026gt; John的形式运行时，输出如下\nHello John Shell模式 ENTRYPOINT指令中的shell模式会忽略任何CMD或Docker容器运行时附带的参数。\n总结 使用RUN指令通过在初始镜像的顶层添加分层来创建我们自己的镜像。\n当构建镜像且需要相关命令始终被执行时，优先使用ENTRYPOINT而非CMD指令，如果有些参数在Docker容器运行期间会被覆盖/改变，可通过额外使用CMD指令来添加默认的参数。\n当需要添加在Docker容器运行期间可被覆盖的默认参数，可使用CMD指令。\n译注: 即让容器一直保存运行状态，如通过java -jar springboot.jar让程序一直运行\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n译注： 原因为通过Dockerfile构建镜像时缓存默认生效\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2021-02-20T15:00:08+08:00","permalink":"https://lucumt.info/post/docker/difference-between-run-and-cmd-and-entrypoint-in-dockerfile-build/","tags":["docker"],"title":"Dockerfile中RUN、CMD与ENTRYPOINT的差异比较"},{"categories":["容器化"],"contents":"简要说明在使用Dockerfile构建镜像时，ADD与COPY指令的使用差异。\n近期在使用Docker时，发现部分项目中采用Dockerfile来构建自定义镜像时存在COPY和ADD两条指令混用的情况，为了规范使用，基于网络上的相关资料，简要的对比总结了它们的差异，供后续参考。\n对比 在Docker官网关于COPY指令的描述如下\nThe COPY instruction copies new files or directories from \u0026lt;src\u0026gt; and adds them to the filesystem of the container at the path \u0026lt;dest\u0026gt;.\n关于ADD的描述如下\nThe ADD instruction copies new files, directories or remote file URLs from \u0026lt;src\u0026gt; and adds them to the filesystem of the image at the path \u0026lt;dest\u0026gt;.\n从它们的描述可知，这两条指令的作用基本上类似，都是将特定文件或文件夹拷贝到镜像中，不同的是ADD指令还能从远程URL中拷贝文件并添加到镜像中。\n继续查看对应的文档，在ADD的指令描述下有如下说明\nIf \u0026lt;src\u0026gt; is a local tar archive in a recognized compression format (identity, gzip, bzip2 or xz) then it\u0026rsquo;s unpacked as a directory. Resources from remote URLs aren\u0026rsquo;t decompressed. When a directory is copied or unpacked, it has the same behavior as tar -x.\n从中可知若要拷贝的本地文件属于tar系列的压缩文件，则会自动解压为对应的文件夹或文件，这是其相对于COPY的另一个显著的不同点。\n关于它们更直观的对比说明，可在源文件中查看相应的备注:\n// COPY foo /path // // Same as \u0026#39;ADD\u0026#39; but without the tar and remote url handling. func dispatchCopy(d dispatchRequest, c *instructions.CopyCommand) error { // xxx } 总结下来就是 COPY指令处理不能进行压缩文件和URL文件流的处理之外，其它功能与ADD指令类似。\n验证 为了便于观察Dockerfile构建过程中的输出，可在构建指令中加入--progress=plain来查看输出的详细信息，类似如下\ndocker build --progress=plain --no-cache -t custom:v1.0 -f Dockerfile . ADD指令 验证普通的文件拷贝\nDockerfile文件如下\nFROM ubuntu:18.04 RUN mkdir /home/lucumt WORKDIR /home/lucumt ADD test.sh /home/lucumt RUN ls /home/lucumt 输出结果如下\n验证URL文件流下载\nDockerfile文件如下1\nFROM ubuntu:18.04 RUN mkdir /home/lucumt WORKDIR /home/lucumt ADD https://nginx.org/download/nginx-1.0.15.tar.gz /home/lucumt RUN ls /home/lucumt 输出结果如下，从中可以看出对于URL类型的文件，在Dockerfile的构建过程中只会拷贝，不会解压缩\n验证tar文件解压\nDockerfile文件如下\nFROM ubuntu:18.04 RUN mkdir /home/lucumt WORKDIR /home/lucumt ADD nginx-1.0.15.tar.gz /home/lucumt RUN ls /home/lucumt 输出结果如下，可以看出对于从本地拷贝的tar类型文件，Dockerfile构建过程中会默认进行解压缩\nCOPY指令 验证普通文件\nDockerfile文件内容如下\nFROM ubuntu:18.04 RUN mkdir /home/lucumt WORKDIR /home/lucumt COPY test.sh /home/lucumt RUN ls /home/lucumt 输出结果如下\n验证URL文件流下载\nDockerfile文件内容如下\nFROM ubuntu:18.04 RUN mkdir /home/lucumt WORKDIR /home/lucumt COPY https://nginx.org/download/nginx-1.0.15.tar.gz /home/lucumt RUN ls /home/lucumt 输出结果如下，可看出由于COPY指令不支持URL格式，构建过程会出错\n验证tar文件解压\nDockerfile文件内容如下\nFROM ubuntu:18.04 RUN mkdir /home/lucumt WORKDIR /home/lucumt COPY nginx-1.0.15.tar.gz /home/lucumt RUN ls /home/lucumt 输出结果如下，可看出此时对于本地压缩文件不会进行解压。\n总结 官方推荐的是在不需要使用ADD指令的高级特性的场景下，优先使用COPY指令，其更直观也不会造成困惑。\n假设对于一个新手来说，采用类似ADD nginx-1.0.15.tar.gz /home/lucumt进行构建后最后却得到的是一个解压文件，在不熟悉相关指令细节时会让人觉得很奇怪。\n参考链接：\nADD or COPY Docker ADD vs. COPY: What are the Differences? What is the difference between the COPY and ADD commands in a Dockerfile? 从1.6.0 版本开始，ADD指令支持通--checksum属性对远程URL文件在下载时进行校验来确保文件准确\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2021-01-16T15:00:05+08:00","permalink":"https://lucumt.info/post/docker/difference-between-add-and-copy-in-dockerfile-build/","tags":["docker"],"title":"Dockerfile中ADD与COPY的使用异同"},{"categories":["Java编程"],"contents":"在多种方式实现在Java中用线程轮流打印ABC中自己本想用单个锁通过调用wait()实现轮流打印，但一直遇到全部等待并停止执行的死锁问题，经过网上求助和自己分析，最终找到问题原因，简单记录下。\n原始代码 public class ThreadPrint4Test { public static void main(String[] args) { new ThreadPrint4Test().testPrint(); } public void testPrint() { Object lock = new Object(); new Thread(new PrintThread(\u0026#34;A\u0026#34;,lock),\u0026#34;thread-A\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;B\u0026#34;,lock),\u0026#34;thread-B\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;C\u0026#34;,lock),\u0026#34;thread-C\u0026#34;).start(); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { throw new RuntimeException(e); } new Thread(() -\u0026gt; { synchronized (lock) { lock.notifyAll(); } }).start(); } class PrintThread implements Runnable { private Object lock; private String value; public PrintThread(String value, Object lock) { this.value = value; this.lock = lock; } public void run() { while (true) { try { synchronized (lock) { lock.wait(); System.out.println(LocalTime.now() \u0026#43; \u0026#34;\\t\u0026#34; \u0026#43; value); lock.notifyAll(); } } catch (InterruptedException e) { throw new RuntimeException(e); } } } } } 执行结果\u0026amp;状态查看 运行上述程序，可发现在输出若干字符后，程序处于阻塞状态，输出停止：\n利用jps和jstack命令查看，可发现3个进程都处于WAITING状态形成类似死锁的现象，由此导致程序停止输出。\n由于多次运行上述代码，均能出现此问题(只不过出现的时间间隔不同)，可知程序代码肯定编写不正确。\n原因分析 最开始检查代码时看起来一切正常:\n某线程首先通过wait()进入等待状态 只有被唤醒后才能继续往下执行输出代码 输出完毕后通过notifyAll() 被notifyAll()唤醒的线程从步骤2开始往下执行 之后该线程调用wait()进入等待状态，重复步骤1实现不间断的打印 public void run() { while (true) { try { synchronized (lock) { lock.wait(); System.out.println(LocalTime.now() \u0026#43; \u0026#34;\\t\u0026#34; \u0026#43; value); lock.notifyAll(); } } catch (InterruptedException e) { throw new RuntimeException(e); } } } 上述推理与代码看起来很完美，无懈可击，但程序执行时就是每次都不能一直打印下去，肯定是自己的理解有问题。\n为了便于定位问题，将run()方法修改为如下代码：\npublic void run() { while (true) { try { synchronized (lock) { String name = Thread.currentThread().getName(); System.out.println(name \u0026#43; \u0026#34;\\t\u0026#34; \u0026#43; LocalTime.now() \u0026#43; \u0026#34;\\t\u0026#34; \u0026#43; \u0026#34; will invoke wait\u0026#34;); lock.wait(); System.out.println(name \u0026#43; \u0026#34;\\t\u0026#34; \u0026#43; LocalTime.now() \u0026#43; \u0026#34;\\t\u0026#34; \u0026#43; \u0026#34; is notified\u0026#34;); System.out.println(name \u0026#43; \u0026#34;\\t\u0026#34; \u0026#43; LocalTime.now() \u0026#43; \u0026#34;\\t\u0026#34; \u0026#43; value); lock.notifyAll(); } } catch (InterruptedException e) { throw new RuntimeException(e); } } } } 之后多次重新执行该程序，执行结果类似如下：\n从上图可以看出中无法找出具体的问题复现规律，查看wait()的官方文档，有如下说明\nThe current thread must own this object\u0026rsquo;s monitor. The thread releases ownership of this monitor and waits until another thread notifies threads waiting on this object\u0026rsquo;s monitor to wake up either through a call to the notify method or the notifyAll method. The thread then waits until it can re-obtain ownership of the monitor and resumes execution.\n查看notifyAll()的官方文档，有如下说明：\nThe awakened threads will not be able to proceed until the current thread relinquishes the lock on this object. The awakened threads will compete in the usual manner with any other threads that might be actively competing to synchronize on this object;\n从上述说明中可获得如下信息：\n调用wait()方法后，程序会处于等待状态，同时释放锁 被notifyAll()唤醒的线程并不会立即执行，需要等当前调用notifyAll()的线程释放对应的锁 被notfiyAll()唤醒的线程需要与其它正在执行的线程一并去竞争获取锁，并没有区别对待 至此，可以大致找出问题原因\n三个线程在某个时间段先后调用了wait()方法都进入了WAITING状态，同时没有其它线程来唤醒它们，导致最终程序停止输出。\n以线程A造成死锁为例，其过程如下:\n线程A调用wait()方法进入WAITING状态并释放锁 线程B获得锁，进入synchronized代码块 线程B执行wait()方法进行WAITING状态并释放锁 线程C获得锁，进入synchronized代码块 线程C执行wait()方法进行WAITING状态并释放锁 至此线程A、线程B、线程C均处于WAITING状态，程序停止输出 图示说明如下：\n改进代码 找到问题原因后，要修复此问题也很容，只需要避免所有的线程同时调用wait()方法即可，可在调用wait()前加个判断，确保始终有一个线程不用进入WAITING状态，能够释放锁。\n消除死循环 public class ThreadPrint4Test { public static void main(String[] args) { new ThreadPrint4Test().testPrint(); } private volatile String runThread; public void testPrint() { Object lock = new Object(); new Thread(new PrintThread(\u0026#34;A\u0026#34;, lock), \u0026#34;thread-A\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;B\u0026#34;, lock), \u0026#34;thread-B\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;C\u0026#34;, lock), \u0026#34;thread-C\u0026#34;).start(); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { throw new RuntimeException(e); } new Thread(() -\u0026gt; { synchronized (lock) { lock.notifyAll(); } }).start(); } class PrintThread implements Runnable { private Object lock; private String value; public PrintThread(String value, Object lock) { this.value = value; this.lock = lock; } public void run() { while (true) { try { synchronized (lock) { boolean process = value.equals(runThread); if (!process) { lock.wait(); System.out.println(LocalTime.now() \u0026#43; \u0026#34;\\t\u0026#34; \u0026#43; value); runThread = value; } lock.notifyAll(); } } catch (InterruptedException e) { throw new RuntimeException(e); } } } } } 实现轮流打印 public class ThreadPrint4Test { public static void main(String[] args) { new ThreadPrint4Test().testPrint(); } private volatile int count = 0; public void testPrint() { Object lock = new Object(); new Thread(new PrintThread(\u0026#34;A\u0026#34;, lock), \u0026#34;thread-A\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;B\u0026#34;, lock), \u0026#34;thread-B\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;C\u0026#34;, lock), \u0026#34;thread-C\u0026#34;).start(); } class PrintThread implements Runnable { private Object lock; private String value; public PrintThread(String value, Object lock) { this.value = value; this.lock = lock; } public void run() { while (true) { try { synchronized (lock) { boolean process = \u0026#34;A\u0026#34;.equals(value) \u0026amp;\u0026amp; count % 3 == 0; if (process) { count = 0; } process = process || (\u0026#34;B\u0026#34;.equals(value) \u0026amp;\u0026amp; count % 3 == 1); process = process || (\u0026#34;C\u0026#34;.equals(value) \u0026amp;\u0026amp; count % 3 == 2); if (process) { lock.wait(); System.out.println(value); count\u0026#43;\u0026#43;; Thread.sleep(500); } lock.notifyAll(); } } catch (InterruptedException e) { throw new RuntimeException(e); } } } } } ","date":"2020-09-12T18:07:27+08:00","permalink":"https://lucumt.info/post/java-concurrency/analysis-deadlock-in-multiple-threads-caused-by-wait/","tags":["Java","Java Concurrency"],"title":"一次由wait造成的死锁问题分析"},{"categories":["Java编程"],"contents":"在Java中采用3个线程不停的轮流打印ABC这3个字符，采用不同的方式实现。\n原理分析 实现思路如下：\n要在一个while循环中，实现不停的打印 多个线程间需要依次唤醒下一个线程，实现依次打印，此时会形成死循环 为了打破死循环，还需要一个启动线程延后调用 代码实现 基于wait\u0026amp;notify public class ThreadPrint1Test { public static void main(String[] args) { new ThreadPrint1Test().testPrint(); } public void testPrint() { Object lockA = new Object(); Object lockB = new Object(); Object lockC = new Object(); new PrintThread(\u0026#34;A\u0026#34;, lockA, lockB).start(); new PrintThread(\u0026#34;B\u0026#34;, lockB, lockC).start(); new PrintThread(\u0026#34;C\u0026#34;, lockC, lockA).start(); try { Thread.sleep(500); } catch (InterruptedException e) { throw new RuntimeException(e); } new Thread(() -\u0026gt; { synchronized (lockA) { lockA.notify(); } }).start(); } class PrintThread extends Thread { private Object waitLock; private Object notifyLock; private String value; public PrintThread(String value, Object waitLock, Object notifyLock) { this.value = value; this.waitLock = waitLock; this.notifyLock = notifyLock; } public void run() { while (true) { synchronized (waitLock) { try { waitLock.wait(); Thread.sleep(500); System.out.println(value); } catch (InterruptedException e) { throw new RuntimeException(e); } synchronized (notifyLock) { notifyLock.notify(); } } } } } } 基于ReentrantLock\u0026amp;Condition public class ThreadPrint2Test { public static void main(String[] args) { new ThreadPrint2Test().testPrint(); } public void testPrint() { Lock lock = new ReentrantLock(); Condition conditionA = lock.newCondition(); Condition conditionB = lock.newCondition(); Condition conditionC = lock.newCondition(); new Thread(new PrintThread(\u0026#34;A\u0026#34;, lock, conditionA, conditionB), \u0026#34;thread-a\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;B\u0026#34;, lock, conditionB, conditionC), \u0026#34;thread-b\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;C\u0026#34;, lock, conditionC, conditionA), \u0026#34;thread-c\u0026#34;).start(); try { Thread.sleep(500); } catch (InterruptedException e) { throw new RuntimeException(e); } new Thread(() -\u0026gt; { lock.lock(); conditionA.signal(); lock.unlock(); }, \u0026#34;init\u0026#34;).start(); } class PrintThread implements Runnable { private Lock lock; private Condition ca; private Condition cb; private String value; public PrintThread(String value, Lock lock, Condition ca, Condition cb) { this.value = value; this.lock = lock; this.ca = ca; this.cb = cb; } public void run() { while (true) { try { lock.lock(); ca.await(); System.out.println(value); Thread.sleep(500); cb.signal(); lock.unlock(); } catch (InterruptedException e) { throw new RuntimeException(e); } } } } } 基于Semaphore public class ThreadPrint3Test { public static void main(String[] args) { new ThreadPrint3Test().testPrint(); } public void testPrint() { Semaphore sa = new Semaphore(1); Semaphore sb = new Semaphore(1); Semaphore sc = new Semaphore(1); try { sb.acquire(); sc.acquire(); Thread.sleep(500); } catch (InterruptedException e) { throw new RuntimeException(e); } new PrintThread(\u0026#34;A\u0026#34;, sa, sb).start(); new PrintThread(\u0026#34;B\u0026#34;, sb, sc).start(); new PrintThread(\u0026#34;C\u0026#34;, sc, sa).start(); } class PrintThread extends Thread { private Semaphore sa; private Semaphore sb; private String value; public PrintThread(String value, Semaphore sa, Semaphore sb) { this.value = value; this.sa = sa; this.sb = sb; } public void run() { while (true) { try { sa.acquire(); System.out.println(value); Thread.sleep(500); sb.release(); } catch (InterruptedException e) { throw new RuntimeException(e); } } } } } 单个锁\u0026amp;volatile变量 此种方式不需要唤醒线程，同时便于很方便的修改线程数目。\npublic class ThreadPrint4Test { public static void main(String[] args) { new ThreadPrint4Test().testPrint(); } private volatile int count = 0; public void testPrint() { Object lock = new Object(); new Thread(new PrintThread(\u0026#34;A\u0026#34;, lock), \u0026#34;thread-A\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;B\u0026#34;, lock), \u0026#34;thread-B\u0026#34;).start(); new Thread(new PrintThread(\u0026#34;C\u0026#34;, lock), \u0026#34;thread-C\u0026#34;).start(); } class PrintThread implements Runnable { private Object lock; private String value; public PrintThread(String value, Object lock) { this.value = value; this.lock = lock; } public void run() { while (true) { try { synchronized (lock) { boolean process = \u0026#34;A\u0026#34;.equals(value) \u0026amp;\u0026amp; count % 3 == 0; if (process) { count = 0; } process = process || (\u0026#34;B\u0026#34;.equals(value) \u0026amp;\u0026amp; count % 3 == 1); process = process || (\u0026#34;C\u0026#34;.equals(value) \u0026amp;\u0026amp; count % 3 == 2); if (process) { lock.wait(); System.out.println(value); count\u0026#43;\u0026#43;; Thread.sleep(500); } lock.notifyAll(); } } catch (InterruptedException e) { throw new RuntimeException(e); } } } } } 基于LockSupport 此种方式更加简洁\nimport java.util.concurrent.TimeUnit; import java.util.concurrent.locks.LockSupport; public class ThreadPrintTestA { public static void main(String[] args) { PThread ta = new PThread(\u0026#34;A\u0026#34;); PThread tb = new PThread(\u0026#34;B\u0026#34;); PThread tc = new PThread(\u0026#34;C\u0026#34;); ta.setWakeupThread(tb); tb.setWakeupThread(tc); tc.setWakeupThread(ta); ta.setName(\u0026#34;thread-1\u0026#34;); tb.setName(\u0026#34;thread-2\u0026#34;); tc.setName(\u0026#34;thread-3\u0026#34;); ta.start(); tb.start(); tc.start(); try { TimeUnit.SECONDS.sleep(1); LockSupport.unpark(ta); } catch (InterruptedException e) { throw new RuntimeException(e); } } } class PThread extends Thread { private String str; private Thread wakeupThread; public PThread(String str) { this.str = str; } public void setWakeupThread(Thread wakeupThread) { this.wakeupThread = wakeupThread; } @Override public void run() { try { while (true) { LockSupport.park(); System.out.println(str \u0026#43; \u0026#34;\\t\u0026#34; \u0026#43; currentThread().getName()); TimeUnit.MILLISECONDS.sleep(100); LockSupport.unpark(wakeupThread); } } catch (InterruptedException e) { throw new RuntimeException(e); } } } ","date":"2020-09-08T11:11:06+08:00","permalink":"https://lucumt.info/post/java-concurrency/print-a-b-c-in-turn-by-threads/","tags":["Java","Java Concurrency"],"title":"多种方式实现在Java中用线程轮流打印ABC"},{"categories":["工具使用"],"contents":"简要介绍如何在Windows中的画图工具新打开一个画图时将其默认菜单从文件切换到菜单。\n问题 自己在工作中经常使用Windows系统自带的画图工具来编写图示说明文档，个人主要是通过Win+R打开运行窗口，之后输入mspaint，最开始其打开的界面类似如下，默认打开的是主页，可直接使用其上的各种工具，非常方便。\n突然某一天不知道发生了什么事情，利用mspaint打开画图后呈现出的界面类似如下，默认打开的是文件菜单，每次要对图片进行操作时都需要手工切换到主页菜单，操作完毕后它又会自动切换回文件菜单，使用起来很不方便。\n解决方法 一开始自己在百度上搜索后没有找到自己想要的答案，只能每次手工切换到主页菜单，但随着使用次数的增多，我有些受不了了，难道我真的是一个这么将就的人？ 我决心解决这个问题！\n百度不行，咱就上Google，一番搜索后终于在这篇文章中找到答案\nPaint does not have a File Tab, it only has a File Menu, that is always highlighted Blue in Paint What happens sometimes is the Home tab becomes hidden, double click the Home Tab to make that open permanently Then restart Paint to see if it then defaults to an open Home Tab . . .\n在下面的回复中有这么一句话\nWorked like a charm! And so simple\u0026hellip;. Thank you Dave.\n看到它我就知道这个答案很靠谱了，试了下果然生效！\n操作方法也很简单，如下图所示，双击主页菜单然后重新打开画图工具即可！\n需要注意的是若默认情况下已经打开主页菜单，再次双击该菜单时，会将主页菜单隐藏，自己之前的问题或许就是这个导致的。\n","date":"2020-04-07T15:21:27+08:00","permalink":"https://lucumt.info/post/other/switch-windows-paint-default-tab-to-home/","tags":["windows"],"title":"将Windows中的画图工具默认菜单从“文件”切换到“菜单”"},{"categories":["Java编程","MyBatis系列"],"contents":"在进行Java开发时，NullPointerException是一个很常见的异常，在Java8中提供了Optional来避免此问题，而在MyBatis 3.5.0中也提供了对Optional的支持，本文简要叙述如何在MyBatis中使用Optional。\n完整代码参见spring-mybatis-example\n查询单条记录 由于在查询单条记录时，若数据库中不存在该记录，则会默认返回null，此时可用Optional进行避免。\n首先确保MyBatis的版本不低于3.5.0，在mapper中可以仿照如下定义接口\npublic interface BookMapper {\rOptional\u0026lt;BookModel\u0026gt; findById(Integer id);\r} 之后在对应的service类中可以按照如下方式使用\n@Service\rpublic class BookService {\r@Autowired\rprivate BookMapper bookMapper;\rpublic BookModel getBook(Integer id) {\rOptional\u0026lt;BookModel\u0026gt; result = bookMapper.findById(id);\rBookModel book = result.orElse(new BookModel());\rreturn book;\r}\r} 执行下述单元测试代码\n@SpringBootTest\rpublic class TestBookService {\r@Autowired\rprivate BookService bookService;\r@Test\rpublic void testGetBook() {\rBookModel book = bookService.getBook(3);\rAssertions.assertNotNull(book);\rSystem.out.println(book);\r}\r} 其执行结果如下，可见Optional在Mapper接口中生效。\n查询多条记录 当查询的结果为List时，即使没有数据MyBatis也会返回一个空的List，其size为0但不为null，此时不需要我们进行非空判断。\n定义如下接口\npublic interface BookMapper {\rList\u0026lt;BookModel\u0026gt; selectByType(Integer type);\r} mapper文件如下\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt;\r\u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt;\r\u0026lt;mapper namespace=\u0026#34;com.lucumt.mapper.BookMapper\u0026#34;\u0026gt;\r\u0026lt;select id=\u0026#34;findById\u0026#34; parameterType=\u0026#34;Integer\u0026#34; resultType=\u0026#34;bookModel\u0026#34;\u0026gt;\rSELECT id,name,price,type FROM book WHERE id=#{id}\r\u0026lt;/select\u0026gt;\r\u0026lt;select id=\u0026#34;selectByType\u0026#34; parameterType=\u0026#34;integer\u0026#34; resultType=\u0026#34;bookModel\u0026#34;\u0026gt;\rSELECT id,name,price FROM book WHERE type=#{type}\r\u0026lt;/select\u0026gt;\r\u0026lt;/mapper\u0026gt; 业务类代码\n@Service\rpublic class BookService {\r@Autowired\rprivate BookMapper bookMapper;\rpublic List\u0026lt;BookModel\u0026gt; selectByType(Integer type){\rList\u0026lt;BookModel\u0026gt; bookList = bookMapper.selectByType(type);\rreturn bookList;\r}\r} 执行下述单元测试代码时能测试通过，可见在查询集合列表是不需要判断是否为空。\n@SpringBootTest\rpublic class TestBookService {\r@Autowired\rprivate BookService bookService;\r@Test\rpublic void testSelectByType() {\rList\u0026lt;BookModel\u0026gt; bookList = bookService.selectByType(3);\rAssertions.assertTrue(bookList != null);\rAssertions.assertTrue(bookList.size() == 0);\r}\r} 从上述试验可知，当获取的结果为List时，不使用Optinal关键字也能避免空指针问题。\n","date":"2020-02-13T14:40:19+08:00","permalink":"https://lucumt.info/post/mybatis/using-optional-in-mybatis-mapper/","tags":["mybatis"],"title":"在MyBatis接口中使用Optional进行非空判断"},{"categories":["翻译","spring系列","java编程"],"contents":"本文翻译自Spring @Configuration vs @Component。\n在前一篇文章中，我说过我们可以使用@Component作为@Configuration的一个备用选择，实际上这是来自于Spring team的官方建议\n也就是说，@Bean在我们不使用任何CGLIB代理时有一种精简模式：只需在未使用@Configuration注释的类上声明@Bean方法(但通常需要用另一种Spring中的stereotype实现替代，如@Component)，只要我们不在 @Bean 方法之间进行编程调用，程序就能正常工作。\n简而言之，下面显示的每个应用程序上下文配置将以完全不同的方式来生效：\n@Configuration public static class Config { @Bean public SimpleBean simpleBean() { return new SimpleBean(); } @Bean public SimpleBeanConsumer simpleBeanConsumer() { return new SimpleBeanConsumer(simpleBean()); } } @Component public static class Config { @Bean public SimpleBean simpleBean() { return new SimpleBean(); } @Bean public SimpleBeanConsumer simpleBeanConsumer() { return new SimpleBeanConsumer(simpleBean()); } } 第一段代码能按照预期正常工作，SimpleBeanConsumer将获取一个指向SimpleBean单例的链接，不幸的是，该段代码在Java数字签名环境中不生效。\n第二个代码则是完全不正确的，因为Spring会创建SimpleBean的单例bean，但是SimpleBeanConsumer会获得另一个SimpleBean实例，该实例不受Spring上下文控制。\n此现象的原因解释如下：\n如果使用@Configuration，则所有标记为@Bean的方法都将被包装到CGLIB包装器中，该包装器的工作方式为该方法第一次调用时将执行原始方法的主体，并将生成的对象注册在Spring上下文中，之后对该方法的调用都只返回从Spring上下文中获取到的bean。\n在上面的第二个代码块中，new SimpleBeanConsumer(simpleBean())只是调用一个纯java方法调用，要更正该代码块，可修改如下：\n@Component public static class Config { @Autowired SimpleBean simpleBean; @Bean public SimpleBean simpleBean() { return new SimpleBean(); } @Bean public SimpleBeanConsumer simpleBeanConsumer() { return new SimpleBeanConsumer(simpleBean); } } 这篇文章的所有代码示例都可以在我的个人GitHub中找到。\n","date":"2020-01-08T16:21:26+08:00","permalink":"https://lucumt.info/post/translate/spring/@configuration-vs-@component-in-spring/","tags":["spring","java"],"title":"[译]Spring中@Configuration和@Component的对比"},{"categories":["数据库"],"contents":"在给MySQL数据库进行配置时，对于mysql数据库表下的user表配置错误，导致无法通过命令登录进入MySQL数据库，查找网上的文档发现可通过安全模式进入，简单记录下。\n公司某个项目采用的MySQL数据库不支持远程连接，于是个人登录后在host表进入如下修改:\n由于将host修改为了%d而正常的写法是%,从而导致在重启MySQL后无法登录\n由于user表主要用于控制用户能否远程登录以及其权限，当此表配置错误时会出现无法通过常规的mysql -uroot -pxxx的方式登录数据库修改其配置，此时只能通过安全模式进行登录。首先在终端输入service mysql stop关闭MySQL服务，接下来输入mysqld_safe --skip-grant-tables以安全模式开启MySQL服务\n接下来在另一个终端中输入mysql -uroot -pxxx即可正常登录，登录之后重新修改mysql数据库下的user表中的相关配置并重启MySQL服务即可。\n参考文档:\nhttps://stackoverflow.com/questions/48246503/user-table-not-having-root-user ","date":"2019-08-22T11:32:19+08:00","permalink":"https://lucumt.info/post/mysql/mysql-can-not-login-due-to-incorrect-host-config/","tags":["mysql"],"title":"MySQL中由于user表中错误的host配置导入无法登录数据库"},{"categories":["java编程"],"contents":"在各种Java编程规范中都强调尽量不用java.util.Arrays.asList()方法以避免调用此方法生成的List无法进行修改操作，个人近期在使用过程中发现该方法的另外一个坑，简单记录下。\n问题描述 在程序中需要检测某个元素是否在数组中，处于缩短代码篇幅的考虑，自己采用了Arrays.asList方法将其转化为List然后调用contains方法来判断：\npublic static boolean checkContains(int ele) { int[] data = {11, 12, 13, 14}; return Arrays.asList(data).contains(ele); } 但实际执行结果和自己预期的不一致，理论上的结果应该为true，而实际返回的结果为false\n问题分析 在Debug模式下查看Arrays.asList(data)返回的值，发现其返回的结果不是预期中的List\u0026lt;Integer\u0026gt;而是List\u0026lt;int[]\u0026gt;，从而导致调用List.contains()方法失效!\n在IDEA中将Arrays.asList(data)返回的结果单独赋值给一个变量，可发现其类型确实为List\u0026lt;int[]\u0026gt;，若将结果类型修改为List\u0026lt;Integer\u0026gt;则会报错，如下图所示：\n在上图右边的报错信息中有如下说明信息:\nno instance(s) of type variable(s) exist so that int[] conforms to Integer inference variable T has incompatible bounds: equality constraints: Integer lower bounds: int[]\n上述文字的核心内容为Arrays.asList需要获取Object类型，而int是原生类型，但int[]符合要求，因此Arrays.asList()方法会将原始的int数组视作一个int[]对象进行处理，从而导致此结果1。\n解决方案 找到问题原因后修改起来也很容易，按照通常的编程习惯，只需要把数组的定义从int修改为Integer即可\npublic static boolean checkContains(int ele) { Integer[] data = {11, 12, 13, 14}; List\u0026lt;Integer\u0026gt; dataList = Arrays.asList(data); return dataList.contains(ele); } 执行结果符合预期\nUpdate:\n在Stackoverflow上找到一个类似问题2，在其回答中提供了一些其它实现方案：\nJDK8实现\nint[] ints = new int[] {1,2,3,4,5}; List\u0026lt;Integer\u0026gt; list11 =Arrays.stream(ints).boxed().collect(Collectors.toList()); JDK16实现\nint[] ints = new int[] {1,2,3,4,5}; Arrays.stream(ints).boxed().toList(); asList不可变原因分析 查看Arrays.asList返回结果中的List，发现其返回的是内部自己实现的ArrayList，但该ArrayList没有重写add方法。\n但AbstractList默认没有实现add()方法而是抛出一个异常，从而导致无法通过调用add()方法添加元素。\nhttps://stackoverflow.com/questions/27522741/incompatible-types-inference-variable-t-has-incompatible-bounds\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://stackoverflow.com/questions/2607289/converting-array-to-list-in-java\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-07-22T10:47:12+08:00","permalink":"https://lucumt.info/post/java-core/arrays-as-list-convert-result-in-java/","tags":["java"],"title":"Arrays.asList类型转换结果的坑"},{"categories":["数据库"],"contents":"在软件开发中采用LIMIT OFFSET对数据库进行分页是常见操作，但在数据量很大时直接使用LIMIT OFFSET查询尾部的数据会导致性能很慢，本文简要介绍2种改进方案。\n以system_user表为例，基于MySQL中快速创建大量测试数据一文中的介绍给其添加1000万的测试数据\nCREATE TABLE `system_user` (\r`id` INT NOT NULL AUTO_INCREMENT,\r`name` VARCHAR(8) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,\r`age` INT DEFAULT NULL,\r`tag` VARCHAR(8) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,\rPRIMARY KEY (`id`)\r) ENGINE = INNODB CHARSET = utf8; 基于查询SQLSELECT * FROM system_user LIMIT 9999990,10;进行优化分析。\n上述SQL在数据库中的查询耗时如下：\n利用explain分析其执行计划结果如下：\n上图中的rows这一例的数据为9722930，由于rows这一列的值是预估值，实际上MySQL会将数据offset+count的数据都获取到内存中，然后再进行过滤。在本例中即会将10000000条数据都获取到然后再进行过滤筛选，而获取这么多数据显然会导致查询速度变慢！\n问题根源为MySQL在执行LIMIT OFFSET时会将数据全部加载到内存中然后再进行过滤，实际上执行的是一种假分页！\n找到问题的根源后，要提高查询速度只能让MySQL查询时返回的数据尽可能小，接下来根据主键是否连续自增来分别叙述。\n自增主键过滤 若主键连续自增，则可从业务逻辑的角度先对数据用WHERE过滤，然后用LIMIT进行分页，类似SQL如下：\nSELECT * FROM `system_user` WHERE id\u0026gt;=9999990 LIMIT 10; 执行结果如下，可以看出时间明显缩短很多\n进一步分析其执行计划，发现rows这一列的值为11，只是获取了我们想要的数据，没有获取大批量数据。\n采用此种方式性能提升的原因如下：\nMySQL中的主键默认有索引，基于索引查询速度很快 WHERE优先于LIMIT执行，数据量相对之前，变得很小 其中最关键的是第2点，只要查询的数据量变小，查询速度自然会提升。\n覆盖索引过滤 基于自增主键过滤要求主键必须主键连续自增，若主键不连续(如主键采用UUID生成)则上述方案不可行，此时可基于覆盖索引来减少获取和传输的数据量大小。\n将查询sql修改为类似如下\nSELECT u1.* FROM `system_user` u1\rJOIN (SELECT id FROM `system_user` LIMIT 9999990,10) u2 ON u1.id=u2.id; 执行结果如下，可以看出耗时只比最初的少1秒\n查看其执行计划，发现获取的数据量仍然很大\n由于MySQL在数据量为千万级时查询速度会变慢，将数据库表中的数据量缩小到500万，执行如下：\n问题的根源在SELECT id FROM system_user LIMIT 9999990,10，虽然此时只查询id，但是id的数量仍然很庞大，由此造成查询速度变慢。\n此时可通过在数据库表中添加一列num并对其创建唯一索引，之后基于num进行过滤查询\n-- 添加索引\rALTER TABLE `system_user` ADD COLUMN `num` INT NOT NULL DEFAULT 1;\rALTER TABLE `system_user` ADD UNIQUE INDEX `user_num_index` (`num`);\r-- 重新制造数据\rTRUNCATE TABLE `system_user`;\rCALL add_user_batch(10000000); 改进后的sql如下\nSELECT u1.* FROM `system_user` u1\rJOIN (SELECT num FROM `system_user` WHERE num\u0026gt;=9999990 LIMIT 10) u2 ON u1.num=u2.num; 执行结果耗时如下：\n可以看出其耗时和采用自增连续主键时类似。对应的执行计划如下，从图中也能看出要获取的数据量明显变小。\n总结 上述两种方案归根到底均为要通过WHERE提前过滤不需要的数据，减少返回的数据量，总结如下：\n若主键连续且自增，则通过主键进行过滤 若主键不连续自增，可额外创建一个自增列或者采用覆盖索引的方式改写 ","date":"2019-02-11T09:52:31+08:00","permalink":"https://lucumt.info/post/mysql/limit-large-size-data-in-mysql/","tags":["mysql"],"title":"在MySQL中对大量数据进行limit offset分页查询的优化"},{"categories":["数据库"],"contents":"在学习MySQL索引和分库分表等知识的过程中，经常会涉及到创建大批量的测试数据，本文简要说明自己常用的几种创建方式以及各自的优劣对比。\n实现方式 以下述的system_user表为例分别说明在不同的方式下如何大批量的创建测试数据。\nCREATE TABLE `system_user` (\r`id` INT NOT NULL AUTO_INCREMENT,\r`name` VARCHAR(8) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,\r`age` INT DEFAULT NULL,\r`tag` VARCHAR(8) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,\rPRIMARY KEY (`id`)\r) ENGINE = INNODB CHARSET = utf8; 通过代码程序创建 工作中使用的编程语言主要是Java，在之前我不熟悉MySQL存储过程用法的时，主要采用JDBC的方式实现批量创建数据，代码类似如下:\nimport lombok.extern.slf4j.Slf4j;\rimport org.apache.commons.lang3.RandomStringUtils;\rimport org.apache.commons.lang3.RandomUtils;\rimport org.junit.jupiter.api.Test;\rimport org.springframework.boot.test.context.SpringBootTest;\rimport javax.annotation.Resource;\rimport javax.sql.DataSource;\rimport java.sql.Connection;\rimport java.sql.PreparedStatement;\rimport java.sql.SQLException;\r@Slf4j\r@SpringBootTest\rpublic class TestBatchInsertData {\r@Resource\rprivate DataSource dataSource;\rprivate int DATA_SIZE = 1000_0000;\rprivate int BATCH_SIZE = 100;\r@Test\rpublic void testAddBatchData() {\rString insertSQL = \u0026#34;insert into system_user(name,age,tag) VALUES(?,?,?)\u0026#34;;\rtry (Connection conn = dataSource.getConnection();\rPreparedStatement pstmt = conn.prepareStatement(insertSQL)) {\rconn.setAutoCommit(false);\rfor (int i = 1; i \u0026lt;= DATA_SIZE; i\u0026#43;\u0026#43;) {\rpstmt.setString(1, RandomStringUtils.randomAlphanumeric(8));\rpstmt.setInt(2, RandomUtils.nextInt(18, 80));\rpstmt.setString(3, RandomStringUtils.randomAlphabetic(8));\rpstmt.addBatch();\rif (i % BATCH_SIZE == 0) {\rpstmt.executeBatch();\rconn.commit();\rlog.info(\u0026#34;执行一次批量提交:\\t\u0026#34; \u0026#43; i / BATCH_SIZE);\r}\r}\rpstmt.executeBatch();\rconn.commit();\rlog.info(\u0026#34;完成数据批量插入\u0026#34;);\r} catch (SQLException e) {\rthrow new RuntimeException(e);\r}\r}\r} 从上述代码可知，此种实现方式较为简洁，实际的业务代码只有20行左右，对于具有Java开发经验的人来说上手很快，不足之处是需要额外准备相应的执行环境。\n通过存储过程创建 DELIMITER $$\rUSE `test`$$\rDROP PROCEDURE IF EXISTS `add_user_batch`$$\rCREATE DEFINER=`root`@`%` PROCEDURE `add_user_batch`(IN COUNT INT)\rBEGIN\rDECLARE i INT;\rDECLARE t_name VARCHAR(8);\rDECLARE t_tag VARCHAR(20);\rDECLARE t_age INT(2);\rDECLARE t_sql_template VARCHAR(100);\rDECLARE t_sql TEXT; DECLARE t_tag_mod_val INT DEFAULT(25);\rDECLARE t_commit_mod_val INT DEFAULT(100);\rDECLARE t_start_time DATETIME;\rDECLARE t_end_time DATETIME; TRUNCATE TABLE `system_user`;\rSET t_start_time=NOW();\rSET t_sql_template = \u0026#34;INSERT INTO `system_user`(NAME, age, tag) VALUES\u0026#34;;\rSET t_sql = t_sql_template;\rSET i = 1;\rWHILE i \u0026lt;= COUNT\rDO\rSET t_age = FLOOR(1 \u0026#43; RAND() * 60);\rSET t_name = LEFT(UUID(), 8);\r-- 给tag随机制造空值\rIF MOD(i, t_tag_mod_val) = 0 THEN\rSET t_tag = \u0026#34;NULL\u0026#34;;\rELSE\rSET t_tag = CONCAT(\u0026#34;\u0026#39;\u0026#34;,LEFT(UUID(), 8),\u0026#34;\u0026#39;\u0026#34;);\rEND IF;\rSET t_sql = CONCAT(t_sql,\u0026#34;(\u0026#39;\u0026#34;,t_name,\u0026#34;\u0026#39;,\u0026#34;,t_age,\u0026#34;,\u0026#34;,t_tag,\u0026#34;)\u0026#34;);\rIF MOD(i,t_commit_mod_val) != 0 THEN\rSET t_sql = CONCAT(t_sql,\u0026#34;,\u0026#34;);\rELSE\rSET t_sql = CONCAT(t_sql,\u0026#34;;\u0026#34;);\r-- 只要达到t_commit_mod_val要求的次数，就执行并提交\rSET @insert_sql = t_sql;\rPREPARE stmt FROM @insert_sql;\rEXECUTE stmt;\rDEALLOCATE PREPARE stmt;\rCOMMIT;\rSET t_sql=t_sql_template;\rEND IF;\rSET i = i \u0026#43; 1;\rEND WHILE;\r-- 不能被t_commit_mod_val整除时，余下的数据处理\rIF LENGTH(t_sql) \u0026gt; LENGTH(t_sql_template) THEN\rSET t_sql=CONCAT(SUBSTRING(t_sql,1,LENGTH(t_sql)-1),\u0026#39;;\u0026#39;);\rSET @insert_sql = t_sql;\rPREPARE stmt FROM @insert_sql;\rEXECUTE stmt;\rDEALLOCATE PREPARE stmt;\rCOMMIT;\rEND IF;\rSET t_end_time=NOW();\rSELECT CONCAT(\u0026#39;insert data success,time cost \u0026#39;,TIMEDIFF(t_end_time,t_start_time)) AS finishedTag;\rEND$$\rDELIMITER ; 调用过程类似如下:\n-- 清空原有记录\rTRUNCATE TABLE `system_user`;\r-- 调用存储过程\rCALL add_user_batch(1000);\r-- 验证查询结果\rSELECT COUNT(*) FROM `system_user`; 可以看出虽然用存储过程也能实现批量提交，但相对于Java实现而言，其代码量更大更为复杂，上手门槛略高。不过其好处也很明显，只要有数据库环境就能执行1。\n通过SQL语句创建 此种方式需要通过SELECT INSERT INTO来实现，具体步骤如下：\n通过如下的SQL初始化表中的数据：\nINSERT INTO `system_user`(NAME,age,tag) VALUES\r(LEFT(UUID(), 8),FLOOR(1 \u0026#43; RAND() * 60),LEFT(UUID(), 8)); 根据实际需要多次执行下述SQL：\nINSERT INTO `system_user`(NAME,age,tag) SELECT LEFT(UUID(), 8),FLOOR(1 \u0026#43; RAND() * 60),LEFT(UUID(), 8) FROM `system_user`; 这种方式主要是利用了SELECT每次查询之前表中的全部数据，然后重新插入，每次SELECT时都会将表中已有的数据全部查询出来，获取出总的记录数，然后根据SELECT后面的条件重新对每一条插入的记录重新赋值插入，实际上相当于翻倍插入。\n由于每次执行SELECT INTO时都是将之前的数据量扩大1倍，故往数据库中插入的总数count与执行次数n的关系如下:\ncount = $2^n$\n更具体的信息如下：\n阶段 插入总数 第1次执行 2 第2次执行 4 第3次执行 8 \u0026hellip; 第10次执行 1024 \u0026hellip; 第20次执行 1048576 第21次执行 2097152 第22次执行 4194304 第23次执行 8388608 在MySQL中tmp_table_size为16M，innodb_buffer_pool_size的默认值是128M，当执行到一定次数后，会出现类似The total number of locks exceeds the lock table size的错误，此时需要根据实际情况调整这两个参数，参考如下：\nSET GLOBAL tmp_table_size =512*1024*1024; -- 512M\rSET global innodb_buffer_pool_size= 2*1024*1024*1024; -- 2G 此种方式虽然需要多次执行SQL语句，但其优点也很明显，只需要将SQL语句稍作修改，就能适用于不同的数据库表。\n对比\u0026amp;总结 各种方式的对比如下：\n优点 缺点 适用场景 代码程序创建 1.实现方便，有编程知识即可\n2.性能不受数据量大小的影响 1.需要具备相关的编程知识\n2.需要有专门的软件运行环境，移植性不好\n3.不具备通用性 需要反复的创建大批量数据 存储过程创建 1.由于直接操作数据库，速度最快\n2.编写完成后可重复使用\n3.性能不受数据量大小的影响 1.存储过程的编写耗时，调试不太方便\n2.不具备通用性 1.需要反复的创建大批量数据\n2.无法通过程序代码创建 SQL语句创建 1.使用最方便，只要有mysql环境就能上手\n2.具备通用性，适合各种数据库表 1.需要多次执行SQL语句\n2.越到后面单次数据量越大，影响性能 创建大批量测试数据的次数较少,通常1到2次 各自执行1000万条数据的粗略耗时对比如下：2\n代码程序创建，6小时 存储过程创建，11分钟 SQL语句创建，5分钟 从上述结果可以看出通过SQL语句创建耗时相对较少3，若只是单纯的插入数据，建议优先选择此种方式。\n说明\n由于代码程序创建和存储过程创建这2种方式与特定的数据表强相关，换做其它表后需要重新修改，故在没有特殊要求的情况下建议采用SQL语句创建。\n疑问\n按存储过程创建从理论上来说速度要比SQL语句创建快很多(存储过程可以控制每次提交的数据量大小)，但多次测试发现前者的耗时约为后者的1倍，原因待继续分析。\n前提是有创建存储过程的权限\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n基于相同的提交次数进行比较，且是在个人电脑环境，只做横向对比，不具有很强的参考价值\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n代码程序创建和存储过程创建中涉及到一些控制逻辑和随机数的生成，这些是造成其耗费时间较长的因素之一\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-02-08T13:57:45+08:00","permalink":"https://lucumt.info/post/mysql/mysql-create-massive-test-data-quickly/","tags":["mysql"],"title":"MySQL中快速创建大量测试数据"},{"categories":["数据库"],"contents":"在数据库中使用COUNT函数统计总数是常用操作，本文参考网上资料以及个人实际操作记录下MySQL中通过COUNT(列名)、COUNT(常量)以及COUNT(*)在相同查询条件下1 的区别以及使用场景。\n本文基于InnoDB和MyISAM这两种常见的MySQL引擎，利用名为add_user_batch的存储过程向system_user表中插入1000万数据，对比测试它们的查询结果和响应性能。\nCREATE TABLE `system_user` (\r`id` INT NOT NULL AUTO_INCREMENT,\r`name` VARCHAR(8) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,\r`age` INT DEFAULT NULL,\r`tag` VARCHAR(8) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL,\rPRIMARY KEY (`id`)\r) ENGINE = INNODB CHARSET = utf8; 在add_user_batch中，采用循环的方式动态生成数据，每循环100次会将insert批量执行语句插入数据库中并提交，每循环25次其中的tag就会被置为空，故tag值为空的记录总共有400000个。\n结果对比 在MySQL的官网中对于COUNT()函数有如下说明：\nReturns a count of the number of non-NULL values of expr in the rows retrieved by a SELECT statement. The result is a BIGINT value.\nIf there are no matching rows,COUNT() returns 0. COUNT(NULL) returns 0.\nCOUNT(*)is somewhat different in that it returns a count of the number of rows retrieved, whether or not they contain NULL values.\n从中可以得出如下结论:\nCOUNT(expr)计算的是SELECT操作获取的数据行中expr不为空的总数 COUNT(*)计算的是SELECT操作获取的所有行数，不论其中是否有列为空 由于COUNT()主要是获取不为空的值，而在使用COUNT(常量)时其值恒为真，故其结果与COUNT(*)相同，同时由于主键不能为空，故COUNT(主键)的结果也与它们相同。基于上述理论分析可获知\nCOUNT(*)=COUNT(常量)=COUNT(主键)\u0026gt;=2COUNT(非主键列)\n采用前面存储过程生成的数据分别用上述4种方式去查询的结果如下，由于tag值为空的记录数为400000个，故COUNT(tag)返回的记录数为9600000，实际查询结果均符合理论预期。\n不同事务中的结果 由于InnoDB引擎支持事务，而在不同事务可能会导致数据库记录不一致，故在MySQL官网中对于InnoDB有如下文字说明，其主要说明的是COUNT()返回的是当前事务中可见的对应行数 ，即同样的查询SQL在不同的事务中其结果可能不相同3\nInnoDB does not keep an internal count of rows in a table because concurrent transactions might “see” different numbers of rows at the same time. Consequently, SELECT COUNT(*) statements only count rows visible to the current transaction.\n性能对比 说明\n由于测试环境以及MySQL查询缓存的原因，即使是同一条SQL查询多次查询的时间消耗也不完全相同，故在性能对比这块只做大致时间的对比，不会精确到毫秒级。\n继续从MySQL官方中寻找相关说明:\nInnoDB handles SELECT COUNT(*) and SELECT COUNT(1) operations in the same way. There is no performance difference.\nFor MyISAM tables, COUNT(*) is optimized to return very quickly if the SELECT retrieves from one table, no other columns are retrieved, and there is no WHERE clause.\nThis optimization only applies to MyISAM tables, because an exact row count is stored for this storage engine and can be accessed very quickly. COUNT(1) is only subject to the same optimization if the first column is defined as NOT NULL\n上述文字的要点如下：\nInnoDB对于COUNT(*)和COUNT(1)以相同的方式处理，它们没有性能上的区别 MyISAM对于COUNT(*)在 没有WHERE条件且只查询一张表 的情况下会进行优化，而COUNT(1)只有在 没有WHERE条件且第1列不为空 的情况下才会进行优化 对于第1点可从前面结果对比查询图中得到验证，其查询时间都近似为0.01s。\n下面分别展示MyISAM在有和没有WHERE过滤条件时COUNT()函数的查询耗时：\n没有WHERE条件执行如下，从中可以看出只有对于可能存在空值的tag列，其查询耗时为2.26s，其余的耗时均为0.01s，这其中的特例是name列，虽然不是主键，但是由于在建表时限制其非空，故InnoDB引擎会对其进行优化处理。\n有WHERE条件执行如下，从图中可以看出，此时由于InnoDB引擎优化不生效，故它们的查询时间都在秒级范围。\n给system_user表添加名为type的列并放在第1列，然后分别执行COUNT(1)与COUNT(*)发现耗时近似相，官方文档上说的只有在第1列不为空的限制条件在此处并不生效，原因待进一步分析。\n总结\u0026amp;建议 总结: SELECT COUNT(*)，查询特定表总行数时 SELECT COUNT(1)，查询特定表总行数，其结果同SELECT COUNT(*) SELECT COUNT(列名),查询指定列中符合条件得所有非空值 使用建议: SELECT COUNT(*)，查询总行数时使用，尤其是MyISAM引擎会在特定场景下进行优化 SELECT COUNT(1)，由于在MyISAM中只有在特定场景下优化才会生效，此种用法较为偏僻不符合SQL规范，不建议使用 SELECT COUNT(列名)，查询对应列的非空总行数 参考文档:\nhttps://segmentfault.com/a/1190000040733649 https://stackoverflow.com/questions/2710621/count-vs-count1-vs-countpk-which-is-better https://github.com/lucumt/myrepository/blob/master/mysql/add_user_batch.sql 即WHERE后面的过滤条件相同\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n相等的场景为SELECT返回的行中该列数据全部不为空\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n依赖于具体的事务隔离级别\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-01-25T17:18:27+08:00","permalink":"https://lucumt.info/post/mysql/difference-and-usage-for-various-select-count/","tags":["mysql"],"title":"MySQL中不同SELECT COUNT统计总数时的区别"},{"categories":["Java编程"],"contents":"ClassNotFoundException与NoClassDefFoundError是Java开发中经常会遇到的异常与错误，本文基于个人工作中遇到的场景以及网上的资料，简要总结它们的差异、出现场景以及规避方案。\nClassNotFoundException 分析 上图为ClassNotFoundException的类继承结构，从图中可看出它继承自Exception且没有继承自RuntimeException,基于Java语言规范它属于Checked Exception1，实际编程时必须在代码中利用try-catch显示的捕获处理或者利用throws将其抛出到上一层调用者处理，否则会导致编译器报错。\n产生原因 在ClassNotFoundException的官方API中对于其产生的原因有如下描述:\nThrown when an application tries to load in a class through its string name using:\nThe forName method in class Class. The findSystemClass method in class ClassLoader . The loadClass method in class ClassLoader. but no definition for the class with the specified name could be found.\n基于上述描述可知ClassNotFoundException产生的根本原因如下：\n在应用程序类中通过对应类的字符串名称去加载该类时找不到类的定义文件，即会抛出此异常\n上述描述实际上可分为2类:\n在Class类中通过forName方法去加载类时找不到类定义文件，由于该方式可在普通的Java类中使用故较为常见(如加载数据库驱动) 在ClassLoader类中通过findSystemClass或loadClass去加载类时找不到类定义文件，由于是在类加载器中使用，一般的业务涉及较少故不常见 问题复现 基于Class类的forName模拟复现:\npublic class TestClassForName { public static void main(String[] args) { testForName(); } private static void testForName() { try { Class.forName(\u0026#34;com.jdbc.mysql.Driver\u0026#34;); System.out.println(\u0026#34;output info after Class.forName invoke inside try-catch\u0026#34;); } catch (ClassNotFoundException e) { e.printStackTrace(); } System.out.println(\u0026#34;output info after Class.forName invoke outside try-catch\u0026#34;); } } 输出结果如下，可见try-catch之后的代码块还能正常执行\n基于ClassLoader中的loadClass复现：\npublic class TestClassLoader { public static void main(String[] args) { testLoadClass(); } private static void testLoadClass() { try { ClassLoader.getSystemClassLoader().loadClass(\u0026#34;com.jdbc.mysql.Driver\u0026#34;); System.out.println(\u0026#34;output info after ClassLoader.loadClass invoke inside try-catch\u0026#34;); } catch (ClassNotFoundException e) { e.printStackTrace(); } System.out.println(\u0026#34;output info after ClassLoader.loadClass invoke outside try-catch\u0026#34;); } } 输出结果如下\n从上述结果可以看出ClassNotFoundException虽然会导致try-catch代码块里面位于异常发生点之后的代码无法执行，但是位于try-catch代码块外面的代码程序执行不受影响(这其实是Checked Exception自身的特性决定的)。\nNoClassDefFoundError 分析 上图为NoClassDefFoundError的类继承结构，从图中可看出它继承自Error,，在Java语言关于Exception的官方API中有如下描述：\nThe unchecked exception classes are the run-time exception classes and the error classes.\n故NoClassDefFoundError属于Unchecked Exception，而对于这类异常不需要在程序中显示的通过try-catch捕获，需要从代码和工程层面进行处理。\n产生原因 在NoClassDefFoundError的官方API中有如下描述：\nThrown if the Java Virtual Machine or a ClassLoader instance tries to load in the definition of a class (as part of a normal method call or as part of creating a new instance using the new expression) and no definition of the class could be found.\nThe searched-for class definition existed when the currently executing class was compiled, but the definition can no longer be found.\n基于上述描述可知NoClassDefFoundError产生的根本原因如下：\n程序在编译时该类存在，在调用过程中JVM虚拟机加载该类时找不到该类的Class文件\n由于Java类加载过程有如下图所示的5个阶段，在其中每个阶段都可能会出现问题，结合实际开发场景，最典型的两类场景如下：\n类加载阶段出错。如在编译时类存在，但执行时不存在，一个典型的场景是 jar包版本不匹配！ 这也是我们开发过程中最容易遇到的场景 类初始化阶段出错。此种场景下编译也能通过，但由于某种原因导致初始化失败，程序仍然无法调用类。 与之相似的错误为NoSuchMethodError，其产生原因为程序执行时类存在，但是当前程序调用的方法不存在。\n问题复现 类加载阶段出错，在编译后jar文件中删除要调用的class类即可实现：\n要编译为jar文件的代码\n/* 类结构 \u0026#43;---src | \u0026#43;---main | | \\---java | | \\---com | | \\---lucumt | | \\---api | | InnerApi.java | | OuterApi.java */ public class OuterApi { public static void invoke() { InnerApi.hello(); } } public class InnerApi { public static void hello() { System.out.println(\u0026#34;hello\u0026#34;); } } 主执行类\nimport com.lucumt.api.OuterApi; public class TestNoClassDefFoundError1 { public static void main(String[] args) { try { OuterApi.invoke(); } catch (NoClassDefFoundError e) { e.printStackTrace(); } System.out.println(\u0026#34;OutApi invoke\u0026#34;); } } 将上述工程编译打包为jar文件，然后在jar文件中去掉InnerApi，将其引入包含执行类的测试工程，此时其结构如下：\n输出结果如下，可以看出虽然抛出了异常，但在try-catch代码块之后的代码还是能够执行\n类初始化阶段出错，通过某种方式强制初始化出错：\npublic class TestNoClassDefFoundError2 { public static void main(String[] args) { try { Demo.hello(); }catch(NoClassDefFoundError e){ e.printStackTrace(); } System.out.println(\u0026#34;invoke Demo.hello()\u0026#34;); } } class Demo { private static int val = 1 / 0; public static void hello() { System.out.println(\u0026#34;hello\u0026#34;); } } 输出结果如下，不同于前一个测试，此处的try-catch之后的代码没有机会执行\n从上面2个实验中可发现虽然都对NoClassDefFoundError进行了try-catch捕获，但第一个能继续执行，而第二个却直接终止。造成这种差异的主要原因是第一个测试中的Demo没能完成初始化，导致整个程序加载失败(实际上程序提示的错误为 ExceptionInInitializerError)，而第二个程序是在执行中才遇到类缺失2。\n基于Unchecked Exception我们通常不需要在代码中显示的利用try-catch捕获，更多的是修改代码本身和调整jar文件版本。\n总结 ClassNotFoundException NoClassDefFoundError 继承关系 java.lang.Exception java.lang.Error 类型 异常 错误 程序受影响程度 添加try-catch后可继续执行 基于产生于类加载的不同阶段，可能直接种植，也可能在try-catch之后继续执行 可能的场景 1.要加载的类不存在\n2.类名编写错误 1.jar包缺失或jar包版本不匹配\n2.类初始化失败 处理方法 1. 修改代码，添加缺失的jar文件\n2. 代码中添加try-catch捕获异常 修改代码业务逻辑 参考:\nhttps://segmentfault.com/a/1190000021292121\nhttps://stackoverflow.com/questions/28322833/classnotfoundexception-vs-noclassdeffounderror\nhttps://docs.oracle.com/javase/specs/jls/se7/html/jls-11.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n实际上应该有更科学更理论的解释，只不过自己目前找不到相关资料，暂时这么解释\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-01-02T14:18:46+08:00","permalink":"https://lucumt.info/post/java-core/difference-between-class-not-found-exception-and-no-class-def-found-error/","tags":["Java"],"title":"ClassNotFoundException与NoClassDefFoundError对比"},{"categories":["Java编程","Java多线程","翻译"],"contents":"本文翻译自 Dealing with InterruptedException\n这个故事可能很熟悉: 你正在编写一个测试程序，需要将程序暂停一段时间,于是你调用了Thread.sleep()来实现。 但此时编译器或IDE会立即提示你没有处理非运行时异常 InterruptedException。那么，什么是InterruptedException,为什么我们要必须处理它呢？\n最常见的处理方式是将该异常吞没掉: 通过try-catch捕获该异常然后不进行任何处理(或许会用日志来记录异常，但并没有改进多少)， 我们将在代码清单4中看见此方式的使用。不幸的是，这种方式丢弃了有关中断产生的重要信息，而这可能会影响应用程序及时取消执行或关闭的能力。\n阻塞方法 当一个方法抛出InterruptedException异常时，除了该异常之外它还会告诉你额外的一些信息。如果你问的好，它会告诉你这是一个阻塞方法， 它会尝试解除阻塞并且提前返回。\n阻塞方法不同于一个需要长时间返回的普通方法，普通方法的完成仅取决于你要求它做多少工作以及是否有足够的计算资源(CPU循环和内存)，另一方面，阻塞方法的完成度还取决于某些外部事件，例如计时器到期、I/O操作完成或另一个线程的操作(释放锁、设置标志位或将任务放到一个工作队列中等)。普通的方法只要其工作任务完成了该方法就完成，而阻塞方法由于它们依赖于外部事件而不太可预测。由于很难预测何时完成，阻塞方法会影响响应能力。\n由于阻塞方法可能由于等待的事件永远不发生而一直阻塞，所以通常能取消该方法对阻塞方法很有用(对于长时间运行的非阻塞方法，通常也是有用的)。可取消的操作是指能从外部提前结束一个需要它自己完成的任务。Object.wait()和Thread提供的Thread.sleep()即是一种取消机制，它允许一个线程请求另外一个线程提前停止它正在执行的任务。当一个方法抛出InterruptedException异常时，意味着如果执行该方法的线程被中断，它将通过抛出InterruptedException异常来尝试停止当前任务并且提前返回。一个设计良好的阻塞库方法应该及时响应中断并抛出InterruptedException异常，因而可以在可取消的任务中使用而不影响响应能力。\n线程中断 每个线程都一个与之关联的布尔属性来表示其中断状态。中断状态的初始值为false，当一个线程被其它线程调用Thread.interrupt()方法中断时，会根据实际情况做出响应: 如果该线程正在执行低级别的可中断方法(如Thread.sleep()、Thread.join()或Object.wait())，则会解除阻塞并抛出InterruptedException异常，否则Thread.interrupt()仅设置线程的中断状态，在该被中断的线程中稍后可通过轮询中断状态来决定是否要停止当前正在执行的任务。中断状态可通过Thread.isInterrupted()来读取，也可通过不规范命名的Thread.interrupted()在单个操作中读取和清除中断状态。\n中断是一种协作机制。当一个线程中断了另外一个线程时，被中断的线程没必要停止正在执行的任务，相反，中断只是礼貌的要求被中断的线程在它方便的时候停止它当前正在执行的任务。有些方法如Thread.sleep()会认真对待这个要求，而其它一些方法则不需要注意中断。不阻塞但需要长时间执行的方法也可通过轮询中断状态来提前返回，你也可以忽略中断求，但这样做可能会影响响应性。\n中断的协作特性的一个好处是它为安全的构建可取消的任务提供了更大的灵活性。实际上我们很少想要立即终止一个任务，如果任务在更新期间被取消，程序数据结构可能会处于不一致的状态。而中断操作允许我们在任务终止之前做其它的一些操作，如清理任何正在运行的任务、恢复不变量、将终端请求通知给其它任务等。\nInterruptedException 如果抛出InterruptedException异常意味着该方法是一个阻塞方法，那么调用一个阻塞方法意味着调用方法也是阻塞方法，我们应该有一个处理InterruptedException异常的策略。通过最简单的策略是直接抛出InterruptedException，如代码清单1中puskTask()和getTask()方法所示,这样做即可使方法响应中断，并且通常只需要在throws字句中添加InterruptedException。\n代码清单1： 通过向调用者传递InterruptedException来避免捕获\npublic class TaskQueue { private static final int MAX_TASKS = 1000; private BlockingQueue\u0026lt;Task\u0026gt; queue = new LinkedBlockingQueue\u0026lt;Task\u0026gt;(MAX_TASKS); public void putTask(Task r) throws InterruptedException { queue.put(r); } public Task getTask() throws InterruptedException { return queue.take(); } } 有时在传播异常之前需要进行一些清理，在这种情况下，你可以捕获InterruptedException，执行清理然后重新抛出异常。代码清单2，一种用于匹配在线游戏服务中玩家的机制展示了这种技术。matchPlayers()方法等待两个玩家到达后就开始一个新的游戏，如果在一个玩家到达后但在第二个玩家到达之前被中断，它会在重新抛出InterruptedException异常之前将该玩家放回队列，这样玩家的请求就不会丢失。\n代码清单2: 在重新抛出InterruptedException之前基于任务进行特定清理\npublic class PlayerMatcher { private PlayerSource players; public PlayerMatcher(PlayerSource players) { this.players = players; } public void matchPlayers() throws InterruptedException { Player playerOne, playerTwo; try { while (true) { playerOne = playerTwo = null; // 等两个玩家到达后开始一个新的游戏 playerOne = players.waitForPlayer(); // 可能抛出InterruptedException playerTwo = players.waitForPlayer(); // 可能抛出InterruptedException startNewGame(playerOne, playerTwo); } } catch (InterruptedException e) { //如果一个玩家达到后线程被中断，将这个玩家放回队列 if (playerOne != null) players.addFirst(playerOne); //重新抛出异常 throw e; } } } 不要吞没中断 有些时候抛出InterruptedException异常并不合适，例如在由Runnable定义的任务中调用一个可中断方法，在这种情形下，你不能抛出InterruptedException，但你也不想做其它任何事情。当阻塞方法检测到中断并抛出InterruptedException时，它会清除中断状态。如果捕获InterruptedException异常但无法重新抛出它，则应保留中断发生时的证据，以便调用堆栈上的代码可以了解中断并在必要时对其进行响应。如代码清单3所示，这个任务是通过调用interrupt()来 重新中断(reinterrupt) 当前线程完成的。每当你捕获InterruptedException并且不重新抛出它时，要在返回之前重新中断当前线程(即清除中断状态)。\n代码清单3: 捕获InterruptedException后恢复中断状态\npublic class TaskRunner implements Runnable { private BlockingQueue\u0026lt;Task\u0026gt; queue; public TaskRunner(BlockingQueue\u0026lt;Task\u0026gt; queue) { this.queue = queue; } public void run() { try { while (true) { Task task = queue.take(10, TimeUnit.SECONDS); task.execute(); } } catch (InterruptedException e) { //重新设置当前线程的中断状态 Thread.currentThread().interrupt(); } } } 对于InterruptedException最糟糕的处理是吞没它，在捕获它之后既不重新抛出它也不重新设置当前线程的中断状态。\n代码清单4: 吞下中断\u0026ndash;不要这样做\n// 不要这么做 public class TaskRunner implements Runnable { private BlockingQueue\u0026lt;Task\u0026gt; queue; public TaskRunner(BlockingQueue\u0026lt;Task\u0026gt; queue) { this.queue = queue; } public void run() { try { while (true) { Task task = queue.take(10, TimeUnit.SECONDS); task.execute(); } } catch (InterruptedException swallowed) { /* 不要这么做 - 相反要恢复线程的中断状态 */ } } } 如果你无法重新抛出InterruptedException，不论你是否计划对中断请求进行响应，你仍然应该重新设置当前线程的中断状态，因为单个中断请求可能有多个接收人。标准线程池(ThreadPoolExecutor)中的工作线程实现了响应中断，因此中断线程池中运行的任务可能会同时影响到取消任务和通知执行线程当前线程池正在关闭。如果该任务吞下中断请求，则工作线程可能不会知道该中断被请求过，这可能会延迟应用程序或关闭服务。\n实现可取消的任务 在Java语言规范中没有任何内容可以中断任何特定语义，但在较大程序中，很难保持除了取消操作之外的任何中断语义。依赖于具体的业务活动，用户可以通过GUI或JMS、WebService服务等来请求取消操作。也可以由程序逻辑请求实现，例如，网络爬虫在检测到磁盘空间已满时自动关闭，或者并行算法可能会启动多个线程来搜索解决方案的不同区域并在其中一个找到解决方案后取消其余的。\n一个任务不能仅仅因为它可以取消而意味着它需要立即响应中断请求。对于通过代码循环执行的任务，通常是在每个循环中检查中断状态。根据循环执行的时间长短，在任务代码通知线程中断之前可能需要一些时间(通过调用Thread.isInterrupted()轮询中断中断或调用一个阻塞方法)。如果任务需要更具响应性，则可以更频繁的轮询中断状态。阻塞方法通常在进入该方法时立即轮询中断状态，如果要提高响应性，可以直接抛出InterruptedException异常。\n当你知道一个线程即将结束执行时，吞下一个中断是可接受的。只有当调用可中断方法的类是Thread的一部分而不是Runnable或通用库代码时才会出现此种情形，如代码清单5所示。它创建了一个枚举质数的线程，并且允许线程在中断时退出。这个寻找质数的循环在两个地方检查中断：一个通过轮迅while循环判断条件中的isInterrupted()方法，另一个则是通过调用阻塞的BlockingQueue.put()方法。\n代码清单5: 在知道线程将结束时可以吞下中断\npublic class PrimeProducer extends Thread { private final BlockingQueue\u0026lt;BigInteger\u0026gt; queue; PrimeProducer(BlockingQueue\u0026lt;BigInteger\u0026gt; queue) { this.queue = queue; } public void run() { try { BigInteger p = BigInteger.ONE; while (!Thread.currentThread().isInterrupted()) queue.put(p = p.nextProbablePrime()); } catch (InterruptedException consumed) { /* 允许线程退出 */ } } public void cancel() { interrupt(); } } 非中断阻塞 并非所有的阻塞方法都会抛出InterruptedException。输入流和输出流由于等待I/O操作完成而阻塞，但它们不会抛出InterruptedException异常，并且如果它们被中断，也不会提前返回。但在套接字I/O的情形下，如果一个线程关闭套接字，在其它线程中的阻塞I/O操作将会通过SocketException提早结束。java.nio包中的非阻塞I/O操作也不支持可中断的I/O操作，但可以通过关闭通道或请求唤醒Selector来实现类似的阻塞操作。类似的，尝试获取内部锁(进入一个同步块)不能被中断，但使用ReentrantLock能实现可中断的获取锁。\n非取消任务 有些任务只是简单的拒绝被中断从而导致它们无法取消。但即使是不可取消的任务也应该保留中断状态，以防在调用堆栈上的代码想要在不可取消的任务完成后响应中断。代码清单6显示了一个方法等待阻塞队列直到其中某个元素可用，无论它是否被中断。为了安分守己，该方法在完成后会清除最终代码块中的中断状态，以避免剥夺调用者发出的中断请求。由于会导致无限循环而不能在该方法中恢复中断状态。(BlockingQueue.take()可以在调用时立即轮询中断状态，如果发现有中断状态集则立即抛出InterruptedException异常。)\n代码清单6: 非取消的任务在返回之前恢复中断状态\npublic Task getNextTask(BlockingQueue\u0026lt;Task\u0026gt; queue) { boolean interrupted = false; try { while (true) { try { return queue.take(); } catch (InterruptedException e) { interrupted = true; // 虽然发生中断，但是继续尝试 } } } finally { if (interrupted) Thread.currentThread().interrupt(); } } 总结 你可以使用Java平台提供的协作中断机制来构建灵活的取消策略。线程活动可以决定它们是否可以取消、如何响应中断，如果立即返回会影响应用程序的完整性时，它们可以推迟中断以执行特定于任务的清理活动。即是想完全忽略代码中的中断，也要确保在捕获InterruptedException时恢复中断状态，并且不要重新抛出它以便调用它的代码不会被剥夺对于中断发生的感知。\n\u0026lt;–翻译结束!–\u0026gt;\n","date":"2018-12-15T11:57:36+08:00","permalink":"https://lucumt.info/post/translate/java-concurrency/dealing-with-interrupted-exception/","tags":["Java"],"title":"[译]如何处理InterruptedException"},{"categories":["Java编程","Java多线程"],"contents":"volatile关键字在Java多线程编程中很常见，由于自己之前学习多线程时一度以为只要需确保线程可见性的代码都需要使用volatile关键字，后来发现并不是这样的，故简单记录下。\n典型使用场景 下面这段代码创建了两个线程threadA和threadB，threadA中运行display()方法，threadB中运行stop()方法，在threadA启动1秒后启动threadB。\n在stop布尔变量上分别注释和不注释volatile的运行结果如下：\n注释volatile关键字时，display()方法一直运行，程序不能终止； 不注释volatile关键字时，display()方法会在调用stop()方法后立即停止运行，程序终止； 注: 根据实际运行电脑的配置，有可能不注释volatile关键字时调用stop()方法也能让display()方法立即停止运行。\n代码清单1: volatile关键字的使用\npublic class VolatileTest { //注释掉volatile关键字时display()方法会一直运行下去 private /*volatile*/ boolean stop = false; private void stop() { stop = true; } private void display() { while(!stop) { } System.out.println(LocalDateTime.now()); } public void test() { Thread threadA = new Thread(()-\u0026gt;{ this.display(); }); Thread threadB = new Thread(()-\u0026gt;{ this.stop(); }); threadA.start(); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } threadB.start(); } public static void main(String[] args) { VolatileTest vt = new VolatileTest(); vt.test(); } } 上述代码展示了volatile的典型使用场景:\n当有两个或以上的线程同时读取一个共享的可变变量时，为了确保每个线程都能获取到最新的值，应该使用volatile关键字对该变量进行修饰，确保该变量的可见性。\n关于volatile如何实现确保变量可见性，网上已经有很多资料，请自行查阅，如volatile和lock原理分析。\n有独占锁时不需要使用volatile 既然volatile变量确保的是在多个线程同时读取一个变量时确保内存可见性，如果有多个线程对共享变量进行读写时，由于排它锁(exclusive lock) 的存在导致任一时刻只能有一个线程对共享变量进行读写操作，此时是否还需要添加volatile关键字呢？答案是否定的，从字面意思可以看出，由于同一时刻只能有一个线程访问变量，所以变量可见性的问题不会存在，故没必要添加volatile关键字。\n以Java8为例，在Java语言规范中有关于volatile的说明volatile Fields中有如下片段:\nThe Java programming language allows threads to access shared variables (§17.1). As a rule, to ensure that shared variables are consistently and reliably updated, a thread should ensure that it has exclusive use of such variables by obtaining a lock that, conventionally, enforces mutual exclusion for those shared variables.\nThe Java programming language provides a second mechanism, volatile fields, that is more convenient than locking for some purposes.\nA field may be declared volatile, in which case the Java Memory Model ensures that all threads see a consistent value for the variable (§17.4).\n从这段文字可以看出volatile相对于独占锁提供了更加简便的方式让变量一致且可靠的更新，volatile只确保读取的值正确，对写入影响不大，而独占锁则限制了同时只能有一个读或写，导致出现性能问题以及在特定的场景下无法使用的问题(如代码清单1所示，若采用独占锁则同时只能有一个线程运行，违背了设计初衷)。\n下述代码展示了一个典型的生产者/消费者模式，由于独占锁的存在，即使没有使用volatile关键字，程序也能正常工作。\n代码清单2: 生产者/消费者模式\npublic class ProducerConsumerTest { private static final int MAX_SIZE = 10; //这两个变量没必要使用volatile关键字修饰 private LinkedList\u0026lt;String\u0026gt; items = new LinkedList\u0026lt;\u0026gt;(); private int count; private Object lock = new Object(); private void produce(String ele) { synchronized (lock) { try { while (count \u0026gt;= MAX_SIZE) { lock.wait(); } } catch (InterruptedException e) { e.printStackTrace(); } items.add(ele); count\u0026#43;\u0026#43;; System.out.println(Thread.currentThread().getName() \u0026#43; \u0026#34; 添加了元素 \u0026#34; \u0026#43; ele \u0026#43; \u0026#34; 当前元素总数为 \u0026#34; \u0026#43; count); lock.notifyAll(); } } private String consume() { String result = null; synchronized (lock) { try { while (count == 0) { lock.wait(); } } catch (InterruptedException e) { e.printStackTrace(); } result = items.pollLast(); count--; System.out.println(Thread.currentThread().getName() \u0026#43; \u0026#34; 获取了元素 \u0026#34; \u0026#43; result \u0026#43; \u0026#34; 当前元素总数为 \u0026#34; \u0026#43; count); lock.notifyAll(); } return result; } public void test() { for(int i=0;i\u0026lt;10;i\u0026#43;\u0026#43;) { new Thread(() -\u0026gt; { for(int j=0;j\u0026lt;5;j\u0026#43;\u0026#43;) { String ele = UUID.randomUUID().toString().replace(\u0026#34;-\u0026#34;, \u0026#34;\u0026#34;); this.produce(ele); } },\u0026#34;Producer_\u0026#34; \u0026#43; i).start(); } for(int i=0;i\u0026lt;5;i\u0026#43;\u0026#43;) { new Thread(() -\u0026gt; { for(int j=0;j\u0026lt;10;j\u0026#43;\u0026#43;) { this.consume(); } },\u0026#34;Consumer_\u0026#34; \u0026#43; i).start(); } } public static void main(String[] args) { new ProducerConsumerTest().test(); } } 利用volatile在单例模式中实现双重检查 volatile关键字不仅可以确保线程可见性，还能禁止重排序，它的一个典型应用是利用双重检查实现线程安全的单例设计模式，如代码清单3所示。在该程序中主要利用了volatile禁止重排序的功能，详细说明请参见Java并发编程的艺术P67中的 双重检查锁定与延迟初始化 。\n代码清单3: 利用双重检查实现线程安全的单例模式\npublic class Singleton { private static volatile Singleton instance = null; private Singleton() { } public static Singleton getInstance() { if(instance == null) { synchronized(Singleton.class) { if(instance == null) { instance = new Singleton(); } } } return instance; } } 参考文章:\nJava并发编程的艺术 volatile和lock原理分析 Simplest and understandable example of volatile keyword in java Difference between volatile and synchronized in Java ","date":"2018-12-08T23:49:33+08:00","permalink":"https://lucumt.info/post/java-concurrency/how-to-use-volatile-in-java/","tags":["Java","Java Concurrency"],"title":"volatile关键字在Java程序中的使用"},{"categories":["Java编程"],"contents":"Java中字符串的比较在面试中很常见，我们都知道比较字符串是否相等要使用equals()而不是==。本文首先利用javap命令从class文件的角度来分析不同字符串比较的结果，然后分析下Tomcat中如何获取前端输入的字符串参数,并以此说明Java Web开发中该如何正确的进行字符串的比较。\n简单字符串比较 测试代码如下：\npublic class StringTest { public static void main(String[] args) { String s1 = \u0026#34;Hello World\u0026#34;; String s2 = \u0026#34;Hello World\u0026#34;; String s3 = new String(\u0026#34;Hello World\u0026#34;); String s4 = new String(\u0026#34;Hello World\u0026#34;); System.out.println(\u0026#34;利用==比较\u0026#34;); System.out.println(s1 == s2); System.out.println(s1 == s4); System.out.println(s3 == s4); System.out.println(s1 == s4.intern()); System.out.println(s3.intern() == s4.intern()); System.out.println(\u0026#34;\\n利用equals()比较\u0026#34;); System.out.println(s1.equals(s2)); System.out.println(s1.equals(s4)); System.out.println(s3.equals(s4)); } } 程序运行的结果如下：\n从上图中可以看出: 利用equals()比较时返回的结果全为true,而利用==比较的结果只有部分为true。利用javap命令输出class文件内容如下(省略掉了System.out.println()相关的)\nCompiled from \u0026#34;StringTest.java\u0026#34; public class StringTest { public StringTest(); Code: 0: aload_0 1: invokespecial #8 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 4: return public static void main(java.lang.String[]); Code: 0: ldc #16 // String Hello World 2: astore_1 3: ldc #16 // String Hello World 5: astore_2 6: new #18 // class java/lang/String 9: dup 10: ldc #16 // String Hello World 12: invokespecial #20 // Method java/lang/String.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 15: astore_3 16: new #18 // class java/lang/String 19: dup 20: ldc #16 // String Hello World 22: invokespecial #20 // Method java/lang/String.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 25: astore 4 27: new #18 // class java/lang/String 30: dup 31: ldc #16 // String Hello World 33: invokespecial #20 // Method java/lang/String.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 36: invokevirtual #23 // Method java/lang/String.intern:()Ljava/lang/String; 39: astore 5 //...... 214: return } 为了能读懂其内容，可先从The Java® Virtual Machine Specification中了解相关的指令，本文将涉及到的指令列举如下\nldc，将字符串从运行时常量池压入操作栈中 astore，将一个数值从操作栈存入局部变量表 dup，复制栈顶的数值并将复制的数值重新压入栈中 invokespecial，调用实例构造器方法、私有方法和父类方法 invokevirtual，调用实例方法，基于类进行分发 基于上述命令我们可以发现字符串s1、s2、s5都是从常量池中的获取的，而s3、s4则是分别创建了两个String对象，如下图所示。\n在Java中==比较的是内存地址是否相同，而equals()比较的是其文本值是否相同，而从常量池中多次获取同一个常量其地址是相同的，新建的String对象JVM会为其重新分配内存地址。故在利用==进行比较时,1、2、5这三个都是基于常量池的比较，它们的结果都为true，而3、4种都包含有String对象，故其结果均为false。\n字符串相加后比较 将上述代码修改为如下:\npublic class StringTest { public static void main(String[] args) { String s1 = \u0026#34;Hello World\u0026#34;; String s2 = \u0026#34;Hello \u0026#34;; String s3 = s2 \u0026#43; \u0026#34;World\u0026#34;; String s4 = \u0026#34;Hello \u0026#34; \u0026#43; \u0026#34;World\u0026#34;; String s5 = \u0026#34;Hello \u0026#34; \u0026#43; new String(\u0026#34;World\u0026#34;); String s6 = \u0026#34;Hello \u0026#34; \u0026#43; new String(\u0026#34;World\u0026#34;).intern(); System.out.println(\u0026#34;利用==比较:\u0026#34;); System.out.println(s1 == s3); System.out.println(s1 == s4); System.out.println(s1 == s5); System.out.println(s1 == s6); System.out.println(\u0026#34;\\n利用equals()比较:\u0026#34;); System.out.println(s1.equals(s3)); System.out.println(s1.equals(s4)); System.out.println(s1.equals(s5)); System.out.println(s1.equals(s6)); } } 程序运行的结果如下:\n此时利用==比较的结果只有1个为true，为了探究原因需要继续分析class文件内容，用javap命令输出的class文件内容如下(省略掉了System.out.println()相关的)\nCompiled from \u0026#34;StringTest.java\u0026#34; public class StringTest { public StringTest(); Code: 0: aload_0 1: invokespecial #8 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 4: return public static void main(java.lang.String[]); Code: 0: ldc #16 // String Hello World 2: astore_1 3: ldc #18 // String Hello 5: astore_2 6: new #20 // class java/lang/StringBuilder 9: dup 10: aload_2 11: invokestatic #22 // Method java/lang/String.valueOf:(Ljava/lang/Object;)Ljava/lang/String; 14: invokespecial #28 // Method java/lang/StringBuilder.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 17: ldc #31 // String World 19: invokevirtual #33 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 22: invokevirtual #37 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 25: astore_3 26: ldc #16 // String Hello World 28: astore 4 30: new #20 // class java/lang/StringBuilder 33: dup 34: ldc #18 // String Hello 36: invokespecial #28 // Method java/lang/StringBuilder.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 39: new #23 // class java/lang/String 42: dup 43: ldc #31 // String World 45: invokespecial #41 // Method java/lang/String.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 48: invokevirtual #33 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 51: invokevirtual #37 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 54: astore 5 56: new #20 // class java/lang/StringBuilder 59: dup 60: ldc #18 // String Hello 62: invokespecial #28 // Method java/lang/StringBuilder.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 65: new #23 // class java/lang/String 68: dup 69: ldc #31 // String World 71: invokespecial #41 // Method java/lang/String.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 74: invokevirtual #42 // Method java/lang/String.intern:()Ljava/lang/String; 77: invokevirtual #33 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 80: invokevirtual #37 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 83: astore 6 //.... 215: return } 基于class文件的内容对s3、s4、s5、s6这4个字符串进行分析，可发现s4是编译器自动优化后从字符常量池中获取的之外，其余的3个字符串都是利用StringBuilder中的toString()方法生成的，toString()的源码如下，可以看出返回的是一个String对象。这正好解释了除了s1==s4输出值为true之外其余的输出值都为false的原因。\n@Override public String toString() { return new String(value, 0, count); } String是不可变的原因分析 在学习Java时我们一直被强调String是不可变的，而实际使用中我们又可以利用类似如下的代码对String进行拼接操作，看起来很矛盾。\npublic class StringTest { public static void main(String[] args) { String s1 = \u0026#34;Hello\u0026#34;; s1 \u0026#43;=\u0026#34; Java\u0026#34;; s1 \u0026#43;=\u0026#34; Golang\u0026#34;; } } 同样可以通过阅读class文件来分析该问题，对应的class文件如下:\nCompiled from \u0026#34;StringTest.java\u0026#34; public class StringTest { public StringTest(); Code: 0: aload_0 1: invokespecial #8 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 4: return public static void main(java.lang.String[]); Code: 0: ldc #16 // String Hello 2: astore_1 3: new #18 // class java/lang/StringBuilder 6: dup 7: aload_1 8: invokestatic #20 // Method java/lang/String.valueOf:(Ljava/lang/Object;)Ljava/lang/String; 11: invokespecial #26 // Method java/lang/StringBuilder.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 14: ldc #29 // String Java 16: invokevirtual #31 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 19: invokevirtual #35 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 22: astore_1 23: new #18 // class java/lang/StringBuilder 26: dup 27: aload_1 28: invokestatic #20 // Method java/lang/String.valueOf:(Ljava/lang/Object;)Ljava/lang/String; 31: invokespecial #26 // Method java/lang/StringBuilder.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 34: ldc #39 // String Golang 36: invokevirtual #31 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 39: invokevirtual #35 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 42: astore_1 43: return } 分析class文件可发现利用+=操作实质上是通过StringBuilder来拼接并重新构建字符串，每次+=操作都会生成新的字符串，原始字符串的指向地址被丢失，String是不可变实际上指的是原有的字符串无法改变，前述的问题得以解决。\n同时通过分析上述class文件还能得出以下结论:\n对于类似String str=\u0026quot;Hello\u0026quot; + \u0026quot;World\u0026quot;的赋值，JVM会将其自动优化为一个字符串常量，除此之外的其它基于String的拼接都会生成新的String对象； 在字符串拼接时，若采用基于String的拼接操作，会频繁的创建StringBuilder对象，影响程序性能，应该采用StringBuilder替代以减少StringBuilder创建的次数; 需要确保线程安全时，可以使用StringBuffer替代StringBuilder Java Web程序中的字符串赋值 利用下述代码在Web页面输入用户名和密码，然后利用==在Servlet代码中和特定的字符串进行比较。\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Type\u0026#34; content=\u0026#34;text/html; charset=UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;测试数据传递\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt; \u0026lt;form action=\u0026#34;addUser\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;table\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;用户名:\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;username\u0026#34;/\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;密码:\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;password\u0026#34;/\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026amp;nbsp;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;提交\u0026lt;/button\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; TestServlet.java public class TestServlet extends HttpServlet { private static final long serialVersionUID = 6174437812832777462L; @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { doPost(request, response); } @Override protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { String username = request.getParameter(\u0026#34;username\u0026#34;); System.out.println(username == \u0026#34;Rosen\u0026#34;); System.out.println(\u0026#34;Rosen\u0026#34;.equals(username)); request.getRequestDispatcher(\u0026#34;index.html\u0026#34;).forward(request, response); } } 在Tomcat7中的运行结果如下，可以看出其运行结果符合前面基于class文件的理论分析。 通过前面的分析可知通过Web服务器传递给Servlet的字符串参数肯定是一个String对象而非一个字符串常量。接下来通过在GitHub中分析Tomcat源码来了解其如何赋值。\n在Tomcat中，生成参数的相关代码位于Parameters.java类中private void processParameters(byte bytes[], int start, int len, Charset charset)方法中，该方法给参数赋值的核心代码如下： if (valueStart \u0026gt;= 0) { if (decodeValue) { urlDecode(tmpValue); } tmpValue.setCharset(charset); value = tmpValue.toString(); } else { value = \u0026#34;\u0026#34;; } 继续查看可知tmpValue的类型为ByteChunk,其toString()核心代码如下： public String toString() { if (isNull()) { return null; } else if (end - start == 0) { return \u0026#34;\u0026#34;; } return StringCache.toString(this); } 继续查看StringCache的toString()方法如下 public static String toString(ByteChunk bc) { // If the cache is null, then either caching is disabled, or we\u0026#39;re // still training if (bcCache == null) { String value = bc.toStringInternal(); if (byteEnabled \u0026amp;\u0026amp; (value.length() \u0026lt; maxStringSize)) { // If training, everything is synced synchronized (bcStats) { // If the cache has been generated on a previous invocation // while waiting for the lock, just return the toString // value we just calculated if (bcCache != null) { return value; } // Two cases: either we just exceeded the train count, in // which case the cache must be created, or we just update // the count for the string if (bcCount \u0026gt; trainThreshold) { long t1 = System.currentTimeMillis(); // Sort the entries according to occurrence TreeMap\u0026lt;Integer,ArrayList\u0026lt;ByteEntry\u0026gt;\u0026gt; tempMap = new TreeMap\u0026lt;\u0026gt;(); for (Entry\u0026lt;ByteEntry,int[]\u0026gt; item : bcStats.entrySet()) { ByteEntry entry = item.getKey(); int[] countA = item.getValue(); Integer count = Integer.valueOf(countA[0]); // Add to the list for that count ArrayList\u0026lt;ByteEntry\u0026gt; list = tempMap.get(count); if (list == null) { // Create list list = new ArrayList\u0026lt;\u0026gt;(); tempMap.put(count, list); } list.add(entry); } // Allocate array of the right size int size = bcStats.size(); if (size \u0026gt; cacheSize) { size = cacheSize; } ByteEntry[] tempbcCache = new ByteEntry[size]; // Fill it up using an alphabetical order // and a dumb insert sort ByteChunk tempChunk = new ByteChunk(); int n = 0; while (n \u0026lt; size) { Object key = tempMap.lastKey(); ArrayList\u0026lt;ByteEntry\u0026gt; list = tempMap.get(key); for (int i = 0; i \u0026lt; list.size() \u0026amp;\u0026amp; n \u0026lt; size; i\u0026#43;\u0026#43;) { ByteEntry entry = list.get(i); tempChunk.setBytes(entry.name, 0, entry.name.length); int insertPos = findClosest(tempChunk, tempbcCache, n); if (insertPos == n) { tempbcCache[n \u0026#43; 1] = entry; } else { System.arraycopy(tempbcCache, insertPos \u0026#43; 1, tempbcCache, insertPos \u0026#43; 2, n - insertPos - 1); tempbcCache[insertPos \u0026#43; 1] = entry; } n\u0026#43;\u0026#43;; } tempMap.remove(key); } bcCount = 0; bcStats.clear(); bcCache = tempbcCache; if (log.isDebugEnabled()) { long t2 = System.currentTimeMillis(); log.debug(\u0026#34;ByteCache generation time: \u0026#34; \u0026#43; (t2 - t1) \u0026#43; \u0026#34;ms\u0026#34;); } } else { bcCount\u0026#43;\u0026#43;; // Allocate new ByteEntry for the lookup ByteEntry entry = new ByteEntry(); entry.value = value; int[] count = bcStats.get(entry); if (count == null) { int end = bc.getEnd(); int start = bc.getStart(); // Create byte array and copy bytes entry.name = new byte[bc.getLength()]; System.arraycopy(bc.getBuffer(), start, entry.name, 0, end - start); // Set encoding entry.charset = bc.getCharset(); // Initialize occurrence count to one count = new int[1]; count[0] = 1; // Set in the stats hash map bcStats.put(entry, count); } else { count[0] = count[0] \u0026#43; 1; } } } } return value; } else { accessCount\u0026#43;\u0026#43;; // Find the corresponding String String result = find(bc); if (result == null) { return bc.toStringInternal(); } // Note: We don\u0026#39;t care about safety for the stats hitCount\u0026#43;\u0026#43;; return result; } } 该方法篇幅很长，但核心代码只有一行String value = bc.toStringInternal();而bc的类型为ByteChunk。\n继续在ByteChunk搜索toStringInternal()方法，其代码如下 public String toStringInternal() { if (charset == null) { charset = DEFAULT_CHARSET; } // new String(byte[], int, int, Charset) takes a defensive copy of the // entire byte array. This is expensive if only a small subset of the // bytes will be used. The code below is from Apache Harmony. CharBuffer cb = charset.decode(ByteBuffer.wrap(buff, start, end - start)); return new String(cb.array(), cb.arrayOffset(), cb.length()); } 查看该方法可知其使用new String(cb.array(), cb.arrayOffset(), cb.length())的方式来构造String对象，故利用==比较字符串时其返回值为false。\n分析了最基本的Servelt后，由于SpringMVC是基于Servlet实现的，故使用如下代码进行参数比较其值也为false。\n@RequestMapping(\u0026#34;addUser\u0026#34;) public String addUser(UserModel user) { System.out.println(user.getUsername() == \u0026#34;Rosen\u0026#34;); return StringConstant.SUCCESS; } 参考文章:\n轻松看懂Java字节码 The Java® Virtual Machine Specification ","date":"2018-12-08T23:02:10+08:00","permalink":"https://lucumt.info/post/java-core/java-string-equal-compare/","tags":["Java"],"title":"Java中利用==和equals()进行字符串比较的说明"},{"categories":["Java编程","Java多线程"],"contents":"最近复习Java多线程相关知识时，发现线程中断的interrupt()、interrupted()、isInterrupted()这3个方法容易让人产生混淆，结合官网的API以及实际代码验证，先简单记录下。\n相关使用说明 下表是根据JDK官网的API总结出的这3个方法的使用说明,从表中可以看出中断线程实际使用的是interrupt()，而interrupted()和isInterrupted()则用来检测线程是否中断，区别为前者会清除中断状态标记。\n方法 是否静态 返回值 作用 interrupt() 否 无 中断调用该方法的当前线程 interrupted() 是 有 检测当前线程是否被中断，如已被中断过则清除中断状态 isInterrupted() 否 有 检测调用该方法的线程是否被中断，不清除中断标记 下面这个程序展示通过2个线程展示了这3个方法的用法，首先启动threadA，间隔30毫秒后启动threadB并在threadB中调用interrupt()中断threadA,然后观察threadA的中断状态。\npublic class InterruptedTest { @Test public void testThread() { Thread threadA = new Thread(() -\u0026gt; { while (!Thread.currentThread().isInterrupted()) { System.out.println(Thread.currentThread().getName() \u0026#43; \u0026#34;\\t\u0026#34; \u0026#43; LocalTime.now()); } System.out.println(Thread.currentThread().isInterrupted()); System.out.println(Thread.interrupted()); System.out.println(Thread.currentThread().isInterrupted()); }, \u0026#34;Thread_A\u0026#34;); Thread threadB = new Thread(() -\u0026gt; { System.out.println(Thread.currentThread().getName() \u0026#43; \u0026#34; interrupt ThreadA\u0026#34;); threadA.interrupt(); }, \u0026#34;Thread_B\u0026#34;); threadA.start(); try { Thread.sleep(30); } catch (InterruptedException e) { e.printStackTrace(); } threadB.start(); } } 根据前述的方法说明，程序的输出结果应改为true、true、false，实际运行结果类似如下,从图中可知其输出结果与理论分析相符。\n将上述代码修改如下,首先给threadA加上同步锁并调用wait()或sleep()方法，然后检测其中断状态。\npublic class InterruptedTest { @Test public void testThread() { Object lock = new Object(); Thread threadA = new Thread(() -\u0026gt; { synchronized(lock) { try { Thread.sleep(1000); //lock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().isInterrupted()); System.out.println(Thread.interrupted()); System.out.println(Thread.currentThread().isInterrupted()); } }, \u0026#34;Thread_A\u0026#34;); Thread threadB = new Thread(() -\u0026gt; { System.out.println(Thread.currentThread().getName() \u0026#43; \u0026#34; will interrupt ThreadA\u0026#34;); threadA.interrupt(); }, \u0026#34;Thread_B\u0026#34;); threadA.start(); try { Thread.sleep(30); } catch (InterruptedException e) { e.printStackTrace(); } threadB.start(); } } 分别调用sleep()和wait()时的运行结果如下\n分析运行结果可知：无论调用哪种方法，在中断线程时都会抛出InterruptedException异常，其运行结果都为false则意味着中断状态也不会设置。\n以JDK1.8为例，关于调用interrupt()方法时中断状态的设置，可以从官网上看到如下描述：\nIf this thread is blocked in an invocation of the wait(), wait(long), or wait(long, int) methods of the Object class, or of the join(), join(long), join(long, int), sleep(long), or sleep(long, int), methods of this class, then its interrupt status will be cleared and it will receive an InterruptedException. If this thread is blocked in an I/O operation upon an InterruptibleChannel then the channel will be closed, the thread\u0026rsquo;s interrupt status will be set, and the thread will receive a ClosedByInterruptException.\nIf this thread is blocked in a Selector then the thread\u0026rsquo;s interrupt status will be set and it will return immediately from the selection operation, possibly with a non-zero value, just as if the selector\u0026rsquo;s wakeup method were invoked.\nIf none of the previous conditions hold then this thread\u0026rsquo;s interrupt status will be set.\n综上，interrupt()、intterupted()、isInterrupted()这3个方法的区别与作用总结如下：\ninterrupt(),中断调用该方法的当前线程，并设置其中断标记，具体而言分下述4种情况 若当前线程被wait()、join()、sleep()这些方法(含超时)阻塞时，调用该方法中断线程时会清除中断标记，同时抛出InterruptedException异常； 若当前线程被一个可中断的I/O操作阻塞，则会设置中断状态，同时关闭I/O通道并抛出ClosedByInterruptException异常； 若当前线程被一个异步I/O操作(Selector)阻塞，则会设置中断状态并立即返回，看起来异步I/O操作的唤醒方法被调用； 除以上3种情况外，其余情形下中断状态会被正常设置； interrupted(),检测当前线程是否被中断，如已被中断过则清除中断状态 isInterrupted(),检测调用该方法的线程是否被中断，不清除中断标记 线程中断的使用 在Oracle官网有关于interrupt的如下如说明\nAn interrupt is an indication to a thread that it should stop what it is doing and do something else. It\u0026rsquo;s up to the programmer to decide exactly how a thread responds to an interrupt, but it is very common for the thread to terminate.\n从上可知，当一个线程被中断时，JVM没有强制让当前线程立即中断,JVM只是要求我们在发生线程中断时应该停止当前正在执行的任务转而去执行其它任务。一个常用的场景是在循环体中利用isInterrupt()进行判断是否被中断，在没有被中断时在循环体中执行业务逻辑，当被中断时则跳出循环体然后执行其它业务逻辑，如下所示：\nwhile (!Thread.currentThread().isInterrupted()) { //do something when not been interrupted } //do other things when been interrupted 与LockSupport的比较 利用LockSupport方法重新修改上述代码，修改后的代码如下:\npublic void testThread() { Thread threadA = new Thread(() -\u0026gt; { LockSupport.park(); System.out.println(Thread.currentThread().isInterrupted()); System.out.println(Thread.interrupted()); System.out.println(Thread.currentThread().isInterrupted()); }, \u0026#34;Thread_A\u0026#34;); Thread threadB = new Thread(() -\u0026gt; { System.out.println(Thread.currentThread().getName() \u0026#43; \u0026#34; will unpark ThreadA\u0026#34;); LockSupport.unpark(threadA); }, \u0026#34;Thread_B\u0026#34;); threadA.start(); try { Thread.sleep(30); } catch (InterruptedException e) { e.printStackTrace(); } threadB.start(); } 程序运行结果如下：\n从上图中可以看出LockSupport中的方法来阻塞和唤醒线程时(更准确的说法是通过许可来觉得线程是否可运行)，既不修改线程的中断状态也不抛出InterruptedException异常。\n参考文章：\nhttps://stackoverflow.com/questions/3590000/what-does-java-lang-thread-interrupt-do https://docs.oracle.com/javase/tutorial/essential/concurrency/interrupt.html https://www.ibm.com/developerworks/library/j-jtp05236/ 关于如何处理InterruptedException异常，请参见本人翻译一篇文章 [译]如何处理InterruptedException\n","date":"2018-12-03T22:57:56+08:00","permalink":"https://lucumt.info/post/java-concurrency/difference-between-interrupt-interrupted-isinterrupted/","tags":["Java","Java Concurrency"],"title":"Java中interrupt()、interrupted()、isInterrupted()的区别"},{"categories":["Java编程"],"contents":"由于工作原因需要在阿里云中部署一个Web系统，该系统会调用邮箱服务器定时给相关人员发送通知邮件,在测试邮箱配置时，发现始终无法正确发送邮件，而之前在研发环境和测试环境都能正常工作。网上查找之后，发现是阿里云出于安全原因默认禁止了25端口的出方向访问，需要进行25端口解封申请，按照说明提交相应的申请后没想到不到一个小时就提醒申请未通过，同时提示使用465端口来发送加密邮件。基于此，本文简要说明如何使用126邮箱通过465端口在阿里云中发送邮件。\n邮箱配置 首先找到一个可用的126邮箱，进入邮箱设置选项，开启SMTP服务，如下图所示\n对于某些类型的邮箱完成上一步的操作后即可通过邮箱和密码发送邮件，但对于126邮箱还需要在“客户端授权密码”中设置相应的授权码。授权码的作用和邮箱密码类似，但授权码主要是供第三方客户端调用时使用，这样可达到即可让第三方软件调用，也不泄露自己邮箱密码的目的。\n代码编写 下述代码为使用25端口发送邮件的Java代码，其实现基于Java Mail 1.4.1。\npublic void testSendMail() { final String sendUserName = \u0026#34;***@126.com\u0026#34;; final String sendUserPassword = \u0026#34;***\u0026#34;; // 收件箱 String receiveUser = \u0026#34;recevie@mail.com\u0026#34;; Properties props = new Properties(); props.put(\u0026#34;mail.smtp.auth\u0026#34;, \u0026#34;true\u0026#34;); props.put(\u0026#34;mail.smtp.host\u0026#34;, \u0026#34;smtp.126.com\u0026#34;); props.put(\u0026#34;mail.smtp.port\u0026#34;, \u0026#34;25\u0026#34;); Session session = Session.getDefaultInstance(props,new Authenticator() { @Override protected PasswordAuthentication getPasswordAuthentication() { return new PasswordAuthentication(sendUserName, sendUserPassword); } }); try { Message message = new MimeMessage(session); message.setFrom(new InternetAddress(sendUserName)); message.setRecipients(Message.RecipientType.TO, InternetAddress.parse(receiveUser)); message.setSubject(\u0026#34;Test Mail Send\u0026#34;); message.setText(\u0026#34;Hello World!\u0026#34;); Transport.send(message); System.out.println(\u0026#34;Send mail success\u0026#34;); } catch (MessagingException e) { e.printStackTrace(); } } 为了使用465端口发送邮件，除了在代码中修改端口之外，还需要将Mail Socket指定为SSL实现，实际使用中我发现通过props.put(\u0026quot;mail.smtp.socketFactory.class\u0026quot;, \u0026quot;javax.net.ssl.SSLSocketFactory\u0026quot;);即可实现，完整的代码如下\npublic void testSendMail() { final String sendUserName = \u0026#34;***@126.com\u0026#34;; final String sendUserPassword = \u0026#34;***\u0026#34;; // 收件箱 String receiveUser = \u0026#34;recevie@mail.com\u0026#34;; Properties props = new Properties(); props.put(\u0026#34;mail.smtp.auth\u0026#34;, \u0026#34;true\u0026#34;); props.put(\u0026#34;mail.smtp.host\u0026#34;, \u0026#34;smtp.126.com\u0026#34;); props.put(\u0026#34;mail.smtp.port\u0026#34;, \u0026#34;465\u0026#34;); //指定使用基于SSL的套接字 props.put(\u0026#34;mail.smtp.socketFactory.class\u0026#34;, \u0026#34;javax.net.ssl.SSLSocketFactory\u0026#34;); Session session = Session.getDefaultInstance(props,new Authenticator() { @Override protected PasswordAuthentication getPasswordAuthentication() { return new PasswordAuthentication(sendUserName, sendUserPassword); } }); try { Message message = new MimeMessage(session); message.setFrom(new InternetAddress(sendUserName)); message.setRecipients(Message.RecipientType.TO, InternetAddress.parse(receiveUser)); message.setSubject(\u0026#34;Test Mail Send\u0026#34;); message.setText(\u0026#34;Hello World!\u0026#34;); Transport.send(message); System.out.println(\u0026#34;Send mail success\u0026#34;); } catch (MessagingException e) { e.printStackTrace(); } } 其他说明 Java Mail中关于邮件设置的选项请参见com.sun.mail.smtp,实际使用时我发现只需要添加props.put(\u0026quot;mail.smtp.socketFactory.class\u0026quot;, \u0026quot;javax.net.ssl.SSLSocketFactory\u0026quot;);即可，额外的添加其它一些配置反而可能会导致不能正常使用。\n如当参照Stackoverflow中的Using JavaMail with TLS这个问题的答案加上如下代码：\nprops.put(\u0026#34;mail.smtp.starttls.enable\u0026#34;,\u0026#34;true\u0026#34;); props.put(\u0026#34;mail.smtp.auth\u0026#34;, \u0026#34;true\u0026#34;); props.put(\u0026#34;mail.smtp.socketFactory.fallback\u0026#34;, \u0026#34;false\u0026#34;); 程序运行的结果如下 此时只需将props.put(\u0026quot;mail.smtp.starttls.enable\u0026quot;,\u0026quot;true\u0026quot;);这行代码去掉或将其值设置为false即可正常发送邮件。\n参考说明:\nJavaMail 使用 163 发送邮件 Using JavaMail with TLS ","date":"2018-12-03T21:54:05+08:00","permalink":"https://lucumt.info/post/java-core/send-ssl-mail-with-126-in-aliyun/","tags":["Java"],"title":"利用126邮箱在阿里云中发送SSL/TSL加密邮件"},{"categories":["java编程"],"contents":"在开发大规模的Java项目时，通常会涉及到各种设计模式，本文简要说明当使用模板方法时，如何利用接口default方法或抽象类对具体的子类进行精简，便于开发与维护。\n背景说明 假设部门要进行一次团建，主要包含如下3个活动：\n轰趴(play) 聚餐(eat) 唱歌(sing) 这3个按照时间顺序先后进行，大家可以选择参加启动的一个或多个，则可以创建一个类似如下的类来表示上述流程\npublic abstract class TeamBuilding { public void participate() { play(); eat(); sing(); } public abstract void play(); public abstract void eat(); public abstract void sing(); } 上述代码中participate()方法表示参加此次活动，里面包含了3个抽象方法，表示 邀请了所有人，被邀请人员可以选择性参加其中一个或多个活动。\n按照正常思维实际使用时需要继承该类并分别实现该类中的方法，即使不参加其中某一项活动，对应的实现类参考如下\npublic class PersonA extends TeamBuilding { @Override public void play() { System.out.println(\u0026#34;play card\u0026#34;); } @Override public void eat() { System.out.println(\u0026#34;eat cake\u0026#34;); } @Override public void sing() { // 不参加该项活动，实现为空方法 } } public class PersonB extends TeamBuilding { @Override public void play() { // 不参加该项活动，实现为空方法 } @Override public void eat() { System.out.println(\u0026#34;eat cake\u0026#34;); } @Override public void sing() { System.out.println(\u0026#34;sing a song\u0026#34;); } } public class PersonC extends TeamBuilding { @Override public void play() { System.out.println(\u0026#34;play basketball\u0026#34;); } @Override public void eat() { // 不参加该项活动，实现为空方法 } @Override public void sing() { System.out.println(\u0026#34;sing a song\u0026#34;); } } 可以看出相关的实现类中，有很多空的实现方法，形成了冗余，不便于维护。\n同时在模板方法中每增加一个步骤，所有的子类中都需要实现方法，改动量大，也不便于维护。\npublic abstract class TeamBuilding { public void participate() { play(); drink(); eat(); sing(); } public abstract void play(); // 新增一个方法后，对应的子类都需要实现该方法 public abstract void drink(); public abstract void eat(); public abstract void sing(); } 期望实现的效果是对应的子类中是实现自己关注的流程，且添加新的步骤时，子类不用全部改动，类似如下\npublic class PersonA extends TeamBuilding { @Override public void play() { System.out.println(\u0026#34;play card\u0026#34;); } @Override public void eat() { System.out.println(\u0026#34;eat cake\u0026#34;); } } public class PersonB extends TeamBuilding { @Override public void eat() { System.out.println(\u0026#34;eat cake\u0026#34;); } @Override public void sing() { System.out.println(\u0026#34;sing a song\u0026#34;); } } public class PersonC extends TeamBuilding { @Override public void play() { System.out.println(\u0026#34;play basketball\u0026#34;); } @Override public void sing() { System.out.println(\u0026#34;sing a song\u0026#34;); } } 接下来以抽象类和接口默认方法分别说明如何设计父类以便达成上述目的。\n抽象类实现 仿照Java多线程编程中的AbstractQueuedSynchronizer类里面的获取锁与释放锁的实现，在父类中给所有的方法都取消abstract修饰符，默认用UnsupportedOperationException实现全部方法，子类按需override即可。\nAbstractQueuedSynchronizer相关实现 ：\nprotected boolean tryAcquire(int arg) { throw new UnsupportedOperationException(); } protected boolean tryRelease(int arg) { throw new UnsupportedOperationException(); } 相关代码如下：\npublic abstract class TeamBuilding { public void participate() { play(); eat(); sing(); } protected void play() { throw new UnsupportedOperationException(); } protected void eat() { throw new UnsupportedOperationException(); } protected void sing() { throw new UnsupportedOperationException(); } } 接口实现 在JDK8和以上版本中，也可将抽象类修改为接口，利用接口默认方法实现，相关代码如下：\npublic interface TeamBuilding { default void participate() { play(); eat(); sing(); } default void play() { throw new UnsupportedOperationException(); } default void eat() { throw new UnsupportedOperationException(); } default void sing() { throw new UnsupportedOperationException(); } } 对应的子类实现如下：\npublic class PersonA implements TeamBuilding { @Override public void play() { System.out.println(\u0026#34;play card\u0026#34;); } @Override public void eat() { System.out.println(\u0026#34;eat cake\u0026#34;); } } public class PersonB implements TeamBuilding { @Override public void eat() { System.out.println(\u0026#34;eat cake\u0026#34;); } @Override public void sing() { System.out.println(\u0026#34;sing a song\u0026#34;); } } public class PersonC implements TeamBuilding { @Override public void play() { System.out.println(\u0026#34;play basketball\u0026#34;); } @Override public void sing() { System.out.println(\u0026#34;sing a song\u0026#34;); } } ","date":"2018-06-02T13:27:06+08:00","permalink":"https://lucumt.info/post/java-core/default-method-in-abstract-class-and-interface/","tags":["java"],"title":"在模板类中利用抽象类或接口default方法实现默认方法以简化开发与维护"},{"categories":["Web编程","Java编程"],"contents":"Quartz是软件开发中常用的任务调度框架，实际中通常结合 Spring 一起使用，并在Spring的配置文件中利用0 0 12 ? \\* WED这种方式以硬编码的方式配置定时任务的执行时间。有时候需要动态的设置定时任务的执行时间，如让用户自己选择何时备份数据，此时就需要采用动态设置其执行时间。\n为实现动态设置定时任务执行时间的功能，首先需要实现以硬编码的方式设置定时任务执行时间，然后在其基础上修改为可动态设置，本文基于这两分部分逐步介绍如何实现。\n硬编码设置定时时间 本文采用 Quartz + SpringMVC 的实现框架，同时基于 Maven运行，相关配置过程如下：\n1.首先在pom.xml文件中引入相应的依赖JAR包。\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.quartz-scheduler\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;quartz\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.25\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.13.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context-support\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.13.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.13.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-webmvc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.13.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-tx\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.13.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.9\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javaee\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;javaee-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 2.创建一个定时任务测试类TestJob\npublic class TestJob { private DateFormat df = new SimpleDateFormat(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); public void schedulerJob(){ System.out.println(\u0026#34;=========定时输出:\\t\u0026#34;\u0026#43;df.format(new Date())); } } 3.结合Spring进行定时任务的配置\n\u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd \u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;testJob\u0026#34; class=\u0026#34;com.lucumt.quartz.TestJob\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;testJobDetail\u0026#34; class=\u0026#34;org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean\u0026#34;\u0026gt; \u0026lt;!-- 指定任务类 --\u0026gt; \u0026lt;property name=\u0026#34;targetObject\u0026#34; ref=\u0026#34;testJob\u0026#34; /\u0026gt; \u0026lt;!-- 指定任务执行的方法 --\u0026gt; \u0026lt;property name=\u0026#34;targetMethod\u0026#34; value=\u0026#34;schedulerJob\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;testJobTrigger\u0026#34; class=\u0026#34;org.springframework.scheduling.quartz.CronTriggerFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;jobDetail\u0026#34; ref=\u0026#34;testJobDetail\u0026#34; /\u0026gt; \u0026lt;!-- 每10秒运行一次 --\u0026gt; \u0026lt;property name=\u0026#34;cronExpression\u0026#34; value=\u0026#34;0/10 * * * * ?\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean class=\u0026#34;org.springframework.scheduling.quartz.SchedulerFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;triggers\u0026#34;\u0026gt; \u0026lt;list\u0026gt; \u0026lt;ref bean=\u0026#34;testJobTrigger\u0026#34; /\u0026gt; \u0026lt;/list\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 4.web.xml中配置如下：\n\u0026lt;web-app version=\u0026#34;2.5\u0026#34; xmlns=\u0026#34;http://java.sun.com/xml/ns/javaee\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\u0026#34;\u0026gt; \u0026lt;display-name\u0026gt;Dynamic Quartz Scheduler\u0026lt;/display-name\u0026gt; \u0026lt;listener\u0026gt; \u0026lt;listener-class\u0026gt;org.springframework.web.context.ContextLoaderListener\u0026lt;/listener-class\u0026gt; \u0026lt;/listener\u0026gt; \u0026lt;context-param\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;classpath*:spring-context-*.xml\u0026lt;/param-value\u0026gt; \u0026lt;/context-param\u0026gt; \u0026lt;/web-app\u0026gt; 配置完成后，在eclipse中运行tomcat7:run运行结果如下，可以看出定时任务每隔10秒执行一次。\n上述的硬编码设置将 Quartz 的执行时间通过硬编码方式写入XML配置文件中，这是最常见的用法，但通过XML配置文件写入定时时间时无法动态的更改其执行时间。\n动态设置定时时间 为了便于演示，本文采用Web程序的方式展示相关操作过程。\n1.增加一个testScheduler.jsp展示操作界面:\n\u0026lt;%@ page language=\u0026#34;java\u0026#34; import=\u0026#34;java.util.*\u0026#34; pageEncoding=\u0026#34;UTF-8\u0026#34;%\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;content-type\u0026#34; content=\u0026#34;text/html; charset=UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;动态设置quartz\u0026lt;/title\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;js/jquery-2.1.1.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; type=\u0026#34;text/css\u0026#34; href=\u0026#34;js/bootstrap/css/bootstrap.min.css\u0026#34;/\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;js/bootstrap/js/bootstrap.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;style type=\u0026#34;text/css\u0026#34;\u0026gt; .container{ margin-top: 30px; margin-left: auto; margin-right: auto; padding: 10px; background-color: #d0d0d0; border-radius: 5px; min-height:400px; } .hidden{ display: none; } \u0026lt;/style\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; function changeScheduler(){ var hiddenId = $(\u0026#34;.hidden\u0026#34;).attr(\u0026#34;id\u0026#34;); var expression = null; if(hiddenId==\u0026#34;scheduler_one\u0026#34;){ $(\u0026#34;#scheduler_one\u0026#34;).removeClass(\u0026#34;hidden\u0026#34;); $(\u0026#34;#scheduler_two\u0026#34;).addClass(\u0026#34;hidden\u0026#34;); expression=\u0026#34;0/10 * * * * ?\u0026#34;; }else{ $(\u0026#34;#scheduler_one\u0026#34;).addClass(\u0026#34;hidden\u0026#34;); $(\u0026#34;#scheduler_two\u0026#34;).removeClass(\u0026#34;hidden\u0026#34;); expression=\u0026#34;0/30 * * * * ?\u0026#34;; } sendChangeRequest(expression); } function sendChangeRequest(expression){ $.ajax({ url:\u0026#34;changeScheduler\u0026#34;, type:\u0026#34;post\u0026#34;, data:{ expression:expression }, success:function(){ } }); } \u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container-fluid container\u0026#34;\u0026gt; \u0026lt;div id=\u0026#34;scheduler_one\u0026#34;\u0026gt; 当前定时任务的表达式为\u0026lt;b\u0026gt;0/10 * * * * ?\u0026lt;/b\u0026gt;,每隔10秒输出一次 \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;scheduler_two\u0026#34; class=\u0026#34;hidden\u0026#34;\u0026gt; 当前定时任务的表达式为\u0026lt;b\u0026gt;0/30 * * * * ?\u0026lt;/b\u0026gt;,每隔30秒输出一次 \u0026lt;/div\u0026gt; \u0026lt;button type=\u0026#34;button\u0026#34; class=\u0026#34;btn btn-primary btn-sm\u0026#34; onclick=\u0026#34;changeScheduler()\u0026#34;\u0026gt;切换定时时间\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 2.增加一个Controller类QuartzController用于响应前端重新设置定时任务时间的请求\n@Controller(\u0026#34;/\u0026#34;) public class QuartzController { @Autowired private JobScheduler jobScheduler; @RequestMapping(\u0026#34;testScheduler\u0026#34;) public String testScheduler(){ return \u0026#34;testScheduler\u0026#34;; } @RequestMapping(\u0026#34;changeScheduler\u0026#34;) @ResponseBody public String changeScheduler(String expression){ System.out.println(\u0026#34;执行时间被修改为:\\t\u0026#34;\u0026#43;expression); jobScheduler.resetJob(expression); return \u0026#34;SUCCESS\u0026#34;; } } 3.在时任务测试类TestJob中添加一个resetJob方法，用于重新设置定时任务执行时间\npublic class JobScheduler implements ServletContextAware { private DateFormat df = new SimpleDateFormat(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); private ServletContext context; @Override public void setServletContext(ServletContext context) { this.context=context;\t} public void schedulerJob() { System.out.println(\u0026#34;=========定时输出:\\t\u0026#34; \u0026#43; df.format(new Date())); } //通过此方法重新设置定时任务调度时间 public void resetJob(String expression){ ApplicationContext applicationContext = WebApplicationContextUtils.getRequiredWebApplicationContext(context); Scheduler scheduler = (Scheduler) applicationContext.getBean(\u0026#34;testScheduler\u0026#34;); CronTriggerImpl trigger = null; try { TriggerKey triggerKeys = TriggerKey.triggerKey(\u0026#34;testJobTrigger\u0026#34;,Scheduler.DEFAULT_GROUP); trigger = new CronTriggerImpl(); trigger.setCronExpression(expression); trigger.setKey(triggerKeys);//要确保key相同 scheduler.rescheduleJob(triggerKeys,trigger); } catch (ParseException | SchedulerException e) { e.printStackTrace(); } } } 4.其他配置文件保持不变，修改后的运行界面如下\n5.多次点击该按钮，控制台输出如下，可以看出实现了动态设置定时任务的功能\n上述代码是基于Quartz2.3.0来实现的，相关源代码请参见 quartz_demo ，其核心在于 resetJob 方法通过调用 CronTriggerImpl 来重新设置定时任务执行时间，需要注意的是要确保定时任务修改前后的triggerKey一致，这样才能修改生效，否则应用程序会在执行原有的定时任务时同时以新的时间来执行新的定时任务，即同时执行两个定时任务，达不到预期效果。\nQuartz1.7.2中的定时任务设置 在旧版的Quartz(1.7.2)中rescheduleJob的方法参数发生了变化，相应的Spring版本也发生了变化，需要用 CronTriggerBean替换 CronTriggerImpl，对应的实现代码可修改为如下：\npublic void resetJob(String expression){ ApplicationContext applicationContext = WebApplicationContextUtils.getRequiredWebApplicationContext(context); Scheduler scheduler = (Scheduler) applicationContext.getBean(\u0026#34;testScheduler\u0026#34;); try { CronTriggerBean trigger = new CronTriggerBean(); trigger.setCronExpression(expression); trigger.setName(\u0026#34;testJobTrigger\u0026#34;); trigger.setGroup(Scheduler.DEFAULT_GROUP); trigger.setJobName(\u0026#34;testJobDetail\u0026#34;); scheduler.rescheduleJob(\u0026#34;testJobTrigger\u0026#34;, Scheduler.DEFAULT_GROUP, trigger); } catch (SchedulerException | ParseException e) { e.printStackTrace(); } } 其运行结果和前面的一致。\n通过Spring获取Trigger导致的重复执行问题 将上述代码中的CronTriggerBean初始化从new*关键字实现变为通过Schduler获取原有的任务后重新更新，修改后的代码如下：\npublic void resetJob(String expression){ ApplicationContext applicationContext = WebApplicationContextUtils.getRequiredWebApplicationContext(context); Scheduler scheduler = (Scheduler) applicationContext.getBean(\u0026#34;testScheduler\u0026#34;); try { CronTriggerBean trigger = (CronTriggerBean) scheduler.getTrigger(\u0026#34;testJobTrigger\u0026#34;, Scheduler.DEFAULT_GROUP);//通过scheduler获取 trigger.setCronExpression(expression); trigger.setName(\u0026#34;testJobTrigger\u0026#34;); scheduler.rescheduleJob(\u0026#34;testJobTrigger\u0026#34;, Scheduler.DEFAULT_GROUP, trigger); } catch (SchedulerException | ParseException e) { e.printStackTrace(); } } 实际运行时会发现每次动态切换 Quartz 的执行时间时都会导致该定时任务被执行两次或错误执行的现象，如下图所示：\n初步上述问题产生的原因为通过Scheduler获取的是已有的Trigger而导致重复执行（不论 Quartz 新旧版本均有此问题 )，如果采用new关键字重新创建一个Trigger则此问题会消失，至于为何采用旧的Trigger会导致定时任务错误执行，还有待进一步分析。\n","date":"2018-01-09T22:10:30+08:00","permalink":"https://lucumt.info/post/quartz/update-quartz-scheduler-dynamic/","tags":["Quartz","Spring","SpringMVC"],"title":"在Quartz中动态设置定时任务的执行时间并立即生效"},{"categories":["Java编程"],"contents":"这几天工作中遇到一个利用dom4j更新XML文件的任务，由于XML文件中部分属性包含有换行符，利用dom4j(1.6.1)默认的方法更新XML文件后换行符会丢失。 各种Google、StackOverflow折腾好久后终于解决该问题，简单记录下。\n对于修改XML文件，自己很自然的想到利用dom4j和 XPath来实现功能，使用的代码类似如下：\npublic static void updateXML() { SAXReader saxReader = new SAXReader(); File oldFile = new File(\u0026#34;D:\\\\test\\\\old_test.xml\u0026#34;); File newFile = new File(\u0026#34;D:\\\\test\\\\new_test.xml\u0026#34;); try { Document oldDoc = saxReader.read(oldFile); Element oldRoot = oldDoc.getRootElement(); Element oldEle = (Element) oldRoot.selectSingleNode(\u0026#34;//book[@id=\u0026#39;01001\u0026#39;]/name\u0026#34;); System.out.println(oldEle.attributeValue(\u0026#34;description\u0026#34;)); OutputFormat format = OutputFormat.createPrettyPrint(); format.setEncoding(\u0026#34;UTF-8\u0026#34;); format.setNewLineAfterDeclaration(false); //写入新文件 XMLWriter writer = new XMLWriter(new FileWriter(newFile), format); writer.write(oldDoc); writer.flush(); writer.close(); System.out.println(\u0026#34;\\n================分隔符==================\\n\u0026#34;); //从新文件中读取数据 Document newDoc = saxReader.read(newFile); Element newRoot = newDoc.getRootElement(); Element newEle = (Element) newRoot.selectSingleNode(\u0026#34;//book[@id=\u0026#39;01001\u0026#39;]/name\u0026#34;); System.out.println(newEle.attributeValue(\u0026#34;description\u0026#34;)); } catch (DocumentException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } } 对应的XML文件类似如下：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;books\u0026gt; \u0026lt;book id=\u0026#34;01001\u0026#34;\u0026gt; \u0026lt;name description=\u0026#34;New coverage includes:\u0026amp;#xD;\u0026amp;#xA;\u0026amp;#xD;\u0026amp;#xA;Functional interfaces, lambda expressions, method references, and streams\u0026amp;#xD;\u0026amp;#xA;Default and static methods in interfaces\u0026amp;#xD;\u0026amp;#xA;Type inference, including the diamond operator for generic types\u0026amp;#xD;\u0026amp;#xA;The @SafeVarargs annotation\u0026amp;#xD;\u0026amp;#xA;The try-with-resources statement\u0026#34;\u0026gt;Effective Java\u0026lt;/name\u0026gt; \u0026lt;price\u0026gt;50.6\u0026lt;/price\u0026gt; \u0026lt;author\u0026gt;Joshua Bloch\u0026lt;/author\u0026gt; \u0026lt;publishDate\u0026gt;2017-12-08\u0026lt;/publishDate\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;/books\u0026gt; 上述代码的逻辑很简单：首先从XML打开一个XML文件，然后输出某个书本的描述信息，将其写入新的XML文件，然后在新XML文件中读取相同的信息。理论上前后两次输出的结果应该一样，但实际运行后发现从新的XML文件中读取出的描述信息换行符都丢失了，前后两次输出的结果不一致！\n对比新旧XML文件后发现，产生此现象的原因是: dom4j 自作主张的在写入XML文件时将 \u0026amp;#xD;\u0026amp;#xA; 替换为了 \\r\\n ，而XML文件中标准的回车换行符是用 \u0026amp;#xD;\u0026amp;#xA; 来表示的 ，将它们替换后再次读取的结果很显然不符合要求。\n了解到问题产生的根源后，则其解决思路也很明确： 写入XML文件时，将 \\r\\n 再次替换为 \u0026amp;#xD;\u0026amp;#xA; 即可。最开始自己想采用如下的方法来简单替换，运行完毕后发现结果和前面的一致，问题依旧。\nString description = oldEle.attributeValue(\u0026#34;description\u0026#34;); description = description.replaceAll(\u0026#34;\\r\\n\u0026#34;,\u0026#34;\u0026amp;#xD;\u0026amp;#xA;\u0026#34;); oldEle.attributeValue(\u0026#34;description\u0026#34;,description); 进一步分析后发现dom4j不仅会在读取XML文件时对\u0026amp;#xD;\u0026amp;#xA;进行转义，而且在写入XML文件时也会对\u0026amp;#xD;\u0026amp;#xA;进行转义，前面的方法只是解决了读取的问题，写入时没有处理，所以问题依旧。\n写入时主要的操作类是OutputFormat和XMLWriter，自己一开始以为可以通过OutputFormat进行响应的设置实现，将代码修改如下，然并卵，问题依旧！\nOutputFormat format = OutputFormat.createPrettyPrint(); format.setNewlines(true); format.setLineSeparator(\u0026#34;\\r\\n\u0026#34;); format.setEncoding(\u0026#34;UTF-8\u0026#34;); format.setNewLineAfterDeclaration(false); OutputFormat不好使，只能从XMLWriter着手，调用writer.setEscapeText(false)方法也不能解决问题，看来只能放出大招，自己定义实现一个 XMLWriter类，将以及转义后的回车换行符又换回去，代码如下：\npublic class HRXMLWriter extends XMLWriter { public HRXMLWriter(Writer wr, OutputFormat format) { super(wr, format); } @Override protected String escapeAttributeEntities(String text) { text = super.escapeAttributeEntities(text); if (text.indexOf(\u0026#34;\\r\\n\u0026#34;) \u0026gt; -1) { text = text.replaceAll(\u0026#34;\\r\\n\u0026#34;, \u0026#34;\u0026amp;#xD;\u0026amp;#xA;\u0026#34;); } return text; } } 然后将写入时的代码修改如下：\n//採用定义写入类HRXMLWriter XMLWriter writer = new HRXMLWriter(new FileWriter(newFile), format); writer.write(oldDoc); writer.flush(); writer.close(); 运行结果如下，问题顺利解决！\n坑爹啊！\n","date":"2018-01-04T11:21:42+08:00","permalink":"https://lucumt.info/post/java-core/update-xml-file-has-line-breaks-using-dom4j/","tags":["Java","XML"],"title":"利用dom4j修改含有回车换行符的XML文件"},{"categories":["个人博客"],"contents":"越来越多的网站和个人博客都变成 HTTPS ，而自己的博客一直都是用的是 HTTP 协议，作为一个具有强迫症的人，每次用 Chrome 浏览器打开个人博客时看见浏览器地址栏显示的 都感觉很不舒服。趁着前段时间不太忙，将个人博客从HTTP迁移到了HTTPS ，先记录下。\n一开始我想直接通过在 GoDaddy 上直接购买HTTPS 服务来实现，去官网查看后发现费用太高，一年大约100美刀，果断弃之。 Google后发现很多人都用Cloudflare通过转发请求来实现HTTPS访问，操作起来也很快，自己便也采用Cloudflare实现， 本文主要是基于Cloudflare 的实现说明。\n操作过程 给博客添加自定义域名 本人使用的是GoDaddy来设置自定义域名，具体操作请参见 利用GoDaddy配置自定义域名， 核心的操作就是给CNAME 文件添加Github Pages给出的两条A记录IP地址，此处不再详述。\n利用Cloudflare修改DNS服务器 打开Cloudflare官网注册一个Cloudflare 账户。注册成功之后，点击页面右上角的add site 链接，添加一个网站，在下图输入框中输入自己的域名，点击 Begin Scan 按钮开始扫描。\n扫描完毕后点击 Contiue Setup ，在类似如下图所示的界面中选择Free Website，然后点击页面底部的Continue按钮。\n在下图所示的Cloudflare Nameservers说明界面中根据要求来修改自定义域名的DNS服务器。 登录GoDaddy，打开响应域名的Manage DNS界面，将Nameservers从Default修改为Custom 然后添加前一个步骤中的两个值分别加上并点击保存。\n回到Cloudflare网站，点击Overview按钮，查看域名的状态是否为如下所示的Active，若是则表示DNS服务器修改成功，若不是 Active请等待几分钟。\nCloudflare中开启HTTPS设置 在Cloudflare网站上点击顶部的Crypto按钮，将状态修改为Full。\n在顶部切换到Page Rules界面，点击Create Page Rule ，添加规则http://lucumt.info/* 并选择Always Use HTTPS来强制该域名下的所有请求都是用HTTPS实现，然后点击Save and Deploy来部署该规则，注意此处的规则是HTTP 而不是HTTPS 。\n执行完这一步后理论上通过HTTPS可以正常的访问个人博客，但还需对博客源码做一些修改。 将代码中所有HTTP修改为HTTPS 在执行完前面的步骤后，在浏览器中用HTTPS访问个人博客时，可能看到的还是而不是自己期望中的小绿锁，同时浏览器控制台可能会出现类似Mixed Content,The page at ...,The request has been blocked,the content must be serverd over HTTPS的错误信息。其原因是由于某些页面中存在混合内容，即部分请求还是以HTTP方式实现的，如加载 JavaScript ,CSS 等，解决方法也很简单，将所有的HTTP请求都改为HTTPS即可 。\n以我个人基于Hugo的博客为例，要进行如下几步操作：\n将个人Hugo源代码中所有的HTTP 请求都修改为HTTP,包括页面中的直接请求和 JavaScript 、CSS等文件中的间接请求。\n利用 hugo server -D --baseUrl=\u0026quot;https://lucumt.info\u0026quot; --appendPort=false 重新生成基于HTTPS的源文件页面。\n将生成的博客源代码重新上传到 Github 仓库中，经过1分钟左右以HTTPS的方式在浏览器中打开个人博客，期待中的小绿锁入愿出现，世界终于和谐了！\n注意事项 通过Cloudflare虽然可以快速的将自己的个人博客迁移到HTTPS，但基于以下两个方面的原因，在条件许可的情况下还是应该使用其他方式实现HTTPS:\n免费计划下的Cloudflare实际上相当于一个中介，我们的访问请求先被Cloudflare代理实现HTTPS 接收到然后将其转发给原始的服务器（如 Github Pages 服务器）。虽然浏览器与Cloudflare之间的通信是HTTPS加密，但是Cloudflare与实际服务器之间的通信不一定是加密的，存在被挟持和篡改的可能。Cloudflare之前也被爆出过 安全漏洞和敏感数据泄露，故商业网站通常不用Cloudflare免费计划，但个人博客出于增加搜索引擎收录和省钱等原因，可以使用Cloudflare免费计划。\n由于经过Cloudflare这层代码，访问速度肯定没有直接访问原始服务器那么快，对于响应速度要求高的用户不合适。 由于众所周知的原因，在天朝Cloudflare访问速度比国内慢，而且指不定哪天就被ban了。 利用Github Page原生HTTPS Github从2018年5月份开始支持自定义域名使用HTTPS1，具体操作说明请参见securing-your-github-pages-site-with-https，通过此种方式可以绕过Cloudflare作为中间层的问题，但是仍然无法解决由于qiang存在导致的访问缓慢的问题。\n由于自己之前采用的是Cloudflare，按照Github的官方文档进行操作时，在进行DNS检查时一开始会提示如下信息\n利用dig命令检查后结果如下\n[root@vm-16-6-centos ~]# dig \u0026#43;noall \u0026#43;answer lucumt.info lucumt.info. 60 IN A 185.199.110.153 lucumt.info. 60 IN A 185.199.111.153 lucumt.info. 60 IN A 185.199.108.153 lucumt.info. 60 IN A 185.199.109.153 [root@vm-16-6-centos ~]# dig www.lucumt.info \u0026#43;nostats \u0026#43;nocomments \u0026#43;nocmd ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.11.4-P2-RedHat-9.11.4-26.P2.el7_9.9 \u0026lt;\u0026lt;\u0026gt;\u0026gt; www.lucumt.info \u0026#43;nostats \u0026#43;nocomments \u0026#43;nocmd ;; global options: \u0026#43;cmd ;www.lucumt.info. IN A www.lucumt.info. 2280 IN CNAME lucumt.github.io. lucumt.github.io. 2280 IN A 185.199.109.153 lucumt.github.io. 2280 IN A 185.199.111.153 lucumt.github.io. 2280 IN A 185.199.110.153 lucumt.github.io. 2280 IN A 185.199.108.153 [root@vm-16-6-centos ~]# 发现已经切换过来，并且通过浏览器也能以HTTPS的方式正常访问，就是DNS检查结果一直失败，虽然不影响使用，但对于一个有强迫症的人来说页面上有一项检查失败还是很难受的。\n给Github官方发送Support Request后很快收到了回复2，原因为Cloudflare的缓存还没有清除干净，等待2-3后即可恢复正常。\n$ dig NS lucumt.info ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.10.3-P4-Debian \u0026lt;\u0026lt;\u0026gt;\u0026gt; NS lucumt.info ;; global options: \u0026#43;cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 9195 ;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ;; QUESTION SECTION: ;lucumt.info. IN NS ;; ANSWER SECTION: lucumt.info. 23305 IN NS anirban.ns.cloudflare.com. lucumt.info. 23305 IN NS angela.ns.cloudflare.com. ;; Query time: 0 msec ;; SERVER: 10.127.5.10#53(10.127.5.10) ;; WHEN: Thu Jan 19 18:28:08 PST 2023 ;; MSG SIZE rcvd: 100 根据官方人员的反馈等待2-3天后再次检查，发现DNS检查通过!\n参考:\nhttps://bakumon.me/blog/p/github-pages-https-ssl.html https://help.github.com/articles/securing-your-github-pages-site-with-https/ https://github.blog/2018-05-01-github-pages-custom-domains-https/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://support.github.com/ticket/personal/0/1974028\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2017-12-24T10:28:03+08:00","permalink":"https://lucumt.info/post/hugo/migrate-github-blog-from-http-to-https/","tags":["Github Pages","github","HTTPS"],"title":"将基于Github Pages的自定义域名博客迁移到HTTPS"},{"categories":["编程杂想"],"contents":"工作中有时候会遇到某些大段复杂代码出现Bug的情况，不同于一般行数较小或逻辑较简单的代码，对于大段复杂的代码进行分析可能会很耗时，本文介绍几种个人在工作中用到的方法，供大家参考。\n将Log级别开启到Debug 将Log的级别变为Debug后，会比INFO状态下看到更多的详细日志信息，仔细分析这些输出信息，有时候可以发现是哪一步不能按照预期工作，据此缩小查找范围，从而解决缺陷。\n实际使用中由于Debug级别的log输出信息庞大，查看输出log很耗时，在实际开发中用得不多，常用的场景如下：\n知道大致的代码范围，通过观察log输出来确定具体的原因 压根不知道问题出在哪里，通过观察log输出来获取有用信息，辅助以其它手段来分析 多线程等无法利用Debug调试的环境 利用IDE进行Debug 在IDE中开启Debug模式进行调试是开发过程中最常用的一种手段，通过Debug调试可以找出哪些代码被执行，哪些没有被执行，以及在执行过程中相关变量的值。Debug调试在大部分情况下都可以帮我们找出缺陷，但在多线程应用、 HTML页面样式调试等场景下并不适用Debug方式。\n在代码仓库中进行版本回溯 若已知出问题的代码在以前没有问题，只是最近的更改才出现问题，可以通过从代码仓库中找出历史版本与目前的版本进行对比，看看有哪些差异，通常问题都发生在这些有差异的地方。\n与其它方式相比此种方法耗时最少，通过这种方式找出的bug一般都是某些关键配置写错了或代码语法不正确时控制台没有输出完整的错误信息，如在Ajax方法中在某些配置项后面少写了一个 ,时，在某些浏览器中进行调试时只会出现 Uncaught SyntaxError: Unexpected identifier 这种错误消息，无法根据错误信息具体定位到哪一行代码出错。\n通过二分查找定位 我最喜欢用的方法之一，二分查找定位的操作和二分查找算法类似，先将一部代码注意掉或插入试探性代码，确定问题是在这一边或那一边，确定完大致的区域后，对该问题区域再次采用二分查找来定位，直到找到问题原因为止。此种方法和二分查找算法一样耗时较少。 此方法常用的场景如下：\n不方便利用Debug日志或Debug调试的地方 HTML 、JSP等View层的代码 刚上手某项技术，对其原理了解不深入 重新编写代码实现 若前面几种方法均不能凑效，可以采取终极大法： 重新编码实现！ ，不识庐山真面目，只缘身在此山中 ，有些代码的实现逻辑本身就有问题，若直接对其进行Debug调试或分析，可能会陷入该代码错误的陷阱中。如我们可能认为某段代码代码是没有问题的，然后基于该代码进行进一步的分析调试，却无论如何都得不到自己想要的结果，问题的原因就在于该段代码本身就是错误的。起始点选错了，无论后面怎么做，都无济于事。\n根据原始的需求，在不参照现有代码实现方式的基础上，以白板的方式重新编程实现功能，在对比旧的代码，就能发现问题产生的原因。若这种方式还不能凑效，可以让其他同事协助审查自己的代码，或者审核原有的需求本身是否有问题，通常这种情形意味着我们的代码必须要重构。\n总结 好的代码会自己说话，平时编码时要注意细节、符合规范，必要时对代码进行重构，将复杂的代码进行抽取简化。代码重构虽然对我们的工作产出不会有立竿见影的效果，但也绝不是白白浪费我们的时间，不断重构后的实现良好的代码，不仅有利于调试分析，也有利于他人顺利接手。\n在一些成立时间较长的公司或多或少都会存在一些炸弹代码，此处说的炸弹代码是指那些功能很重要实现又很复杂的代码，最开始开发该功能的人离职后，后面接手的人看不懂该代码，由于各种原因无法对其进行重构，在后续开发时，只能不断的在其后面添加新的业务逻辑，而不敢修改已有的，导致代码量越来越臃肿，越臃肿就越看不懂，陷入恶性循环。这样的代码在后续每次调试分析时都是大坑，而如果一开始就进行适当的重构，或许不会发生这种情况。\nOrz~ 我承认炸弹代码 这个词是我自己发明的！\n","date":"2017-12-23T12:07:40+08:00","permalink":"https://lucumt.info/post/other/different-ways-find-bug-in-complex-code/","tags":null,"title":"从复杂代码中找出Bug的几种方法"},{"categories":["Java编程","MyBatis系列"],"contents":"项目中ORM框架用的是 MyBatis，最近由于业务上的需求将MyBatis从3.1.1升级到3.4.5，发现升级后通过Log4j显示SQL的配置方式发生了变化，由于变化较大，故先记录下。\n假设我们测试的sql文件为UserMapper.xml ， 对应的代码如下，其命名空间为com.lucumt.mapper.UserMappper\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.lucumt.mapper.UserMappper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;getUsers\u0026#34; parameterType=\u0026#34;String\u0026#34; resultType=\u0026#34;com.lucumt.model.UserModel\u0026#34;\u0026gt; SELECT id,username,password,create_time AS createTime FROM system_users WHERE username!=#{username} \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt; 对应的执行代码如下\n@Test public void testMybatis(){ String resource = \u0026#34;mybatis-config.xml\u0026#34;; InputStream is = AppTest.class.getClassLoader().getResourceAsStream(resource); SqlSessionFactory sessionFactory = new SqlSessionFactoryBuilder().build(is); SqlSession session = sessionFactory.openSession(); String statement = \u0026#34;com.lucumt.mapper.UserMappper.getUsers\u0026#34;; List\u0026lt;UserModel\u0026gt; userList = session.selectList(statement, \u0026#34;admin\u0026#34;); for(UserModel u:userList){ System.out.println(u.toString()); } } 本文会基于上述代码说明不同版本下如何利用Log4j在MyBatis中配置打印日志以及其实现原理。\nMyBatis3.1.1分析 Log4j相关配置 在MyBatis3.1.1及以前的版本中若我们想通过Log4j配置来打印实际执行的SQL，log4j.properties的配置通常类似如下\n# 在不开启log4j DEBUG模式下显示mybatis中运行的SQL语句 log4j.logger.java.sql.Connection=DEBUG log4j.logger.java.sql.Statement=DEBUG log4j.logger.java.sql.PreparedStatement=DEBUG log4j.logger.java.sql.ResultSet=DEBUG 原理分析 以log4j.logger.java.sql.Connection=DEBUG这个配置为例，分析源码可知其sql日志来源于ConnectionLogger，查看 ConnectionLogger的代码可知ConnectionLogger以硬编码的方式生成了一个log对象,当DEBUG模式开启时该log对象会打印sql语句等信息。\npublic final class ConnectionLogger extends BaseJdbcLogger implements InvocationHandler { //生成一个Connection的log private static final Log log = LogFactory.getLog(Connection.class); private Connection connection; private ConnectionLogger(Connection conn, Log statementLog) { super(statementLog); this.connection = conn; if (isDebugEnabled()) { debug(\u0026#34;ooo Using Connection [\u0026#34; \u0026#43; conn \u0026#43; \u0026#34;]\u0026#34;); } } public Object invoke(Object proxy, Method method, Object[] params) throws Throwable { try { if (\u0026#34;prepareStatement\u0026#34;.equals(method.getName())) { if (isDebugEnabled()) {//打印执行的SQL语句 debug(\u0026#34;==\u0026gt; Preparing: \u0026#34; \u0026#43; removeBreakingWhitespace((String) params[0])); } PreparedStatement stmt = (PreparedStatement) method.invoke(connection, params); stmt = PreparedStatementLogger.newInstance(stmt, getStatementLog()); return stmt; } //... other code } catch (Throwable t) { throw ExceptionUtil.unwrapThrowable(t); } } //... other code } 运行结果如下\n从上述代码可知在Mybatis3.1.1中通过Log4j实现打印执行SQL的操作很简单，实现原理也易懂，但其存在的一个缺点: 当开启打印SQL日志后，会打印所有正在执行的SQL语句，不能实现针对特定SQL的打印 ，基于此MyBatis从3.2.0版本之后重新实现了相关功能。\nMyBatis3.4.5分析 Log4j相关配置 在MyBatis3.2.0及以后的版本中若我们想通过Log4j配置来打印实际执行的SQL，log4j.properties的配置通常类似如下\n# 在不开启log4j DEBUG模式下显示mybatis中运行的SQL语句 log4j.logger.com.lucumt.mapper=DEBUG 在本文写作时，mybatis官网上已有关于这方面更 详细的说明 。\n原理分析 同样以log4j.logger.java.sql.Connection=DEBUG为例，其sql日志来源于ConnectionLogger，对应代码如下\npublic final class ConnectionLogger extends BaseJdbcLogger implements InvocationHandler { private final Connection connection; //通过注入的方式生成log对象 private ConnectionLogger(Connection conn, Log statementLog, int queryStack) { super(statementLog, queryStack); this.connection = conn; } @Override public Object invoke(Object proxy, Method method, Object[] params) throws Throwable { try { if (Object.class.equals(method.getDeclaringClass())) { return method.invoke(this, params); } if (\u0026#34;prepareStatement\u0026#34;.equals(method.getName())) { if (isDebugEnabled()) { debug(\u0026#34; Preparing: \u0026#34; \u0026#43; removeBreakingWhitespace((String) params[0]), true); } } //... other code } catch (Throwable t) { throw ExceptionUtil.unwrapThrowable(t); } } //... other code } 从上述代码可知，其日志生成是调用BaseJdbcLogger的构造方法生成的，BaseJdbcLogger 代码如下\npublic abstract class BaseJdbcLogger { protected Log statementLog; protected int queryStack; public BaseJdbcLogger(Log log, int queryStack) { this.statementLog = log; if (queryStack == 0) { this.queryStack = 1; } else { this.queryStack = queryStack; } } //... other code } DEBUG模式下查看ConnectionLogger的调用堆栈如下\n从其调用堆栈可知log对象是通过MappedStatement生成的，如下\npublic class SimpleExecutor extends BaseExecutor { //... other code @Override public \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; doQuery(MappedStatement ms,Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException { Statement stmt = null; try { Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); //log对象通过MappedStatement生成 stmt = prepareStatement(handler, ms.getStatementLog()); return handler.\u0026lt;E\u0026gt;query(stmt, resultHandler); } finally { closeStatement(stmt); } } } 查看MappedStatement的源码，发现log的生成是在Builder方法中，如下\npublic final class MappedStatement { public static class Builder { private MappedStatement mappedStatement = new MappedStatement(); public Builder(Configuration configuration, String id, SqlSource sqlSource, SqlCommandType sqlCommandType) { mappedStatement.configuration = configuration; mappedStatement.id = id; mappedStatement.sqlSource = sqlSource; mappedStatement.statementType = StatementType.PREPARED; mappedStatement.parameterMap = new ParameterMap.Builder(configuration, \u0026#34;defaultParameterMap\u0026#34;, null, new ArrayList\u0026lt;ParameterMapping\u0026gt;()).build(); mappedStatement.resultMaps = new ArrayList\u0026lt;ResultMap\u0026gt;(); mappedStatement.sqlCommandType = sqlCommandType; mappedStatement.keyGenerator = configuration.isUseGeneratedKeys() \u0026amp;\u0026amp; SqlCommandType.INSERT.equals(sqlCommandType) ? Jdbc3KeyGenerator.INSTANCE : NoKeyGenerator.INSTANCE; String logId = id; //可以通过设置logPrefix的方法来生成log对象 if (configuration.getLogPrefix() != null) { logId = configuration.getLogPrefix() \u0026#43; id; } //通过logId生成log对象 mappedStatement.statementLog = LogFactory.getLog(logId); mappedStatement.lang = configuration.getDefaultScriptingLanguageInstance(); } } 通过上面的代码可知log对象是由logId生成的，进一步debug发现logId是由 namespace+方法id 组成，在本例中为com.lucumt.mapper.UserMappper.getUsers，而前面的配置为log4j.logger.com.lucumt.mapper=DEBUG ，由于Log4j中的log示例的继承关系，相当于com.lucumt.mapper.UserMappper.getUser也开启了DEBUG模式，故在实际执行时可以显示打印SQL语句，运行结果如下\n利用新版MyBatis的这一特性，我们可以实现类似如下的不同粒度sql打印\nlog4j.logger.com.xxx.mapper=DEBUG #打印xxx包下所有的执行SQL log4j.logger.com.yyy.mapper.PersonMapper=DEBUG #打印PersonMapper下所有的执行SQL log4j.logger.com.zzz.mapper.GroupMapper.getGroups=DEBUG #只打印getGroups对应的执行SQL 由前面的代码可知MappedStatement的Build方法在生成log对象时会检测是否有logPrefix配置，若有则用logPrefix来生成log对象，于是可以通过设置logPrefix以另外一种方式配置打印sql。 可在MyBatis配置文件中添加如下配置\n\u0026lt;settings\u0026gt; \u0026lt;setting name=\u0026#34;logPrefix\u0026#34; value=\u0026#34;dao.\u0026#34;/\u0026gt; \u0026lt;!-- 设置前缀为dao --\u0026gt; \u0026lt;setting name=\u0026#34;logImpl\u0026#34; value=\u0026#34;log4j\u0026#34;/\u0026gt; \u0026lt;!-- 设置使用log4j为日志实现类 --\u0026gt; \u0026lt;/settings\u0026gt; 然后将 log4j.properties的配置修改为\nlog4j.logger.dao=DEBUG 执行结果与前面相同，通过 logPrefix可以在有些时候简化sql打印配置。\n待分析问题 若将MyBatis的版本变3.3.0时，通过Log4j配置打印SQL时，如下所示的配置方式只有部分生效，原因待分析\nlog4j.logger.com.xxx=DEBUG #可以打印SQL log4j.logger.com.xxx.mapper=DEBUG #可以打印SQL log4j.logger.com.xxx.mapper.UserMapper=DEBUG #不能打印SQL log4j.logger.com.xxx.mapper.UserMapper.getUsers=DEBUG #不能打印SQL ","date":"2017-12-18T18:33:14+08:00","permalink":"https://lucumt.info/post/mybatis/print-sql-in-different-mybatis-version/","tags":["Java","MyBatis"],"title":"在不同版本的MyBatis中通过Log4j打印实际执行的SQL"},{"categories":["Java编程"],"contents":"Java程序实际上执行的是Java文件编译后的Class文件，这是任何一个Java开发人员都了解的基本知识。\n若Java程序执行的结果不符合要求，通常的解决方法是先修改Java文件，重新编译成Class文件后再次执行。但有时候我们不能直接修改Java文件（如只有包含class文件的jar包），此时我们就只能直接修改Class文件，本文将展示在基于不同的需求通过可视化工具和Javassist库来直接对Class文件进行修改的方法。\n注：由于直接修改class文件会涉及到class文件结构的相关知识，所以利用此种方式时最好对class文件结构有一定的了解\n修改Class文件中的变量 下面的代码为一个典型的输出Hello World的Java小程序\npackage com.lucumt; public class Test { public static String language = \u0026#34;Java\u0026#34;; public static void main(String[] args) { sayHello(); } public static void sayHello() { System.out.println(\u0026#34;=====Hello \u0026#34;\u0026#43;language\u0026#43;\u0026#34; World!======\u0026#34;); } } 在cmd命令行中运行该程序的结果如下\n若想将运行结果从Hello Java World修改为Hello Golang China，除了通过修改源代码重新编译运行这个方法之外我们还可以利用工具直接修改原有的class文件来实现。\n首先从 JBE下载 JBE(Java Bytecode Editor),JBE是一个用于浏览和修改Java Class文件的开源软件，在其官网上可以看到如下图所示的说明信息\n下载完该软件后，在该软件中打开我们要修改的Class文件\n首先我们需要将静态变量language的值从Java修改为Golang, 由于language是一个静态变量，故我们需要在class文件的clinit方法中找到该变量并修改其值。如下图所示，展开clinit并切换到Code Editor页，可以看到language的值为Java ，在Code Editor部分将Java修改为Golang然后点击Save method即可完成静态变量值的修改。\n接着展开sayHello方法，同样切换到Code Editor页，将World修改为China后点击Save method，至此整个修改操作完成。\n在命令行中重新执行该程序，输出结果为Hello Golang China，符合我们的要求。\n修改Class文件中的方法 对于较为简单的修改需求我们可以利用JBE等工具来直接修改，若要对class文件进行较为复杂的修改，如增加新方法，修改已有方法的实现逻辑等，对于此种需求虽然也可以用JBE实现目的，但工作量很大，容易出错，此时JBE已经不太适合使用，需要寻找其它更快捷的方法。\n由于Java文件后生成的class文件是一个包含Java字节码的二进制文件，程序最终执行的就是二进制文件中的字节码，我们的需求可以归纳为如何修改Java字节码文件。前一部分通过JBE来修改class文件只不过是将这个过程进行了图形化封装，我们需要找到更底层的实现方法来适应我们的需求。\n此时Javassist闪亮登场！在Javassit官网关于其的第一句介绍为Javassist (Java Programming Assistant) makes Java bytecode manipulation simple. It is a class library for editing bytecodes in Java 。Javassist天生就是为修改Java字节码而来的，它提供了源代码和字节码两种级别的API接口，为了实现的简便性，本文主要介绍利用源代码API来修改class文件。\n下面的代码为一个计算两个整数相加的程序\npackage com.lucumt; public class Test1 { public static void main(String[] args) { Test1 t1 = new Test1(); int result = t1.addNumber(3, 5); System.out.println(\u0026#34;result is: \u0026#34;\u0026#43;result); } public int addNumber(int a,int b){ return a\u0026#43;b; } } 正常情况下，其输出结果如下\n若我们想将addNumber的返回结果从两个数之和变为两个数立方后求和，则可以利用Javassist提供的API通过Java程序来直接修改class文件。关于如何使用Javassist请直接参看相应的 入门教程，本文不再详细说明，利用Javassist修改 addNumber的Java代码如下：\npackage com.lucumt.test; import java.io.IOException; import javassist.CannotCompileException; import javassist.ClassPool; import javassist.CtClass; import javassist.CtMethod; import javassist.NotFoundException; public class UpdateMethod { public static void main(String[] args) { updateMethod(); } public static void updateMethod(){ try { ClassPool cPool = new ClassPool(true); //如果该文件引入了其它类，需要利用类似如下方式声明 //cPool.importPackage(\u0026#34;java.util.List\u0026#34;); //设置class文件的位置 cPool.insertClassPath(\u0026#34;D:\\\\Java\\\\eclipse\\\\newworkspace\\\\test\\\\bin\u0026#34;); //获取该class对象 CtClass cClass = cPool.get(\u0026#34;com.lucumt.Test1\u0026#34;); //获取到对应的方法 CtMethod cMethod = cClass.getDeclaredMethod(\u0026#34;addNumber\u0026#34;); //更改该方法的内部实现 //需要注意的是对于参数的引用要以$开始，不能直接输入参数名称 cMethod.setBody(\u0026#34;{ return $1*$1*$1\u0026#43;$2*$2*$2; }\u0026#34;); //替换原有的文件 cClass.writeFile(\u0026#34;D:\\\\Java\\\\eclipse\\\\newworkspace\\\\test\\\\bin\u0026#34;); System.out.println(\u0026#34;=======修改方法完=========\u0026#34;); } catch (NotFoundException e) { e.printStackTrace(); } catch (CannotCompileException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } } } 运行该代码后重新执行后的结果如下，从图中可以看出运行结果符合预期\n关于UpdateMethod工具类有如下几点说明：\n如果要修改的class文件中引入了其它类，需要调用ClassPool中的importPackage方法引入该类，否则程序会报错\n修改完后，一定要调用CtClass中的writeFile方法覆盖原有的class文件，否则修改不生效\n在修改方法的过程中若要引用方法参数，不能在修改程序代码中直接写该参数，否则程序会抛出javassist.CannotCompileException: [source error] no such field:异常。在本例中addNumber的两个参数分别为a和b，在修改时不能写成cMethod.setBody(\u0026quot;{ return a*a*a+b*b*b; }\u0026quot;)需要修改为cMethod.setBody(\u0026quot;{ return $1*$1*$1+$2*$2*$2; }\u0026quot;)\n在Javassist的 Introspection and customization部分有如下一段话\nThe parameters passed to the target method are accessible with $1, $2, \u0026hellip; instead of the original parameter names. $1 represents the first parameter, $2 represents the second parameter, and so on. The types of those variables are identical to the parameter types. $0 is equivalent to this. If the method is static, $0 is not available.\n从中可知，方法中的参数从$1开始，若该方法为非static方法，可以用$0来表示该方法实例自身，若该方法为static方法，则 $0 不可用\n在Class文件中增加方法 Javassist不仅可以修改已有的方法，还可以给class文件增加新的方法。仍以前面的 Test1 Java代码中为例，现要求增加一个名为showParameter的方法并在addNumber方法中调用，其主要功能是输出addNumber中传入的参数。利用Javassist修改class文件实现该功能的代码如下\npackage com.lucumt.test; import java.io.IOException; import javassist.CannotCompileException; import javassist.ClassPool; import javassist.CtClass; import javassist.CtMethod; import javassist.CtNewMethod; import javassist.NotFoundException; public class AddMethod { public static void main(String[] args) { addMethod(); } public static void addMethod(){ try { ClassPool cPool = new ClassPool(true); cPool.insertClassPath(\u0026#34;D:\\\\Java\\\\eclipse\\\\newworkspace\\\\test\\\\bin\u0026#34;); CtClass cClass = cPool.get(\u0026#34;com.lucumt.Test1\u0026#34;); CtMethod cMethod = cClass.getDeclaredMethod(\u0026#34;addNumber\u0026#34;); //增加一个新方法 String methodStr =\u0026#34;public void showParameters(int a,int b){\u0026#34; \u0026#43;\u0026#34; System.out.println(\\\u0026#34;First parameter: \\\u0026#34;\u0026#43;a);\u0026#34; \u0026#43;\u0026#34; System.out.println(\\\u0026#34;Second parameter: \\\u0026#34;\u0026#43;b);\u0026#34; \u0026#43;\u0026#34;}\u0026#34;; CtMethod newMethod = CtNewMethod.make(methodStr, cClass); cClass.addMethod(newMethod); //调用新增的方法 cMethod.setBody(\u0026#34;{ showParameters($1,$2);return $1*$1*$1\u0026#43;$2*$2*$2; }\u0026#34;); cClass.writeFile(\u0026#34;D:\\\\Java\\\\eclipse\\\\newworkspace\\\\test\\\\bin\u0026#34;); } catch (NotFoundException e) { e.printStackTrace(); } catch (CannotCompileException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } } } 运行该代码后重新执行Test1后的结果如下，从图中可以看出运行结果符合预期 从上述代码可以看出，利用Javassist增加方法比修改方法更简单，先将要新增的方法内容赋值到字符串，然后分别调用相关类的make和 addMethod方法即可。\n后记 利用JBE或Javassist虽然可以实现直接修改class文件的内容，但毕竟属于不正规的做法，可能会导致后续版本不一致等问题，在条件允许的情况下还是要尽量通过修改Java文件然后重新编译的方式来实现目的。\n","date":"2017-08-12T18:09:53+08:00","permalink":"https://lucumt.info/post/java-core/modify-java-class-file-content-directly/","tags":["Java","JVM"],"title":"在不重新编译的情况下直接修改Java Class文件中的内容"},{"categories":["Web编程"],"contents":"相对于传统的用HTML中TABLE实现的表格，利用EasyUI中的DataGrid实现的表格具有很多优点，如可以对列宽进行拖动调整、列冻结、行冻结、自定义格式化等功能，故而在Web开发中得到了广泛的应用。最近自己在使用DataGrid的列冻结功能时遇到了由于某些单元格中的内容较多导致该行无法对齐的问题，由于当前在EasyUI官网中无法找到该问题的解决方案，自己研究DataGrid的实现原理后，找到了变通的解决方案，故先记录下。\nEasyUI DataGrid正常情况下的列冻结 下图为一个常见的DataGrid使用示例，该图展示了我们在使用EasyUI DataGrid时经常会遇到的一个问题：由于某个列的长度很长导致表格出现滚动条\n对应的代码为\n\u0026lt;thead\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th data-options=\u0026#34;field:\u0026#39;name\u0026#39;\u0026#34;\u0026gt;\u0026lt;b\u0026gt;书名\u0026lt;/b\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;th data-options=\u0026#34;field:\u0026#39;price\u0026#39;,align:\u0026#39;center\u0026#39;,width:70\u0026#34;\u0026gt;\u0026lt;b\u0026gt;价格\u0026lt;/b\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;th data-options=\u0026#34;field:\u0026#39;pubdate\u0026#39;,align:\u0026#39;center\u0026#39;,width:90\u0026#34;\u0026gt;\u0026lt;b\u0026gt;出版日期\u0026lt;/b\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;th data-options=\u0026#34;field:\u0026#39;description\u0026#39;,width:800\u0026#34;\u0026gt;\u0026lt;b\u0026gt;简要介绍\u0026lt;/b\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; 得益于EasyUI DataGrid强大的功能，当表格中列的宽度太长时，它会自动加上横向滚动条，避免像传统的HTML TABLE表格在内容过多时会自己挤成一团，通过拖动滚动条，我们可以很方便的查看表格中各列的内容。\n但有时候我们会运到另外一个问题，拖动滚动条时前面的某些列就不见了，如本例中的书名，在某些情况下可能会对我们的使用带来不便。\n此时DataGrid的列冻结功能就可以派上用场了，只需要将需要固定的列冻结即可，在本例中我想把书名列冻结，在需要修改代码如下\n\u0026lt;thead frozen=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th data-options=\u0026#34;field:\u0026#39;name\u0026#39;\u0026#34;\u0026gt;\u0026lt;b\u0026gt;书名\u0026lt;/b\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th data-options=\u0026#34;field:\u0026#39;price\u0026#39;,align:\u0026#39;center\u0026#39;,width:70\u0026#34;\u0026gt;\u0026lt;b\u0026gt;价格\u0026lt;/b\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;th data-options=\u0026#34;field:\u0026#39;pubdate\u0026#39;,align:\u0026#39;center\u0026#39;,width:90\u0026#34;\u0026gt;\u0026lt;b\u0026gt;出版日期\u0026lt;/b\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;th data-options=\u0026#34;field:\u0026#39;description\u0026#39;,width:800\u0026#34;\u0026gt;\u0026lt;b\u0026gt;简要介绍\u0026lt;/b\u0026gt;\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; 其对应的运行效果如下：\nEasyUI DataGrid非正常情形下的列冻结效果 大多数情况下这种列冻结都能满足我们的需求，但上述冻结列正常显示有一个前提：表格中每一行各列的高度一致，若表格中某些行中存在列高超出DataGrid正常高度的情形(25px)，在进行列冻结时就会出现冻结行和非冻结行无法对齐的问题。\n下图为一个列超出正常高度的DataGrid显示效果，从图中可以看出由于描述信息中的文字较多，导致正常的高度都比DataGrid默认的高度要很多，直观的显示就是不同行的高度不一致。 此时若对该表格进列冻结，同样会出现出现如前所述的冻结效果，但如果我们在一开始就将描述信息这列隐藏掉，之后通过点击等方式让该列显示，则会出现冻结行和非冻结行无法对齐的情况，如下图所示 对应的关键代码如下，也可以点击jsfiddle.net/wch9rnr2/8/查看完整的代码\n\u0026lt;button type=\u0026#34;button\u0026#34; onclick=\u0026#34;toggleDescription()\u0026#34;\u0026gt;隐藏或显示描述信息\u0026lt;/button\u0026gt; function toggleDescription(){ var colOptions = $(\u0026#34;#dg\u0026#34;).datagrid(\u0026#34;getColumnOption\u0026#34;,\u0026#34;description\u0026#34;); var isHidden = !!colOptions.hidden; if(isHidden){ $(\u0026#34;#dg\u0026#34;).datagrid(\u0026#34;showColumn\u0026#34;,\u0026#34;description\u0026#34;); }else{ $(\u0026#34;#dg\u0026#34;).datagrid(\u0026#34;hideColumn\u0026#34;,\u0026#34;description\u0026#34;); } } 从上图可以看出此时书名列和其余列已经无法对齐，严重印象了我们的使用效果。\n解决方案 要想解决该问题，首先需要找出该问题产生的根源，利用Chrome或其它浏览器调试工具可知，当有部分列冻结时，DataGrid表格被分成了两个不同的表格，一个是冻结的表格，一个是未冻结的表格。进一步分析发现导致无法对齐的问题根源为 由于两个表格中同一行的高度不同，导致实际显示时看起来表格行没有对齐。\n找到问题根源后，要解决该问题，我们只需要让表格中每一行高度保持一致即可，具体来说就是 要在EasyUI DataGrid渲染表格之前将同一行的每一个单元格的高度保持一致即可。问题转化为寻找适当的方法切入点来修改单元格高度，即对单元格的高度进行校验。\n为了修正单元格的高度，我们需要首先找出特定行已冻结单元格和未冻结单元格的高度，而要找出它们的高度必须要等EasyUI DataGrid渲染完毕之后才能获取到其实际高度。本列中由于点击按钮时会对最后一列进行隐藏或显示，所以我们可以在toggleDescription方法的最后执行相应的校验逻辑。\n进一步调试分析后发现，对于DataGrid中的某一个数据行而言，冻结列的单元格高度都一样，非冻结列的单元格高度也一样，为了保持整行对齐，我们只需要高度较小的单元格的高度设置为高度较高的单元格的高度即可。考虑到有些影响列，同时为了简化实现，可以将及解决方案从设置单元格的高度更改为设置特定行在冻结和非冻结部分的行高即可。至于如何设置EasyUI DataGrid中数据行的高度，请参见EasyUI作者stworthy大神在datagrid dynamically set / reset row height中的回复，在该问题中stworthy给出的解决方案如下：\nvar dg = $(\u0026#39;#dg\u0026#39;); dg.datagrid(\u0026#39;options\u0026#39;).rowHeight = 40; for(var i=0; i\u0026lt;dg.datagrid(\u0026#39;getRows\u0026#39;).length; i\u0026#43;\u0026#43;){ dg.datagrid(\u0026#39;refreshRow\u0026#39;, i); } 基于此，我们可以将toggleDescription方法改进如下，完整的代码请参见jsfiddle.net/wch9rnr2/9/\nfunction toggleDescription(){ var dg = $(\u0026#34;#dg\u0026#34;); var colOptions = dg.datagrid(\u0026#34;getColumnOption\u0026#34;,\u0026#34;description\u0026#34;); var isHidden = !!colOptions.hidden; if(isHidden){ dg.datagrid(\u0026#34;showColumn\u0026#34;,\u0026#34;description\u0026#34;); }else{ dg.datagrid(\u0026#34;hideColumn\u0026#34;,\u0026#34;description\u0026#34;); } var dgOptions = dg.datagrid(\u0026#34;options\u0026#34;); var rows = dg.datagrid(\u0026#34;getRows\u0026#34;); var row = null; var tr = null; var height1 =0; var height2 =0; for(var i in rows){ row = rows[i]; tr = dgOptions.finder.getTr(dg[0],i); height1 = $(tr[0]).height();//冻结行的高度 height2 = $(tr[1]).height();//非冻结行的高度 if((isHidden\u0026amp;\u0026amp;height2\u0026gt;height1)||(!isHidden\u0026amp;\u0026amp;height1\u0026gt;height2)){ //冻结部分在显示时的高度取较大的那个 $(tr[0]).css(\u0026#34;height\u0026#34;,height2\u0026#43;\u0026#34;px\u0026#34;); } } } 此时当我们点击按钮来显示描述信息时，DataGrid中的每一行都已经对齐，如下图所示，至此问题获得解决！\n在实际使用中，我发现有时候上述JavaScript校验代码还是不能正常工作，其原因为在执行校验代码时，EasyUI DataGrid还没有完全渲染完毕，此时可以利用setTimeout函数来延后校验代码的执行，修改后的代码如下：\nfunction toggleDescription(){ var dg = $(\u0026#34;#dg\u0026#34;); var colOptions = dg.datagrid(\u0026#34;getColumnOption\u0026#34;,\u0026#34;description\u0026#34;); var isHidden = !!colOptions.hidden; if(isHidden){ dg.datagrid(\u0026#34;showColumn\u0026#34;,\u0026#34;description\u0026#34;); }else{ dg.datagrid(\u0026#34;hideColumn\u0026#34;,\u0026#34;description\u0026#34;); } var dgOptions = dg.datagrid(\u0026#34;options\u0026#34;); var rows = dg.datagrid(\u0026#34;getRows\u0026#34;); var row = null; var tr = null; var height1 =0; var height2 =0; setTimeout(function(){ for(var i in rows){ row = rows[i]; tr = dgOptions.finder.getTr(dg[0],i); height1 = $(tr[0]).height();//冻结行的高度 height2 = $(tr[1]).height();//非冻结行的高度 if((isHidden\u0026amp;\u0026amp;height2\u0026gt;height1)||(!isHidden\u0026amp;\u0026amp;height1\u0026gt;height2)){ //冻结部分在显示时的高度取较大的那个 $(tr[0]).css(\u0026#34;height\u0026#34;,height2\u0026#43;\u0026#34;px\u0026#34;); } } },1000);//延后一秒执行 } 考虑到实际使用中EasyUI DataGrid的渲染时间无法确定，用setTimeout并非最优解，希望EasyUI官方后续能为该问题提供更合理的解决方案!\n","date":"2017-08-06T00:06:36+08:00","permalink":"https://lucumt.info/post/web/easyui-datagrid-row-not-align-when-column-frozen/","tags":["JavaScript","EasyUI"],"title":"解决EasyUI DataGrid中的行在列冻结时无法对齐的问题"},{"categories":["Java编程","翻译"],"contents":"本文翻译自Java Concurrency / Concurrency Models\n并发系统可以使用不同的并发模型来实现，并发模型是指线程在系统中如何写作来完成给定的任务。不同的并发模型以不同的方式拆分任务，线程间以不同的方式协作和通信，本文将深入研究在撰写本文时最流行并发模型(2015年)。\n并发模型和分布式系统相似之处 本文中描述的并发模型与分布式系统中使用的架构类似，在一个并发系统中，不同的线程之间互相通信，在一个分布式系统中，不同的进程间彼此通信（这些进程可能在不同的电脑上）。线程和进程在本质上时非常相似的，这就是为什么不同的并发模型与不同的分布式系统架构通常看起来相似。\n虽然分布式系统还有额外的挑战，如网络故障、远程计算机或进程关闭等，但一个运行在大型服务器上的并发系统也可能会遇到类似的问题，如CPU故障、网卡故障、硬盘故障等，虽然其发生的概率较低，但理论上仍然可以发生。\n由于并发模型和分布式系统架构类似，它们通常可以相互借鉴，比如在线程中分配工作的模型通常与分布式系统中的负载均衡类似，它们的错误处理手段也类似，例如日志（logging）、故障切换（fail-over）和等幂性任务（idempotency of jobs）等。\n并行工作者模型(Parallel Workers model) 并行工作者模型是本文要说明的第一个并发模型，该模型会将系统中到来的任务分配给不同的工作者，如下图所示：\n并发模型中有一个“委托者”将到来的任务分配给不同的工作者，每个工作者完成整个任务，每个工作者在不同的线程中（也有可能在不同的CPU）并行工作。\n如果一个汽车厂采用了并行工作者模型，那么每辆汽车将由一个工人根据说明书从头到尾来制造。\n并行工作者模型是Java应用程序中使用最广泛的并发模型（尽管这种情形正在发生变化），java.util.concurrent 中的许多包都被设计用于此模型，你也可以在Java企业级服务器的设计中找到此模型的应用踪迹。\n并行工作者模型的优点 并行工作者模型的优点是理解容易，当要增加应用程序的并行能力时我们只需添加更多的工作者即可。\n例如，假设你想实现一个网络爬虫，你可以使用不同数量的工作者线程来爬取制定数量的页面，根据结果来决定使用多少个工作者线程具有最短的抓取时间（同时意味着最优性能）。由于网络爬虫是IO密集型工作，在等待下载数据时会浪费大量时间，若每个CPU只运行一个线程时效率不高，所以最终的结果可能会是在电脑中一个CPU/内核运行多个线程。\n并行工作者模型的缺点 并行工作者模式在其简单外表之下还有若干缺点，我将在以下部分说明其中最为明显的几个。\n状态共享将使复杂性增加 实际上并行工作者模型比上面说明的还要复杂一些，并行工作者通常需要访问一些共享数据，它们可能存储在内存中也可能存在数据库中，下面的图标展示了这种情形是如何是的并行工作者模型变得复杂的。\n其中的一些共享状态可能在类似于任务队列的通信过程中，但是另外一些共享状态可能是商业数据、缓存数据、数据库的连接池等。一旦共享状态引入到了并行工作者模型，问题就开始变得复杂。线程需要一种方式来访问共享数据以确保一个线程对共享数据的更改对其它线程是可见的（将其推送到主内存中，而不是仅停留在执行线程的CPU缓存中）。线程间需要避免竞争条件、死锁和其它共享状态相关的问题。\n另外，当线程间在等待彼此访问共享数据结构时，会降低应用程序的并行性。许多并发数据结构都是阻塞式的，这意味着在给定时间只有一个或一组有限的线程可以访问它们，这可能导致线程对这些共享数据的竞争，高度竞争将会导致访问共享数据的代码从本质上变为串行执行。\n现代的非阻塞并行算法(non-blocking concurrency algorithms )可能会减少竞争和提高性能，但是非阻塞算法很难实现。\n持久化数据结构是另外一种选择，一个持久化数据在自身被修改时会始终保留之前的值。因此，如果多个线程同时操作一个持久化数据并且其中一个修改了该数据，该线程会得到新数据的引用，而其它线程在则保持着对未修改的旧数据的引用，从而依旧保持一致。在Scala编程中包含若干个持久化的数据结构。\n虽然持久化数据结构是并发修改共享数据的一种看似优雅的解决方案，但其执行性能并不理想。例如，一个持久化的列表会把新元素加入其首部并且返回对该新增元素的引用（它将会指向列表的其余元素）。所有其它的线程仍然保持着对先前列表中第一个元素的引用，对这些线程而言该列表并没有发生修改，它们看不见新增加的元素。\n这种持久化的列表可以用链表来实现，不幸的是，现在的硬件并不能很好的支持链表，链表中的每一个元素都是一个单独的对象，这些对象可以遍布计算机的内存。现在的CPU在访问连续的内存地址时速度更快，因此实现为数组(Array)结构会获得更高的性能。对于一个以数组方式存储的数据而言，CPU缓存可以一次将更大的数组块加载到缓存中，一旦数据加载完毕，CPU可以直接在缓存中访问这些数据，而这对于元素分散在RAM中的链表而言是不太可能实现的。\n无状态的工作者 共享状态可以被系统中的其它线程修改，因此工作者(workers)在每次需要它们时都必须重新读取该状态，以确保它在最新的副本上工作，无论共享状态是保存在内存还是外部数据库中，都是如此。一个工作者不在其内部保存状态（而是在每次需要时都重新读取），我们称之为无状态。\n任务顺序的不确定 并行工作者模型的另一个缺点是任务执行的顺序无法确定。没有办法来确保某个任务最先执行或最后执行，任务A在任务B之前分配给一个工作者，但是任务B可能先于任务A执行。\n并能工作者模型的不确定性使得很难在任何给定的时间点推理系统的状态，它同样使得确保一个任务在另外一个任务之前执行变得更难（如果可能）。\n流水线模型（Assembly Line） 第二种并发模型我称之为流水线模型，我选择名称以符合早期“并行工作者”的含义。在不同的平台/社区中，其他的开发人员或许使用其它的名称，如反应式系统(reactive systems)，或事件驱动系统(event driven systems)，下图是流水线并发模型的一个展示\n这些工作者就像工厂里的工人一样组织起来，每个工作者只完成整个任务的一部分，当该部分任务完成时，该工作者将任务转移到下一个工作者。每个工作者都在自己的线程中运行，并且没有与其它的工作者共享状态，因此流水线模型有时也被称之为无共享的并发模型。\n流水线模型通常用于系统中的非阻塞IO操作，非阻塞IO意味着当一个工作者(worker)开始一个IO操作时(如从网络读取文件或数据)，该工作者(worker)不必等待IO操作结束。IO操作通常较慢，因此等待IO操作完成是对CPU时间的浪费，CPU可以在此时做一些其它事情。当IO操作完成时，IO操作的结果（如数据状态读取或输入写入）会传给下一个工作者(worker)。\n使用非阻塞IO时，IO操作的结果决定了工作者(worker)之间的边界，一个工作者(worker)在不得不开始IO操作之前可以尽可能的完成任务，然后放弃对该任务的控制，当IO操作结束时，在流水线上的另一个工作者(worker)以类似的方式继续完成该任务，直到它不得不开始IO操作。\n实际中，上述这些任务可能不会沿着一条流水线流动，因为大多数操作系统可以同时运行多个任务，这些任务根据实际需求沿着流水线逐个的被工作者处理。在实际使用中可能会有多个虚拟流水线同时运行，下图展示了在实际使用中任务如何在这种流水线上流转。\n任务甚至可以转发给多个工作者进行并发处理，例如，一个任务可以被同时转发给一个任务执行器和一个任务日志记录器。下图展示了如何将三条装配线的中任务转发给同一个工作者完成（中间装配线上的最后一个工人）：\n流水线甚至可以做的比上面展示的更复杂。\n响应式、事件驱动系统 使用流水线并发模型的系统有时候也被称之为 响应式系统 或 事件驱动系统 。系统工作者在事件发生时做出对应的响应：从外部接收消息或转发给其它工作者等。事件驱动的例子可能是传入的HTTP请求，也可能是某个文件完成加载到内存中等。\n在写作本文时，已经有一些有趣的响应式/事件驱动平台可以使用，并且在将来会出现更多的。其中一些比较受欢迎的如下：\nVert.x Akka Node.JS (JavaScript) 对我个人而言，我发现Vert.x十分有趣(尤其是像我这种对Java/JVM落伍的人)。\n参与者(Actors)与管道(Channels)对比 参与者（Actors）和管道（Channels）是两种类似的流水线（响应式/事件驱动）模型。\n在参与者模型中，每个工作者被称之为一个参与者，参与者之间可以直接发消息给对方，这些消息以异步方式来发送和处理。参与者可以用于处理如前所述的一个或多个流水线任务，下图展示了这种模型：\n在管道(Channel)模型中，工作者之间不直接互相沟通，相反地，他们会将消息发布到不同的管道中，其他的工作者可以在这些管道上收听消息，同时消息发送者不必知道谁在收听消息。下图展示了该模型：\n在写作本文时，管道模型对我而言似乎更灵活：一个工作者不必知道在流水线上的哪个工作者要处理接下来的任务，它只需要知道需要将任务转发到哪个管道（或发送消息哪个管道等），在管道中的收听者可以订阅和取消订阅而不会影响到往管道中正在写入的工作者，这允许工作者之间有某种程度的低耦合。\n流水线模型（Assembly Line）的优点 相对于并行工作者模型，流水线模型有一些优点，在接下来的部分，我会叙述其中最突出的几个优点。\n无共享状态 工作者之间不共享状态的情形意味着它们可以在实现时不必考虑在状态共享时所遇到的各种并发问题，这让工作者的实现变得更加容易，在实现工作者时可以假设只有一个线程在处理该工作，本质上就是一个单线程实现。\n有状态的工作者 由于工作者知道没有其它线程修改它们的数据，这些工作者可以具有状态。在说有状态时我的意思是它们可以保留在内存中操作所需的数据，只有写入才会改变最终的外部存储系统。因此，一个有状态的工作者通常比无状态的工作者执行更快。\n更好的硬件协同 单线程代码的优点在于它通常更符合底层硬件的工作原理。首先你通常可以创建更优化的数据结构和算法当你能假定代码会以单线程模式执行。\n其次,如前所述单线程有状态的工作者可以在内存中缓存数据，当数据在内存中缓存时，有很大的概率该数据也会被缓存到CPU缓存中，这样数据获取变得更快。\n当代码以一种自然受益于底层硬件工作原理的方式编写时，我称之为 硬件协调，有些开发者称之为mechanical sympathy，我更倾向于硬件协同因为计算机只有很少的机械部件，同时单词sympathy在这种情况下被用作比喻“更高的匹配”，而我认为单词conform能更高的传达其含义。不管怎么说，这些都是吹毛求疵，可以使用你喜欢的任何术语来描述。\n任务可排序 根据流水线模型实现的并发系统使得排序变得可能，任务排序使得在任何给定时间点更容易理解系统的状态。此外，你可以将所有传入的任务写入日志，如果系统的任何部分发生故障，则可以使用该日志从头重建系统的状态。这些任务以某种顺序写入日志，这个顺序称为该任务顺序，下图展示了这种设置如何实现： 确保一个任务的顺序实现起来不一定容易，但通常是可能的。如果你可以实现的话，它将会大大简化类似于数据备份、恢复数据、复制数据等的任务，这些都可以通过日志文件来完成。\n流水线模型（Assembly Line）的缺点 流水线模型的最主要缺点是通常将执行一个任务分配到多个工作者，因此，当项目中有多个类时，将难以准确的看出哪段代码在执行给定的任务。\n代码编写也可能会变得更难，工作者代码有时候被写作回调处理器(callback handlers)。在代码中有太多嵌套的回调处理器时可能会导致某些开发人员所谓的 回调陷阱(callback hell) 。回调陷阱简单的说就是在所有的回调中很难追踪代码真正在干啥以及确保每个回调都可以访问它需要的数据。\n而使用并行工作者模型，这往往很容易。你可以打开对应的工作者代码，并从头到尾读取要执行的代码。当然，并行工作者模型也可能传播到不同的类中，但是要执行的序列通常更容易从代码中读取。\n功能并行(Functional Parallelism)模型 功能\\函数并行模型是第三种并发模型，最近谈论得很多(2015)。\n功能\\函数并行性的基本思想是通过函数调用实现程序，功能可以被看作是发送消息到彼此的“代理”或“角色”，就像流水线并发模型（AKA反应或事件驱动系统）一样，当一个函数调用另一个函数时，类似于消息发送。\n传递给函数的所有参数都被复制，所以在接收函数之外没有任何实体可以操纵数据，这种复制对于对于避免共享数据的条件竞争至关重要，它使得函数执行类似于原子操作，每个函数调用都可以独立于任何其他函数调用执行。\n当每个函数调用可以独立执行时，可以在单独的CPU上执行每个函数调用，这意味着，在多个CPU上可以并行执行功能实现的算法。\n使用Java 7，我们得到了包含ForkJoinPool模型的 java.util.concurrent 包，可以帮助您实现类似于功能并行性的功能，而使用Java 8，我们将得到并行流，可以帮助您并行化大型集合的迭代。请记住，有开发人员批评ForkAndJoinPool模型（您可以在我的ForkAndJoinPool教程中找到一个相应的批评链接）。\n关于功能\\函数并行的难点在于知道哪个函数调用需要并行化，跨CPU的协调功能调用带来了一定的开销。只有由功能/函数完成的工作单位具有一定的大小，才能值得这个开销，如果函数调用非常小，尝试并行化它们可能比单个线程的单个CPU执行更慢。\n从我的理解（事实上根本不完美），您可以使用事件响应驱动模型来实现实现算法，并实现与功能并行性相似的工作分解。在我看来，通过事件响应驱动模型，你可以掌握如何来实现并行化。\n另外，只有当前任务是程序执行的唯一任务时，将任务分配给多个CPU，协调开销才有意义。然而，如果系统同时执行多个其他任务（如Web服务器，数据库服务器和许多其它系统），则无需尝试并行化单个任务。计算机中的其它CPU可能正在忙于处理其它任务，所以没有理由试图用较慢的功能并行任务来打扰他们。如有可能，你最好使用流水线并发模型，因为它在以单线程模式顺序执行的程序中具有更少的开销，并且更好的符合底层硬件的工作原理。\n孰优孰劣 那么，哪种并发模型更好呢？\n通常情况下，答案取决于你的系统应该做什么。 如果你的工作自然并行，独立，无需共享状态，则可以使用并行工作模型来实现系统。但许多任务不是自然并行和独立的，对于这些类型的系统，我相信流水线并发模型比缺点有更多的优点，比并行工作模型更有优势。你甚至不需要自己编写所有的流水线路基础设施，像Vert.x这样的现代平台为你已经实现了很多。 就个人而言，我将探索在Vert.x等平台上运行的设计，以便我的下一个项目。我个人感觉JavaEE没有尽头。\n\u0026lt;–翻译结束!–\u0026gt;\n","date":"2017-08-05T00:10:11+08:00","permalink":"https://lucumt.info/post/translate/java-concurrency/concurrency-models/","tags":["Java","Java Concurrency"],"title":"4. [译]并发的模型"},{"categories":["Web编程","工具使用"],"contents":"由于业务要求，需要在利用MyEclipse中开发的Web项目中添加Birt报表统计功能，新建完一个report.rptdesign文件后双击该文件出现如下错误:\n错误信息提示MyEclipse无法打开Birt报表编辑器，对于此种情况，网上搜索相应的解决方案后一般都让我们给该项目添加报表支持，即选中该项目，然后右键MyEclipse -\u0026gt; Add Report Capabilities来对该项目添加Birt报表支持。此种方式虽能解决问题，但却同时额外的引入了系统内置的Birt jar包和相应的report文件夹，给我们的项目造成了一定的干扰。\n分析上述添加完Birt报表支持的项目文件后，可发现与普通的Java Web项目相比 .project文件在natures下面多了一个 com.genuitec.eclipse.reporting.reportnature的配置项，而该配置项正是用于在项目中支持Birt报表操作。据此，我们可以采用另外一个方式来解决在MyEclipse中无法打开Birt报表的问题：\n将 com.genuitec.eclipse.reporting.reportnature配置项添加到当前项目.project文件的natures配置项下面\n如下所示:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;projectDescription\u0026gt; \u0026lt;name\u0026gt;teq\u0026lt;/name\u0026gt; \u0026lt;comment\u0026gt;\u0026lt;/comment\u0026gt; \u0026lt;projects\u0026gt; \u0026lt;/projects\u0026gt; \u0026lt;buildSpec\u0026gt; ... \u0026lt;/buildSpec\u0026gt; \u0026lt;natures\u0026gt; \u0026lt;!--添加报表支持 --\u0026gt; \u0026lt;nature\u0026gt;com.genuitec.eclipse.reporting.reportnature\u0026lt;/nature\u0026gt; \u0026lt;nature\u0026gt;com.genuitec.eclipse.j2eedt.core.webnature\u0026lt;/nature\u0026gt; \u0026lt;nature\u0026gt;org.eclipse.jdt.core.javanature\u0026lt;/nature\u0026gt; \u0026lt;nature\u0026gt;org.eclipse.wst.jsdt.core.jsNature\u0026lt;/nature\u0026gt; \u0026lt;/natures\u0026gt; \u0026lt;/projectDescription\u0026gt; 利用此种方式既可解决无法打开Birt报表问题，又能避免添加冗余的jar文件和文件夹，给我们的开发省去不必要的麻烦。\n","date":"2017-04-07T10:47:28+08:00","permalink":"https://lucumt.info/post/web/cannot-open-birt-report-in-myeclipse-project/","tags":["Birt"],"title":"在MyEclipse项目中不能打开birt报表的解决方法"},{"categories":["Java编程","翻译"],"contents":"本文翻译自Java Concurrency / Multithreading Costs\n从一个单线程程序切换为多线程程序在给我们带来好处的同时也会产生一些额外的成本，不要因为会使用多线程就将一个程序变为多线程实现。在准备使用多线程时，我们应该有一个清楚的认识：使用多线程带来的好处大于其成本，当有不确定时，我们应该尝试度量应用程序的性能和响应性来决定是否采用多线程，而不是靠猜来决定。\n更复杂的设计 尽管多线程应用程序的某些部分比单线程应用程序更简单，但其它部分却更为复杂。在执行通过多线程访问共享数据时需要特别注意，同时多线程间的交互也不是那么简单,由不正确的线程同步引起的错误可能会非常难以检测、复现和修复。\n上下文切换开销 当CPU从执行一个线程切换到执行另外一个线程时，CPU需要保存当前线程的本地数据，程序指针等，并加载下一个线程的本地数据，程序指针等来执行线程，这种切换被称作上下文切换，CPU从一个线程的上下文中执行切换到在另一个线程的上下文中执行。\n上下文切换的代价并不便宜，在线程间要避免不必要的切换。可以在维基百科上阅读 Context switch来了解更多关于上下文切换的知识。\n加重资源消耗 线程需要计算机的一些资源才能运行，除了CPU时间之外，线程需要一些内存来维护其本地堆栈，它也可能会占用操作系统的一些资源来管理该线程。我们可以尝试创建100个什么操作也没有的等待线程来看看在运行这些线程时应用程序需要多少内存。\n\u0026lt;–翻译结束!–\u0026gt;\n","date":"2017-04-01T21:57:30+08:00","permalink":"https://lucumt.info/post/translate/java-concurrency/multithreading-costs/","tags":["Java","Java Concurrency"],"title":"3. [译]多线程的成本"},{"categories":["Java编程","翻译"],"contents":"本文翻译自Java Concurrency / Multithreading Benefits\n尽管多线程给程序实现带来了挑战，但由于多线程的一些优点我们仍然在使用它，其中的一些优点如下：\n更好的资源利用 在某些场景可以简化程序设计 提高程序响应 更好的资源利用 假设我们有一个程序从本地磁盘中读取和处理文件，若读取和处理一个文件的耗时分别为5秒钟和2秒钟，则读取处理2个文件的耗时如下：\n5 seconds reading file A 2 seconds processing file A 5 seconds reading file B 2 seconds processing file B ----------------------- 14 seconds total//串行读取时总共耗时14秒 当从磁盘读取文件时CPU的大部分时间都花费在等待从磁盘读取数据，在此期间CPU大部分时间都处于空闲状态。这些空闲时间可以做一些其它的事情，通过改变操作顺序，CPU可以被更好的利用，如下面的列子：\n5 seconds reading file A 5 seconds reading file B \u0026#43; 2 seconds processing file A 2 seconds processing file B ----------------------- 12 seconds total//并行读取时总共耗时12秒 在上面的例子中，CPU先等待读取第一个文件，然后开始读取第二个文件，在读取第二个文件的同时，CPU可以同时处理第一个文件。请记住，当等待从磁盘读取数据时，CPU大部分时间处于空闲状态！\n通常情况下，CPU在等待IO响应时可以做一些其它事情，这不仅适用于磁盘IO操作，也适用于网络IO操作，或者读取用户输入,网络和磁盘IO操作通常比CPU和内存IO操作慢很多。\n简化程序设计 如果在单线程应用程序中编程实现上述读取和处理文件的功能，就必须跟踪每个文件的读取和处理状态。相反的，在多线程程序中我们可以开启两个线程，每个线程读取和处理同一个文件。每个线程在等待从磁盘读取文件时都会被阻塞，但在等待的同时，其它线程可以利用CPU来处理已经读取的文件。这样能够是的CPU和磁盘都被更好的使用，而且由于每个线程只需要跟踪一个文件，编程实现也会变得更简单。\n提高程序响应 将单线程应用变为多线程应用的另一个常见目的是获得更快的响应。假设有一个服务器程序在某个端口监听请求，当接收到一个请求后，服务器处理该请求，处理完后再继续监听，该循环监听服务器的设计草图如下：\nwhile(server is active){ listen for request //监听请求 process request//处理请求 } 如果某个请求需要花费很长的时间来处理，那么在此期间其它的客户端就不能向此服务器发送请求，只有当服务器处于监听状态时才能够接收请求。\n一种替代方案是让监听线程将接收到的请求发送给worker线程处理，然后立即恢复监听，worker线程对请求进行处理并给客户端发送回复，此种服务器的设计草图如下：\nwhile(server is active){ listen for request //监听请求 hand request to worker thread//将接收到的请求发送给worker线程处理 } 在这种方式下，服务器线程会迅速返回监听，因而更多的客户端可以给服务器发送请求，服务器的响应也得以提高。\n该方法同样适用于桌面应用程序，如果你点击一个按钮来开启一个长任务，而执行该任务的线程是更新窗口、按钮等部件的线程，那么在该任务运行期间，该桌面程序将无法响应其它操作。相反的，可以将该任务移交给一个worker线程，当worker线程处理该任务时，更新窗口的线程处于空闲状态，可以响应其它用户请求，当worker线程执行完任务时通知更新窗口线程，该窗口线程根据执行结果来更新程序。因而利用worker线程设计实现的程序对用户更具有响应性。\n\u0026lt;–翻译结束!–\u0026gt;\n","date":"2017-04-01T13:18:43+08:00","permalink":"https://lucumt.info/post/translate/java-concurrency/multithreading-benefits/","tags":["Java","Java Concurrency"],"title":"2. [译]多线程的优点"},{"categories":["Java编程","翻译"],"contents":"本文翻译自Java Concurrency / Multithreading Tutorial\n最开始一台电脑只有单个CPU，只能一次运行一个任务，之后出现的多任务处理则意味着计算机在同一时间可以处理多个程序（也可以称之为任务或进程），虽然它们并不是真正的并发。由于单个CPU被不同的程序共用，操作系统需要在程序运行过程中不停地切换CPU，在短暂的执行一个程序后就立即切换到下一个程序。\n多任务处理给软件开发人员提出了新的挑战，程序不能再假定拥有CPU所有的可用时间、内存和其它计算机资源，一个好的程序应该及时释放所有不需要使用的资源，以便其它程序可以使用它们。 之后出现的多线程则意味着可以在同一个程序里面执行多个线程，每一个执行的线程可以被认为是CPU在执行当前程序，当在同一个程序里面执行多个线程时，看起来像是拥有多个CPU在执行该程序。\n多线程虽然是提高某些类型程序性能的良方，但是多线程比多任务更具有挑战性。由于这些线程执行的是相同的程序，因此它们同时读写相同的内存，这可能会导致在单线程中不会出现的错误结果。某些错误结果不会出现在单CPU中机器中是由于两个线程不可能同时执行。现在的电脑大都拥有多核甚至多CPU，这意味着多个不同的线程可以被不同的内核或CPU同时执行。\n如果一个线程读取一个内存地址同时另一个线程向其写入信息，第一个线程在读取完成时会得到什么值呢？旧的值还是被第二个线程写入的新值？亦或是这两个值得混合？若两个线程同时向一个内存地址写入信息，当这两个线程运行完毕时，最终的值会是什么呢？是第一个线程写入的值还是第二个线程写入的值？亦或是这两个线程写入值的混合？\n在缺少适当措施的情况下，上述的任意一种结果都可能出现，程序的运行结果甚至不可预测，每一次的执行结果可能都不同。因此怎么处理多线程对于软件开发人员很重要，这意味着我们需要学习如何控制线程来访问共享资源如内存、文件、数据库等，而这正是本系列教程所要阐述的主题之一。\nJava中的多线程和并发 Java是最先让多线程对开发人员变得简单的程序语言之一，Java在最开始的时候就已经具备了多线程的能力，因此Java开发人员经常面临上文所述的并发问题。这正是我编写本系列Java并发教程的原因，作为自己的笔记以及其他可能从中获益的Java开发人员。\n本教程将主要关注于Java中的多线程，但其中的一些多线程问题与多任务和分布式系统系统中出现的问题类似，因此在本教程中可能会出现对多任务和分布式系统的引用。并发不等于多线程，它们是不同的概念。\nJava并发在2015的现状和展望 自从第一本Java并发书籍问世之后，关于并发架构和设计领域已经发生了很多变化，Java5甚至提供了concurrency工具包。新的类似于Vert.x、Play/Akka和Qbit的异步无共享平台和API已经出现。这些平台使用了一个不同于标准Java/JEE并发的模型来处理线程、共享内存和锁。新的无阻塞并发算法已经公开，类似于LMax Disrupter这样的非阻塞工具也已经添加到我们的工具箱。在Java7中通过Fork和Join框架引入了并行性功能编程，并在Java8中引入了流相关的API。\n所有这些新的进展让我觉得是时候编更新本系列的Java并发教程，因此本教程再一次处于编写中状态，新的教程会在时间允许编写时发布。\n\u0026lt;–翻译结束!–\u0026gt;\n","date":"2017-03-30T14:49:08+08:00","permalink":"https://lucumt.info/post/translate/java-concurrency/java-concurrency-multithreading-tutorial/","tags":["Java","Java Concurrency"],"title":"1. [译]Java多线程与并发教程"},{"categories":["Go编程","工具使用"],"contents":"在学习Golang时，自己最开始用的是Eclipse中的goclipse插件来进行Golang编程，但其对Golang的支持不是太好，如代码格式化、自动导入引用包等都无法直接在Eclipse中使用，并且其自动提示功能也没有像Java那么强，于是转用Intellij IDEA安装Golang插件来替代使用，安装完插件后的Intellij IDEA对Golang的支持在各方面都很令人满意，唯独引入本地包的支持不太好用。经过一阵摸索自己找出了解决方案，先记录下。\n在Eclipse中引用Golang本地包 若我们采用的是goclipse来开发Golang ,则在其中引用本地包很简单，和引用Java包类似。如下图所示，假设 src是源代码所在的目录，在src的sec文件夹下有一个名为calculate.go的文件，其中有一个名为Add的函数用于计算两个整数的相加之和。\n若要在主程序main方法中调用Add方法，先通过import引入该文件的包名import service，然后通过包名调用该方法service.Add(1,2)，如下图所示，可以看出在eclipse中引用Golang本地包与引用Java包没有太大的区别，都是将包文件放到src源文件夹下，然后通过包名来引用。\n也可以通过直接导入该包所在的文件夹的名称来调用该方法，此时需要将import service改为import sec，如下图所示\n可以看出在Eclipse中导入Golang本地包时有两种方法： 通过import导入包名或通过import导入该包对应的文件夹，这两种方法均可使程序正常运行。\n在Intellij IDEA中引用Golang本地包 下面2张图为在IDEA中建立的对应项目，图中gproject是一个项目，gotest是一个模块，我们在gotest下建立相关的测试文件。\n在上述代码中我们是通过import service的方式来导入相应包的，由于IDEA对Golang很强，从图中可以看出service的颜色与其它导入包的颜色不一致，当把鼠标移动到service上时会提示Cannot resolve file 'service' ，直接运行时，会出现如下图所示cannot find package错误，将import service修改为import sec时，会出现同样的错误，可以看出在idea中默认不支持直接导入本地 Golang包。 从报错信息可以看出，程序在运行时先去 GOROOT 去搜索导入包，然后去 GOPATH 寻找导入包，最后在当前项目模块下寻找导入包，但实际上不存在D:\\program\\IntelliJ IDEA 2016.2.1\\workspace\\gproject\\gotest\\src\\service这个目录，故而程序报错，不能正常运行。\n解决该问题的关键是明白GOROOT和GOPATH的作用，根据官方文档的解释GOPATH的主要作用是存放文件以便Golang程序编译时可以进行搜索引用，GOPATH可以设置一个值或多个值，多个值之间以分号隔开。很明显只要我们将本地Golang加入到GOPATH中即可在IDEA中正常运行该程序。\n如下图所示，在IDEA中依次选择 File-\u0026gt;Settings-\u0026gt;Language\u0026amp;Frameworks-\u0026gt;Go-\u0026gt;Go Libraries ，会出现如下图所示的配置Golang 库的界面，在该界面可以添加Golang本地包所在的路径，该界面包含3个不同作用范围的配置方式：Global libraries、Project libraries和 Module libraries，其中Global libraries的配置对所有项目生效为全局配置，Project libraries的配置对整个项目生效，Module libraries的配置只对模块生效，可以看出在Global libraries默认包含了GOPATH。根据实际使用的需求我们可Z选择把本地包设置在Project libraries还是Module libraries中。\n本文的程序都是在gotest模块下，故将其添加到Module libraries下，添加完的结果如下所示：\n将本地包添加到模块库之后，还需要在go文件中将导入包的语句设置为import sec，不能设置为import service，然后该Golang程序即可正常运行。\n可以看出，不同于goclipse，在IDEA中只能使用通过import导入该包对应的文件夹来导入本地Golang包，至于原因还需要进一步研究。\n利用Goclipse时无法运行程序的解决方法 在使用goclipse运行 Golang程序时，偶尔会出现程序无法编译和运行的情况，这种情形一般都是src没有被设置成源代码目录造成的，此时可以通过如下图所示的方法，将src目录添加源代码目录。在Eclipse中选中该项目然后点击 Properties ，会出现项目属性配置界面，点击 Go Project Configuration ，通过 Add Folder 可以将src添加到源代码中，之后程序即可正常运行。\n更新 在本文写作的时(2017年3月份)，jetbrain官方出版了GoLand，建议在条件许可的情况下优先使用GoLand\n支持正版，从我做起！\n","date":"2017-03-05T14:04:43+08:00","permalink":"https://lucumt.info/post/golang/import-local-package-in-intellij-idea/","tags":["Go","Intellij IDEA"],"title":"在Intellij IDEA中引用Golang本地包"},{"categories":["算法","Java编程"],"contents":"之前面试时遇到一个算法题:\n假定两个矩形各条边都是平行于坐标轴，已知k、l、m、n分别为其中一个矩形左下角和右上角x轴、y轴坐标，p、q、r、s分别为另一个矩形的左下角和右上角x轴、y轴坐标，求这两个矩形的总面积，当矩形相交时要减去相交的面积。\n此题利用常规的枚举法很复杂，但利用排除法和归纳法却能很快解决，故先记录下。\n很明显，此题的重点在于如何判断矩形是否相交以及检测相交形成的新矩形面积，当不相交时总面积直接为两个矩形的面积之和，当相交时需要减去相交矩形的面积，由于题目已经告诉了矩形的左下角和右上角坐标已知，问题又转化为在相交时如何计算相交矩形的左下角和右上角的坐标。\n最开始我想通过常规的枚举法把矩形相交的所有情况都列出来，在稿纸上简单的比划后，发现采用枚举的方式太复杂，矩形相交理论上有下图所示的16种组合方式，短时间内很难一一列举出来，实际编程中不仅代码量大还很容易产生遗漏:\n两个矩形边角相交以及完全包含\n矩形横向相交\n矩形纵向相交\n矩形被完全包含\n排除枚举方法之后，只能对其进行分析找出通用的处理方式。下图展示了在相交矩形的左下角和右上角的位置，仔细分析后便可发现相交矩形的左下角x,y坐标是两个矩形左下角x,y坐标中取较大值，相交矩形的右上角x,y坐标是两个矩形右上角x,y坐标中取较小值。\n通过分析归纳之后，我们将之前的16种相交情况统一为1个表达式，而这个表达式在编程时是很容易实现的，下面的代码展示了如何利用该表达式计算相交矩形的坐标以及其面积。\npublic static int calculateIntersectArea(int k, int l, int m, int n, int p,int q, int r, int s) { int leftDownX = 0, leftDownY = 0, rightUpX = 0, rightUpY = 0; leftDownX = k \u0026gt; p ? k : p; leftDownY = l \u0026gt; q ? l : q; rightUpX = m \u0026lt; r ? m : r; rightUpY = n \u0026lt; s ? n : s; return (rightUpX - leftDownX) * (rightUpY - leftDownY); } 寻找出如何计算相交矩形的面积之后，还需要解决一个问题:上述实现只有在矩形相交时才正确，当矩形不相交时计算结果错误，为此需要找出一个方法判定两个矩形是否相交。若利用枚举方法同样会有前述的16种情形需要考虑，同样很复杂，显然枚举方法不适合使用。换一种思路：如果把矩形不相交的情形排除掉，那么剩下的情形就是矩形相交了！，而矩形不相交则相对容易多了，假设这两个矩形分别为A和B，则它们不相交一共有如下图所示的4种情况：\n相应的代码实现如下：\npublic static boolean isIntersect(int k, int l, int m, int n, int p, int q, int r, int s) { boolean nointersect = false; // B在A的上面 nointersect = q \u0026gt; n; // B在A的下面 nointersect = l \u0026gt; s; // B在A的左侧 nointersect = r \u0026lt; k; // B在A的右侧 nointersect = m \u0026lt; p; return !nointersect; } 利用上述2个判断方法，可以方便准确的计算出两个矩形在相交时的总面积，相应的代码如下:\npublic static int solution(int k, int l, int m, int n, int p, int q, int r, int s) { int widthA = m - k; int heightA = n - l; int areaA = widthA * heightA; int widthB = r - p; int heightB = s - q; int areaB = widthB * heightB; int totalArea = areaA \u0026#43; areaB; boolean hasIntersect = isIntersect(k, l, m, n, p, q, r, s); if (hasIntersect) { totalArea -= calculateIntersectArea(k, l, m, n, p, q, r, s); } return totalArea; } 分析解决这个问题给我最深的感触是：有时候若某一类问题用枚举实现很复杂时，尝试去分析其中的规律，找出通用的解决方法，不仅在算法方面，或许在生活中其它方面也适用吧！\n","date":"2017-02-26T19:26:33+08:00","permalink":"https://lucumt.info/post/algorithm/calculate-total-area-of-two-rectangles/","tags":null,"title":"计算两个平行于坐标轴的矩形相交的面积"},{"categories":["Web编程"],"contents":"由于项目需要，最近使用了在html5中播放视频的功能，期间遇到了几个坑，先简单记录下。\n在html5页面中播放视频 如何在html5页面中嵌入视频的代码在网上很容易直接搜索到，典型的代码如下所示：\n\u0026lt;video width=\u0026#34;320\u0026#34; height=\u0026#34;240\u0026#34; controls=\u0026#34;controls\u0026#34;\u0026gt; \u0026lt;source src=\u0026#34;movie.mp4\u0026#34; type=\u0026#34;video/mp4\u0026#34;/\u0026gt; Your browser does not support the video tag. \u0026lt;/video\u0026gt; 之后的效果显示如下，从图中我们可以看出该视频播放界面包含快进 、音量调整 和全屏播放这几个按钮\n在iframe中不能全屏播放视频 项目中好多地方都用iframe来嵌套html页面，最开始我是用类似如下代码在被iframe包含的页面中嵌入前面的视频播放代码， 发现显示出来的视频播放器没有全屏播放按钮，通过升级浏览器版本和清除缓存等方法依然不奏效。搜索stackoverflow找到一个类似的问题How to make a video fullscreen when it is placed inside an iframe?，阅读后发现只需要将iframe修改成\u0026lt;iframe … allowfullscreen=\u0026quot;true\u0026quot; webkitallowfullscreen=\u0026quot;true\u0026quot; mozallowfullscreen=\u0026quot;true\u0026quot;\u0026gt;即可\n\u0026lt;iframe\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head /\u0026gt; \u0026lt;body\u0026gt; \u0026lt;video width=\u0026#34;320\u0026#34; height=\u0026#34;240\u0026#34; controls=\u0026#34;controls\u0026#34;\u0026gt; \u0026lt;source src=\u0026#34;movie.mp4\u0026#34; type=\u0026#34;video/mp4\u0026#34;/\u0026gt; Your browser does not support the video tag. \u0026lt;/video\u0026gt; \u0026lt;body\u0026gt; \u0026lt;/html\u0026gt; \u0026lt;/iframe\u0026gt; 隐藏声音调整按钮 有些演示视频只有图像没有声音，为了避免对使用者造成不必要的干扰，可以将声音播放按钮屏蔽掉，由于自己项目只支持基于webkit内核的Chrome浏览器访问，通过Google之后在 stackoverflow找到 Why do no user-agents implement the CSS cursor style for video elements这篇文章，其中列出了播放视频时相关控制按钮的css类：\nvideo::-webkit-media-controls-panel video::-webkit-media-controls-play-button video::-webkit-media-controls-volume-slider-container video::-webkit-media-controls-volume-slider video::-webkit-media-controls-mute-button video::-webkit-media-controls-timeline video::-webkit-media-controls-current-time-display video::-webkit-full-page-media::-webkit-media-controls-panel video::-webkit-media-controls-timeline-container video::-webkit-media-controls-time-remaining-display video::-webkit-media-controls-seek-back-button video::-webkit-media-controls-seek-forward-button video::-webkit-media-controls-fullscreen-button video::-webkit-media-controls-rewind-button video::-webkit-media-controls-return-to-realtime-button video::-webkit-media-controls-toggle-closed-captions-button 为了屏蔽掉声音播放按钮，我们只需使用video::-webkit-media-controls-volume-slider和video::-webkit-media-controls-mute-button这两个属性即可，相应的css代码如下：\n/**隐藏视频音量大小调整控件**/ .no_sound_style\u0026gt;video::-webkit-media-controls-volume-slider{ display:none; } /**隐藏视频音量喇叭**/ .no_sound_style\u0026gt;video::-webkit-media-controls-mute-button{ display:none; } 对应的显示效果如下图所示，可以看到音量喇叭和音量调整空间都消失不见\n","date":"2016-10-30T19:48:17+08:00","permalink":"https://lucumt.info/post/web/show-video-in-html5-page/","tags":["html5"],"title":"在iframe嵌套的html5中播放视频时全屏显示和取消音量调整"},{"categories":["算法","Java编程","位运算"],"contents":"变量交换是编程中经常使用的功能，本文记录几种不通过不添加第三方变量来交换两个变量的实现方式。\n交换变量通常采用类似如下代码：\nint a = 3, b = 4, temp; temp = a; a = b; b = temp; System.out.println(a); System.out.println(b); 上述代码实现和理解起来都很容易，除此之外还有其它的实现方式，本文以非0的int变量为例，简单记录下自己了解的相关实现。\n加减法实现 int a = 3, b = 4; a = a \u0026#43; b; b = a - b; a = a - b; System.out.println(a); System.out.println(b); 上述代码可以进一步精简如下:\nint a = 3, b = 4; a = a \u0026#43; b - (b = a); System.out.println(a); System.out.println(b); 乘除法实现 int a = 3, b = 4; a = a * b; b = a / b; a = a / b; System.out.println(a); System.out.println(b); 位运算实现 int a = 3, b = 4; a = a ^ b; b = a ^ b; a = a ^ b; System.out.println(a); System.out.println(b); ","date":"2016-08-12T11:03:09+08:00","permalink":"https://lucumt.info/post/algorithm/swap-two-variables-without-temp-variable/","tags":["bit"],"title":"不通过第三方变量来交换两个变量的值"},{"categories":["Java编程","MyBatis系列"],"contents":"在利用 MyBatis进行多条数据插入时，为了提高性能我们可能会使用批量插入的功能来实现。示例代码如下:\nSQL配置文件:\n\u0026lt;insert id=\u0026#34;addAuthorityRoleBatch\u0026#34; parameterType=\u0026#34;List\u0026#34;\u0026gt; INSERT INTO system_authority_role(role_id,authority_id) VALUES \u0026lt;foreach collection=\u0026#34;list\u0026#34; item=\u0026#34;authRole\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; (#{authRole.roleId},#{authRole.authorityId}) \u0026lt;/foreach\u0026gt; \u0026lt;/insert\u0026gt; Java代码:\npublic void adjustRoleAuth(String roleId, String authIdsStr) { authRoleDao.deleteAuthorityRoleByRole(roleId); String[] authIds=authIdsStr.split(\u0026#34;;\u0026#34;); List\u0026lt;AuthorityRoleModel\u0026gt; authRoleList=new ArrayList\u0026lt;AuthorityRoleModel\u0026gt;(); for(String authId:authIds){ authRoleList.add(new AuthorityRoleModel(roleId,authId)); } authRoleDao.addAuthorityRoleBatch(authRoleList); } 上面的代码大多数时候可以正常运行，但是偶尔会出现如下异常：\n### SQL: INSERT INTO system_authority_role(role_id,authority_id) VALUES ### Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \u0026#39;\u0026#39; at line 2 ; bad SQL grammar []; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \u0026#39;\u0026#39; at line 2 at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:233 上面的异常堆栈信息显示现在执行的MySQL语句发生了语法错误，INSERT VALUE后面的值为空，由于该问题有时候发生，有时候不发生，给我们分析该问题造成了一定的困扰。该问题产生的根源为批量插入时的集合数据为空，使得SQL配置文件中的foreach循环没有执行，从而导致SQL语句不完整，进而产生该异常。 为了解决该问题我们可以批量插入之前先检查List数据集合是否为空，只有在不为空的情况下才进行插入，如下所示：\npublic void adjustRoleAuth(String roleId, String authIdsStr) { authRoleDao.deleteAuthorityRoleByRole(roleId); String[] authIds=authIdsStr.split(\u0026#34;;\u0026#34;); List\u0026lt;AuthorityRoleModel\u0026gt; authRoleList=new ArrayList\u0026lt;AuthorityRoleModel\u0026gt;(); for(String authId:authIds){ authRoleList.add(new AuthorityRoleModel(roleId,authId)); } if(authRoleList.size()\u0026gt;0){//只有在List不为空时才进行插入 authRoleDao.addAuthorityRoleBatch(authRoleList);\t} } ","date":"2016-05-30T18:20:37+08:00","permalink":"https://lucumt.info/post/mybatis/mybatis-batch-insert-exception/","tags":["Java","MyBatis"],"title":"mybatis batch insert exception的解决方法"},{"categories":["Java编程","Spring系列"],"contents":"文件的上传和下载是Web系统中的一个很普通的功能，实现的方式也有很多种，如利用 java.io下面的各种IO类自己实现，或者利用 Commons IO包中的FileUtils、 IOUtils 类中封装好的方法直接调用。由于目前我所开发的系统采用了 SpringMVC来作为项目的MVC实现，所以很自然的采用 SpringMVC内置的API进行文件的下载，但在实际使用过程中发现其对大文件的下载支持不太好，现把解决方案记录如下：\n@RequestMapping(\u0026#34;downloadRequireDocument\u0026#34;) public ResponseEntity\u0026lt;byte[]\u0026gt; downloadRequireDocument(String fileId,String fileName,String fileType, HttpServletRequest request) throws IOException{ String filePath=fileName\u0026#43;fileId\u0026#43;\u0026#34;.\u0026#34;\u0026#43;fileType; HttpHeaders headers=new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_OCTET_STREAM); headers.setContentDispositionFormData(\u0026#34;attachment\u0026#34;,URLEncoder.encode(fileName,\u0026#34;UTF-8\u0026#34;)\u0026#43;\u0026#34;.\u0026#34;\u0026#43;fileType); File downloadFile=new File(request.getSession().getServletContext().getRealPath(File.separator)\u0026#43;filePath); return new ResponseEntity\u0026lt;byte[]\u0026gt;(FileUtils.readFileToByteArray(downloadFile),headers,HttpStatus.CREATED); } 该段代码在下载小文件时可以正常工作，但是当要下载的文件很大时（如几百M或上G），就会发生如下错误：\njava.lang.OutOfMemoryError: Java heap space at org.apache.commons.io.output.ByteArrayOutputStream.toByteArray(ByteArrayOutputStream.java:271) at org.apache.commons.io.IOUtils.toByteArray(IOUtils.java:219) at org.apache.commons.io.FileUtils.readFileToByteArray(FileUtils.java:1136) 去网上搜索java.lang.OutOfMemoryError: Java heap space 这个错误时，一般都建议我们在tomcat中添加如下类似设置来提高JVM的配置:\nset JAVA_OPTS=%JAVA_OPTS% -server -Xms800m -Xmx800m -XX:MaxNewSize=256m -XX:MaxPermSize=256m\n但即使按照把上面的参数配置都扩大一倍，在下载更大的文件时还是会遇到java.lang.OutOfMemoryError: Java heap space这个错误，上面的解决方法治标不治本。分析下异常堆栈可以发现问题产生的根源在于at org.apache.commons.io.FileUtils.readFileToByteArray(FileUtils.java:1136)这行代码，FileUtils.readFileToByteArray会把文件一次性读入内存中，要下载的文件越大，需要占用的内存也越大，当文件的大小超过JVM和Tomcat的内存配置时，OutOfMemoryError这个问题就会不可避免的发生。\n弄清产生该问题的原因之后，解决的方法也很简单：不利用Commons IO把文件一次性读入内存，而是利用普通的文件输出流按字节分段写入文件，把占用的内存固定在一个指定的范围内，从根本上避免内存占用过高的问题,替代的代码如下:\n@RequestMapping(\u0026#34;downloadRequireDocument\u0026#34;) public void downloadRequireDocument(String fileId,String fileName,String fileType, HttpServletRequest request,HttpServletResponse response) throws IOException { String filePath = request.getSession().getServletContext().getRealPath(File.separator)\u0026#43;fileName\u0026#43;\u0026#34;.\u0026#34;\u0026#43;fileType; fileName = URLEncoder.encode(fileName.trim(),\u0026#34;UTF-8\u0026#34;)\u0026#43;\u0026#34;.\u0026#34;\u0026#43;fileType; response.setHeader(\u0026#34;Content-Disposition\u0026#34;,\u0026#34;attachment;filename=\u0026#34;\u0026#43;fileName); InputStream is = new FileInputStream(filePath); int read =0; byte[] bytes = new byte[2048]; OutputStream os = response.getOutputStream(); while((read = is.read(bytes))!=-1){//按字节逐个写入，避免内存占用过高 os.write(bytes, 0, read); } os.flush(); os.close(); is.close(); } ","date":"2016-03-20T16:41:29+08:00","permalink":"https://lucumt.info/post/spring/spring-mvc/download-big-file-using-springmvc/","tags":["Java","Spring","SpringMVC"],"title":"利用SpringMVC下载大文件时内存溢出的处理"},{"categories":["Java编程","Spring系列","单元测试"],"contents":"在进行Java程序开发时，我们偶尔会被要求使用JUnit进行单元测试来确保我们所写的程序逻辑是正确的。一个良好的单元测试应该具备 覆盖度高，可重复执行,单一性等特点。本文主要关注可重复执行，在Web开发中，大部分方法都会使数据库的记录发生变化，为了能够重复执行，必须利用数据库事务来进行回滚从而达到重复执行的目的。最原始的方法是利用 java.sql.Connection类的 commit() 或 rollback() 方法来在每个单元测试方法中手动的进行提交或回滚，此种方式使得单元测试代码嵌入了与实际业务逻辑无关的数据库操作事务控制代码。利用Spring和JUnit通过注解的方式我们可以很容易的对单元测试中的数据库操作进行事务控制。\n所有方法都回滚 在该单元测试类的开头加上 @TransactionConfiguration(defaultRollback=true) 可以确保该类中的所有方法在执行完毕之后默认都进行回滚。\npackage com.hirain.testmanagement.service.test; import static org.junit.Assert.assertEquals; import java.util.Date; import javax.inject.Inject; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.test.context.ContextConfiguration; import org.springframework.test.context.junit4.SpringJUnit4ClassRunner; import org.springframework.test.context.transaction.TransactionConfiguration; import org.springframework.transaction.annotation.Transactional; import com.hirain.testmanagement.common.util.StringUtil; import com.hirain.testmanagement.model.ProjectModel; import com.hirain.testmanagement.service.IProjectService; @RunWith(SpringJUnit4ClassRunner.class) @Transactional @TransactionConfiguration(defaultRollback=true) @ContextConfiguration(\u0026#34;classpath:spring/spring-context-*.xml\u0026#34;) public class ProjectServiceTest{ @Inject private IProjectService projectService; @Test @Transactional public void testAddProject(){ ProjectModel pModel=new ProjectModel(); String projectId=StringUtil.getUUID(); pModel.setId(projectId); pModel.setName(\u0026#34;汽车电子测试管理系统\u0026#34;); pModel.setAlias(\u0026#34;INTA\u0026#34;); pModel.setLastModifyTime(new Date()); pModel.setLastModifyUser(\u0026#34;6e518d0819d14148ae489f76dad80967\u0026#34;); pModel.setCreateTime(new Date()); pModel.setCreateUser(\u0026#34;cface18d5fac11e28c68c89cdca4c015\u0026#34;); projectService.addProject(pModel); assertEquals(\u0026#34;Add project failed!\u0026#34;,projectService.getProject(projectId).getName(),pModel.getName()); } } 指定方法回滚 若想只对某个特定的方法进行回滚，需要在该单元测试类的开头去掉 @TransactionConfiguration(defaultRollback=true) ，同时在对应的方法上加上注解声明 @Rollback(true) 即可达到目的。\npackage com.hirain.testmanagement.service.test; import static org.junit.Assert.assertEquals; import java.util.Date; import javax.inject.Inject; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.test.annotation.Rollback; import org.springframework.test.context.ContextConfiguration; import org.springframework.test.context.junit4.SpringJUnit4ClassRunner; import org.springframework.transaction.annotation.Transactional; import com.hirain.testmanagement.common.util.StringUtil; import com.hirain.testmanagement.model.ProjectModel; import com.hirain.testmanagement.service.IProjectService; @RunWith(SpringJUnit4ClassRunner.class) @Transactional @ContextConfiguration(\u0026#34;classpath:spring/spring-context-*.xml\u0026#34;) public class ProjectServiceTest{ @Inject private IProjectService projectService; @Test @Rollback(true) public void testAddProject(){ ProjectModel pModel=new ProjectModel(); String projectId=StringUtil.getUUID(); pModel.setId(projectId); pModel.setName(\u0026#34;汽车电子测试管理系统\u0026#34;); pModel.setAlias(\u0026#34;INTA\u0026#34;); pModel.setLastModifyTime(new Date()); pModel.setLastModifyUser(\u0026#34;6e518d0819d14148ae489f76dad80967\u0026#34;); pModel.setCreateTime(new Date()); pModel.setCreateUser(\u0026#34;cface18d5fac11e28c68c89cdca4c015\u0026#34;); projectService.addProject(pModel); assertEquals(\u0026#34;Add project failed!\u0026#34;,projectService.getProject(projectId).getName(),pModel.getName()); } } ","date":"2016-03-20T16:27:21+08:00","permalink":"https://lucumt.info/post/spring/spring-core/using-junit-in-spring/","tags":["Java","JUnit"],"title":"利用Spring和JUnit对数据库操作进行单元测试"},{"categories":["Java编程","Spring系列"],"contents":"利用Spring Security来管理我们的web程序时，通常需要在UserDetailsService接口中的loadUserByUsername方法中来初始化权限信息,但UserDetailsService一般用于登录验证，这也意味着用户的权限在登录过程中就会被计算出来。通常情况下由于用户的权限很少发生变化，在登录过程中计算出用户权限是合理的，但有些情况下，我们需要在中途来动态的改变用户的权限，此时我们可以利用Spring Security提供的API来实现。\n以我自己的项目为例，UserDetailsService接口中的loadUserByUsername具体实现如下：\n@Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { UserModel userModel=userDao.getUserByUsername(username); if(userModel==null){ throw new UsernameNotFoundException(username\u0026#43;\u0026#34; not exist!\u0026#34;); } List\u0026lt;GrantedAuthority\u0026gt; userAuthList=new ArrayList\u0026lt;GrantedAuthority\u0026gt;(); //查询出用户相关的所有权限并放入List中 List\u0026lt;AuthorityVO\u0026gt; authList=authorityDao.queryAuthorityByUserId(userModel.getId()); for(AuthorityVO authVO:authList){ userAuthList.add(new SimpleGrantedAuthority(authVO.getAuthName())); } //将查询出来的权限赋予用户 UserDetails userDetails=new User(userModel.getUsername(),userModel.getPassword(),true,true,true,true,userAuthList); return userDetails; } 上述代码会一次性的把用户权限查询出来然后放入特定的session中，但是UserDetailService方法一般只在用户登录web系统成功时才会被调用一次，使用范围较为局限，有时候我们需要在用户使用的过程中动态的改变用户的权限（譬如在我自己的项目中，当用户选中不同的项目之后，不同的项目对应不同的权限）。利用 Spring Security来管理权限信息时，用户的权限本质上是存储在一个 session中，只不过被Spring Security进行了进一步的封装而已。所以若想动态的改变用户的权限，我们只需要将用户的信息重新存储到 session中即可，具体代码如下所示：\nList\u0026lt;GrantedAuthority\u0026gt; authList=new ArrayList\u0026lt;GrantedAuthority\u0026gt;();//用于存储修改之后的权限列表 authList.add(new SimpleGrantedAuthority(\u0026#34;addUser\u0026#34;)); authList.add(new SimpleGrantedAuthority(\u0026#34;editUser\u0026#34;)); SecurityContext context=SecurityContextHolder.getContext(); UserDetails userDetails=(UserDetails) context.getAuthentication().getPrincipal(); Authentication auth=new UsernamePasswordAuthenticationToken(userDetails,userDetails.getPassword(),authList); context.setAuthentication(auth); //重新设置上下文中存储的用户权限 ","date":"2016-03-20T16:05:52+08:00","permalink":"https://lucumt.info/post/spring/update-authority-dynamic-using-spring-security/","tags":["Java","Spring","Spring Security"],"title":"利用Spring Security动态改变登录用户的权限"},{"categories":["Java编程","Spring系列","单元测试"],"contents":"编写单元测试时的注意事项 根据软件开发过程中的TDD理论，在我们编写自己的代码时，要尽量使得该代码能够进行单元测试。为了能够使得代码可以进行单元测试，我们在给接口或方法传入参数时要尽量传入简单参数，避免传入HttpServletRequest , ServletContext等和web上下文相关的复杂对象。但仍有部分情况下基于代码简洁性和可维护性的考虑，我们需要传入HttpServletRequest对象，此时对此类方法进行JUnit单元测试时会较为困难，本文介绍一种在Spring中通过Mock来模拟HttpServletRequest对象进行JUnit单元测试的方法。\n假设在HttpServletRequest中有一个userId字符串对象，我们想在queryUserById方法中调用该参数来获取用户信息，则正确的做法应如下所示:\nString userId = request.getAttribute(\u0026#34;userId\u0026#34;).toString();//先获取userId对象 queryUserById(userId);//然后将获取的userId传入对应方法 public User queryUserById(String userId){//相关该方法 User userModel = userDao.findById(userId); return userModel; } 请尽量避免使用第二种方式\nqueryUserById(request);//直接传入request对象 public User queryUserById(HttpServletRequest request){//相关方法 String userId = request.getAttribute(\u0026#34;userId\u0026#34;).toString();//在该方法内部获取userId User userModel = userDao.findById(userId); return userModel; } 若采用第一种方法，我们在进行单元测试时，可以很容易的自己制造一个String字符串来代表userId进行测试，但当采用第二种方法后，在进行单元测试时我们是比较难以模拟一个HttpServletRequest对象，从而影响我们的测试。\nSpring和Mock在单元测试中的使用 在某些方法中，为了减少代码量和提高程序的可读性，我们有时候需要直接传入HttpServletRequest或ServletContext对象，如果我们想对这种方法进行测试，可以利用Mock来模拟相关的对象。\n由于Spring自身已经整合了Mock相关的类，故在此处展示一个示例代码，以供参考:\nimport java.io.File; import org.junit.Test; import org.springframework.mock.web.MockHttpServletRequest; import org.springframework.mock.web.MockServletContext; public class SpringMockTest { @Test public void testHttpServletRequest(){ String realPath =\u0026#34;file:D:\\\\Java\\\\apache-tomcat-7.0.23\\\\webapps\\\\tmn\u0026#34;; //模拟ServletContext,同时初始化realPath，注意要有file:前缀否则会报错 MockServletContext context = new MockServletContext(realPath); //获取realPath System.out.println(context.getRealPath(File.separator)); //模拟HttpServletRequest MockHttpServletRequest request = new MockHttpServletRequest(context); //通过HttpServletRequest来获取realPath System.out.println(request.getSession().getServletContext().getRealPath(File.separator)); } } 注意:请在上下文路径的字符串前面加上file:前缀，否则程序会报错。如上面的程序，realPath的值应为 file:D:\\Java\\apache-tomcat-7.0.23\\webapps\\tmn ，若去掉file:前缀，改为 D:\\Java\\apache-tomcat-7.0.23\\webapps\\tmn ，则程序会报错。\n","date":"2016-03-19T22:43:47+08:00","permalink":"https://lucumt.info/post/spring/spring-mvc/using-mock-test-http-servlet-request/","tags":["Java","Spring","SpringMVC","JUnit"],"title":"在Spring中利用Mock对HttpServletRequest进行单元测试"},{"categories":["其它"],"contents":"Mediawiki是维基百科系统所采用的框架，适合于需要快速搭建知识分享的场合。采用Mediawiki生成的知识共享平台和维基百科的操作与使用类似，都支持采用Markdown语法来编辑。在有些时候，某些词条的内容很长，使得浏览器出现了滚动条，如果能仿照微博等网站添加一个回到顶部的功能，将会给我们的使用带来很大的便利，本文介绍一种实现方法：\n以 Mediawiki 管理员身份登录mediawiki,在搜索栏输入MediaWiki:Common.js,然后输入如下代码并保存：\n/* 此处的JavaScript将加载于所有用户每一个页面。 */ $(window).scroll(function(){ if($(window).scrollTop()\u0026gt;100){ $(\u0026#34;.back-to-top\u0026#34;).fadeIn(1000); }else{ $(\u0026#34;.back-to-top\u0026#34;).fadeOut(1000); } }); 在mediawiki\\skins\\Vector.php中的第252行添加如下代码：\n\u0026lt;div class=\u0026#34;back-to-top\u0026#34; onClick=\u0026#34;$(\u0026#39;html,body\u0026#39;).animate({scrollTop:0},500);\u0026#34;\u0026gt; \u0026lt;span\u0026gt;返回顶部\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; 在mediawiki\\skins\\vector\\screen.css的最后添加如下代码：\n.back-to-top { position: fixed; bottom: 6em; right: 3em; background-color: rgba(46, 46, 46, 0.8); text-align: center; padding: 5px 6px; color: #eee; -webkit-border-radius: 3px; -moz-border-radius: 3px; border-radius: 3px; cursor: pointer; display: none; } .back-to-top:hover { background: rgba(0, 221, 255, 0.8); } 当页面的高度超出限制时，就会出现“返回顶部”的悬浮框，效果图如下：\n","date":"2016-03-18T23:14:59+08:00","permalink":"https://lucumt.info/post/web/mediawiki-back-to-top/","tags":["Mediawiki"],"title":"Mediawiki添加回到顶部的方法"},{"categories":["Java编程","翻译"],"contents":"本文翻译自 Java Volatile Keyword\nJava关键字volatile用于将一个Java变量标记为在主内中存储，更准确的解释为：每次读取一个volatile变量时将从电脑的主内存中读取而不是从CPU缓存中读取，每次对一个volatile变量进行写操作时，将会写入到主内存中而不是写入到CPU缓存中。\n事实上，从Java5之后，volatile关键字不仅仅可以用来确保volatile变量是写入到主内存和从主内存读取数据，我会在下面的章节进行详细的介绍：\nVolatile变量可见性保证 Java中的volatile关键字确保了 volatile变量的修改在多线程中是可见的。这听起来有些抽象，接下来我将详细说明。\n在一个对非volatile变量进行操作的多线程应用，由于性能的关系，当对这些变量进行读写时，每个线程都可能从主线程中拷贝变量到CPU缓存中。如果你的电脑不止一个CPU，每个线程可能会在不同的CPU上运行。这意味着，每个线程都可能将变量拷贝到不同的CPU的CPU缓存中，如下图所示：\n对于非volatile变量而言，Java虚拟机(JVM)不能确保什么时候将数据从主内存读取到CPU缓存以及什么时候将CPU缓存的数据写入到主内存中。而这可能会引起一些问题，我将稍后解释。\n假设两个或更多的线程对下面这个包含一个计数器的共享变量拥有访问权限：\npublic class SharedObject { public int counter = 0; } 再次假设，只有Thread1会增加counter变量的值，但是Thread1和Thread2都能在任意时刻读取counter变量的值。\n如果couner变量没有声明为volatile将无法保证在何时把CPU缓存中的值写入主内存中。这意味着counter变量在CPU缓存中的值可能会与主内存中的值不一样，如下所示：\n造成线程不能获取变量最新值得原因为变量值没有被其它线程及时写回主内存中，这就是所谓的可见性问题。某个线程的更新对其它线程不可见。\n将counter变量声明为volatile之后，所有对counter变量的写操作会立即写入主内存中，同样，所有对counter变量的读操作都会从主内存中读取数据。下面的代码块展示了如何将counter变量声明为volatile ：\npublic class SharedObject { public volatile int counter = 0; } 因此定义一个volatile变量可以保证写变量的操作对于其它线程可见。\nVolatile先行发生原则 从Java5之后volatile关键字不仅能用于确保变量从主内存中读取和写入，事实上volatile关键字还有如下作用：\n如果线程A写入了一个volatile变量然后线程B读取了这个相同的volatile变量，那么所有在线程A写之前对其可见的变量，在线程B读取这个 volatile之后也会对其可见。 volatile变量的读写指令不能被JVM重排序（出于性能的考虑，JVM可能会对指令重排序如果JVM检测到指令排序不会对程序运行产生变化）。前后的指令可以重排序，但是volatile变量的读和写不能与这些重排序指令混在一起。任何跟随在volatile变量读写之后的指令都会确保只有在变量的读写操作之后才能执行。 上述说明需要更进一步的解释。\n当一个线程向一个volatile变量写操作，此时不仅这个volatile变量自身会写入主内存，所有这个volatile变量写入之前受影响发生改变的变量也会刷写入主内存。当一个线程向一个volatile变量读操作时它同样也会从主内存中读取所有和这个volatile变量一起刷写入主内存的变量。\n看看下面这个示例：\nThread A: sharedObject.nonVolatile = 123; sharedObject.counter = sharedObject.counter \u0026#43; 1; Thread B: int counter = sharedObject.counter; int nonVolatile = sharedObject.nonVolatile; 由于线程A在写操作volatile变量sharedObject.counter之前写操作非volatile变量sharedObject.nonVolatile，因而当线程A写操作变量sharedObject.counter后,变量sharedObject.nonVolatile和sharedObject.counter都被写入主内存。\n由于线程B以读取volatile变量sharedObject.counter开始，因而变量sharedObject.counter和变量sharedObject.nonVolatile都会被写入线程B所使用的CPU缓存中。当线程B读取sharedObject.nonVolatile变量时，它将能看见被线程A写入的变量。\n开发人员可以利用这个扩展的可见性来优化线程之间变量的可见性。不同于把每个变量都设置为volatile ，此时只有少部分变量需要声明为volatile 。下面是一个利用此规则编写的简单示例程序Exchanger ：\npublic class Exchanger { private Object object = null; private volatile hasNewObject = false; public void put(Object newObject) { while(hasNewObject) { //等待，不覆盖已经存在的新对象 } object = newObject; hasNewObject = true; //volatile写入 } public Object take(){ while(!hasNewObject){ //volatile读取 //等待，不获取旧的对象（或null对象） } Object obj = object; hasNewObject = false; //volatile写入 return obj; } } 线程A随时可能会通过调用put()方法增加对象，线程B随时可能会通过调用 take()方法获取对象。只要线程A只调用 put() ，线程B只调用take() ,这个Exchanger就可以通过一个volatile变量正常工作（排除 synchronized代码块的使用）。\n然而，JVM可能会重排序Java指令来优化性能，如果JVM可以通过不改变这些重排序指令的语义来实现此功能。如果JVM调换了put()和 take()中的读和写的指令，会发生什么呢？如果put()真的像下面这样执行会出现什么情况呢？\nwhile(hasNewObject) { //等待，不覆盖已经存在的新对象 } hasNewObject = true; //volatile写入 object = newObject; 请注意此时对于volatile变量hasNewObject的写操作会在新变量的实际设置前先执行，而这在JVM看来可能会完全合法。两个写操作指令的值不再依赖于对方。\n但是，对于执行指令重排序可能会损害object变量的可见性。首先，线程B可能会在线程A对object真实的写入一个值到object之前读取到hasNewObject的值为true。其次,现在甚至不能保证什么时候写入object的新值会刷写入主内存（好吧，下次线程A在其它地方写入 volatile变量。。。）\n为了阻止上面所述的这种情况发生，volatile关键字提供了一个 先行发生原则。先行发生保证确保对于volatile变量的读写指令不会被重排序。程序运行中前后的指令可能会被重排序，但是volatile读写指令不能和它前后的任何指令重新排序。\n看看下面这个例子：\nsharedObject.nonVolatile1 = 123; sharedObject.nonVolatile2 = 456; sharedObject.nonVolatile3 = 789; sharedObject.volatile = true; //a volatile variable int someValue1 = sharedObject.nonVolatile4; int someValue2 = sharedObject.nonVolatile5; int someValue3 = sharedObject.nonVolatile6; JVM可能会重新排序前3条指令，只要它们都先发生于volatile写指令（它们都必须在volatile写指令之前执行）。\n同样的，JVM可能会重新排序最后3条指令，只要volatile写指令先行发生于它们，这3条指令都不能被重新排序到volatile指令的前面。\n这就是volatile先行发生原则的基本含义。\nVolatile并不是万能的 尽管volatile关键字确保了所有对于volatile变量的读操作都是直接从主内存中读取的，所有对于volatile变量的写操作都是直接写入主内存的，但仍有一些情况只定义一个volatile变量是不够的。\n在前面的场景中，线程1对共享变量counter写入操作，声明counter变量为volatile之后就能够确保线程2总是可以看见最新的写入值。\n事实上，如果写入该变量的值不依赖于它前面的值，多个线程甚至可以在写入一个共享的volatile变量时仍然能够持有在主内存中存储的正确值。换句话解释为，如果一个线程在写入volatile共享变量时，不需要先读取该变量的值以计算下一个值。\n一旦一个线程需要首先读取一个volatile变量的值，然后基于该值产生volatile共享变量的下一个值，那么该 volatile 变量将不再能够完全确保正确的可见性。在读取volatile变量和写入它的新值这个很短的时间间隔内，产生了一个 竞争条件 :多个线程可能会读取 volatile变量的相同值，然后产生新值并写入主内存，这样将会覆盖互相的值。\n这种多个线程同时增加相同计数器的场景正是volatile变量不适用的地方，接下来的部分进行了更详细的解释。\n假设线程1读取一个值为0的共享变量counter到它的CPU缓存中，将它加1但是并没有将增加后的值写入主内存中。线程2可能会从主内存中读取同一个counter变量，其值仍然为0，同样不将其写入主内存中，就如下面的图片所展示的那样：\n线程1和线程2现在都没有同步，共享变量counter的真实值应该是2，但是在每个线程的CPU缓存中，其值都为1，并且主内存中的值仍然是0。它成了一个烂摊子，即使这些线程终于它们对共享变量counter的计算值写入到主内存中，counter的值仍然是错的。\nVolatile的适用场景 就如在前面提到的那样，如果两个线程同时对一个共享变量进行读和写，那么仅用volatile变量是不够的。在这种情况下，你需要使用 synchronized来确保关于该变量的读和写都是原子操作。读或写一个volatile变量时并不会阻塞其它线程对该变量的读和写。在这种情况下必须用synchronzied关键字来修饰你的关键代码。\n除了使用synchronzied之外，你也可以使用 java.util.concurrent包中的一些原子数据类型，如 AtomicLong ， AtomicReference等。\n当只有一个线程对一个volatile变量进行读写而其它线程只读取该变量时， volatile可以确保这些读线程读取到的是该变量的最新写入值。如果不声明该变量为volatile ，则不能这些读线程保证读取的是最新写入值。\nvolatile关键字适用于32位变量和64位变量。\nVolatile性能思考 由于volatile变量的读和写都是直接从主内存中进行的，相对于CPU缓存，直接对主内存进行读写代价更高， 访问一个volatile变量也会阻止指令重新排序，而指令排序也是一个常用的性能增强技术。因此，你应该在只有当你确实需要确保变量可见性的时候才使用volatile变量。\n\u0026lt;\u0026ndash;终于翻译完了!\u0026ndash;\u0026gt;\n","date":"2016-03-07T18:03:18+08:00","permalink":"https://lucumt.info/post/translate/java-concurrency/java-volatile-keyword/","tags":["Java","Java Concurrency"],"title":"[译] Java Volatile 关键字详解"},{"categories":["Java编程","数据库"],"contents":"项目中用到了MySQL数据库的备份功能，通过调用Java程序中的Runtime来执行mysqldump命令自动的生成相关的MySQL数据库文件以供恢复之用。相关的代码如下:\nRuntime runtime = Runtime.getRuntime(); String mysqlCmd = \u0026#34;mysqldump\u0026#34; \u0026#43; \u0026#34; -u\u0026#34; \u0026#43; username \u0026#43; \u0026#34; -p\u0026#34; \u0026#43; password \u0026#43; \u0026#34; -h \u0026#34; \u0026#43; databaseAddress \u0026#43; \u0026#34; \u0026#34; \u0026#43;databaseName; Process process = runtime.exec(mysqlCmd); 但是在客户那里实际使用时，有时候会出现在cmd中MySQL命令可以正常识别但是程序不能正常执行的情况，报错信息如下:\njava.io.IOException: Cannot run program \u0026#34;mysqldump\u0026#34;: CreateProcess error=2, The system cannot find the file specified at java.lang.ProcessBuilder.start(ProcessBuilder.java:460) at java.lang.Runtime.exec(Runtime.java:593) at java.lang.Runtime.exec(Runtime.java:431) at java.lang.Runtime.exec(Runtime.java:328) Google之后，在Stackoverflow发现两个相关的问题：\nError when backing up MYSQL database backup mysql database java code 阅读之后，发现上面说问题产生的原因是mysqldump命令无法识别，把mysqldump可执行文件的路径加入PATH环境变量中即可解决问题。但当我在cmd中无论执行mysql或mysqldump命令时，都显示这两个命令可以正常执行：\n在cmd中输出PATH环境变量时，也显示MySQL的bin目录已经添加:\n即使重启电脑，上述通过Java备份MySQL的代码还是不能正常执行，但当在cmd中执行mysql、mysqldump命令或输出PATH环境变量时，结果任何上面图片中显示的一致。\n这下让我感到很困惑:\n通过Java代码来执行mysqldump导出操作时去不能正常执行原因是MySQL的执行路径没有加到PATH环境变量中,但实际检查发现MySQL的环境变量设置正常，在命令行通过mysqldump导出sql文件可以成功操作!\n继续在网上搜索该问题的解决方案，得到的答案也都是MySQL的执行路径没有加到PATH环境变量中去，问题依旧。。。\n正当我在为这个问题发愁时，测试部门有个同事的新Win7电脑上利用我们的软件执行MySQL备份时也出现了类似的问题，之前我还猜有可能是由于客户服务器的操作系统版本太低或某些DLL文件不存在导致的。但现在居然在刚装好的Win7电脑上也出现此问题，基本可以排除操作系统的问题。\n由于在我自己的笔记本和台式研发机上都没出现这个问题，无奈之下我只好把同事的电脑拿过来和我自己的电脑进行对比，看看哪里设置不一样。通过Win7中高级系统设置查看PATH环境变量，很快就发现了问题的根源：\nMySQL的执行路径被设置到了用户变量中的PATH变量里，系统变量中的PATH变量里却没有MySQL的执行路径，而Java代码是匿名执行的，无法获取到用户变量，只能去系统变量中寻找相关的可执行命令,因而程序会出错！\n这下问题原因变得很清楚了，我们在cmd中执行mysql和mysqldump命令以及输出PATH环境变量时，系统会把当前用户的用户变量中的PATH和操作系统的系统变量中的PATH变量整合到一块，所以我们在cmd中操作时一切正常。但是当我们在Java程序中执行mysqldump命令时，由于Java程序的运行和用户无关，无法获取到用户变量中的PATH值，所以当我们在Java程序中执行mysqldump命令时会出错。这也正好和Stackoverflow中说明的原因一致。\n由于有的电脑上会出现此问题，有的电脑上没有此问题，进一步的深究问题的根源，发现发生问题的电脑和服务器在安装MySQL数据库时都是通过我们自己写的bat脚本来安装的。而bat脚本中设置环境变量的代码如下:\n@echo %Path% setx PATH \u0026#34;%Path%;C:\\INTA\\Database\\bin;\u0026#34; @echo %Path% 问题的关键就在于setx PATH \u0026quot;%Path%;C:\\INTA\\Database\\bin;\u0026quot;这行代码，这样写的话只会把MySQL的执行路径加入到当前执行该脚本的用户变量中，不会加入到环境变量中。而那些没有出问题的电脑都是我自己手动在系统变量中设置MySQL执行路径的！该问题的解决方法也很简单，在setx后面加上-m即可，这样bat脚本执行时会把MySQL的执行路径写入系统变量的PATH变量中，不会写入用户变量的PATH变量中：\n@echo %Path% setx -m PATH \u0026#34;%Path%;C:\\INTA\\Database\\bin;\u0026#34; @echo %Path% Orz~\n想不到由于一个-m而让自己郁闷了这么久!\n","date":"2016-03-03T14:33:43+08:00","permalink":"https://lucumt.info/post/mysql/can-not-run-program-mysqldump/","tags":["MySQL","Java"],"title":"Windows中由于系统权限不同导致的mysqldump不生效的原因分析"},{"categories":["Go编程","个人博客"],"contents":"一直以来都想拥有一个属于自己的博客，前段时间在学习Go ，于是利用Hugo 和Github Pages 搭建了一个简易的个人博客，先简单记录下。\n环境准备 Go1.18.3+ Hugov0.100+ Github账号 GoDaddy域名 过程概要 在Github上创建一个自己的项目 在Github上创建一个项目，本文中该项目名为blog\n由于Github Pages强制要求在托管博客时该项目必须有一个名为gh-pages的分支，所以要预先给该项目创建一个名为gh-pages的分支 在Github中打开blog项目主页面，点击 Settings按钮\n在 Github Pages这个区域可以看见本项目的发布链接为https://fox321.github.io/blog/ ，点击该链接可以访问该项目对应的静态页面\n利用Hugo作为博客生成器 由于Github Pages只支持静态的HTML页面托管，所以需要采用Jekyll 、Logdown 等静态博客生成器来快速生成HTML页面，避免纯手动编写时的费时费力。由于自己近期一直在学习Go，为了加深自己对于Go的运用，于是便选择 Hugo作为自己的博客生成器。 Hugo是一个基于Go开发的静态生成器，它采用Markdown语法来编写博客生成，然后生成相应的HTML页面。\n安装Go 访问Golang下载页根据自己电脑的操作系统选择是Linux版本或Windows版本，同时注意是选择32位还是64位，一定要与自己的操作系统相匹配。以我自己的64位win7系统为例，安装过程如下：\n下载Go安装文件\n双击安装，默认是安装在C盘下，由于windows操作系统的特性，我通常不倾向于安装在C盘，故需要设置PATH、GOPATH和GOROOT这三个环境变量，我自己把Go安装在D:\\code\\go下，这三个变量相应的设置为:\nPATH=\u0026#39;D:\\code\\go\\bin\u0026#39;;%PATH% GOPATH=\u0026#39;D:\\code\\gopath\u0026#39; GOROOT=\u0026#39;D:\\code\\go\u0026#39;、 安装完成之后，重新打开cmd窗口，输入go version之后按Enter键，若出现如下信息，则表示Go安装成功\nC:\\Users\\Administrator\u0026gt;go version go version go1.18.3 windows/amd64 安装Hugo Hugo的安装过程与Go的类似.\n首先在Hugo下载页根据自己操作系统的类型和位数下载相应的安装包，然后设置对应的PATH环境变量即可。我的安装在 D:\\program\\hugo所以相应的环境变量设置为\nPATH=\u0026#39;D:\\program\\hugo\u0026#39;;%PATH% 重新打开cmd窗口，输入hugo version，若出现如下信息，则表示 Hugo安装成功\nC:\\Users\\Administrator\u0026gt;hugo version hugo v0.100.2-d25cb2943fd94ecf781412aeff9682d5dc62e284\u0026#43;extended windows/amd64 BuildDate=2022-06-08T10:25:57Z VendorInfo=gohugoio 关于Hugo的基本操作命令，可以参见Hugo快速入门，此处不再详述。\n在Github Pages上托管Hugo 安装命令 虽然官方文档在Github Pages上托管Hugo上有相应的说明,个人总感觉其说明信息不够详细，故将自己的实现过程记录如下：\n将之前在Github上创建的blog项目clone到本地目录\n切换到blog目录并利用hugo new site命令创建一个名为person_blog的Hugo站点，然后将其内容移入到blog目录下并删除 person_blog目录\n利用hugo new命令创建一个md文件用于存储我们的第一篇博客\n在 blog 目录下创建一个名为themes的文件夹用于存储Hugo样式，并将自己选中的样式下载到本地\n输入hugo server --theme=hugo-redlounge --buildDrafts在本地启动Hugo，启动正常后命令行输出如下\n此时在浏览器中输入http://127.0.0.1:1313会看到如下输出，该页面意味着本地博客创建成功，接下来要将其上传到Github Pages中托管 我们需要将相关的链接地址修改为https://fox321.github.io/blog，同时将端口号去掉，相关的命令为 hugo server -D --theme=hugo-redlounge --baseUrl=\u0026quot;https://fox321.github.io/blog\u0026quot; --appendPort=false，运行截图如下 修改完链接地址之后，需要将生成的页面提交到Github中才能被访问，首先需要将页面提交到master，由于我是在Windows操作系统上进行的，而CMD对Git的支持不是很好，故从此步开始切换为在Git Bash进行相关操作 利用subtree命令将master中public目录下的内容同步到gh-pages目录下\n此时访问该项目的设置页面，在Github Pages部分会看见如下信息\n访问 https://fox321.github.io/blog ，出现如下页面，至此Hugo博客托管到Github Pages成功！\n相关命令 生成绑定到指定域名的页面\nhugo server -D --baseUrl=\u0026#34;http://lucumt.info\u0026#34; --appendPort=false 新版本的命令\nhugo server --baseUrl=\u0026#34;https://lucumt.info/\u0026#34; --watch=false \\ --appendPort=false --renderToDisk --environment production 将 master的public目录同步到分支\ngit subtree push --prefix=public git@github.com:fox321/blog.git gh-pages 利用GoDaddy配置自定义域名 在Using a custom domain with GitHub Pages中有详细的说明，我自己配置的时候主要是按照Setting up an apex domain中的说明在GoDaddy上的说明来设置的。\n在public目录下创建一个名为 CNAME的文件，并在该文件中写入我们要自定义的域名，我自己的域名为 http://lucumt.info ，故填入lucumt.info\n登陆Godaddy，然后在页面右上角点击自己的用户名，出现如下图所示的页面，选择Manage My Domains\n选择完Manage My Domains之后会出现如下图所示的界面，选择Manage DNS\n选择完Manage DNS之后会出现如下图所示的界面，点击Add按钮会出现下拉框让我们增加A记录\n在Type部分选择 A ，Host部分选择 @， Poinst to根据Setting up an apex domain中的说明在GoDaddy中Configuring A records with your DNS provider部分的说明添加 192.30.252.153 ,点击Save即完成一条A记录的添加\n再次点击Add添加，按照步骤5添加第二条A记录，除了Points to设置为 192.30.252.154 之外，其它的配置都相同 在Github项目中点击Settings按钮查看Github Pages区域的设置信息，若出现类似如下图所示的设置信息，则表示我们自定义域名添加成功\n至此利用GoDaddy来配置自自定义域名的过程完成，输入 http://lucumt.info 即可访问自己的博客！\nPS:吐槽下让人觉得不爽的几个地方：\n域名续费几乎没有折扣，所以建议第一次买的时间长一点。 取消订单功能消失了，现在只能打人工客服电话取消。 如果大家有GoDaddy之外更好的域名服务网站，欢迎给我留言，当然国内的域名服务商除外！\n开启自定义域名的HTTPS访问 请参见本人写的另外一篇文章 将基于Github Pages的自定义域名博客迁移到Https ，此处不再详述。\n\u0026lt;\u0026ndash;待续\u0026ndash;\u0026gt;\n","date":"2016-02-27T22:23:37+08:00","permalink":"https://lucumt.info/post/hugo/create-website-with-hugo/","tags":["Go","Hugo","Github Pages","Github"],"title":"利用Github Pages和基于Go的Hugo搭建个人博客"}]